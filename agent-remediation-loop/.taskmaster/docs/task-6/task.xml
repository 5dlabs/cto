<prompt>
    <role>You are a senior distributed systems engineer specializing in Kubernetes, concurrency control, and high-availability system design.</role>
    <task>
        <id>6</id>
        <title>Implement Agent Cancellation System</title>
        <description>Enhance existing agent cancellation system to handle concurrent operations and improve race condition handling when Rex pushes remediation fixes</description>
        <priority>high</priority>
        <status>pending</status>
        <dependencies>1, 3, 4</dependencies>
    </task>
    <technical_specifications>
        <spec>Enhance existing implementation-agent-remediation sensor with advanced filtering and state validation</spec>
        <spec>Implement distributed locking using Kubernetes coordination/v1 API with lease-based concurrency control</spec>
        <spec>Build state-aware cancellation logic integrating with Task 4's StateManager for consistency</spec>
        <spec>Create atomic label transitions using GitHub API ETag-based optimistic concurrency control</spec>
        <spec>Develop concurrent cancellation coordinator with ConfigMap-based queue management</spec>
        <spec>Implement advanced recovery system with 30-second reconciliation loop and automatic repair</spec>
        <spec>Support 20+ concurrent cancellation operations with sub-30-second completion times</spec>
        <spec>Build comprehensive stress testing suite validating concurrency and failure scenarios</spec>
        <spec>Integrate circuit breaker pattern preventing cascading failures across operations</spec>
        <spec>Maintain backward compatibility with existing sensor and workflow functionality</spec>
    </technical_specifications>
    <implementation_details>
        Enhance the existing agent cancellation system with advanced concurrency control and state management:

        1. Enhance existing Rex push event sensor (implementation-agent-remediation):
           - Add advanced filtering for concurrent push event detection
           - Implement state validation before triggering cancellation operations
           - Enhanced error handling for webhook processing with retry logic
           - Generate correlation IDs for operation tracking and debugging
           - Configure improved resource limits and reliability features
           - Maintain backward compatibility with current functionality

        2. Implement distributed locking system using Kubernetes coordination API:
           - Create DistributedLock struct using k8s.io/client-go coordination/v1
           - Implement lease acquisition with automatic renewal and timeout
           - Add exponential backoff for lock contention and deadlock prevention
           - Create namespace isolation per task-id preventing cross-task conflicts
           - Implement lease expiration detection and automatic cleanup
           - Ensure proper lock release on process restart or crash scenarios

        3. Build state-aware cancellation logic:
           - Create StateAwareCancellation struct integrating with Task 4's StateManager
           - Query state ConfigMap before cancellation to verify current status
           - Implement agent completion verification preventing unnecessary operations
           - Add graceful termination with SIGTERM before SIGKILL force deletion
           - Implement deletion confirmation via status polling and verification
           - Update remediation state after successful cancellation operations

        4. Implement atomic GitHub label transitions:
           - Create AtomicLabelManager using GitHub API with authentication
           - Use ETag headers for optimistic concurrency control
           - Implement compare-and-swap operations for atomic label updates
           - Add retry logic with exponential backoff for conflict resolution
           - Batch label operations reducing API calls and improving atomicity
           - Add comprehensive validation before and after operations

        5. Build concurrent cancellation coordinator:
           - Create CancellationCoordinator managing multiple simultaneous operations
           - Implement ConfigMap-based coordination store for active tracking
           - Add duplicate request prevention and priority queue management
           - Implement circuit breaker pattern preventing cascading failures
           - Provide status API for monitoring and debugging operations
           - Add comprehensive metrics collection for success/failure rates

        6. Implement advanced recovery system:
           - Create RecoveryManager with automated inconsistency detection
           - Implement automatic rollback for failed multi-step operations
           - Add manual intervention triggers for unrecoverable states
           - Build reconciliation loop running every 30 seconds
           - Implement cleanup for orphaned locks and resources
           - Add comprehensive observability and alerting integration

        7. Create comprehensive testing framework:
           - Build stress tests simulating 20+ concurrent Rex pushes
           - Test with network delays, failures, and various load patterns
           - Verify state consistency after chaos testing scenarios
           - Test lock contention and timeout handling
           - Measure performance under sustained high load
           - Validate integration with all existing workflow components

        The system must handle high concurrency while maintaining data consistency and providing robust recovery from partial failures.
    </implementation_details>
    <acceptance_criteria>
        <criterion>Enhanced sensor processes concurrent Rex push events without race conditions</criterion>
        <criterion>Distributed locking prevents conflicts in high-load scenarios using Kubernetes leases</criterion>
        <criterion>State-aware cancellation integrates seamlessly with Task 4's StateManager</criterion>
        <criterion>Atomic label transitions handle concurrent GitHub API modifications</criterion>
        <criterion>Cancellation coordinator manages 20+ simultaneous operations efficiently</criterion>
        <criterion>Recovery system detects and repairs partial failures automatically</criterion>
        <criterion>Circuit breaker prevents cascading failures across operations</criterion>
        <criterion>All cancellation operations complete within 30 seconds maximum</criterion>
        <criterion>Lock acquisition completes within 5 seconds average latency</criterion>
        <criterion>System maintains state consistency across all distributed operations</criterion>
        <criterion>Comprehensive stress tests validate performance under concurrent load</criterion>
        <criterion>No memory leaks or resource orphaning under sustained operation</criterion>
        <criterion>Integration maintains backward compatibility with existing workflow</criterion>
        <criterion>Monitoring provides comprehensive visibility into all operations</criterion>
        <criterion>Recovery reconciliation loop maintains system consistency</criterion>
    </acceptance_criteria>
    <test_strategy>
        1. Concurrency Testing:
           - Simulate 20+ simultaneous Rex push events with realistic timing
           - Test lock contention scenarios with various timeout configurations
           - Verify state consistency under concurrent modification attempts
           - Test atomic operations with high contention rates
           - Validate no race conditions in distributed locking implementation

        2. Failure Scenario Testing:
           - Test network partitions between Kubernetes API and components
           - Simulate GitHub API failures and rate limiting scenarios
           - Test partial operation failures and rollback mechanisms
           - Verify recovery from corrupted state ConfigMaps
           - Test circuit breaker activation and recovery patterns

        3. Performance Testing:
           - Benchmark lock acquisition latency under various loads
           - Measure cancellation throughput with concurrent operations
           - Profile memory usage during sustained high load
           - Test API call efficiency and optimization
           - Validate recovery system performance impact

        4. Integration Testing:
           - Test end-to-end workflow with enhanced cancellation system
           - Verify integration with Task 4's state management
           - Test backward compatibility with existing sensors
           - Validate GitHub webhook processing enhancements
           - Test monitoring and alerting integration

        5. Stress Testing:
           - Sustained load testing with 50+ active tasks
           - Burst load testing with 5x normal traffic patterns
           - Chaos testing with random component failures
           - Long-running tests validating resource cleanup
           - Recovery system effectiveness under high load

        6. Security Testing:
           - Validate RBAC permissions for enhanced operations
           - Test GitHub token handling and scoping
           - Verify input validation and sanitization
           - Test audit logging and security monitoring
           - Validate resource isolation and access controls
    </test_strategy>
    <instructions>
        Begin by thoroughly understanding the existing implementation-agent-remediation sensor and its current capabilities. Study the codebase to identify enhancement points without breaking existing functionality.

        Design the distributed locking system carefully, paying special attention to lease timeout scenarios and proper cleanup. Test lock contention thoroughly with realistic concurrent loads.

        Integrate with Task 4's state management system ensuring consistency across all operations. Design state transitions carefully to prevent partial updates and inconsistent states.

        Implement GitHub API integration with proper concurrency control. Use ETags effectively and handle all possible conflict scenarios. Test rate limiting and retry logic extensively.

        Build the coordination system with scalability in mind. Design queue management and status tracking to handle high loads efficiently while maintaining visibility into operations.

        Create a robust recovery system that can detect and repair various inconsistency patterns. Design the reconciliation loop to be efficient and non-disruptive to normal operations.

        Implement comprehensive testing that covers all concurrency scenarios and failure modes. Pay special attention to edge cases and race conditions that only appear under high load.

        Focus on observability throughout the implementation. Ensure all operations are properly logged, metriced, and traceable for debugging and monitoring.

        Design for operational excellence with clear error messages, comprehensive monitoring, and automated recovery wherever possible.

        Test thoroughly in realistic environments before deployment. Validate performance requirements and ensure the system degrades gracefully under extreme load.
    </instructions>
</prompt>