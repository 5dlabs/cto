# Codex CLI Configuration
# Reference: https://developers.openai.com/codex/local-config#cli
# Generated by CTO controller

# Model configuration
model = "{{model}}"
{{#if temperature}}
temperature = {{temperature}}
{{/if}}
{{#if max_output_tokens}}
model_max_output_tokens = {{max_output_tokens}}
{{/if}}
{{#if model_reasoning_effort}}
model_reasoning_effort = "{{model_reasoning_effort}}"
{{/if}}

# Automation settings
# approval_policy: untrusted | on-failure | on-request | never
approval_policy = "{{#if approval_policy}}{{approval_policy}}{{else}}on-failure{{/if}}"

# sandbox_mode: read-only | workspace-write | danger-full-access
sandbox_mode = "{{#if sandbox_mode}}{{sandbox_mode}}{{else}}workspace-write{{/if}}"

# Project documentation limits
project_doc_max_bytes = {{#if project_doc_max_bytes}}{{project_doc_max_bytes}}{{else}}32768{{/if}}

{{#if tools.tools}}
# Tools MCP server for remote tools
[mcp_servers.tools]
command = "tools"
args = [
  "--url",
  "{{tools.url}}",
  "--working-dir",
  "/workspace"
]
env = { "TOOLS_SERVER_URL" = "{{tools.url}}" }
startup_timeout_sec = 30
tool_timeout_sec = 120
# Tool filtering: only expose the tools configured for this agent
available_tools = [
  {{#each tools.tools}}
  "{{this}}"{{#unless @last}},{{/unless}}
  {{/each}}
]
{{/if}}

{{#if model_provider}}
[model_providers.openai]
name = "{{model_provider.name}}"
base_url = "{{model_provider.base_url}}"
env_key = "{{model_provider.env_key}}"
wire_api = "{{model_provider.wire_api}}"
{{#if model_provider.request_max_retries}}
request_max_retries = {{model_provider.request_max_retries}}
{{/if}}
{{#if model_provider.stream_max_retries}}
stream_max_retries = {{model_provider.stream_max_retries}}
{{/if}}
{{/if}}

{{#if telemetry.enabled}}
# OpenTelemetry configuration for observability
[otel]
environment = "production"
log_user_prompt = false

[otel.exporter.otlp-grpc]
endpoint = "{{telemetry.otlpEndpoint}}"
{{/if}}

{{#if raw_additional_toml}}
{{{raw_additional_toml}}}
{{/if}}

