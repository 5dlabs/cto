#!/bin/sh
# Factory Heal Remediation - Rex
# Executes remediation tasks identified by the heal monitoring system
# Spawned via CodeRun CRD when heal detects issues requiring intervention
#
# IMPORTANT: This template does NOT use the docs workflow.
# Issue context comes from heal-generated files on the shared PVC.
# Completion is verified against acceptance criteria with retry loop.

set -e

echo '‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'
echo '‚ïë            REX HEAL REMEDIATION (FACTORY) STARTING           ‚ïë'
echo '‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'

# ============================================================================
# DOCKER SIDECAR MANAGEMENT
# ============================================================================
{{#if enable_docker}}
# Docker is enabled - wait for daemon and set up cleanup

wait_for_docker() {
  echo "üê≥ Waiting for Docker daemon..."
  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15; do
    if docker info >/dev/null 2>&1; then
      echo "‚úÖ Docker daemon ready"
      return 0
    fi
    echo "   Waiting... ($i/15)"
    sleep 2
  done
  echo "‚ö†Ô∏è Docker daemon not available after 30s (continuing anyway)"
  return 1
}

stop_docker_sidecar() {
  if [ ! -S /var/run/docker.sock ]; then
    return
  fi

  echo "üõë Stopping Docker sidecar"

  if command -v pkill >/dev/null 2>&1; then
    pkill dockerd >/dev/null 2>&1 || true
    sleep 1
    if pidof dockerd >/dev/null 2>&1; then
      pkill -9 dockerd >/dev/null 2>&1 || true
    fi
    if pidof docker-init >/dev/null 2>&1; then
      pkill docker-init >/dev/null 2>&1 || true
    fi
  elif command -v killall >/dev/null 2>&1; then
    killall dockerd >/dev/null 2>&1 || true
  else
    PID=$(pidof dockerd 2>/dev/null || true)
    if [ -n "$PID" ]; then
      kill "$PID" >/dev/null 2>&1 || true
    fi
    PID_INIT=$(pidof docker-init 2>/dev/null || true)
    if [ -n "$PID_INIT" ]; then
      kill "$PID_INIT" >/dev/null 2>&1 || true
    fi
  fi

  for _ in 1 2 3 4 5; do
    if ! pidof dockerd >/dev/null 2>&1 && ! pidof docker-init >/dev/null 2>&1; then
      echo "‚úÖ Docker sidecar stopped"
      return
    fi
    sleep 1
  done

  REMAINING_DOCKER=$(pidof dockerd 2>/dev/null || true)
  REMAINING_INIT=$(pidof docker-init 2>/dev/null || true)
  echo "‚ö†Ô∏è Docker sidecar still running (dockerd: ${REMAINING_DOCKER:-none}, docker-init: ${REMAINING_INIT:-none})"
}

# Set up EXIT trap to ensure Docker sidecar cleanup
trap 'stop_docker_sidecar || true' EXIT

# Wait for Docker daemon to be ready
wait_for_docker || true
echo "üê≥ Docker enabled: You can use 'docker pull', 'docker run', etc. for image debugging"
{{else}}
echo "üê≥ Docker disabled: Set enableDocker: true in heal-config.json to enable image debugging"
{{/if}}
echo "üéØ Agent: {{github_app}}"
echo "üìã Task ID: {{task_id}}"
echo "üîß Alert Type: ${ALERT_TYPE:-unknown}"
echo "üìÇ Repository: {{repository_url}}"
echo "üå≥ CodeRun: ${CODERUN_NAME:-unknown}"
if [ -n "${HEAL_ISSUE_NUMBER}" ]; then
    echo "üîó GitHub Issue: #${HEAL_ISSUE_NUMBER}"
fi

# ============================================================================
# CONFIGURATION
# ============================================================================
# No max iterations - iterate until acceptance criteria met
COMPLETION_TIMEOUT=${HEAL_COMPLETION_TIMEOUT:-60}

# Derive repo name and path from repository URL
REPO_NAME=$(basename "{{repository_url}}" .git | tr '/' '-')
REPO_PATH="/workspace/${REPO_NAME}"
export REPO_PATH

# Export worktree path for agent instructions
export WORKTREE_PATH="/workspace/worktrees/${CODERUN_NAME}"
echo "üìÅ Worktree: ${WORKTREE_PATH}"

# Create worktrees directory if needed
mkdir -p /workspace/worktrees

# ============================================================================
# WORKSPACE CLEANUP (PVC persists between runs)
# ============================================================================
echo ""
echo "‚ïê‚ïê‚ïê WORKSPACE CLEANUP ‚ïê‚ïê‚ïê"

# Configure git safe.directory to avoid "dubious ownership" errors on shared PVC
# This is needed because the PVC may have been created by a different user/pod
git config --global --add safe.directory '*' 2>/dev/null || true
echo "‚úì Git safe.directory configured"

# Clean up stale worktrees from previous runs
if [ -d "/workspace/worktrees" ]; then
    echo "üßπ Cleaning stale worktrees..."
    WORKTREE_COUNT=$(find /workspace/worktrees -maxdepth 1 -type d 2>/dev/null | wc -l)
    if [ "$WORKTREE_COUNT" -gt 1 ]; then
        # Remove worktrees older than 24 hours (exclude current)
        find /workspace/worktrees -maxdepth 1 -type d -mmin +1440 -not -name "$(basename ${WORKTREE_PATH})" 2>/dev/null | while read -r old_wt; do
            if [ -d "$old_wt" ] && [ "$old_wt" != "/workspace/worktrees" ]; then
                echo "   Removing stale worktree: $old_wt"
                rm -rf "$old_wt" 2>/dev/null || true
            fi
        done
    fi
    echo "‚úì Worktree cleanup complete"
fi

# Clean up stale git lock files
find /workspace -name "*.lock" -type f -mmin +30 2>/dev/null | while read -r lockfile; do
    echo "   Removing stale lock: $lockfile"
    rm -f "$lockfile" 2>/dev/null || true
done

# Clean up archived issues older than 7 days
if [ -d "/workspace/archived" ]; then
    echo "üßπ Cleaning old archived issues..."
    find /workspace/archived -maxdepth 1 -type d -mtime +7 2>/dev/null | while read -r old_archive; do
        if [ -d "$old_archive" ] && [ "$old_archive" != "/workspace/archived" ]; then
            echo "   Removing old archive: $old_archive"
            rm -rf "$old_archive" 2>/dev/null || true
        fi
    done
    echo "‚úì Archive cleanup complete"
fi

# ============================================================================
# GIT RETRY LOGIC (handles transient GitHub outages like HTTP 500)
# ============================================================================
# Retry git operations with exponential backoff for transient errors (5xx, network)
# Fails fast on permanent errors (4xx, auth, invalid ref)
git_with_retry() {
    _gwr_max_attempts=5
    _gwr_attempt=1
    _gwr_base_delay=2
    _gwr_max_delay=60
    _gwr_delay=$_gwr_base_delay

    while [ $_gwr_attempt -le $_gwr_max_attempts ]; do
        echo "   git_with_retry: attempt $_gwr_attempt/$_gwr_max_attempts: git $*"

        # Run the git command and capture output
        _gwr_output=$(git "$@" 2>&1) && {
            echo "$_gwr_output"
            return 0
        }

        # Check if this is a transient error (5xx, network issues)
        if echo "$_gwr_output" | grep -qiE "(500|502|503|504|internal server error|connection refused|connection reset|network|timed out|couldn't connect)"; then
            echo "   Transient error detected (attempt $_gwr_attempt/$_gwr_max_attempts)"
            echo "   Error: $_gwr_output"

            if [ $_gwr_attempt -lt $_gwr_max_attempts ]; then
                echo "   Waiting ${_gwr_delay}s before retry..."
                sleep $_gwr_delay
                # Exponential backoff (capped at max_delay)
                _gwr_delay=$((_gwr_delay * 2))
                if [ $_gwr_delay -gt $_gwr_max_delay ]; then
                    _gwr_delay=$_gwr_max_delay
                fi
            fi
        else
            # Permanent error (4xx, auth issues, invalid ref, etc.) - fail fast
            echo "   Permanent error detected, not retrying"
            echo "   Error: $_gwr_output"
            return 1
        fi

        _gwr_attempt=$((_gwr_attempt + 1))
    done

    echo "   All $_gwr_max_attempts attempts failed"
    return 1
}

# ============================================================================
# REPOSITORY PRE-STAGING (Optimization: reset instead of clone)
# ============================================================================
echo ""
echo "‚ïê‚ïê‚ïê REPOSITORY PRE-STAGING ‚ïê‚ïê‚ïê"
echo "üì¶ Repository: {{repository_url}}"
echo "üìÇ Local path: ${REPO_PATH}"

if [ -d "${REPO_PATH}/.git" ]; then
    echo "‚úì Repository exists, syncing with origin/main..."
    cd "${REPO_PATH}"

    # Ensure safe.directory is set for this specific repo
    git config --global --add safe.directory "${REPO_PATH}" 2>/dev/null || true

    # Clean up any stale worktrees registered in git
    git worktree prune 2>/dev/null || true

    # Fetch latest with retry (handles GitHub outages)
    echo "üì• Fetching latest changes..."
    if ! git_with_retry fetch --depth 1 origin main; then
        echo "‚ùå Failed to fetch from origin after retries"
        echo "   This may indicate a persistent network issue or GitHub outage"
        echo "   Check https://www.githubstatus.com/ for service status"
        exit 1
    fi

    # Clean any uncommitted changes and reset to origin/main
    git reset --hard origin/main
    git clean -fd

    echo "‚úì Repository synced to $(git rev-parse --short HEAD)"
else
    echo "üì• Repository not found, cloning (shallow)..."
    # Derive clone URL - append .git only if not already present
    CLONE_URL="{{repository_url}}"
    if ! echo "${CLONE_URL}" | grep -q "\.git$"; then
        CLONE_URL="${CLONE_URL}.git"
    fi
    # Clone with retry (handles GitHub outages)
    if ! git_with_retry clone --depth 1 "${CLONE_URL}" "${REPO_PATH}"; then
        echo "‚ùå Failed to clone repository after retries"
        echo "   This may indicate a persistent network issue or GitHub outage"
        echo "   Check https://www.githubstatus.com/ for service status"
        exit 1
    fi
    cd "${REPO_PATH}"

    # Configure safe.directory for the newly cloned repo
    git config --global --add safe.directory "${REPO_PATH}" 2>/dev/null || true

    echo "‚úì Repository cloned to $(git rev-parse --short HEAD)"
fi

# Ensure worktrees can be created from this repo
git config core.bare false 2>/dev/null || true
echo "‚úì Repository ready at ${REPO_PATH}"

# ============================================================================
# VERIFY HEAL CONTEXT FILES
# ============================================================================
# Note: Heal server mounts PVC at /workspace/watch, but remediation pods mount at /workspace
# So files that heal creates at /workspace/watch/issues/... appear at /workspace/issues/... here
PROMPT_FILE="${HEAL_PROMPT_FILE:-/workspace/issues/issue-${HEAL_ISSUE_NUMBER:-unknown}/prompt.md}"
LOG_FILE="${HEAL_LOG_FILE:-/workspace/logs/${ALERT_TYPE:-A7}-*.log}"

# Determine acceptance file path - handle legacy mode gracefully
if [ -n "${HEAL_ACCEPTANCE_FILE}" ]; then
    ACCEPTANCE_FILE="${HEAL_ACCEPTANCE_FILE}"
    LEGACY_MODE="false"
elif [ -n "${HEAL_ISSUE_DIR}" ]; then
    ACCEPTANCE_FILE="${HEAL_ISSUE_DIR}/acceptance-criteria.md"
    LEGACY_MODE="false"
elif [ -n "${HEAL_ISSUE_NUMBER}" ]; then
    ACCEPTANCE_FILE="/workspace/issues/issue-${HEAL_ISSUE_NUMBER}/acceptance-criteria.md"
    LEGACY_MODE="false"
else
    # Legacy mode - no issue number, acceptance criteria may not exist
    ACCEPTANCE_FILE=""
    LEGACY_MODE="true"
fi

echo ""
echo "‚ïê‚ïê‚ïê HEAL CONTEXT FILES ‚ïê‚ïê‚ïê"
echo "üìÑ Prompt file: ${PROMPT_FILE}"
echo "üìã Log pattern: ${LOG_FILE}"
if [ "${LEGACY_MODE}" = "true" ]; then
    echo "‚ö†Ô∏è  Legacy mode: No acceptance criteria (--issue-file used instead of --issue-number)"
else
    echo "‚úÖ Acceptance: ${ACCEPTANCE_FILE}"
fi

if [ -f "${PROMPT_FILE}" ]; then
    echo "   ‚úì Prompt file exists"
else
    echo "   ‚ö†Ô∏è  Prompt file not found at ${PROMPT_FILE}"
    echo "   Checking /workspace/issues/..."
    ls -la /workspace/issues/ 2>/dev/null || echo "   No issues directory"
    echo "   Checking /workspace/alerts/..."
    ls -la /workspace/alerts/ 2>/dev/null || echo "   No alerts directory"
fi

# Find latest matching log file (|| true prevents glob expansion errors)
LATEST_LOG=$(ls -t ${LOG_FILE} 2>/dev/null | head -1 || true)
if [ -n "${LATEST_LOG}" ]; then
    echo "   ‚úì Log file: ${LATEST_LOG}"
    export HEAL_LOG_FILE="${LATEST_LOG}"
else
    echo "   ‚ö†Ô∏è  No log files matching ${LOG_FILE}"
fi

if [ -f "${ACCEPTANCE_FILE}" ]; then
    echo "   ‚úì Acceptance criteria exists"
else
    echo "   ‚ö†Ô∏è  No acceptance criteria at ${ACCEPTANCE_FILE}"
fi

# Source common utilities if available
if [ -f /workspace/scripts/lib/common.sh ]; then
    . /workspace/scripts/lib/common.sh
fi

# Load agent prompt
AGENT_PROMPT="/task-files/CLAUDE.md"
if [ ! -f "${AGENT_PROMPT}" ]; then
    echo "‚ùå Agent prompt not found at ${AGENT_PROMPT}"
    exit 1
fi
echo "‚úÖ Agent prompt file exists: ${AGENT_PROMPT}"

# ============================================================================
# MCP TOOLS VALIDATION
# ============================================================================
echo ""
echo "‚ïê‚ïê‚ïê MCP TOOLS VALIDATION ‚ïê‚ïê‚ïê"
echo "üîç Checking MCP tools..."

if command -v droid >/dev/null 2>&1; then
    TOOL_LIST=$(droid exec --list-tools 2>&1 || echo "FAILED")
    
    if [ "$TOOL_LIST" != "FAILED" ] && echo "$TOOL_LIST" | grep -q "mcp_tools\|github\|kubernetes"; then
        TOOL_COUNT=$(echo "$TOOL_LIST" | wc -l)
        echo "‚úÖ MCP tools available: ~${TOOL_COUNT} tools"
        echo ""
        echo "üìã Sample tools:"
        echo "$TOOL_LIST" | grep -E "github|kubernetes|argocd|cto" | head -10 || echo "   (showing first 10 matching tools)"
    else
        echo "‚ö†Ô∏è  No MCP tools found (proceeding anyway)"
        echo "   Output: $(echo "$TOOL_LIST" | head -5)"
    fi
else
    echo "‚ö†Ô∏è  Droid CLI not found - MCP validation skipped"
fi

# List configured remote tools from heal config
echo ""
echo "üìã Configured remote tools (from heal-config):"
echo "   - mcp_tools_github_*"
echo "   - mcp_tools_kubernetes_*"
echo "   - mcp_tools_argocd_*"
echo "   - mcp_tools_cto_*"
echo "   - mcp_tools_context7_*"
echo "   - mcp_tools_firecrawl_*"
echo "   - mcp_tools_grafana_*"

# ============================================================================
# COMPLETION PROBE LOOP
# ============================================================================
ATTEMPT=1
SUCCESS=0
COMPLETION_LAST_MESSAGE="/tmp/heal-completion-last.txt"
COMPLETION_LOG="/tmp/heal-completion.log"

echo ""
echo "‚ïê‚ïê‚ïê STARTING REMEDIATION (iterating until acceptance criteria met) ‚ïê‚ïê‚ïê"

while [ $SUCCESS -eq 0 ]; do
    echo ""
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo "‚ïë ITERATION ${ATTEMPT}                                                ‚ïë"
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

    # Build the prompt content for this iteration
    PROMPT_CONTENT=$(cat "${AGENT_PROMPT}")

    # Add iteration context if not first attempt
    if [ $ATTEMPT -gt 1 ] && [ -f "${COMPLETION_LAST_MESSAGE}" ]; then
        LAST_REASON=$(cat "${COMPLETION_LAST_MESSAGE}" 2>/dev/null || echo "")
        if [ -n "${LAST_REASON}" ]; then
            PROMPT_CONTENT="${PROMPT_CONTENT}

üîÅ **ITERATION ${ATTEMPT} - Previous attempt incomplete**

The previous completion probe indicated these items remain:
${LAST_REASON}

Focus on addressing the above items before re-checking acceptance criteria."
        fi
    fi

    # Run Factory with the remediation prompt
    echo "üöÄ Running Factory remediation agent..."
    set +e
    droid exec \
        --auto high \
        --model "{{model}}" \
        --output-format stream-json \
        "${PROMPT_CONTENT}"
    AGENT_EXIT=$?
    set -e

    echo ""
    echo "üß≠ Agent exited with code: ${AGENT_EXIT}"

    # ========================================================================
    # MERGE CONFLICT & CI CHECK - Handle PR issues before completion probe
    # ========================================================================
    echo ""
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo "‚ïë CHECKING PR STATUS & MERGE CONFLICTS                         ‚ïë"
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

    # Check if we have an open PR
    cd "${WORKTREE_PATH}" 2>/dev/null || cd "${REPO_PATH}" || true
    PR_NUMBER=$(gh pr view --json number -q '.number' 2>/dev/null || echo "")
    
    if [ -n "${PR_NUMBER}" ]; then
        echo "üìã Found PR #${PR_NUMBER}"
        
        # Check for merge conflicts
        MERGEABLE=$(gh pr view ${PR_NUMBER} --json mergeable -q '.mergeable' 2>/dev/null || echo "")
        if [ "${MERGEABLE}" = "CONFLICTING" ]; then
            echo "‚ö†Ô∏è Merge conflict detected - rebasing on main..."
            git_with_retry fetch origin main
            if git rebase origin/main; then
                git push origin HEAD --force-with-lease
                echo "‚úÖ Rebased and pushed successfully"
            else
                echo "‚ùå Rebase failed - conflicts need manual resolution"
                git rebase --abort 2>/dev/null || true
                # Store reason for next iteration
                echo "Merge conflict with main branch - need to resolve conflicts" > "${COMPLETION_LAST_MESSAGE}"
            fi
            sleep 10  # Give GitHub time to process
        fi
        
        # Check CI status and wait if pending
        echo "üîç Checking CI status..."
        CI_ATTEMPTS=0
        MAX_CI_WAIT=20  # Max 20 iterations of 30s = 10 minutes wait
        while [ $CI_ATTEMPTS -lt $MAX_CI_WAIT ]; do
            CI_STATUS=$(gh pr checks ${PR_NUMBER} --json state -q '.[].state' 2>/dev/null | sort -u || echo "")
            
            if echo "${CI_STATUS}" | grep -q "FAILURE"; then
                echo "‚ùå CI failed - agent should fix in next iteration"
                break
            elif echo "${CI_STATUS}" | grep -q "PENDING"; then
                echo "‚è≥ CI still running... (${CI_ATTEMPTS}/${MAX_CI_WAIT})"
                sleep 30
                CI_ATTEMPTS=$((CI_ATTEMPTS + 1))
            else
                echo "‚úÖ CI checks passed or no checks running"
                break
            fi
        done
        
        # Check if already merged
        MERGED=$(gh pr view ${PR_NUMBER} --json merged -q '.merged' 2>/dev/null || echo "false")
        if [ "${MERGED}" = "true" ]; then
            echo "‚úÖ PR already merged!"
        fi
    else
        echo "üìù No PR found yet - agent may create one in next iteration"
    fi

    # ========================================================================
    # COMPLETION PROBE - Check acceptance criteria
    # ========================================================================
    echo ""
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo "‚ïë COMPLETION PROBE - Checking Acceptance Criteria              ‚ïë"
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

    # Build completion probe prompt
    if [ -n "${ACCEPTANCE_FILE}" ] && [ -f "${ACCEPTANCE_FILE}" ]; then
        ACCEPTANCE_CONTENT=$(cat "${ACCEPTANCE_FILE}")
    elif [ "${LEGACY_MODE}" = "true" ]; then
        ACCEPTANCE_CONTENT="**Legacy Mode** - No formal acceptance criteria available.

Use basic health checks:
- [ ] Fix has been deployed (PR merged)
- [ ] ArgoCD sync successful
- [ ] Target pod running without errors
- [ ] No new alerts for this issue type"
    else
        ACCEPTANCE_CONTENT="No acceptance criteria file found at: ${ACCEPTANCE_FILE}

Use basic health checks:
- [ ] Fix has been deployed (PR merged)
- [ ] ArgoCD sync successful
- [ ] Target pod running without errors
- [ ] No new alerts for this issue"
    fi

    COMPLETION_PROMPT="You are a completion probe for a heal remediation task.

## Acceptance Criteria
${ACCEPTANCE_CONTENT}

## Instructions
Review the current state and determine if ALL acceptance criteria are met.

Check:
1. Was a PR created and merged? (use: gh pr list --state merged --search 'fix heal')
2. Did ArgoCD sync successfully? (use: kubectl get application -n argocd)
3. Is the target pod running without errors? (use: kubectl get pods -n cto)
4. Are there any new errors in the logs?

Respond with ONLY:
- **yes** - if ALL criteria are satisfied
- **no** - if ANY criteria are NOT satisfied

If no, add:
REASON: [list the specific criteria that are not met]

Your response:"

    echo "üìã Running completion probe..."
    set +e
    COMPLETION_OUTPUT=$(droid exec --auto high --model "{{model}}" --output-format text "${COMPLETION_PROMPT}" 2>&1 | tee "${COMPLETION_LOG}")
    COMPLETION_EXIT=$?
    set -e

    echo "üß≠ Completion probe response:"
    printf '%s\n' "${COMPLETION_OUTPUT}"

    # Extract yes/no from response (flexible pattern handles leading text, whitespace, or markdown)
    COMPLETION_RESPONSE=$(printf '%s\n' "${COMPLETION_OUTPUT}" | tr -d '\r' | grep -Eio '\*\*(yes|no)\*\*|(^|[[:space:]])(yes|no)([[:space:]]|$)' | sed 's/\*//g; s/^[[:space:]]*//; s/[[:space:]]*$//' | head -n1 | tr '[:upper:]' '[:lower:]')

    if [ "${COMPLETION_RESPONSE}" = "yes" ]; then
        echo ""
        echo "‚úÖ Completion probe confirmed: ALL acceptance criteria met!"
        SUCCESS=1
        break
    elif [ "${COMPLETION_RESPONSE}" = "no" ]; then
        # Extract reason for next iteration
        CURRENT_REASON=$(printf '%s\n' "${COMPLETION_OUTPUT}" | awk 'BEGIN{IGNORECASE=1}/^reason:/{sub(/^reason:[[:space:]]*/,"");flag=1} flag{print}')
        if [ -n "${CURRENT_REASON}" ]; then
            echo ""
            echo "‚ö†Ô∏è Completion probe found incomplete criteria:"
            echo "${CURRENT_REASON}"
            printf '%s\n' "${CURRENT_REASON}" > "${COMPLETION_LAST_MESSAGE}"
        else
            echo "‚ö†Ô∏è Completion probe reported 'no' without specific reason"
            echo "Task incomplete - review acceptance criteria" > "${COMPLETION_LAST_MESSAGE}"
        fi
    else
        echo "‚ö†Ô∏è Could not parse completion probe response: ${COMPLETION_RESPONSE:-<empty>}"
        echo "Treating as incomplete..."
        echo "Unable to verify completion" > "${COMPLETION_LAST_MESSAGE}"
    fi

    ATTEMPT=$((ATTEMPT + 1))
done

# ============================================================================
# FINAL STATUS
# ============================================================================
echo ""
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
if [ $SUCCESS -eq 1 ]; then
    echo "‚ïë ‚úÖ REMEDIATION COMPLETE                                       ‚ïë"
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo "Completed in ${ATTEMPT} attempt(s)"

    # Update and close GitHub issue if we have an issue number
    if [ -n "${HEAL_ISSUE_NUMBER}" ]; then
        echo "üìù Adding completion comment to issue #${HEAL_ISSUE_NUMBER}..."
        gh issue comment "${HEAL_ISSUE_NUMBER}" --repo 5dlabs/cto --body "‚úÖ **Remediation Complete**

All acceptance criteria have been verified:
- PR merged to main
- ArgoCD sync successful
- Target system healthy

Completed by: ${CODERUN_NAME}
Attempts: ${ATTEMPT}" 2>/dev/null || echo "   (could not comment on issue)"

        echo "üîí Closing issue #${HEAL_ISSUE_NUMBER}..."
        gh issue close "${HEAL_ISSUE_NUMBER}" --repo 5dlabs/cto --reason completed 2>/dev/null || echo "   (could not close issue)"
    fi

    # Clean up issue folder on PVC
    if [ -n "${HEAL_ISSUE_DIR}" ] && [ -d "${HEAL_ISSUE_DIR}" ]; then
        echo "üßπ Archiving issue folder: ${HEAL_ISSUE_DIR}"
        ARCHIVE_DIR="/workspace/archived/${HEAL_ISSUE_NUMBER:-unknown}"
        mkdir -p "$(dirname ${ARCHIVE_DIR})"
        mv "${HEAL_ISSUE_DIR}" "${ARCHIVE_DIR}" 2>/dev/null || echo "   (folder already moved or missing)"
    fi

    # Clean up worktree if it exists
    if [ -n "${WORKTREE_PATH}" ] && [ -d "${WORKTREE_PATH}" ]; then
        echo "üßπ Removing worktree: ${WORKTREE_PATH}"
        cd "${REPO_PATH:-/workspace/5dlabs-cto}" 2>/dev/null || true
        git worktree remove "${WORKTREE_PATH}" --force 2>/dev/null || rm -rf "${WORKTREE_PATH}" 2>/dev/null || true
    fi

    # Explicitly stop Docker sidecar before exiting
    {{#if enable_docker}}
    echo "üõë Explicitly stopping Docker sidecar..."
    stop_docker_sidecar || true
    {{/if}}
    
    exit 0
else
    # This branch should not be reached since we iterate until success
    echo "‚ïë ‚ö†Ô∏è REMEDIATION LOOP EXITED UNEXPECTEDLY                        ‚ïë"
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo "Loop exited after ${ATTEMPT} iterations without success flag"

    # Update GitHub issue if we have an issue number
    if [ -n "${HEAL_ISSUE_NUMBER}" ]; then
        echo "üìù Adding status comment to issue #${HEAL_ISSUE_NUMBER}..."
        LAST_REASON=$(cat "${COMPLETION_LAST_MESSAGE}" 2>/dev/null || echo "Unknown")
        gh issue comment "${HEAL_ISSUE_NUMBER}" --repo 5dlabs/cto --body "‚ö†Ô∏è **Remediation Loop Exited**

Loop exited unexpectedly after ${ATTEMPT} iterations.

**Last known status:**
${LAST_REASON}

**Next steps:** Check agent logs for errors.

Agent: ${CODERUN_NAME}" 2>/dev/null || echo "   (could not comment on issue)"
    fi

    # Explicitly stop Docker sidecar before exiting
    {{#if enable_docker}}
    echo "üõë Explicitly stopping Docker sidecar..."
    stop_docker_sidecar || true
    {{/if}}
    
    exit 1
fi
