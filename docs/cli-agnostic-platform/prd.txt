<context>
# Overview
The CTO platform currently uses Claude Code CLI (`@anthropic-ai/claude-code`) as the primary AI coding assistant. However, we have Docker images for multiple AI CLI tools (Cursor, Gemini, Grok, OpenHands, Qwen, Codex) that remain untested and unintegrated. This project will research, test, and integrate these CLI tools to provide flexibility in choosing the best tool for each task while maintaining consistent functionality across different AI providers.

# Core Features
## CLI Discovery & Documentation
- **CLI Capability Assessment**: Test and document each CLI's capabilities, limitations, and configuration requirements
- **Configuration Mapping**: Understand how each CLI handles context files, settings, and tool definitions
- **Command Structure Analysis**: Document command patterns, parameters, and response formats
- **Session Management Study**: How each CLI maintains state and handles long-running sessions

## Standardization Middleware
- **Universal Configuration Schema**: Create a common format that can be translated to each CLI's requirements
- **Configuration Bridge**: Middleware layer that translates our standard config to CLI-specific formats
- **Context File Translation**: Convert between CLAUDE.md, cursor configs, OpenHands settings, etc.
- **Tool/Function Mapping**: Map our universal tool definitions to each CLI's function calling format

## CLI Integration Framework
- **Dynamic CLI Selection**: Choose CLI based on task type, cost, or availability
- **Graceful Fallback**: If one CLI fails, automatically try another
- **Performance Monitoring**: Track success rates, token usage, and execution time per CLI
- **A/B Testing**: Compare CLI performance on identical tasks

# User Experience
## User Personas
- **Platform Engineers**: Need to understand and configure multiple CLI tools
- **DevOps Teams**: Require cost optimization and vendor flexibility
- **Development Teams**: Want consistent experience regardless of underlying CLI
- **QA Teams**: Need to validate functionality across different AI providers

## Key User Flows
1. **CLI Selection**: User specifies preferred CLI or system auto-selects based on task
2. **Transparent Execution**: Task runs with chosen CLI without user knowing specifics
3. **Performance Comparison**: Platform shows metrics across different CLIs
4. **Cost Optimization**: System routes to most cost-effective CLI for task type
</context>

<PRD>
# Technical Architecture

## System Components

### Core Infrastructure
- **CLI Discovery Service**: Tests and profiles each CLI tool's capabilities
- **Configuration Middleware**: Translates between universal and CLI-specific formats
- **CLI Router**: Selects appropriate CLI based on rules and availability
- **Session Manager**: Maintains state across different CLI session models

### CLI Tool Inventory
```yaml
Supported CLIs:
  claude:
    package: "@anthropic-ai/claude-code"
    type: npm
    config_dir: ~/.claude
    config_format: CLAUDE.md (markdown)
    session_model: persistent
    
  cursor:
    binary: cursor-agent
    type: standalone
    config_dir: ~/.cursor
    config_format: unknown (needs discovery)
    session_model: unknown
    
  openhands:
    package: "openhands-ai"
    type: python
    config_dir: ~/.openhands
    config_format: unknown (needs discovery)
    session_model: unknown
    
  grok:
    package: "@vibe-kit/grok-cli"
    type: npm
    config_dir: project-local
    config_format: unknown (needs discovery)
    session_model: unknown
    
  gemini:
    package: unknown
    type: unknown
    config_format: unknown
    session_model: unknown
    
  qwen:
    package: unknown
    type: unknown
    config_format: unknown
    session_model: unknown
    
  codex:
    package: unknown
    type: unknown
    config_format: unknown
    session_model: unknown
```

### Configuration Middleware Architecture
```yaml
Middleware Components:
  Configuration Translator:
    - Input: Universal configuration schema
    - Output: CLI-specific configuration files
    - Handles: Context, settings, tool definitions
    
  Command Adapter:
    - Translates universal commands to CLI-specific syntax
    - Handles parameter differences
    - Manages response parsing
    
  Session Bridge:
    - Maps session concepts between CLIs
    - Handles state persistence differences
    - Manages context window variations
```

## Data Models

### Universal Configuration Schema
```yaml
universal_config:
  context:
    project:
      name: string
      description: string
      architecture: object
      constraints: array
    agent:
      role: string
      capabilities: array
      instructions: string
    session:
      id: string
      state: object
      history: array
      
  tools:
    - name: string
      description: string
      parameters: object
      implementation:
        claude: string
        cursor: string
        openhands: string
        grok: string
        
  settings:
    model: string
    temperature: float
    max_tokens: integer
    timeout: integer
```

### CLI Profile Schema
```rust
#[derive(Debug, Serialize, Deserialize)]
pub struct CLIProfile {
    pub name: String,
    pub cli_type: CLIType,
    pub capabilities: CLICapabilities,
    pub configuration: CLIConfiguration,
    pub limitations: Vec<String>,
    pub cost_model: CostModel,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct CLICapabilities {
    pub max_context_window: usize,
    pub supports_tools: bool,
    pub supports_vision: bool,
    pub supports_web_search: bool,
    pub supports_code_execution: bool,
    pub supports_file_operations: bool,
    pub session_persistence: SessionType,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct CLIConfiguration {
    pub config_format: ConfigFormat,
    pub config_location: PathBuf,
    pub required_env_vars: Vec<String>,
    pub init_commands: Vec<String>,
    pub cleanup_commands: Vec<String>,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum ConfigFormat {
    Markdown,        // Claude
    JSON,           // Likely for several
    YAML,           // Likely for Cursor
    TOML,           // Possible for Rust-based
    Custom(String), // Unknown formats
}
```

## APIs and Integrations

### Discovery Test Suite
```rust
// Discovery tests to run on each CLI
pub struct CLIDiscoveryTests {
    pub basic_tests: Vec<BasicTest>,
    pub configuration_tests: Vec<ConfigTest>,
    pub capability_tests: Vec<CapabilityTest>,
    pub performance_tests: Vec<PerfTest>,
}

impl CLIDiscoveryTests {
    pub async fn run_discovery(&self, cli_name: &str) -> DiscoveryReport {
        let mut report = DiscoveryReport::new(cli_name);
        
        // Test 1: Basic execution
        report.can_execute = self.test_basic_execution().await;
        
        // Test 2: Configuration format
        report.config_format = self.discover_config_format().await;
        
        // Test 3: File operations
        report.file_operations = self.test_file_operations().await;
        
        // Test 4: Code generation
        report.code_generation = self.test_code_generation().await;
        
        // Test 5: Tool/function calling
        report.tool_support = self.test_tool_calling().await;
        
        // Test 6: Session management
        report.session_model = self.test_session_persistence().await;
        
        // Test 7: Context window
        report.max_context = self.measure_context_window().await;
        
        // Test 8: Error handling
        report.error_handling = self.test_error_scenarios().await;
        
        report
    }
}
```

### Configuration Bridge Implementation
```rust
pub trait ConfigurationBridge {
    fn translate_to_cli(&self, universal: &UniversalConfig) -> Result<String>;
    fn translate_from_cli(&self, cli_specific: &str) -> Result<UniversalConfig>;
    fn get_config_location(&self) -> PathBuf;
    fn get_required_files(&self) -> Vec<ConfigFile>;
}

// Claude implementation (known)
impl ConfigurationBridge for ClaudeBridge {
    fn translate_to_cli(&self, universal: &UniversalConfig) -> Result<String> {
        let mut claude_md = String::new();
        
        // Project context
        claude_md.push_str("# Project Context\n\n");
        claude_md.push_str(&format!("Project: {}\n", universal.context.project.name));
        claude_md.push_str(&format!("{}\n\n", universal.context.project.description));
        
        // Agent instructions
        claude_md.push_str("# Instructions\n\n");
        claude_md.push_str(&universal.context.agent.instructions);
        
        Ok(claude_md)
    }
}

// Cursor implementation (needs discovery)
impl ConfigurationBridge for CursorBridge {
    fn translate_to_cli(&self, universal: &UniversalConfig) -> Result<String> {
        // TODO: Implement after discovery phase
        todo!("Cursor configuration format unknown - needs discovery")
    }
}
```

## Infrastructure Requirements

### Discovery Environment
```yaml
# Isolated test environment for each CLI
apiVersion: v1
kind: Pod
metadata:
  name: cli-discovery-{{cli_name}}
spec:
  containers:
  - name: cli-test
    image: ghcr.io/5dlabs/{{cli_name}}:latest
    env:
    - name: DISCOVERY_MODE
      value: "true"
    - name: TEST_SUITE
      value: "full"
    volumeMounts:
    - name: test-workspace
      mountPath: /workspace
    - name: discovery-scripts
      mountPath: /discovery
```

### Test Harness Structure
```bash
#!/bin/bash
# discovery-harness.sh

CLI_NAME=$1
echo "Starting discovery for $CLI_NAME"

# Test 1: Check CLI availability
echo "Test 1: CLI Availability"
case $CLI_NAME in
  claude)
    claude-code --version || echo "FAIL: CLI not found"
    ;;
  cursor)
    cursor-agent --version || echo "FAIL: CLI not found"
    ;;
  openhands)
    python -m openhands.cli.main --version || echo "FAIL: CLI not found"
    ;;
  grok)
    grok-cli --version || echo "FAIL: CLI not found"
    ;;
esac

# Test 2: Configuration discovery
echo "Test 2: Configuration Format"
case $CLI_NAME in
  claude)
    echo "Creating CLAUDE.md test file..."
    cat > /workspace/CLAUDE.md << EOF
# Test Context
This is a test context for discovery.
EOF
    ;;
  cursor)
    echo "Searching for cursor configuration format..."
    find ~ -name "*cursor*" -type f 2>/dev/null | head -20
    ;;
  *)
    echo "Unknown configuration format - needs investigation"
    ;;
esac

# Test 3: Basic code generation
echo "Test 3: Code Generation"
cat > /tmp/test-prompt.txt << EOF
Write a simple hello world function in Python
EOF

# Try to execute with discovered CLI
# ... implementation varies per CLI
```

# Development Roadmap

## Phase 1: Discovery & Documentation (Days 1-3)
### CLI Investigation
- Deploy each CLI container in test environment
- Run discovery test suite on each CLI
- Document configuration formats and requirements
- Map command structures and parameters
- Test file operations and code generation
- Investigate session management models

### Capability Matrix Creation
- Build comprehensive comparison matrix
- Document context window limits
- Test tool/function calling support
- Measure performance characteristics
- Identify unique features and limitations

### Deliverables
- Complete CLI capability matrix
- Configuration format documentation
- Command mapping spreadsheet
- Session model analysis
- Performance baseline data
- Gap analysis report

## Phase 2: Standardization Design (Days 3-4)
### Universal Schema Development
- Design configuration schema that covers all CLIs
- Create tool definition standard
- Define session state model
- Plan translation strategies

### Bridge Architecture
- Design configuration translator components
- Plan command adaptation layer
- Design session state bridge
- Create error handling strategy

### Deliverables
- Universal configuration schema
- Bridge component designs
- Translation strategy document
- Error handling framework

## Phase 3: Bridge Implementation (Days 5-6)
### Core Bridge Development
- Implement configuration translators
- Build command adapters
- Create session managers
- Develop error handlers

### CLI-Specific Adapters
- Claude adapter (refactor existing)
- Cursor adapter
- OpenHands adapter
- Grok adapter
- Stub adapters for untested CLIs

### Deliverables
- Working bridge middleware
- CLI-specific adapters
- Translation validation tests
- Integration test suite

## Phase 4: Integration & Testing (Day 7)
### System Integration
- Integrate bridge with controller
- Update CodeRun CRDs
- Modify container scripts
- Test end-to-end workflows

### Validation Testing
- Run same task across all CLIs
- Compare outputs and performance
- Validate configuration translation
- Test fallback mechanisms

### Deliverables
- Integrated system
- Test results report
- Performance comparison
- Bug fixes and optimizations

# Risks and Mitigations

## Technical Challenges

### Unknown CLI Behaviors
**Risk**: CLIs may have undocumented behaviors or limitations
**Mitigation**: Extensive discovery phase, defensive coding, graceful degradation

### Configuration Incompatibilities
**Risk**: Some configuration concepts may not translate between CLIs
**Mitigation**: Universal schema with optional fields, CLI-specific extensions

### Session State Differences
**Risk**: Session models may be fundamentally incompatible
**Mitigation**: Abstract session layer, stateless operation mode as fallback

## Resource Constraints

### Testing Time
**Challenge**: Testing all CLIs thoroughly takes significant time
**Approach**: Prioritize most promising CLIs, parallel testing where possible

### Documentation Gaps
**Challenge**: Some CLIs may have poor or no documentation
**Approach**: Reverse engineering, community resources, vendor support

## Minimum Viable Product Definition

### MVP Scope
- Support for Claude + 2 additional CLIs (Cursor, OpenHands)
- Basic configuration translation
- Simple task execution (file operations, code generation)
- Manual CLI selection (no auto-routing yet)

### MVP Success Criteria
- Execute same task on 3 different CLIs
- Configuration properly translated
- No degradation from current Claude-only setup
- Clear path to add more CLIs

# Appendix

## Discovery Questions Per CLI

### Essential Questions
1. What configuration files does it expect and in what format?
2. How does it handle context/memory between sessions?
3. What's the command structure for basic operations?
4. How does it handle tool/function definitions?
5. What environment variables are required?
6. How does it report errors and status?
7. What's the maximum context window?
8. How does it handle file operations?

### Cursor Specific
- How does cursor-agent binary work?
- What's the relationship to Cursor IDE?
- Can it work standalone without IDE?
- What's the configuration format?

### OpenHands Specific
- How does the Python module structure work?
- What's the difference between cli.main and core.main?
- How does it handle long-running sessions?
- What's the configuration format?

### Grok Specific
- What's the authentication model?
- How does it handle the GROK_API_KEY?
- What's in the grok-entrypoint.sh script?
- What's the configuration format?

## Testing Matrix Template
| Test Case | Claude | Cursor | OpenHands | Grok | Gemini | Qwen | Codex |
|-----------|---------|---------|-----------|-------|---------|-------|--------|
| CLI Available | ✓ | ? | ? | ? | ? | ? | ? |
| Config Format | Markdown | ? | ? | ? | ? | ? | ? |
| File Read/Write | ✓ | ? | ? | ? | ? | ? | ? |
| Code Generation | ✓ | ? | ? | ? | ? | ? | ? |
| Tool Support | MCP | ? | ? | ? | ? | ? | ? |
| Session Persist | ✓ | ? | ? | ? | ? | ? | ? |
| Max Context | 200k | ? | ? | ? | ? | ? | ? |
| Error Handling | ✓ | ? | ? | ? | ? | ? | ? |

## Success Metrics
- Discovery completeness: 100% of CLIs tested
- Configuration translation: 90% fidelity
- Performance overhead: <10% from bridge layer
- CLI support: 3+ CLIs fully integrated
- Fallback success: 95% successful failover
</PRD>