{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Helm values and Agents ConfigMap for personas and project-wide tools",
        "description": "Add Helm values and templates to render agent personas' system prompts into a ConfigMap and define project-wide MCP tools configuration per PRD.",
        "details": "Implementation:\n- Update charts/platform (or create a new chart) with values.yaml:\n  agents:\n    - name: rex\n      githubApp: rex-agent\n      systemPromptFile: rex_system-prompt.md\n    - name: clippy\n      githubApp: clippy-agent\n      systemPromptFile: clippy_system-prompt.md\n    - name: qa\n      githubApp: qa-agent\n      systemPromptFile: qa_system-prompt.md\n    - name: triage\n      githubApp: triage-agent\n      systemPromptFile: triage_system-prompt.md\n    - name: security\n      githubApp: security-agent\n      systemPromptFile: security_system-prompt.md\n  mcp:\n    requirementsFile: requirements.yaml\n- Helm template to render controller-agents ConfigMap:\n  apiVersion: v1\n  kind: ConfigMap\n  metadata:\n    name: controller-agents\n  data:\n    rex_system-prompt.md: |-\n      {{ .Values.agents | include \"renderPrompt\" }}\n    clippy_system-prompt.md: |-\n      ...\n    qa_system-prompt.md: |-\n      ...\n    triage_system-prompt.md: |-\n      ...\n    security_system-prompt.md: |-\n      ...\n- Include a project-level requirements.yaml for MCP tools (not per-task), e.g.:\n  tools:\n    - name: github-comments\n      transport: http\n      endpoint: http://mcp-github-comments:8080\n    - name: k8s-verify\n      transport: exec\n      command: [/bin/kubectl, ...]\n- Mount controller-agents ConfigMap into workflow pods using volume/volumeMounts in WorkflowTemplate(s) so agent processes can read their system prompts at /etc/agents/*.md.\n- Ensure docs live under repo path docs/.taskmaster per I2; add architecture.md skeleton referencing this PRD.\nPseudocode (Helm helper):\n- define \"renderPrompt\" to select .Values.agents by name and include file content from files/ dir: {{- $f := printf \"agents/%s\" .systemPromptFile -}} {{ .Files.Get $f | nindent 6 }}",
        "testStrategy": "Helm template rendering: run `helm template` and verify controller-agents ConfigMap includes all expected keys; deploy to a dev namespace; exec into a workflow pod and confirm /etc/agents/* exist. Validate MCP requirements.yaml is packaged via Helm and mounted or accessible at runtime. Lint prompts for size and encoding. Validate docs path exists.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Helm values schema and helpers for agents and MCP tools",
            "description": "Create/extend the platform chart values, add a JSON schema, and add Helm helper templates to render agent prompt files.",
            "dependencies": [],
            "details": "- Chart name/location: charts/platform\n- Files to add/modify:\n  - charts/platform/values.yaml (add agents[] and mcp.requirementsFile)\n  - charts/platform/values.schema.json (validate required fields and types)\n  - charts/platform/templates/_helpers.tpl (add helper templates)\n- values.yaml additions:\n  agents:\n    - name: rex\n      githubApp: rex-agent\n      systemPromptFile: rex_system-prompt.md\n    - name: clippy\n      githubApp: clippy-agent\n      systemPromptFile: clippy_system-prompt.md\n    - name: qa\n      githubApp: qa-agent\n      systemPromptFile: qa_system-prompt.md\n    - name: triage\n      githubApp: triage-agent\n      systemPromptFile: triage_system-prompt.md\n    - name: security\n      githubApp: security-agent\n      systemPromptFile: security_system-prompt.md\n  mcp:\n    requirementsFile: requirements.yaml\n- values.schema.json (excerpt):\n  {\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"agents\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"object\",\n          \"required\": [\"name\", \"githubApp\", \"systemPromptFile\"],\n          \"properties\": {\n            \"name\": {\"type\": \"string\", \"minLength\": 1},\n            \"githubApp\": {\"type\": \"string\", \"minLength\": 1},\n            \"systemPromptFile\": {\"type\": \"string\", \"pattern\": \"^.+\\\\.md$\"}\n          }\n        },\n        \"minItems\": 1\n      },\n      \"mcp\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"requirementsFile\": {\"type\": \"string\", \"minLength\": 1}\n        },\n        \"required\": [\"requirementsFile\"]\n      }\n    },\n    \"required\": [\"agents\", \"mcp\"]\n  }\n- templates/_helpers.tpl additions:\n  {{- define \"platform.renderPrompt\" -}}\n  {{- $f := printf \"agents/%s\" .systemPromptFile -}}\n  {{- .Files.Get $f | nindent 6 -}}\n  {{- end -}}\n  {{- define \"platform.agentVolumes\" -}}\n  - name: agents-prompts\n    configMap:\n      name: controller-agents\n  - name: mcp-requirements\n    configMap:\n      name: mcp-requirements\n  {{- end -}}\n  {{- define \"platform.agentVolumeMounts\" -}}\n  - name: agents-prompts\n    mountPath: /etc/agents\n    readOnly: true\n  - name: mcp-requirements\n    mountPath: /work/requirements.yaml\n    subPath: requirements.yaml\n    readOnly: true\n  {{- end -}}\n- Acceptance criteria:\n  - helm lint passes and validates values.schema.json.\n  - Helpers are renderable via helm template without errors.\n  - Values remain overridable via -f or --set for per-environment overrides.\n- Test commands:\n  - helm lint charts/platform\n  - helm template charts/platform | head -n 50\n- Risks:\n  - Helper name collisions; use chart-scoped names (platform.*).\n  - Incorrect nindent leading whitespace in rendered ConfigMaps.\n  - Missing files under charts/platform/files will break .Files.Get at template time.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement controller-agents ConfigMap template rendering system prompts",
            "description": "Create a Helm template that renders each agent system prompt into a controller-agents ConfigMap using the helper.",
            "dependencies": [
              "1.1"
            ],
            "details": "- Chart name/location: charts/platform\n- Files to add:\n  - charts/platform/templates/controller-agents-configmap.yaml\n- Template snippet (controller-agents-configmap.yaml):\n  apiVersion: v1\n  kind: ConfigMap\n  metadata:\n    name: controller-agents\n    labels:\n      app.kubernetes.io/name: controller-agents\n      app.kubernetes.io/part-of: platform\n  data:\n  {{- range .Values.agents }}\n    {{ .systemPromptFile }}: |-\n  {{ include \"platform.renderPrompt\" . }}\n  {{- end }}\n- Notes:\n  - Keys are the exact systemPromptFile names (e.g., rex_system-prompt.md).\n  - If a file is missing under charts/platform/files/agents, helm template/install will fail fast.\n- Acceptance criteria:\n  - helm template renders a single ConfigMap named controller-agents with one key per agent systemPromptFile.\n  - Rendered content preserves newlines/formatting of the source .md files.\n- Test commands:\n  - helm template charts/platform | yq '. | select(.kind==\"ConfigMap\" and .metadata.name==\"controller-agents\") | .data | keys' -o yaml\n  - helm template charts/platform | yq '. | select(.kind==\"ConfigMap\" and .metadata.name==\"controller-agents\") | .data[\"rex_system-prompt.md\"]' -o yaml | head -n 20\n- Risks:\n  - Indentation errors if helper nindent changes.\n  - Very large prompt files can bloat the ConfigMap; see size checks in validation subtask.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Package prompt files and MCP requirements.yaml into the chart",
            "description": "Add all agent prompt files under files/agents and include a project-level MCP requirements.yaml with a ConfigMap to expose it.",
            "dependencies": [
              "1.1",
              "1.2"
            ],
            "details": "- Chart name/location: charts/platform\n- Files to add:\n  - charts/platform/files/agents/rex_system-prompt.md\n  - charts/platform/files/agents/clippy_system-prompt.md\n  - charts/platform/files/agents/qa_system-prompt.md\n  - charts/platform/files/agents/triage_system-prompt.md\n  - charts/platform/files/agents/security_system-prompt.md\n  - charts/platform/files/requirements.yaml\n  - charts/platform/templates/mcp-requirements-configmap.yaml\n- Example charts/platform/files/requirements.yaml:\n  tools:\n    - name: github-comments\n      transport: http\n      endpoint: http://mcp-github-comments:8080\n    - name: k8s-verify\n      transport: exec\n      command: [/bin/kubectl, version, --client]\n- Template (mcp-requirements-configmap.yaml):\n  apiVersion: v1\n  kind: ConfigMap\n  metadata:\n    name: mcp-requirements\n    labels:\n      app.kubernetes.io/name: mcp-requirements\n      app.kubernetes.io/part-of: platform\n  data:\n    requirements.yaml: |-\n  {{ .Files.Get (printf \"%s\" .Values.mcp.requirementsFile) | nindent 6 }}\n- Acceptance criteria:\n  - helm template renders a ConfigMap named mcp-requirements with requirements.yaml key matching the file content.\n  - All .md prompt files are packaged under the chart's files/ directory and referenced correctly by controller-agents ConfigMap.\n- Test commands:\n  - helm template charts/platform | yq '. | select(.kind==\"ConfigMap\" and .metadata.name==\"mcp-requirements\") | .data[\"requirements.yaml\"]' -o yaml\n  - helm package charts/platform && tar -tzf platform-*.tgz | grep 'files/agents/'\n- Risks:\n  - requirements.yaml path override must remain valid; a wrong path will break install.\n  - YAML syntax in requirements.yaml must be valid; consider a CI yaml-lint step.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Mount controller-agents and MCP requirements into WorkflowTemplates",
            "description": "Add reusable volume and volumeMount helpers and wire them into WorkflowTemplates so pods see prompts at /etc/agents/*.md and /work/requirements.yaml.",
            "dependencies": [
              "1.2",
              "1.3"
            ],
            "details": "- Chart name/location: charts/platform\n- Helpers to use (already added in 1.1): platform.agentVolumes and platform.agentVolumeMounts\n- Update or create WorkflowTemplates to include mounts:\n  - If existing: patch the following files to include helpers where pod specs are defined:\n    - charts/platform/templates/workflowtemplates/coderun-template.yaml (when Task 3 lands)\n    - charts/platform/templates/workflowtemplates/pr-validation.yaml (Task 4)\n    - charts/platform/templates/workflowtemplates/implementation-dag.yaml (Task 5)\n  - Add a smoke test WorkflowTemplate now to validate mounts:\n    - charts/platform/templates/workflowtemplates/agent-mount-smoke.yaml\n- Snippet to include in container templates:\n  spec:\n    templates:\n      - name: main\n        container:\n          image: alpine:3.20\n          command: ['sh', '-c']\n          args: ['ls -l /etc/agents && test -f /work/requirements.yaml && echo OK']\n          volumeMounts:\n  {{ include \"platform.agentVolumeMounts\" . | nindent 12 }}\n    volumes:\n  {{ include \"platform.agentVolumes\" . | nindent 6 }}\n- Acceptance criteria:\n  - helm template shows volumes and volumeMounts injected wherever applicable.\n  - Deploying the chart creates the agent-mount-smoke WorkflowTemplate that successfully validates mounts when executed.\n- Test commands:\n  - helm template charts/platform | yq '. | select(.kind==\"WorkflowTemplate\" and .metadata.name==\"agent-mount-smoke\")' -o yaml\n  - helm upgrade --install platform charts/platform -n dev\n  - kubectl -n dev create wf --from=wftmpl/agent-mount-smoke\n  - argo -n dev get wf | tail -n +1 (or kubectl logs) and verify \"OK\" output\n- Risks:\n  - Some templates (e.g., resource templates creating CRs) may not accept volume mounts; ensure mounts are applied only to container templates.\n  - Name collisions for volumes; using helper ensures consistent names across templates.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Add docs/.taskmaster/architecture.md skeleton referencing PRD",
            "description": "Create documentation describing the agents ConfigMap, MCP requirements, mounting approach, and overrides, referencing the PRD.",
            "dependencies": [
              "1.4"
            ],
            "details": "- File to add: docs/.taskmaster/architecture.md\n- Content outline:\n  - Title: Agents ConfigMap and Project-wide MCP Tools Configuration\n  - PRD reference: link or path to the PRD this implements.\n  - Chart: charts/platform overview and how values.yaml controls agents and mcp.requirementsFile.\n  - How prompts are packaged (files/agents) and rendered via platform.renderPrompt helper.\n  - ConfigMaps: controller-agents and mcp-requirements; keys and expected paths.\n  - Mounting: helpers platform.agentVolumes and platform.agentVolumeMounts; mount points /etc/agents and /work/requirements.yaml.\n  - Overrides per environment: examples using helm -f env/values-dev.yaml or --set.\n  - Risks and limits: ConfigMap size limits, newline/indentation, file encoding.\n  - Validation steps: helm lint/template, cluster smoke run.\n- Acceptance criteria:\n  - Document exists under docs/.taskmaster and accurately reflects implemented chart structure and helpers.\n  - Includes copy-pastable commands for linting, templating, and a sample smoke Workflow execution.\n- Test commands:\n  - test -f docs/.taskmaster/architecture.md && echo OK\n- Risks:\n  - Doc drift as templates evolve; keep in same PR to ensure accuracy.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Validation, linting, and dev deployment checks",
            "description": "Run helm lint/template, deploy to a dev namespace, verify mounts in a running pod, and check size/encoding constraints.",
            "dependencies": [
              "1.1",
              "1.2",
              "1.3",
              "1.4",
              "1.5"
            ],
            "details": "- Linting and render checks:\n  - helm lint charts/platform\n  - helm template charts/platform --set mcp.requirementsFile=requirements.yaml | grep -q 'controller-agents'\n  - helm template charts/platform | yq '. | select(.kind==\"ConfigMap\" and .metadata.name==\"controller-agents\") | .data | length' -o json\n- Dev install/upgrade:\n  - kubectl create ns dev || true\n  - helm upgrade --install platform charts/platform -n dev\n  - kubectl -n dev get cm controller-agents -o yaml | head -n 30\n  - kubectl -n dev get cm mcp-requirements -o yaml | head -n 30\n- Runtime validation (smoke):\n  - kubectl -n dev create wf --from=wftmpl/agent-mount-smoke\n  - argo -n dev logs @latest | tee /tmp/agent-mount-smoke.log\n  - grep -q 'OK' /tmp/agent-mount-smoke.log\n- Size and encoding checks (guard against ConfigMap limits ~1MiB per object):\n  - find charts/platform/files/agents -type f -name '*_system-prompt.md' -print0 | xargs -0 stat -f '%N %z' 2>/dev/null || find charts/platform/files/agents -type f -printf '%p %s\\n'\n  - total=$(find charts/platform/files/agents -type f -printf '%s\\n' | awk '{s+=$1} END {print s}'); echo \"Total bytes:\" $total; test $total -lt 900000\n  - file -I charts/platform/files/agents/*.md | grep -v 'charset=utf-8' && echo 'Non-UTF-8 detected' && exit 1 || echo 'All UTF-8'\n- Failure injection:\n  - Temporarily set a non-existent systemPromptFile in values to ensure helm template fails with .Files.Get error (fast-fail safety).\n- Acceptance criteria:\n  - All lint/render commands succeed.\n  - Dev install succeeds; smoke workflow prints OK; mounted files present.\n  - Combined prompt sizes stay comfortably under ConfigMap limit; files are UTF-8.\n- Risks:\n  - Cluster RBAC may block WorkflowTemplate creation; ensure chart has necessary permissions or adjust namespace.\n  - Large prompts can exceed limits; if close to limit, consider splitting ConfigMaps or compressing prompts.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 2,
        "title": "External Secrets for GitHub App credentials and token generation pattern",
        "description": "Configure External Secrets to source GitHub App app-id and private key and expose them to workflows; implement a lightweight token generator to exchange for installation tokens without using PATs.",
        "details": "Implementation:\n- Create ExternalSecret resources (backed by your chosen SecretStore) to project secrets:\n  - Name: github-app-rex, keys: appId, privateKey\n  - Name: github-app-clippy, keys: appId, privateKey\n  - Name: github-app-qa, keys: appId, privateKey\n  - Name: github-app-triage, keys: appId, privateKey\n  - Name: github-app-security, keys: appId, privateKey\n- Define a common initContainer (or sidecar) image (tiny Go/Node) that:\n  - Reads APP_ID and PRIVATE_KEY from mounted secret\n  - Reads INSTALLATION_ID (passed via param or detected from repo) via GitHub API /app/installations\n  - Creates a JWT with RS256 for the GitHub App\n  - Exchanges JWT for installation token via POST /app/installations/{id}/access_tokens\n  - Exports GITHUB_TOKEN to a shared emptyDir for steps that need GitHub access\n- Mount: /var/run/github (emptyDir) shared between initContainer and main container(s).\n- WorkflowTemplate adds env:\n  - GITHUB_APP_ID, GITHUB_APP_PRIVATE_KEY from secret\n  - GITHUB_TOKEN_FILE=/var/run/github/token\n- Permissions: Lock down RBAC to only read the secrets; least privilege scopes for the Apps (contents:read/write, pull_requests:read/write, issues:read/write, checks:read, security_events:read as needed).\nPseudocode (token generator in Node.js):\nconst jwt = createAppJWT(appId, privateKey)\nconst inst = await gh('/app/installations',{auth: jwt})\nconst token = await gh(`/app/installations/${instId}/access_tokens`, {method:'POST', auth: jwt})\nfs.writeFileSync('/var/run/github/token', token.token)\nprocess.env.GITHUB_TOKEN = token.token",
        "testStrategy": "Deploy ExternalSecrets and verify Kubernetes secrets are synced. Run a dry-run Workflow that mounts a GitHub App secret and prints `gh auth status` using the token. Confirm no PAT usage. Rotate secrets in the backend and verify refresh. Negative test: invalid key should fail fast.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "SecretStore wiring and ExternalSecret manifests for GitHub Apps",
            "description": "Configure External Secrets to sync appId and privateKey for rex, clippy, qa, triage, security GitHub Apps from the chosen SecretStore.",
            "dependencies": [],
            "details": "Manifests (example using External Secrets Operator with AWS Secrets Manager):\n- SecretStore:\n  apiVersion: external-secrets.io/v1beta1\n  kind: SecretStore\n  metadata:\n    name: aws-secrets\n    namespace: workflows\n  spec:\n    provider:\n      aws:\n        service: SecretsManager\n        region: us-east-1\n        auth:\n          jwt:\n            serviceAccountRef:\n              name: external-secrets-sa\n              namespace: workflows\n- ExternalSecret (repeat for each app: rex, clippy, qa, triage, security):\n  apiVersion: external-secrets.io/v1beta1\n  kind: ExternalSecret\n  metadata:\n    name: github-app-rex\n    namespace: workflows\n  spec:\n    refreshInterval: 1h\n    secretStoreRef:\n      name: aws-secrets\n      kind: SecretStore\n    target:\n      name: github-app-rex\n      template:\n        type: Opaque\n    data:\n      - secretKey: appId\n        remoteRef: { key: /github-apps/rex/appId }\n      - secretKey: privateKey\n        remoteRef: { key: /github-apps/rex/privateKey }\nRepeat with keys under /github-apps/{clippy|qa|triage|security}/.\nCommand lines:\n- kubectl apply -f secretstore.yaml\n- kubectl apply -f externalsecret-github-app-*.yaml\nSecurity notes:\n- No PATs; only GitHub App credentials. Restrict SecretStore IAM to read exact secret ARNs/paths. Ensure privateKey stored base64-encoded or plain PEM per provider guidance and is never logged.\nAcceptance criteria:\n- K8s Secrets github-app-{rex,clippy,qa,triage,security} exist with keys appId and privateKey.\n- ExternalSecret status Synced with no errors.\n- Rotating a value in the backend reflects into the K8s Secret within refreshInterval.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Minimal token generator implementation (JWT + installation token)",
            "description": "Build a tiny Node.js or Go service/CLI that creates a GitHub App JWT and exchanges it for an installation token.",
            "dependencies": [],
            "details": "Implementation outline (Node.js):\n- Inputs: APP_ID, PRIVATE_KEY (PEM), INSTALLATION_ID (optional), GITHUB_API_URL (default https://api.github.com), OUTPUT_PATH (/var/run/github/token).\n- Steps:\n  1) Create JWT (RS256) with claims: iss=APP_ID, iat=now-60s, exp=now+540s.\n  2) If INSTALLATION_ID unset, call GET /app/installations (requires JWT) and select the correct installation (by repo/org if provided via params REPO/OWNER).\n  3) Exchange JWT for installation token: POST /app/installations/{id}/access_tokens.\n  4) Write token.token to OUTPUT_PATH with 0600 perms; optionally export to stdout if requested.\n- API endpoints used:\n  - GET https://api.github.com/app\n  - GET https://api.github.com/app/installations\n  - POST https://api.github.com/app/installations/{installation_id}/access_tokens\n- Security notes:\n  - Do not log PRIVATE_KEY or tokens. Use memory-only variables; zero buffers when possible. Set file mode 0600 and atomic write.\n  - Do not use PATs. Limit scopes via App permissions only.\nAcceptance criteria:\n- Running locally with env vars produces a valid token file and gh auth status recognizes it.\n- Handles errors with clear exit codes/messages for 401/403, 404, 5xx.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Containerization and CI publish for the generator",
            "description": "Create Docker image for the token generator and set up CI to build, tag, scan, and publish.",
            "dependencies": [
              "2.2"
            ],
            "details": "Containerization:\n- Dockerfile (Node.js example):\n  FROM node:20-alpine AS build\n  WORKDIR /app\n  COPY package*.json .\n  RUN npm ci --omit=dev\n  COPY . .\n  RUN npm run build || true\n  FROM gcr.io/distroless/nodejs20-debian12\n  WORKDIR /app\n  COPY --from=build /app /app\n  USER 65532:65532\n  ENV NODE_ENV=production\n  ENTRYPOINT [\"node\",\"/app/index.js\"]\nCI (GitHub Actions example):\n- Trigger on push to main and tags.\n- Steps: checkout, set up QEMU+Buildx, docker/login-action, docker/metadata-action, docker/build-push-action with SBOM and provenance, trivy scan.\nCommand lines:\n- docker build -t ghcr.io/ORG/ghapp-token-gen:0.1.0 .\n- docker push ghcr.io/ORG/ghapp-token-gen:0.1.0\nSecurity notes:\n- Run as non-root, read-only rootfs if possible, drop NET_RAW.\n- Publish SBOM and sign image (cosign).\nAcceptance criteria:\n- Image is published (e.g., ghcr.io/ORG/ghapp-token-gen:TAG) and <50MB compressed if feasible.\n- CI passes with vulnerability scan clean or justified.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Env/secret mounts and parameterization (APP_ID, PRIVATE_KEY, INSTALLATION_ID)",
            "description": "Define how workflows pass GitHub App credentials and installation parameters to the generator using secrets and params.",
            "dependencies": [
              "2.1"
            ],
            "details": "Workflow wiring patterns:\n- Mount K8s Secret for the chosen App and export env to the generator:\n  env:\n    - name: APP_ID\n      valueFrom: { secretKeyRef: { name: github-app-rex, key: appId } }\n    - name: PRIVATE_KEY\n      valueFrom: { secretKeyRef: { name: github-app-rex, key: privateKey } }\n    - name: INSTALLATION_ID\n      value: \"{{workflow.parameters.installationId}}\"  # optional\n    - name: OUTPUT_PATH\n      value: /var/run/github/token\n    - name: GITHUB_API_URL\n      value: https://api.github.com\n- Alternatively, mount secret as volume for large PEMs:\n  volumeMounts: [{ name: github-app-secret, mountPath: /secrets/github, readOnly: true }]\n  volumes:\n    - name: github-app-secret\n      secret: { secretName: github-app-rex }\n  Then set PRIVATE_KEY by reading /secrets/github/privateKey inside the container.\nParameters:\n- workflow.parameters.githubApp: one of {rex, clippy, qa, triage, security} to select which Secret to mount.\n- workflow.parameters.installationId: optional; if empty, generator will auto-discover via /app/installations.\nSecurity notes:\n- Avoid printing env with secrets. Prefer secret volume + file read for PRIVATE_KEY to minimize env exposure. Use least-privileged App per workflow role.\nAcceptance criteria:\n- A template can switch GitHub App by parameter and receives correct APP_ID/PRIVATE_KEY.\n- PRIVATE_KEY accessible to generator with no logs or leaks.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Workflow/initContainer or sidecar integration writing token to /var/run/github/token",
            "description": "Integrate the token generator as an initContainer or sidecar that writes token to a shared emptyDir consumed by main steps.",
            "dependencies": [
              "2.3",
              "2.4"
            ],
            "details": "Argo WorkflowTemplate snippet (initContainer pattern):\n- volumes:\n  - name: github-tmp\n    emptyDir: {}\n- initContainers:\n  - name: gh-token\n    image: ghcr.io/ORG/ghapp-token-gen:TAG\n    env: [APP_ID, PRIVATE_KEY, INSTALLATION_ID, OUTPUT_PATH=/var/run/github/token, GITHUB_API_URL=https://api.github.com]\n    volumeMounts:\n      - { name: github-tmp, mountPath: /var/run/github }\n      - { name: github-app-secret, mountPath: /secrets/github, readOnly: true }\n- containers (main):\n  - name: runner\n    image: alpine:3.20\n    env:\n      - name: GITHUB_TOKEN_FILE\n        value: /var/run/github/token\n    volumeMounts:\n      - { name: github-tmp, mountPath: /var/run/github }\nSecurity notes:\n- Token file mode 0600; do not echo token. Consider sidecar with periodic refresh for long-running jobs; initContainer is sufficient for <60 min tasks.\nAcceptance criteria:\n- Main step can read /var/run/github/token and successfully call GitHub APIs.\n- Token is not present in container logs or env dumps.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "RBAC scoping for reading secrets only",
            "description": "Create ServiceAccount, Role, and RoleBinding to allow workflow pods to read only the specific GitHub App secrets.",
            "dependencies": [
              "2.1"
            ],
            "details": "Manifests:\n- ServiceAccount: workflows-sa (namespace: workflows).\n- Role (namespace-scoped):\n  kind: Role\n  metadata: { name: github-app-secrets-read, namespace: workflows }\n  rules:\n    - apiGroups: [\"\"]\n      resources: [\"secrets\"]\n      resourceNames: [\"github-app-rex\",\"github-app-clippy\",\"github-app-qa\",\"github-app-triage\",\"github-app-security\"]\n      verbs: [\"get\"]\n- RoleBinding:\n  kind: RoleBinding\n  metadata: { name: workflows-sa-secrets-read, namespace: workflows }\n  subjects: [{ kind: ServiceAccount, name: workflows-sa }]\n  roleRef: { kind: Role, name: github-app-secrets-read, apiGroup: rbac.authorization.k8s.io }\nArgo config:\n- Set the Workflow defaultServiceAccount to workflows-sa or reference per WorkflowTemplate.\nSecurity notes:\n- Principle of least privilege: no list/watch on secrets, no cluster-wide access.\n- Ensure External Secrets Operator has separate, appropriate RBAC/IAM for SecretStore access.\nAcceptance criteria:\n- Workflow pods using workflows-sa can mount/read only the listed secrets; attempts to access other secrets are forbidden.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Rotation and failure handling (fast-fail, retries, backoff)",
            "description": "Implement token generator retry/backoff and document secret/token rotation behavior.",
            "dependencies": [
              "2.2",
              "2.5"
            ],
            "details": "Generator behavior:\n- Retries: exponential backoff for 5xx/429 (e.g., 5 attempts, base 500ms, max 5s, jitter). Fast-fail on 401/403 with clear message.\n- Token TTL management: respect expires_at; for sidecar mode, refresh at 80% TTL; for init mode, exit after write.\n- Atomic token write: write to temp file then rename; chmod 0600.\nExternalSecret rotation:\n- Set refreshInterval (e.g., 1h). Rotating backend secrets should update K8s Secret; new workflows pick up new credentials.\n- For live rotation needs, mount secrets as volumes and signal sidecar to reload (optional enhancement).\nCommand lines:\n- Rotate backend secret (provider-specific) then observe K8s Secret update: kubectl get secret github-app-rex -o jsonpath='{.metadata.resourceVersion}'.\nSecurity notes:\n- On rotation failure, do not continue with stale or partial tokens. Never fall back to PATs.\nAcceptance criteria:\n- 5xx transient errors are retried with backoff; 401/403 fail fast (non-zero exit).\n- After backend key rotation, new workflow runs succeed using refreshed secrets.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Tests and documentation (dry-run workflow, gh auth status, rotation test)",
            "description": "Add validation workflows and docs to verify token generation and secret rotation, and ensure no PAT usage.",
            "dependencies": [
              "2.1",
              "2.3",
              "2.5",
              "2.6",
              "2.7"
            ],
            "details": "Tests:\n- Dry-run Workflow: mount a GitHub App secret, run initContainer to write token, then main step runs:\n  - apk add gh (or use gh CLI image) and executes: GH_TOKEN=$(cat /var/run/github/token) gh auth status -h github.com -t \"$GH_TOKEN\"\n  - Call a read API (GET /rate_limit) to confirm access.\n- Negative test: inject invalid privateKey to confirm fast-fail and clear error.\n- Rotation test: update backend secret value; wait for ExternalSecret sync; rerun dry-run workflow and confirm success with new credentials.\nDocs:\n- README with: architecture diagram, security notes (no PATs; key handling; RBAC), how to choose init vs sidecar, parameters, troubleshooting matrix, and acceptance criteria.\nAcceptance criteria:\n- Dry-run workflow passes and prints authenticated status for the selected App account.\n- Negative test fails quickly with 401/403.\n- Rotation test demonstrates refreshed credentials being used in a subsequent run.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Common Argo WorkflowTemplate wrapper for CodeRun/DocsRun with simplified API",
        "description": "Create a reusable WorkflowTemplate that encapsulates creation of CodeRun/DocsRun CRs, auto-detects parameters from event payloads, and reduces required arguments to 1-2 per PRD.",
        "details": "Implementation:\n- Create a WorkflowTemplate named coderun-template with a template coderun-main using a resource template to create CodeRun CRs. Expose minimal params: github-app (required), taskRef (optional), repo/ref inferred.\n- Auto-detection logic:\n  - Read event payload from Argo Events (passed via workflow.parameters.event) to infer repo, owner, ref/branch, prNumber, issueNumber, workflowRunId, etc.\n  - If not provided, infer from git in workspace (git rev-parse --abbrev-ref HEAD).\n  - Mount controller-agents ConfigMap to locate the system prompt file based on github-app param.\n- Create an init step to prepare workspace and MCP tools; then resource step applies CodeRun CR:\n  templates:\n  - name: coderun-main\n    inputs:\n      parameters:\n        - name: github-app\n        - name: event\n          default: \"{}\"\n        - name: taskRef\n          default: \"\"\n    script:\n      image: alpine/git:latest\n      command: [sh]\n      source: |\n        echo \"$event\" > /tmp/event.json\n        OWNER=$(jq -r '.repository.owner.login // .organization.login // empty' /tmp/event.json)\n        REPO=$(jq -r '.repository.name // empty' /tmp/event.json)\n        REF=$(jq -r '.pull_request.head.ref // .ref // .workflow_run.head_branch // \"main\"' /tmp/event.json)\n        PRNR=$(jq -r '.pull_request.number // empty' /tmp/event.json)\n        echo \"owner=$OWNER repo=$REPO ref=$REF pr=$PRNR\" > /tmp/ctx\n    - name: create-coderun\n      resource:\n        action: create\n        manifest: |\n          apiVersion: taskmaster.io/v1\n          kind: CodeRun\n          metadata:\n            generateName: coderun-\n          spec:\n            repo: {{=sprig.jsonPath .workflow.parameters.event \"$.repository.full_name\"}}\n            ref: {{inputs.parameters.ref}}\n            prompts:\n              system: /etc/agents/{{inputs.parameters.github-app}}_system-prompt.md\n              user: task/prompt.md\n            mcpRequirementsFile: /work/requirements.yaml\n            github:\n              appName: {{inputs.parameters.github-app}}\n              tokenFile: /var/run/github/token\n            workspace:\n              path: /work/src\n            taskRef: {{inputs.parameters.taskRef}}\n- Additionally create a docsrun-template for documentation/deploy/acceptance tasks using DocsRun CRD.\n- Provide a separate Workflow called press-play that accepts a project list and creates child workflows for each backlog item, relying on coderun-template; include concurrency controls via spec.parallelism.\n- Ensure no CRDs changed; only create them via resource templates.",
        "testStrategy": "Unit-test the parameter auto-detection by feeding synthetic event payloads (PR, issue, workflow_run, push) and asserting inferred values. Integration: Submit a workflow referencing coderun-template and verify a CodeRun CR is created and reconciled by the existing controller. Validate minimal arguments work (only github-app provided). Negative tests: malformed events should gracefully default or fail with clear message.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define coderun-template WorkflowTemplate skeleton and minimal parameters",
            "description": "Create the base WorkflowTemplate named coderun-template with entrypoint coderun-main and minimal inputs.",
            "dependencies": [],
            "details": "- Name: coderun-template; entrypoint: coderun-main\n- Inputs (coderun-main):\n  - parameters:\n    - name: github-app (required)\n    - name: event (default: \"{}\")\n    - name: taskRef (default: \"\")\n- High-level templates (filled in by later subtasks):\n  - coderun-context (script) -> validate-prompt (script) -> create-coderun (resource)\n- Apply via kubectl and ensure argo recognizes the template.\nAcceptance criteria:\n- argo template list shows coderun-template with template coderun-main.\n- Only parameter required in happy path is github-app; event and taskRef have safe defaults.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement event payload ingestion and jq-based inference",
            "description": "Add coderun-context script template to parse Argo Events payload and infer repo/owner/ref/PR/issue/workflow_run/sha with fallbacks.",
            "dependencies": [
              "3.1"
            ],
            "details": "- Template name: coderun-context (script)\n- Image: alpine:3.19; install jq and git (apk add --no-cache jq git)\n- Inputs: parameters.event\n- Behavior:\n  - Write event to /tmp/event.json\n  - Infer values with jq; fallback to git in workspace (/work/src) or defaults (ref=main):\n    OWNER=$(jq -r '.repository.owner.login // .organization.login // empty' /tmp/event.json)\n    REPO=$(jq -r '.repository.name // empty' /tmp/event.json)\n    FULL=$(jq -r '.repository.full_name // empty' /tmp/event.json)\n    REF=$(jq -r '.pull_request.head.ref // .ref // .workflow_run.head_branch // empty' /tmp/event.json)\n    PRNR=$(jq -r '.pull_request.number // empty' /tmp/event.json)\n    ISSNR=$(jq -r '.issue.number // empty' /tmp/event.json)\n    WRID=$(jq -r '.workflow_run.id // empty' /tmp/event.json)\n    SHA=$(jq -r '.pull_request.head.sha // .after // .workflow_run.head_sha // empty' /tmp/event.json)\n    [ -z \"$REF\" ] && [ -d /work/src/.git ] && REF=$(cd /work/src && git rev-parse --abbrev-ref HEAD || true)\n    [ -z \"$FULL\" ] && [ -n \"$OWNER\" ] && [ -n \"$REPO\" ] && FULL=\"$OWNER/$REPO\"\n    [ -z \"$REF\" ] && REF=main\n  - Emit outputs.parameters: repoFullName, owner, repo, ref, prNumber, issueNumber, workflowRunId, sha, isPR (1 if PRNR set else 0)\n- Artifact: /tmp/event.json for debugging\nAcceptance criteria:\n- Given synthetic PR/issue/workflow_run/push payloads, outputs are correctly populated with sane defaults when fields are missing.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Workspace preparation and MCP requirements mounting",
            "description": "Prepare /work directories, mount MCP requirements and tokens, and ensure tools are available to subsequent steps.",
            "dependencies": [
              "3.1"
            ],
            "details": "- Volumes/mounts on coderun-main:\n  - ConfigMap controller-agents -> mountPath: /etc/agents (readOnly: true)\n  - ConfigMap mcp-requirements (key: requirements.yaml) -> mountPath: /work/requirements.yaml (subPath)\n  - Secret github-app-token (populated by Task 2) -> mountPath: /var/run/github/token (file)\n  - EmptyDir workspace -> mountPath: /work/src\n- Init step template: init-workspace (script, alpine:3.19)\n  - mkdir -p /work/src\n  - If git URL derivable from event, optional shallow clone can be skipped; CodeRun controller will manage workspace.\n  - Verify jq/git present or install as needed.\n- Standardize paths for downstream:\n  - Workspace: /work/src\n  - MCP requirements: /work/requirements.yaml\n  - System prompts: /etc/agents\n  - GitHub token: /var/run/github/token\nAcceptance criteria:\n- Workflow pod mounts all paths; files /etc/agents/*_system-prompt.md and /work/requirements.yaml are readable; /var/run/github/token exists.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "System prompt resolution via controller-agents ConfigMap",
            "description": "Derive the system prompt path from github-app and validate the file exists before creating CRs.",
            "dependencies": [
              "3.1"
            ],
            "details": "- Add validate-prompt (script) between coderun-context and create-coderun:\n  - PATH: /etc/agents\n  - FILE: /etc/agents/${GITHUB_APP}_system-prompt.md\n  - If not found, check /etc/agents/default_system-prompt.md; if neither exists, exit non-zero with clear message.\n- Inputs: parameter github-app; env GITHUB_APP sourced from inputs\n- Outputs: parameter systemPromptPath\n- Example snippet:\n  SYSTEM=\"/etc/agents/${GITHUB_APP}_system-prompt.md\"; [ -f \"$SYSTEM\" ] || SYSTEM=\"/etc/agents/default_system-prompt.md\"; [ -f \"$SYSTEM\" ] || { echo \"missing prompt\" >&2; exit 2; }; echo -n \"$SYSTEM\" > /tmp/system.txt\n- Use this path in CR manifests (subtask 5/6)\nAcceptance criteria:\n- For any valid github-app, the resolved prompt path points to an existing file; workflow fails fast if none exist.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Resource template to create CodeRun CR with simplified API",
            "description": "Emit a CodeRun CR using resource template with minimal params (github-app required, taskRef optional) and inferred repo/ref.",
            "dependencies": [
              "3.2",
              "3.3",
              "3.4"
            ],
            "details": "- Add create-coderun (resource) in coderun-template:\n  apiVersion: argoproj.io/v1alpha1\n  kind: WorkflowTemplate\n  ... templates:\n    - name: coderun-main\n      inputs:\n        parameters:\n          - name: github-app\n          - name: event\n            value: \"{}\"\n          - name: taskRef\n            value: \"\"\n      steps:\n        - - name: context\n            template: coderun-context\n            arguments: {parameters: [{name: event, value: '{{inputs.parameters.event}}'}]}\n          - name: validate-prompt\n            template: validate-prompt\n            arguments: {parameters: [{name: github-app, value: '{{inputs.parameters.github-app}}'}]}\n        - - name: create\n            template: create-coderun\n            arguments:\n              parameters:\n                - {name: github-app, value: '{{inputs.parameters.github-app}}'}\n                - {name: taskRef, value: '{{inputs.parameters.taskRef}}'}\n    - name: create-coderun\n      inputs:\n        parameters:\n          - name: github-app\n          - name: taskRef\n      resource:\n        action: create\n        manifest: |\n          apiVersion: taskmaster.io/v1\n          kind: CodeRun\n          metadata:\n            generateName: coderun-\n          spec:\n            repo: \"{{steps.context.outputs.parameters.repoFullName}}\"\n            ref: \"{{steps.context.outputs.parameters.ref}}\"\n            prompts:\n              system: \"{{steps.validate-prompt.outputs.parameters.systemPromptPath}}\"\n              user: \"task/prompt.md\"\n            mcpRequirementsFile: \"/work/requirements.yaml\"\n            github:\n              appName: \"{{inputs.parameters.github-app}}\"\n              tokenFile: \"/var/run/github/token\"\n            workspace:\n              path: \"/work/src\"\n            taskRef: \"{{inputs.parameters.taskRef}}\"\n- Ensure no CRDs are modified; only instantiated via resource action create.\nAcceptance criteria:\n- argo submit --from workflowtemplate/coderun-template -p github-app=clippy creates a CodeRun CR with repo/ref inferred from provided event or defaults.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Create docsrun-template for DocsRun CRD",
            "description": "Provide a parallel WorkflowTemplate for DocsRun tasks with the same simplified API and inference.",
            "dependencies": [
              "3.2",
              "3.3",
              "3.4"
            ],
            "details": "- Name: docsrun-template; entrypoint: docsrun-main\n- Parameters: github-app (required), event (default: \"{}\"), taskRef (default: \"\")\n- Reuse coderun-context and validate-prompt via templateRef or duplicate templates for isolation.\n- Resource manifest snippet:\n  apiVersion: taskmaster.io/v1\n  kind: DocsRun\n  metadata:\n    generateName: docsrun-\n  spec:\n    repo: \"{{steps.context.outputs.parameters.repoFullName}}\"\n    ref: \"{{steps.context.outputs.parameters.ref}}\"\n    prompts:\n      system: \"{{steps.validate-prompt.outputs.parameters.systemPromptPath}}\"\n      user: \"docs/task.md\"\n    github:\n      appName: \"{{inputs.parameters.github-app}}\"\n      tokenFile: \"/var/run/github/token\"\n    workspace:\n      path: \"/work/src\"\n    taskRef: \"{{inputs.parameters.taskRef}}\"\n    docs:\n      path: \"docs/\"\n      action: \"build-preview\"\nAcceptance criteria:\n- argo submit --from workflowtemplate/docsrun-template -p github-app=clippy creates a DocsRun CR with inferred repo/ref and no other required params.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Press-play orchestrator workflow with concurrency controls",
            "description": "Create a Workflow that fans out over a backlog list and invokes coderun-template for each item with parallelism limits.",
            "dependencies": [
              "3.5",
              "3.6"
            ],
            "details": "- Name: press-play (Workflow)\n- Parameters:\n  - backlog (JSON array of items: [{\"githubApp\":\"clippy\",\"taskRef\":\"task/format\"}, ...])\n  - parallelism (default: 3)\n  - event (optional, default: \"{}\")\n- spec.parallelism: \"{{workflow.parameters.parallelism}}\"\n- Template: run-backlog (steps or DAG) with withParam over {{workflow.parameters.backlog}}:\n  - Each item submits coderun-template via templateRef:\n    templateRef: {name: coderun-template, template: coderun-main}\n    arguments:\n      parameters:\n        - {name: github-app, value: '{{item.githubApp}}'}\n        - {name: taskRef, value: '{{item.taskRef}}'}\n        - {name: event, value: '{{workflow.parameters.event}}'}\n- Optional: retryStrategy for transient errors; pod GC policy to clean completed pods.\nAcceptance criteria:\n- Submitting press-play with N backlog items starts N CodeRuns, capped by parallelism; all succeed when coderun-template succeeds.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Negative-path handling and robust defaults",
            "description": "Define and implement failure modes and safe defaults when inference fails; prevent malformed CR creation.",
            "dependencies": [
              "3.2",
              "3.5"
            ],
            "details": "- In coderun-context:\n  - If repoFullName is empty and cannot be constructed from owner/repo and no git remote present, write a clear error and exit 78.\n  - Ensure ref defaults to main when not found.\n  - Validate github-app is non-empty in coderun-main; fail fast otherwise.\n- In validate-prompt:\n  - Fail clearly if no prompt files found; include searched paths in message.\n- In create-coderun:\n  - Add successCondition and failureCondition (if using k8s resource template) to surface CR creation errors:\n    successCondition: status.phase in (Created,Queued,Running)\n    failureCondition: status.phase in (Error,Failed)\n- Logging: echo resolved context (owner/repo/ref/pr/issue/sha) for audit.\nAcceptance criteria:\n- With empty/invalid event and no git context, workflow fails before creating a CR with actionable error.\n- With missing prompt file, workflow fails in validate-prompt step.\n- With missing ref, defaults to main and proceeds.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Unit/integration tests with synthetic events and documentation",
            "description": "Add tests for inference and end-to-end CR creation; provide README and examples.",
            "dependencies": [
              "3.5",
              "3.6",
              "3.7",
              "3.8"
            ],
            "details": "- Unit tests (scripted):\n  - Run coderun-context locally/in a Job with examples/events/*.json for: pull_request, issue_comment, workflow_run, push.\n  - Assert outputs: repoFullName, ref, prNumber, etc., and defaults.\n- Integration:\n  - argo submit --from workflowtemplate/coderun-template -p github-app=clippy -p event=\"$(cat examples/events/pr.opened.json)\" --watch; verify k get coderuns shows a new CR with expected spec.\n  - argo submit --from workflowtemplate/docsrun-template -p github-app=clippy --watch; verify DocsRun CR created.\n  - argo submit press-play -p backlog='[{\"githubApp\":\"clippy\",\"taskRef\":\"task/format\"},{\"githubApp\":\"qa\",\"taskRef\":\"task/verify\"}]' -p parallelism=2\n- Documentation:\n  - README.md covering parameters, default resolution, required mounts/paths, examples, and acceptance criteria (only github-app required in happy path).\n  - Place sample payloads under examples/events/ and command cheatsheet under examples/README.md.\nAcceptance criteria:\n- All unit tests pass; CRs are created in integration runs; docs clearly show that only github-app is required for happy path.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "PR validation DAG WorkflowTemplate (Clippy → QA) with compliance gates",
        "description": "Implement the PR validation flow as an Argo DAG that runs Clippy then QA, enforcing fmt/clippy pedantic/zero warnings and QA verification in Kubernetes with proof.",
        "details": "Implementation:\n- Create WorkflowTemplate pr-validation with entrypoint dag:\n  dag:\n    tasks:\n      - name: clippy-format\n        templateRef: {name: coderun-template, template: coderun-main}\n        arguments:\n          parameters:\n            - {name: github-app, value: clippy}\n      - name: qa-testing\n        dependencies: [clippy-format]\n        templateRef: {name: coderun-template, template: coderun-main}\n        arguments:\n          parameters:\n            - {name: github-app, value: qa}\n      - name: verify-compliance\n        dependencies: [clippy-format]\n        template: verify-compliance\n      - name: verify-k8s-proof\n        dependencies: [qa-testing]\n        template: verify-k8s-proof\n- Add verify-compliance template (container step) to independently enforce gates:\n  - Runs: `cargo fmt --check && cargo clippy -- -D warnings` (or language-specific equivalents) based on repo language; use a language detector or project config to choose toolchain.\n  - Fails the DAG if non-zero warnings.\n- Add verify-k8s-proof template to parse QA artifacts for proof of Kubernetes verification (logs, curl responses), and ensure artifacts exist (e.g., /artifacts/qa/proof/*.log). If missing, fail.\n- Expose outputs: links to PR, CI runs, and artifacts via workflow.outputs.parameters.\n- Ensure both verify-compliance and verify-k8s-proof are required; the overall workflow fails if they fail.\nPseudocode (verify-k8s-proof):\n- Check existence of /artifacts/qa/proof/summary.json; validate fields: cluster, namespace, testCases[], evidence[].\n- kubectl get pods/services for the namespace and include into artifacts for auditability.",
        "testStrategy": "E2E: Open a PR; trigger pr-validation via event (or manual). Validate that Clippy agent modifies code and pushes commits; verify-compliance fails when warnings introduced and passes when clean. QA step must generate artifacts; verify-k8s-proof fails if artifacts missing. Confirm PR remains unmerged and QA agent posts review comments. Collect logs and confirm correlation labels are present.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "DAG skeleton: pr-validation WorkflowTemplate (Clippy → QA) via coderun-template",
            "description": "Create the pr-validation WorkflowTemplate with a DAG entrypoint wiring clippy-format → qa-testing, plus verify-compliance and verify-k8s-proof tasks.",
            "dependencies": [],
            "details": "- Define WorkflowTemplate: name pr-validation, entrypoint dag.\n- DAG tasks:\n  - clippy-format: templateRef coderun-template/coderun-main with parameter github-app=clippy.\n  - qa-testing: depends on clippy-format; templateRef coderun-template/coderun-main with github-app=qa.\n  - verify-compliance: depends on clippy-format; template verify-compliance (added in subtask 2).\n  - verify-k8s-proof: depends on qa-testing; template verify-k8s-proof (added in subtask 3).\n- Inputs/params: accept repo, owner, prNumber, ref, event payload pointer (as needed by coderun-template).\n- Volumes/artifacts: mount a shared /artifacts workspace (emptyDir or artifact repository) accessible by all tasks.\n- Acceptance criteria:\n  - kubectl apply of the template is valid.\n  - argo lint passes.\n  - Submitting the workflow creates four tasks with correct dependencies.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "verify-compliance template: language detection + fmt/lint/clippy gates",
            "description": "Add a container template that enforces zero warnings and format compliance, with language detection and repo-config overrides.",
            "dependencies": [
              "4.1"
            ],
            "details": "- Container image: ghcr.io/your-org/ci-multilang:latest (includes: bash, git, jq, yq, rustup/cargo/rustfmt/clippy, node/npm/npx/eslint/prettier, go/gofmt/golangci-lint, python3/pip/black/ruff, shellcheck).\n- Command (entry script outline):\n  - Detect language:\n    - If .pr-validation.yml exists, read language and custom commands.\n    - Else: Rust if Cargo.toml; Node if package.json; Go if go.mod; Python if pyproject.toml or requirements.txt; fallback to shell lint only.\n  - Rust:\n    - rustup component add rustfmt clippy || true\n    - cargo fmt --all -- --check\n    - cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic\n  - Node:\n    - npm ci\n    - npx prettier -c .\n    - npx eslint . --max-warnings=0\n  - Go:\n    - test -z \"$(gofmt -l .)\" || { echo 'gofmt issues'; exit 1; }\n    - golangci-lint run --timeout 5m\n  - Python:\n    - pip install -U pip\n    - pip install black ruff\n    - black --check .\n    - ruff check --no-cache\n  - On success, write /artifacts/compliance/summary.json with fields: {language, tools: {name,version}, fmtStatus, lintStatus, warningsCount, timestamp}.\n- Config override: .pr-validation.yml supports keys: language, fmtCommand, lintCommand, workingDir.\n- Artifact schema (summary.json):\n  - language: string\n  - tools: array of {name:string, version:string}\n  - fmtStatus: \"passed\"|\"failed\"\n  - lintStatus: \"passed\"|\"failed\"\n  - warningsCount: integer (0 required)\n  - timestamp: RFC3339 string\n- Acceptance criteria:\n  - Fails when warningsCount > 0 or any fmt check fails.\n  - Produces summary.json with populated tool versions.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "verify-k8s-proof template: validate QA artifacts and collect cluster evidence",
            "description": "Add a container template that validates /artifacts/qa/proof/summary.json and evidence logs, and captures kubectl inventory into artifacts.",
            "dependencies": [
              "4.1"
            ],
            "details": "- Container image: ghcr.io/your-org/kubectl-jq:1.30 (kubectl 1.30, jq, bash, tar).\n- Inputs: expects QA step to write /artifacts/qa/proof/summary.json and evidence files under /artifacts/qa/proof/.\n- Validation steps:\n  - Check existence of summary.json.\n  - jq validation: require fields: cluster (string), namespace (string), testCases (array of {name,status,details?}), evidence (array of {path,type}). Ensure testCases[].status ∈ {passed,failed,skipped}.\n  - Verify each evidence[].path exists (e.g., *.log, *.json, screenshots) under /artifacts/qa/proof/.\n  - Fail if any required field missing or any evidence path missing.\n- Cluster audit capture:\n  - kubectl get pods -n \"$NAMESPACE\" -o json > /artifacts/qa/proof/cluster-pods.json\n  - kubectl get services -n \"$NAMESPACE\" -o json > /artifacts/qa/proof/cluster-services.json\n  - Optional: kubectl get events -n \"$NAMESPACE\" -o json > /artifacts/qa/proof/cluster-events.json\n- Derive NAMESPACE from summary.json (.namespace) and export as env.\n- Output: write /artifacts/qa/proof/verification.json with fields: {valid:true|false, missingEvidence:[], counts:{tests:int,passed:int,failed:int}, timestamp}.\n- Acceptance criteria:\n  - Fails if summary.json missing/invalid or evidence files absent.\n  - Succeeds when schema valid and evidence present; emits cluster inventory artifacts.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Artifact wiring and workflow outputs (PR/CI links, artifact paths)",
            "description": "Wire artifacts between tasks and expose workflow outputs with links to PR, CI runs, and artifact locations.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "- Shared artifact path: mount /artifacts for all tasks (emptyDir or artifact repository). Ensure coderun-template writes QA outputs under /artifacts/qa/.\n- Expose outputs via workflow.outputs.parameters:\n  - pr-url: from event payload or coderun-template outputs file (/tmp/pr-url).\n  - ci-run-url: from coderun-template output (/tmp/ci-run-url) if available.\n  - compliance-summary: path reference /artifacts/compliance/summary.json.\n  - qa-proof-summary: path reference /artifacts/qa/proof/summary.json.\n- Add artifact outputs (S3/Artifactory configured in Argo):\n  - name: compliance-summary, path: /artifacts/compliance/summary.json\n  - name: qa-proof, path: /artifacts/qa/proof/\n- Template snippets:\n  - Use outputs.parameters.from to read files (e.g., '{{tasks.verify-compliance.outputs.parameters.compliance-summary}}').\n- Acceptance criteria:\n  - argo get shows outputs parameters populated.\n  - Downloaded artifacts contain compliance summary and QA proof folder.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Failure policies and gates: ensure both verify-* tasks block success",
            "description": "Configure DAG behavior so both verification steps are required, with explicit gating and appropriate retries.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4"
            ],
            "details": "- Add a final gates-passed task (template: script that echoes success) depending on [verify-compliance, verify-k8s-proof].\n- Do not set continueOn: failed on verification tasks; allow DAG-level failFast: false so both branches run and surface errors concurrently.\n- Overall success requires gates-passed to run; overall failure occurs if any verify-* fails (Argo prevents gates-passed from running).\n- Retry strategy:\n  - clippy-format and qa-testing: retries: 1-2 with exponential backoff.\n  - verify-compliance and verify-k8s-proof: no retry (logic errors should fail fast).\n- Acceptance criteria:\n  - If either verify-* fails, workflow status is Failed and gates-passed does not execute.\n  - If both pass, workflow status is Succeeded and gates-passed executed.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Test data and E2E scenarios",
            "description": "Create fixtures and end-to-end tests covering clean and failing paths, including missing artifacts and introduced warnings.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4",
              "4.5"
            ],
            "details": "- Test repos/fixtures:\n  - Rust project (clean): no clippy warnings; QA step writes valid proof summary and logs.\n  - Rust project (warning): introduce allow(dead_code) removal to trigger warning; expect verify-compliance fail.\n  - QA missing artifacts: run QA without writing /artifacts/qa/proof/summary.json; expect verify-k8s-proof fail.\n- E2E flows:\n  - Submit workflow with parameters referencing test repo/PR; verify task sequence and outcomes.\n  - Validate workflow outputs parameters and artifact contents.\n- Commands:\n  - argo submit --from wftmpl/pr-validation -p owner=... -p repo=... -p prNumber=...\n  - argo watch <wf-name>\n- Acceptance criteria:\n  - Clean case: all tasks succeed; gates-passed runs; outputs populated.\n  - Warning case: verify-compliance fails with logs showing -D warnings; workflow fails.\n  - Missing artifact case: verify-k8s-proof fails citing missing summary.json/evidence.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Documentation and required repo/configs",
            "description": "Document required repository structure, configuration, artifact schemas, images, and acceptance criteria for teams.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4",
              "4.5",
              "4.6"
            ],
            "details": "- Required repo elements:\n  - For Rust: Cargo.toml, rust-toolchain (optional), rustfmt/clippy configs; ensure code compiles for clippy.\n  - QA step must write /artifacts/qa/proof/summary.json and evidence files; provide example generator script.\n  - Optional .pr-validation.yml to override language and commands:\n    - keys: language, fmtCommand, lintCommand, workingDir.\n- Artifact schema references:\n  - compliance summary: {language, tools[], fmtStatus, lintStatus, warningsCount, timestamp}.\n  - QA proof summary: {cluster, namespace, testCases[], evidence[]}.\n- Container images used:\n  - ghcr.io/your-org/ci-multilang:latest\n  - ghcr.io/your-org/kubectl-jq:1.30\n- RBAC and environment:\n  - ServiceAccount with read-only access to target namespaces for kubectl get pods/services/events.\n  - Variables required by templates (e.g., GITHUB_* from token generator in Task 2; namespace resolution from summary.json).\n- Acceptance criteria:\n  - README with setup steps and examples.\n  - Example .pr-validation.yml and QA proof summary.json templates included.\n  - Teams can adopt the workflow by adding QA artifact generation and optional config file.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 5,
        "title": "Implementation DAG WorkflowTemplate (Rex → Clippy → QA → Deploy → Acceptance)",
        "description": "Create an Argo DAG for task/issue implementation including deployment and acceptance verification as per FR3.",
        "details": "Implementation:\n- WorkflowTemplate implementation with tasks:\n  - implement (Rex): templateRef coderun-template; github-app=rex\n  - clippy-format: depends implement; github-app=clippy\n  - qa-testing: depends clippy-format; github-app=qa\n  - deploy: depends qa-testing; template: deploy (DocsRun or container step)\n  - acceptance: depends deploy; template: acceptance (DocsRun/container step)\n- deploy template:\n  - Uses DocsRun CR to execute deployment script (e.g., helm upgrade --install to a preview namespace) using existing infra/Argo CD patterns; avoid secret duplication; namespace per PR/task as available.\n- acceptance template:\n  - Runs black-box checks against the deployed service endpoints; captures logs/responses to artifacts; enforces success thresholds.\n- Ensure rollback/cleanup on failure (best-effort): delete preview releases/namespace.\n- Emphasize no auto-merge; success results in QA approval only.\n- Output parameters include deploy URLs and evidence artifact paths.\nPseudocode (deploy via DocsRun resource template):\napiVersion: taskmaster.io/v1\nkind: DocsRun\nmetadata:\n  generateName: docsrun-deploy-\nspec:\n  command: [\"/bin/sh\",\"-lc\",\"helm upgrade --install ${RELEASE} charts/app -n ${NS} --values values-preview.yaml\"]",
        "testStrategy": "Trigger via issue-to-task flow; confirm Rex commits code; clippy runs and cleans; QA generates tests; deploy creates a preview environment in the expected namespace; acceptance verifies endpoints and gathers proof artifacts. Failure cases: acceptance fails on 5xx and blocks approval. Ensure resources are cleaned on failure.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Argo WorkflowTemplate DAG (Rex → Clippy → QA → Deploy → Acceptance)",
            "description": "Create the top-level WorkflowTemplate with a DAG entrypoint encoding the task order and high-level parameters.",
            "dependencies": [],
            "details": "- Create WorkflowTemplate name: implementation-dag (or fr3-impl-dag) with entrypoint dag.\n- Global parameters (with sane defaults): repo, owner, pr, commit, domain, chartPath, valuesFile, imageTag, env.\n- DAG tasks in order: implement, clippy-format, qa-testing, deploy, acceptance. Use templateRef for coderun-template in first three; custom templates for deploy and acceptance.\n- Wire task dependencies explicitly: clippy-format depends implement; qa-testing depends clippy-format; deploy depends qa-testing; acceptance depends deploy.\n- Example skeleton (excerpt):\n  apiVersion: argoproj.io/v1alpha1\n  kind: WorkflowTemplate\n  metadata:\n    name: implementation-dag\n  spec:\n    entrypoint: dag\n    arguments:\n      parameters:\n        - {name: owner}\n        - {name: repo}\n        - {name: pr}\n        - {name: commit, value: \"\"}\n        - {name: domain, value: preview.example.com}\n        - {name: chartPath, value: charts/app}\n        - {name: valuesFile, value: values-preview.yaml}\n        - {name: imageTag, value: \"pr-{{workflow.parameters.pr}}\"}\n    templates:\n      - name: dag\n        dag:\n          tasks:\n            - name: implement\n              templateRef: {name: coderun-template, template: coderun-main}\n              arguments: {parameters: [{name: github-app, value: rex}]}\n            - name: clippy-format\n              dependencies: [implement]\n              templateRef: {name: coderun-template, template: coderun-main}\n              arguments: {parameters: [{name: github-app, value: clippy}]}\n            - name: qa-testing\n              dependencies: [clippy-format]\n              templateRef: {name: coderun-template, template: coderun-main}\n              arguments: {parameters: [{name: github-app, value: qa}]}\n            - name: deploy\n              dependencies: [qa-testing]\n              template: deploy\n            - name: acceptance\n              dependencies: [deploy]\n              template: acceptance\n- Add onExit template placeholder for cleanup; implemented in a later subtask.\n- Acceptance criteria: WorkflowTemplate validates with kubectl; argo list templates shows implementation-dag; dry-run produces DAG with the exact dependencies.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Coderun invocations for Rex, Clippy, and QA",
            "description": "Invoke coderun-template for implement, clippy-format, and qa-testing with correct github-app parameterization and artifact conventions.",
            "dependencies": [
              "5.1"
            ],
            "details": "- For each of the three tasks, pass parameters: owner, repo, pr, commit (if applicable), github-app in {rex, clippy, qa}.\n- Mount GitHub App token via the token generator sidecar (Task 2), expose token at /var/run/github/token.\n- Set consistent working directory (/workspace) and artifact root (/artifacts/{task}).\n- Example task argument block:\n  arguments:\n    parameters:\n      - {name: github-app, value: rex}\n      - {name: owner, value: {{workflow.parameters.owner}}}\n      - {name: repo, value: {{workflow.parameters.repo}}}\n      - {name: pr, value: {{workflow.parameters.pr}}}\n- Expected outputs/artifacts per task:\n  - implement: /artifacts/rex/commit.txt, /artifacts/rex/logs.txt\n  - clippy-format: /artifacts/clippy/report.json, /artifacts/clippy/logs.txt\n  - qa-testing: /artifacts/qa/proof/index.json, /artifacts/qa/logs.txt\n- Enforce that coderun steps never attempt merges; they may push commits to the PR.\n- Acceptance criteria: On a test PR, Rex produces commits; Clippy runs and formats; QA produces proof artifacts in the specified paths. All three tasks succeed in sequence.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Deploy template using DocsRun to helm upgrade/install to preview namespace",
            "description": "Create deploy template leveraging DocsRun CR to install/upgrade the app in a per-PR namespace following existing Argo CD/infra patterns.",
            "dependencies": [
              "5.2",
              "5.5"
            ],
            "details": "- Implement Argo template: deploy (type: resource) to create a DocsRun CR.\n- Parameters consumed: NS, RELEASE, chartPath, valuesFile, imageTag, owner, repo, pr.\n- Pre-deploy: ensure namespace exists and label it; avoid duplicating secrets by referencing shared ExternalSecrets/Secrets.\n- Helm command example: helm upgrade --install ${RELEASE} ${CHART_PATH} -n ${NS} -f ${VALUES_FILE} --set image.tag=${IMAGE_TAG}\n- Example template:\n  - name: deploy\n    inputs:\n      parameters:\n        - {name: NS}\n        - {name: RELEASE}\n        - {name: chartPath, value: {{workflow.parameters.chartPath}}}\n        - {name: valuesFile, value: {{workflow.parameters.valuesFile}}}\n        - {name: imageTag, value: {{workflow.parameters.imageTag}}}\n    resource:\n      action: create\n      manifest: |\n        apiVersion: taskmaster.io/v1\n        kind: DocsRun\n        metadata:\n          generateName: docsrun-deploy-\n        spec:\n          command: [\"/bin/sh\",\"-lc\",\"set -euo pipefail; kubectl get ns ${NS} >/dev/null 2>&1 || kubectl create ns ${NS}; kubectl label ns ${NS} preview=true pr=${PR} --overwrite; helm upgrade --install ${RELEASE} ${CHART_PATH} -n ${NS} -f ${VALUES_FILE} --set image.tag=${IMAGE_TAG}; kubectl get ing -n ${NS} -o json > /tmp/ing.json; jq -r '[.items[].spec.rules[].host] | {hosts: ., ns: \"'${NS}'\", release: \"'${RELEASE}'\"}' /tmp/ing.json > /tmp/urls.json\" ]\n          env:\n            - {name: NS, value: \"{{inputs.parameters.NS}}\"}\n            - {name: RELEASE, value: \"{{inputs.parameters.RELEASE}}\"}\n            - {name: CHART_PATH, value: \"{{inputs.parameters.chartPath}}\"}\n            - {name: VALUES_FILE, value: \"{{inputs.parameters.valuesFile}}\"}\n            - {name: IMAGE_TAG, value: \"{{inputs.parameters.imageTag}}\"}\n            - {name: PR, value: \"{{workflow.parameters.pr}}\"}\n    outputs:\n      artifacts:\n        - name: deploy-urls\n          path: /tmp/urls.json\n- Output: urls.json containing hosts, ns, release.\n- Acceptance criteria: Helm install succeeds in a new or existing preview namespace; docsrun outputs urls.json artifact; no new secrets created for GitHub Apps.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Acceptance template with black-box checks and artifact collection",
            "description": "Implement acceptance template to probe service endpoints, enforce success thresholds, and capture artifacts (responses/logs).",
            "dependencies": [
              "5.3",
              "5.5"
            ],
            "details": "- Template type: container or DocsRun; use container for portability.\n- Inputs: urls.json from deploy, thresholds (min_success_pct, max_p95_ms), NS/RELEASE for context.\n- Behavior:\n  - Parse urls.json to get hosts; for each host, perform N HTTP GETs with timeouts.\n  - Consider a request successful if status < 500 and response within timeout.\n  - Collect artifacts: acceptance/report.json (summary and per-endpoint results), acceptance/responses/*.txt, acceptance/logs.txt.\n  - Fail step if success ratio below threshold or any 5xx encountered if policy requires.\n- Example template:\n  - name: acceptance\n    inputs:\n      artifacts:\n        - name: deploy-urls\n          path: /input/urls.json\n      parameters:\n        - {name: min_success_pct, value: \"0.95\"}\n        - {name: max_p95_ms, value: \"1200\"}\n    container:\n      image: curlimages/curl:8.8.0\n      command: [\"/bin/sh\",\"-lc\"]\n      args:\n        - |\n          set -euo pipefail\n          mkdir -p /artifacts/acceptance/responses\n          HOSTS=$(jq -r '.hosts[]' /input/urls.json)\n          TOTAL=0 OK=0; TIMES=\"\"\n          for H in $HOSTS; do\n            for i in $(seq 1 10); do\n              START=$(date +%s%3N)\n              CODE=$(curl -ksS -o /artifacts/acceptance/responses/${H//./_}-$i.txt -w \"%{http_code}\" https://$H/ || true)\n              END=$(date +%s%3N); LAT=$((END-START))\n              TOTAL=$((TOTAL+1))\n              if [ \"$CODE\" -lt 500 ] && [ \"$CODE\" -ge 200 ]; then OK=$((OK+1)); TIMES=\"$TIMES $LAT\"; fi\n              echo \"$H $i $CODE $LAT\" >> /artifacts/acceptance/logs.txt\n            done\n          done\n          P95=$(printf \"%s\\n\" $TIMES | awk '{ print $1 }' | sort -n | awk 'BEGIN{c=0} {a[c++]=$1} END{ if (c==0) {print 999999} else { print a[int(0.95*c)] } }')\n          SUCCESS=$(awk -v o=$OK -v t=$TOTAL 'BEGIN{ if(t==0){print 0}else{print o/t} }')\n          jq -n --argjson success \"$SUCCESS\" --argjson p95 \"$P95\" --arg ns \"{{tasks.deploy.outputs.parameters.NS}}\" '{ns:$ns, success_pct:$success, p95_ms:$p95}' > /artifacts/acceptance/report.json\n          awk -v s=$SUCCESS -v thr={{inputs.parameters.min_success_pct}} -v p=$P95 -v pthr={{inputs.parameters.max_p95_ms}} 'BEGIN{ if(s+0<thr+0 || p+0>pthr+0) exit 2 }'\n    outputs:\n      artifacts:\n        - {name: acceptance-report, path: /artifacts/acceptance/report.json}\n        - {name: acceptance-logs, path: /artifacts/acceptance/logs.txt}\n- Acceptance criteria: Step fails if thresholds violated; artifacts present; report captures per-run metrics and overall success.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Environment discovery and parameterization (namespace and release naming)",
            "description": "Implement a setup template that computes namespace, release, and related parameters and exposes them to dependent tasks.",
            "dependencies": [
              "5.1"
            ],
            "details": "- Create a script template set-params that determines:\n  - NS = impl-pr-${pr}\n  - RELEASE = ${repo}-pr-${pr}\n  - DOMAIN derived from workflow.parameters.domain\n  - IMAGE_TAG from workflow.parameters.imageTag (default pr-<pr>)\n- Expose outputs as parameters for use by deploy and acceptance.\n- Example template:\n  - name: set-params\n    script:\n      image: alpine:3.20\n      command: [\"/bin/sh\",\"-lc\"]\n      source: |\n        set -euo pipefail\n        NS=\"impl-pr-{{workflow.parameters.pr}}\"\n        RELEASE=\"{{workflow.parameters.repo}}-pr-{{workflow.parameters.pr}}\"\n        echo -n $NS > /tmp/ns\n        echo -n $RELEASE > /tmp/release\n    outputs:\n      parameters:\n        - name: NS\n          valueFrom: {path: /tmp/ns}\n        - name: RELEASE\n          valueFrom: {path: /tmp/release}\n- Wire DAG: add a dag task set-params at the beginning; make deploy and acceptance consume its outputs via withParam references.\n- Acceptance criteria: NS and RELEASE match naming scheme; values are accessible in templates 3 and 4 via inputs.parameters.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Rollback/cleanup on failure (best-effort)",
            "description": "Implement onExit cleanup to uninstall preview release and delete namespace if the workflow fails, without impacting successful runs.",
            "dependencies": [
              "5.3",
              "5.4",
              "5.5"
            ],
            "details": "- Add onExit: cleanup template that checks {{workflow.status}}. If Failed/Error, attempt helm uninstall and ns deletion. If Succeeded, keep for manual review with TTL.\n- Prefer DocsRun CR for cleanup or a lightweight kubectl/helm container.\n- Strategy:\n  - Labels: all resources labeled preview=true pr=<pr> so they can be selected.\n  - Commands:\n    helm uninstall ${RELEASE} -n ${NS} || true\n    kubectl delete ns ${NS} --ignore-not-found=true || true\n  - Optional: set TTL on the namespace via annotation for cluster janitor.\n- Example onExit template:\n  - name: cleanup\n    inputs:\n      parameters:\n        - {name: NS}\n        - {name: RELEASE}\n    script:\n      image: alpine/helm:3.14.4\n      command: [\"/bin/sh\",\"-lc\"]\n      source: |\n        set -euo pipefail\n        if [ \"{{workflow.status}}\" != \"Succeeded\" ]; then\n          echo \"Cleaning up preview ${RELEASE} in ${NS}\"\n          helm uninstall \"{{inputs.parameters.RELEASE}}\" -n \"{{inputs.parameters.NS}}\" || true\n          kubectl delete ns \"{{inputs.parameters.NS}}\" --ignore-not-found=true || true\n        else\n          echo \"Workflow succeeded; leaving preview env for QA approval only.\"\n        fi\n- Wire onExit at WorkflowTemplate spec level and pass NS/RELEASE from set-params outputs.\n- Acceptance criteria: Simulate a failing acceptance; namespace/release are removed; simulate success; environment remains.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Outputs and evidence schema (deploy URLs and artifact paths)",
            "description": "Define workflow-level outputs and standardized artifact schema for downstream consumers and FR3 evidence.",
            "dependencies": [
              "5.3",
              "5.4"
            ],
            "details": "- Define outputs.parameters in the main DAG wrapper to surface:\n  - preview_urls (JSON from deploy-urls)\n  - acceptance_report_path (artifact URI)\n  - acceptance_logs_path (artifact URI)\n- Artifact schema:\n  - deploy-urls: {hosts: [\"host1\",\"host2\"], ns: \"impl-pr-123\", release: \"repo-pr-123\"}\n  - acceptance/report.json: {ns, success_pct (0..1), p95_ms (int), timestamp, endpoints: [{host, samples, successes, failures, p95_ms}]}\n- Example outputs wiring in Workflow spec:\n  outputs:\n    parameters:\n      - name: preview_urls\n        valueFrom: {artifact: {name: deploy-urls, from: \"{{tasks.deploy.outputs.artifacts.deploy-urls}}\"}}\n      - name: acceptance_report_path\n        value: \"{{workflow.outputs.artifacts.acceptance-report.url}}\"\n      - name: acceptance_logs_path\n        value: \"{{workflow.outputs.artifacts.acceptance-logs.url}}\"\n- Ensure no auto-merge behavior; these outputs are used for QA approval only (per FR3).\n- Acceptance criteria: After a successful run, parameters are populated; artifacts are browseable in the artifact repository; JSON validates against the documented schema.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Security: secret reuse and access controls (no duplication)",
            "description": "Ensure the workflow reuses ExternalSecrets and token generator (Task 2), and enforce least-privilege RBAC for DocsRun and Kubernetes access.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3"
            ],
            "details": "- Secret reuse:\n  - Mount GitHub App secrets via ExternalSecret-provisioned Kubernetes Secrets; no duplication per namespace.\n  - Token generator sidecar mounts APP_ID/PRIVATE_KEY and exposes /var/run/github/token (read-only) to main containers.\n- RBAC:\n  - ServiceAccount with permissions to create DocsRun CRs, get/list namespaces, get/list ingresses, install Helm releases in target NS.\n  - ClusterRole example rules: [docsrun.taskmaster.io/* verbs create,get], [\"\",\"extensions\",\"apps\"] resources: namespaces, deployments, ingresses with get/list.\n  - Bind SA to Argo WorkflowTemplate via spec.serviceAccountName.\n- Pod Security:\n  - Run as non-root, readOnlyRootFilesystem where possible, drop ALL capabilities, add NET_BIND_SERVICE only if required (likely not needed).\n  - Do not write secrets to logs or artifacts; redact tokens.\n- Example mounts (coderun steps):\n  volumeMounts:\n    - {name: gh-token, mountPath: /var/run/github, readOnly: true}\n  volumes:\n    - name: gh-token\n      projected:\n        sources:\n          - secret: {name: github-app-$(GITHUB_APP), items: [{key: token, path: token}]}\n- Acceptance criteria: Workflow runs without creating new GitHub App secrets; SA cannot list secrets cluster-wide; security scan finds no tokens in artifacts.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "E2E tests and documentation",
            "description": "Add end-to-end tests demonstrating the full DAG and produce concise documentation for operators and contributors.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4",
              "5.5",
              "5.6",
              "5.7",
              "5.8"
            ],
            "details": "- Test plan:\n  - Happy path: Open a PR; trigger workflow; verify order Rex→Clippy→QA→Deploy→Acceptance; confirm preview URLs; acceptance passes; no auto-merge occurs; environment remains for manual QA approval per policy.\n  - Failure path: Force acceptance failure (return 5xx from app or set strict thresholds); check that cleanup removed Helm release and namespace.\n  - Security: Rotate ExternalSecrets; ensure workflow picks new tokens; verify no secrets in logs.\n- Commands:\n  - argo submit --from workflowtemplate/implementation-dag -p owner=... -p repo=... -p pr=123\n  - kubectl get ns impl-pr-123; kubectl get ing -n impl-pr-123\n- Documentation (README.md in ops/argo/implementation-dag):\n  - Overview, parameters, required prerequisites (Task 2 secrets, ArgoCD/helm), how to trigger, artifacts and outputs, cleanup behavior, acceptance criteria, troubleshooting.\n- Acceptance criteria: All tests pass in CI or a staging cluster; documentation reviewed and usable by another engineer to run the flow end-to-end.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Argo Events GitHub EventSource and Sensors mapping to workflows",
        "description": "Configure Argo Events to consume GitHub webhooks and trigger appropriate workflows with parameters for repo, PR, branch, taskId, and agent type.",
        "details": "Implementation:\n- Create an EventSource of type github with webhook secret from External Secrets:\n  apiVersion: argoproj.io/v1alpha1\n  kind: EventSource\n  metadata: {name: github-es}\n  spec:\n    github:\n      main:\n        repositories:\n          - owner: \"*\"\n            repository: \"*\"\n        webhook:\n          endpoint: /events\n          port: 12000\n          method: POST\n          secret:\n            name: github-webhook-secret\n            key: secret\n        events:\n          - pull_request\n          - issues\n          - issue_comment\n          - pull_request_review_comment\n          - push\n          - workflow_run\n          - check_run\n          - security_advisory\n- Create Sensors mapping to workflows:\n  - PR opened/updated → pr-validation WorkflowTemplate\n  - issue_comment or pull_request_review_comment → coderun-template with github-app=rex and include downloaded comments param\n  - workflow_run/check_run failure → coderun-template with github-app=triage\n  - issues opened → implementation WorkflowTemplate (start with Rex)\n  - security events or scan complete → coderun-template with github-app=security\n  - push/merge → trigger orchestrator to resume/close as needed\n- Use trigger.template.ref to reference WorkflowTemplates and pass the raw event payload into workflow.parameters.event. Add rate limiters/concurrencyPolicy per Sensor to mitigate event storms.\n- Ensure Sensors include serviceAccounts with minimal RBAC to submit Workflows.\nPseudocode (Sensor trigger):\ntriggers:\n- template:\n    name: pr-validation\n    k8s:\n      group: argoproj.io\n      version: v1alpha1\n      resource: Workflow\n      operation: create\n      source:\n        resource:\n          apiVersion: argoproj.io/v1alpha1\n          kind: Workflow\n          metadata:\n            generateName: pr-validation-\n          spec:\n            workflowTemplateRef: {name: pr-validation}\n            arguments:\n              parameters:\n                - name: event\n                  value: \"{{events.github-es.main.body}}\"",
        "testStrategy": "Webhook integration test using a GitHub test repo: point its webhook to the EventSource service; create PRs, issues, comments, force failing checks; verify corresponding workflows are created with correct parameters. Security: invalid signature payloads must be rejected. Load test moderate event bursts; confirm debounce/rate limits prevent storm cascades.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "GitHub EventSource with webhook secret from External Secrets",
            "description": "Provision ExternalSecret-backed webhook secret and create a GitHub EventSource to receive GitHub webhooks at /events.",
            "dependencies": [],
            "details": "Manifests:\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: github-webhook-secret-es\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: my-secret-store\n    kind: ClusterSecretStore\n  target:\n    name: github-webhook-secret\n    creationPolicy: Owner\n  data:\n    - secretKey: secret\n      remoteRef:\n        key: github/webhook\n        property: secret\n---\napiVersion: argoproj.io/v1alpha1\nkind: EventSource\nmetadata:\n  name: github-es\nspec:\n  github:\n    main:\n      repositories:\n        - owner: \"*\"\n          repository: \"*\"\n      webhook:\n        endpoint: /events\n        port: 12000\n        method: POST\n        secret:\n          name: github-webhook-secret\n          key: secret\n      events:\n        - pull_request\n        - issues\n        - issue_comment\n        - pull_request_review_comment\n        - push\n        - workflow_run\n        - check_run\n        - security_advisory\nNotes:\n- Expose the EventSource service via your ingress/gateway as https://<domain>/events.\nAcceptance criteria:\n- EventSource pod ready; service routes POST /events.\n- Valid signature payloads accepted; invalid signatures rejected (HTTP 401/403).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Sensor for PR events → pr-validation WorkflowTemplate",
            "description": "Create a Sensor that triggers pr-validation on PR opened/updated events with parameters for repo, owner, pr, branch, and full event.",
            "dependencies": [
              "6.1"
            ],
            "details": "Manifest:\n---\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-pr-to-pr-validation\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: pr\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"pull_request\"]\n          - path: body.action\n            type: string\n            value: [\"opened\", \"reopened\", \"synchronize\", \"ready_for_review\"]\n        exprs:\n          - expression: \"body.pull_request.draft == false\"\n  triggers:\n    - template:\n        name: pr-validation\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: pr-validation-\n              spec:\n                workflowTemplateRef:\n                  name: pr-validation\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{events.github-es.main.body}}\"\n                    - name: owner\n                      value: \"{{events.github-es.main.body.repository.owner.login}}\"\n                    - name: repo\n                      value: \"{{events.github-es.main.body.repository.name}}\"\n                    - name: pr\n                      value: \"{{events.github-es.main.body.number}}\"\n                    - name: branch\n                      value: \"{{events.github-es.main.body.pull_request.head.ref}}\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: pr-validation\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 20\nAcceptance criteria:\n- Opening/updating a non-draft PR creates a Workflow from WorkflowTemplate pr-validation with parameters set correctly.\n- Draft PRs do not trigger.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Sensors for issue_comment/review_comment → coderun-template (rex) with comment payload",
            "description": "Create Sensors to trigger coderun-template with github-app=rex for issue_comment and pull_request_review_comment events, including comment body and option to fetch full thread.",
            "dependencies": [
              "6.1"
            ],
            "details": "Manifests (2 Sensors):\n---\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-issue-comment-to-rex\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: ic\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"issue_comment\"]\n          - path: body.action\n            type: string\n            value: [\"created\"]\n        exprs:\n          - expression: \"body.comment.user.type != 'Bot'\"\n  triggers:\n    - template:\n        name: coderun-rex-issue-comment\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: coderun-rex-\n              spec:\n                workflowTemplateRef:\n                  name: coderun-template\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{events.github-es.main.body}}\"\n                    - name: owner\n                      value: \"{{events.github-es.main.body.repository.owner.login}}\"\n                    - name: repo\n                      value: \"{{events.github-es.main.body.repository.name}}\"\n                    - name: issue\n                      value: \"{{events.github-es.main.body.issue.number}}\"\n                    - name: agent\n                      value: \"rex\"\n                    - name: includeComments\n                      value: \"true\"\n                    - name: commentBody\n                      value: \"{{events.github-es.main.body.comment.body}}\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: coderun\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 30\n---\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-pr-review-comment-to-rex\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: prc\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"pull_request_review_comment\"]\n          - path: body.action\n            type: string\n            value: [\"created\"]\n        exprs:\n          - expression: \"body.comment.user.type != 'Bot'\"\n  triggers:\n    - template:\n        name: coderun-rex-pr-comment\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: coderun-rex-\n              spec:\n                workflowTemplateRef:\n                  name: coderun-template\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{events.github-es.main.body}}\"\n                    - name: owner\n                      value: \"{{events.github-es.main.body.repository.owner.login}}\"\n                    - name: repo\n                      value: \"{{events.github-es.main.body.repository.name}}\"\n                    - name: pr\n                      value: \"{{events.github-es.main.body.pull_request.number}}\"\n                    - name: agent\n                      value: \"rex\"\n                    - name: includeComments\n                      value: \"true\"\n                    - name: commentBody\n                      value: \"{{events.github-es.main.body.comment.body}}\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: coderun\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 30\nAcceptance criteria:\n- Creating a new issue comment or PR review comment triggers a Workflow from coderun-template with agent=rex and includes comment body.\n- Bot comments are ignored.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Sensors for workflow_run/check_run failures → coderun-template (triage)",
            "description": "Route failing CI checks and workflow runs to triage via coderun-template with github-app=triage.",
            "dependencies": [
              "6.1"
            ],
            "details": "Manifest (one Sensor with OR condition):\n---\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-ci-failures-to-triage\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: wr\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"workflow_run\"]\n          - path: body.action\n            type: string\n            value: [\"completed\"]\n        exprs:\n          - expression: \"body.workflow_run.conclusion in ['failure','timed_out']\"\n    - name: cr\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"check_run\"]\n          - path: body.action\n            type: string\n            value: [\"completed\"]\n        exprs:\n          - expression: \"body.check_run.conclusion in ['failure','timed_out']\"\n  triggers:\n    - template:\n        name: coderun-triage\n        conditions: \"wr || cr\"\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: coderun-triage-\n              spec:\n                workflowTemplateRef:\n                  name: coderun-template\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{inputs.parameters.event}}\"\n                    - name: owner\n                      value: \"{{inputs.parameters.owner}}\"\n                    - name: repo\n                      value: \"{{inputs.parameters.repo}}\"\n                    - name: agent\n                      value: \"triage\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: coderun\n      parameters:\n        - src:\n            dependencyName: wr\n            dataKey: body\n          dest: spec.arguments.parameters.0.value\n        - src:\n            dependencyName: cr\n            dataKey: body\n          dest: spec.arguments.parameters.0.value\n        - src:\n            dependencyName: wr\n            dataKey: body.repository.owner.login\n          dest: spec.arguments.parameters.1.value\n        - src:\n            dependencyName: cr\n            dataKey: body.repository.owner.login\n          dest: spec.arguments.parameters.1.value\n        - src:\n            dependencyName: wr\n            dataKey: body.repository.name\n          dest: spec.arguments.parameters.2.value\n        - src:\n            dependencyName: cr\n            dataKey: body.repository.name\n          dest: spec.arguments.parameters.2.value\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 15\nAcceptance criteria:\n- Failing workflow_run or check_run events create a coderun-template Workflow with agent=triage, passing full event body.\n- Success/neutral conclusions do not trigger.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Sensors for issues opened → implementation DAG, security events → security agent, and push/merge → orchestrator",
            "description": "Create Sensors to trigger the implementation WorkflowTemplate on new issues, security agent on security signals, and orchestrator on push/merge.",
            "dependencies": [
              "6.1"
            ],
            "details": "Manifests (3 Sensors):\n---\n# Issues → implementation\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-issues-to-implementation\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: issues\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"issues\"]\n          - path: body.action\n            type: string\n            value: [\"opened\"]\n  triggers:\n    - template:\n        name: implementation-dag\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: implementation-\n              spec:\n                workflowTemplateRef:\n                  name: implementation\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{events.github-es.main.body}}\"\n                    - name: owner\n                      value: \"{{events.github-es.main.body.repository.owner.login}}\"\n                    - name: repo\n                      value: \"{{events.github-es.main.body.repository.name}}\"\n                    - name: issue\n                      value: \"{{events.github-es.main.body.issue.number}}\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: implementation\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 10\n---\n# Security advisories / scans → security agent\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-security-to-agent\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: secadv\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"security_advisory\"]\n    - name: secscan\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"workflow_run\"]\n          - path: body.action\n            type: string\n            value: [\"completed\"]\n        exprs:\n          - expression: \"has(body.workflow_run.name) && (body.workflow_run.name.matches('(?i)security|scan'))\"\n  triggers:\n    - template:\n        name: coderun-security\n        conditions: \"secadv || secscan\"\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: coderun-security-\n              spec:\n                workflowTemplateRef:\n                  name: coderun-template\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{events.github-es.main.body}}\"\n                    - name: owner\n                      value: \"{{events.github-es.main.body.repository.owner.login}}\"\n                    - name: repo\n                      value: \"{{events.github-es.main.body.repository.name}}\"\n                    - name: agent\n                      value: \"security\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: coderun\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 10\n---\n# Push/merge → orchestrator\napiVersion: argoproj.io/v1alpha1\nkind: Sensor\nmetadata:\n  name: github-push-merge-to-orchestrator\nspec:\n  template:\n    serviceAccountName: argo-events-workflow-submitter\n  dependencies:\n    - name: push\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"push\"]\n        exprs:\n          - expression: \"['refs/heads/main','refs/heads/master'].exists(body.ref) || body.base_ref == body.repository.default_branch\"\n    - name: merged\n      eventSourceName: github-es\n      eventName: main\n      filters:\n        data:\n          - path: headers.X-GitHub-Event\n            type: string\n            value: [\"pull_request\"]\n          - path: body.action\n            type: string\n            value: [\"closed\"]\n        exprs:\n          - expression: \"body.pull_request.merged == true\"\n  triggers:\n    - template:\n        name: orchestrator-resume-close\n        conditions: \"push || merged\"\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: orchestrator-\n              spec:\n                workflowTemplateRef:\n                  name: orchestrator-resume-close\n                arguments:\n                  parameters:\n                    - name: event\n                      value: \"{{events.github-es.main.body}}\"\n                    - name: owner\n                      value: \"{{events.github-es.main.body.repository.owner.login}}\"\n                    - name: repo\n                      value: \"{{events.github-es.main.body.repository.name}}\"\n                synchronization:\n                  semaphore:\n                    configMapKeyRef:\n                      name: workflow-semaphores\n                      key: orchestrator\n      policy:\n        rateLimit:\n          unit: minute\n          requestsPerUnit: 10\nAcceptance criteria:\n- New issues trigger implementation Workflow with correct parameters.\n- Security advisories or security-related workflow runs trigger coderun-template with agent=security.\n- Pushes to main/master and merged PRs trigger orchestrator-resume-close.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Parameter mapping: pass full event body and core fields to workflows",
            "description": "Define and enforce a consistent parameter contract across Sensors and WorkflowTemplates for event, owner, repo, pr/issue, branch, taskId, and agent.",
            "dependencies": [
              "6.2",
              "6.3",
              "6.4",
              "6.5"
            ],
            "details": "Parameter contract:\n- event: full raw event payload (body) as JSON string.\n- owner: repository.owner.login\n- repo: repository.name\n- pr: number (PR events only)\n- issue: issue.number (Issue events only)\n- branch: pull_request.head.ref (PR) or ref (Push)\n- agent: one of [rex, triage, security]\n- includeComments: boolean when comment-driven tasks should hydrate full thread\n- commentBody: original comment content (when applicable)\n- taskId: to be parsed by downstream templates from comment/issue title using a pattern like /task[:\\s]*([A-Za-z0-9_-]+)/i.\nEnforcement:\n- Sensors in 6.2–6.5 already pass parameters per this contract using template values or parameter mappings.\n- Downstream WorkflowTemplates (pr-validation, coderun-template, implementation, orchestrator-resume-close) must declare matching parameters; example:\n---\napiVersion: argoproj.io/v1alpha1\nkind: WorkflowTemplate\nmetadata:\n  name: pr-validation\nspec:\n  arguments:\n    parameters:\n      - name: event\n      - name: owner\n      - name: repo\n      - name: pr\n      - name: branch\nAcceptance criteria:\n- All referenced WorkflowTemplates compile with argo lint and accept the defined parameters.\n- Event JSON arrives intact in workflows (.spec.arguments.parameters[event]).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Concurrency, rate limiting, and minimal RBAC for Sensors",
            "description": "Apply trigger rate limits, workflow semaphores, and minimal RBAC service accounts for Sensors to submit Workflows.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4",
              "6.5",
              "6.6"
            ],
            "details": "Manifests:\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: argo-events-workflow-submitter\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: argo-events-workflow-submit-role\nrules:\n  - apiGroups: [\"argoproj.io\"]\n    resources: [\"workflows\"]\n    verbs: [\"create\", \"get\", \"list\"]\n  - apiGroups: [\"\"]\n    resources: [\"configmaps\"]\n    verbs: [\"get\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: argo-events-workflow-submit-rb\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: argo-events-workflow-submit-role\nsubjects:\n  - kind: ServiceAccount\n    name: argo-events-workflow-submitter\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: workflow-semaphores\ndata:\n  pr-validation: \"5\"\n  coderun: \"10\"\n  implementation: \"5\"\n  orchestrator: \"2\"\nNotes:\n- Sensors in 6.2–6.5 already reference serviceAccountName and include trigger policy.rateLimit and workflow synchronization.semaphore.\n- Adjust semaphore values to suit cluster capacity.\nAcceptance criteria:\n- Sensors can create workflows; no permission to modify unrelated resources.\n- Rate limits enforced (no more than configured requests per minute per Sensor).\n- Concurrent workflows do not exceed semaphore limits.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Integration tests and documentation",
            "description": "Validate end-to-end event routing and document deployment, webhook setup, and acceptance criteria.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4",
              "6.5",
              "6.6",
              "6.7"
            ],
            "details": "Test plan:\n- Configure a GitHub test repo webhook pointing to https://<domain>/events with secret.\n- PR flow: open PR (non-draft), push commits → expect pr-validation workflow with correct owner/repo/pr/branch.\n- Comments: add issue and PR review comments → expect coderun-template with agent=rex and commentBody.\n- CI failure: force a failing workflow_run/check_run → expect coderun-template with agent=triage.\n- Issues: open an issue → expect implementation workflow.\n- Security: publish a security advisory or complete a security scan workflow → expect coderun-template with agent=security.\n- Merge/push: merge a PR to main and push to main → expect orchestrator workflow.\n- Negative tests: invalid signatures rejected; drafts ignored; successful checks do not trigger triage; bot comments ignored.\nVerification:\n- Inspect Workflow parameters to match mapping in 6.6.\n- Confirm rate limiting and semaphore behavior under burst (simulate with webhook replay).\nDocs:\n- README covering manifests apply order, required WorkflowTemplates, ingress config, webhook configuration, parameter contract, and troubleshooting.\nAcceptance criteria:\n- All event types trigger correct WorkflowTemplates with correct parameters.\n- Security and negative test conditions behave as specified.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 7,
        "title": "MCP tool/API for efficient PR comment retrieval",
        "description": "Implement a lightweight MCP tool/service that fetches PR and review comments for use by Rex and other agents when reacting to feedback.",
        "details": "Implementation:\n- Implement a small HTTP service (Go/Node) called mcp-github-comments exposing endpoints:\n  - GET /repos/{owner}/{repo}/pulls/{number}/comments (review comments)\n  - GET /repos/{owner}/{repo}/issues/{number}/comments (issue comments on PR)\n  - Optional: GET /repos/{owner}/{repo}/issues/{number}/timeline for richer context\n- Auth: read installation token from /var/run/github/token populated by the token generator (Task 2).\n- Response shaping: return combined sorted comments with author, created_at, body, in a compact JSON suitable for prompts and include a token budget friendly summarization option.\n- Package as a container and deploy as a ClusterIP service mcp-github-comments; add to requirements.yaml tools list.\n- In coderun-template, when github-app=rex and event is a comment, call the MCP endpoint to fetch comments and store at /work/comments.json; pass the path to CodeRun as an input so the agent can use it.\nPseudocode (Go):\nr.GET(\"/repos/:owner/:repo/pulls/:number/comments\", func(c) {\n  tok := os.ReadFile(\"/var/run/github/token\")\n  f := fetch(\"https://api.github.com/repos/..\", tok)\n  c.JSON(200, normalize(f))\n})",
        "testStrategy": "Unit-test normalization and pagination handling. Integration: with a PR containing both review and issue comments, verify merged output ordering and content. Security: ensure no secret is logged; rate limit requests; handle 403/404 gracefully. In a workflow run, assert that /work/comments.json exists and includes the latest comments.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Service design and OpenAPI-lite specification",
            "description": "Design the mcp-github-comments HTTP service contract, including endpoints, query parameters, headers, response schema, and non-functional requirements.",
            "dependencies": [],
            "details": "Scope:\n- Service name: mcp-github-comments (HTTP, port 8080)\n- Endpoints:\n  - GET /repos/{owner}/{repo}/pulls/{number}/comments           (review comments)\n  - GET /repos/{owner}/{repo}/issues/{number}/comments          (issue comments on PR)\n  - GET /repos/{owner}/{repo}/issues/{number}/timeline          (optional timeline)\n  - GET /repos/{owner}/{repo}/pulls/{number}/comments/combined  (merged review+issue+optional timeline)\n- Query parameters:\n  - summarize=none|brief|compact (default: none)\n  - include=review,issue,timeline (only for combined; default: review,issue)\n  - since=ISO8601, until=ISO8601 (optional server-side filtering)\n  - max_items=int (cap to prevent oversized payloads; default 2000)\n  - summary_budget_chars=int (default 2000 when summarize!=none)\n- Request headers:\n  - If-None-Match: client ETag for conditional GETs\n- Response schema (combined endpoint):\n  {\n    \"comments\": [\n      {\n        \"id\": \"string\",\n        \"type\": \"review\"|\"issue\"|\"timeline\",\n        \"author\": {\"login\": \"string\", \"type\": \"User|Bot|Organization\"},\n        \"created_at\": \"RFC3339\",\n        \"updated_at\": \"RFC3339\",\n        \"body\": \"string\",\n        \"url\": \"string\",\n        \"html_url\": \"string\",\n        \"file_path\": \"string?\",\n        \"line\": \"number?\",\n        \"commit_id\": \"string?\",\n        \"in_reply_to_id\": \"string?\",\n        \"review_state\": \"approved|changes_requested|commented|dismissed|pending?\"\n      }\n    ],\n    \"summary\": {\n      \"text\": \"string\",\n      \"stats\": {\n        \"total_comments\": \"number\",\n        \"review_comments\": \"number\",\n        \"issue_comments\": \"number\",\n        \"timeline_events\": \"number\",\n        \"characters\": \"number\"\n      }\n    }?\n  }\n- Error schema:\n  {\"error\": {\"code\": \"string\", \"message\": \"string\", \"upstream_status\": \"number?\", \"retry_after_seconds\": \"number?\"}}\n- Non-functional:\n  - Content-Type: application/json; charset=utf-8\n  - ETag support on all endpoints (304 when not modified)\n  - Max response size cap; safe defaults; timeouts documented\nAcceptance criteria:\n- OpenAPI-lite (YAML/JSON) spec checked into repo covering all endpoints, params, headers, response and error schemas.\n- Example requests/responses for each endpoint included in docs.\n- Stakeholder sign-off on API surface and constraints.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "GitHub API integration with installation token, pagination, and ETag",
            "description": "Implement upstream GitHub calls using the installation token from /var/run/github/token with pagination and ETag handling.",
            "dependencies": [
              "7.1"
            ],
            "details": "Implementation:\n- Token: read from GITHUB_TOKEN_FILE (default /var/run/github/token); header: Authorization: Bearer <token>; Accept: application/vnd.github+json\n- Upstream endpoints:\n  - Review comments: https://api.github.com/repos/{owner}/{repo}/pulls/{number}/comments\n  - Issue comments:  https://api.github.com/repos/{owner}/{repo}/issues/{number}/comments\n  - Timeline:        https://api.github.com/repos/{owner}/{repo}/issues/{number}/timeline\n- Pagination: parse Link headers (rel=\"next\"/\"last\"); iterate until exhausted; allow caller to force page/per_page passthrough for raw endpoints; combined endpoint fetches all pages by default under max_items cap.\n- ETag: maintain in-memory cache keyed by upstream URL+query; send If-None-Match; on 304, reuse cached body; compute and return service-level ETag for combined responses.\n- Timeouts: connect 5s, read 10s; user-agent header set; context propagation per request.\n- Retries: limited retry with backoff for 502/503/504; no retry on 4xx except 409 transient.\n- Security: never log token; validate owner/repo/number inputs.\nAcceptance criteria:\n- Service reads token from file and authenticates successfully.\n- For a PR with >100 comments, retrieves all pages correctly.\n- Subsequent call with If-None-Match returns 304 when unchanged.\n- Requests include correct headers; errors from GitHub are mapped to service error schema.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Normalization, merge, sorting, and summarization",
            "description": "Normalize upstream payloads into a compact schema, merge streams, sort deterministically, and add optional token/char-budget summarization.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Normalization:\n- Map review comments, issue comments, and selected timeline events into NormalizedComment schema.\n- Timeline: include key events (review submitted states, label changes, commits) when requested; exclude noisy events by default.\n- Preserve threading via in_reply_to_id when present; capture file_path, line, commit_id for review comments.\nMerge and sorting:\n- Merge sources per include parameter; sort by created_at ascending; tie-break by id lexicographically for stability.\nSummarization:\n- Modes: none|brief|compact; budget via summary_budget_chars.\n- Produce concise bullets: key themes, requested changes, approvals, action items, per-file hotspots; deterministic algorithm (no external LLM dependency).\n- Include stats: totals by type and character count.\nResponse shaping:\n- Apply schema defined in subtask 7.1; omit summary when summarize=none.\nAcceptance criteria:\n- Given a PR with both review and issue comments, combined output is correctly merged, sorted, and fields populated.\n- Summaries respect budget and mode, contain no secrets, and reflect major feedback accurately.\n- Handles >1k comments within memory/time bounds; output adheres to schema.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Containerization and Kubernetes Deployment/Service",
            "description": "Package as a container and deploy as a ClusterIP service mcp-github-comments with token volume mount.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "Containerization:\n- Multi-stage Dockerfile (Go build); minimal runtime (distroless/alpine); non-root user; port 8080; env GITHUB_TOKEN_FILE=/var/run/github/token.\n- Health endpoint: GET /healthz returns 200.\nKubernetes manifests:\n- Deployment: replicas=2; resources requests/limits; readiness/liveness probes (/healthz); volume /var/run/github shared with token generator sidecar; labels app=mcp-github-comments.\n- Service: ClusterIP mcp-github-comments, port 80 -> 8080.\n- Optional: /metrics endpoint for Prometheus scraping; basic NetworkPolicy to restrict ingress within namespace.\nRelease:\n- Build and push image to registry; kustomize/helm templates committed.\nAcceptance criteria:\n- kubectl shows ready pods; Service endpoints reachable inside cluster.\n- Health probes pass; token volume mounted; image size reasonably small (<50 MB if feasible).\n- curl from a debug pod to combined endpoint returns valid JSON.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Tool registration and coderun-template integration",
            "description": "Add tool entry to requirements.yaml and integrate service call in coderun-template on comment events; store output at /work/comments.json and pass to CodeRun.",
            "dependencies": [
              "7.4",
              "7.3"
            ],
            "details": "Tool registration:\n- Update requirements.yaml tools list:\n  - name: mcp-github-comments\n  - baseUrl: http://mcp-github-comments\n  - endpoints documented for discovery.\nWorkflow integration:\n- In coderun-template, when github-app=rex AND event is a comment (issue_comment or pull_request_review_comment), add a step to call:\n  GET http://mcp-github-comments/repos/{owner}/{repo}/pulls/{number}/comments/combined?summarize=compact&include=review,issue,timeline\n- Write response to /work/comments.json and pass parameter comments_path=/work/comments.json into CodeRun.\n- Ensure network access to Service and no token leakage in logs.\nAcceptance criteria:\n- On a PR comment-triggered run, /work/comments.json exists with merged comments.\n- CodeRun receives comments_path and can read the file.\n- requirements.yaml contains the tool entry; pipeline step is conditional on comment events and rex app.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Rate limiting, error handling, and logging redaction",
            "description": "Implement rate limiting aligned with GitHub quotas, robust error handling, retries/backoff, and strict log redaction.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "Rate limiting:\n- In-memory token bucket per installation/repo key; tune to stay within GitHub rate (e.g., 5000/h); honor X-RateLimit-* headers and set Retry-After on 429.\nResilience:\n- Exponential backoff for 5xx and secondary rate limiting 403; cap retries; circuit breaker on repeated upstream failures; request timeouts and context cancellation respected.\nErrors and responses:\n- Use unified error schema with upstream_status and retry_after_seconds when applicable.\n- Map 403/404/422 from GitHub appropriately; return 304 on conditional requests when unchanged.\nLogging and PII:\n- Redact Authorization and token values; avoid logging full comment bodies at info level; include request id, method, path, status, latency.\nAcceptance criteria:\n- Load test shows graceful 429 with Retry-After when budget exceeded; normal traffic stays under limits.\n- No secrets appear in logs; structured errors are returned with useful messages.\n- Circuit breaker triggers on repeated failures and recovers automatically.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Unit/integration tests and documentation",
            "description": "Add tests for normalization, pagination, ETag and error paths; create integration/E2E tests and documentation (README and OpenAPI-lite).",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4",
              "7.5",
              "7.6"
            ],
            "details": "Tests:\n- Unit: normalization mapping, merge/sort determinism, summarization budget enforcement, Link header pagination, ETag cache hits/misses, error mapping.\n- Integration: against a test PR with both review and issue comments; verify combined output and 304 on repeat with If-None-Match; timeline include/exclude behavior.\n- E2E: run coderun-template in cluster on a synthetic comment event; verify /work/comments.json created and passed to CodeRun.\nDocs:\n- README covering setup, environment variables, endpoints, query params, response and error schemas, limits, examples (curl); troubleshooting section.\n- OpenAPI-lite artifact checked in and linked; example response payloads included.\nAcceptance criteria:\n- CI passes with high coverage on core packages (>80%).\n- Example curl commands in README return expected shapes.\n- E2E demonstration recorded in PR or docs; stakeholder sign-off on documentation.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 8,
        "title": "Parallelism and workspace isolation using git worktrees or PVCs",
        "description": "Enable safe batching/parallelization of independent tasks using git worktrees as working directories with optional PVC isolation; apply rate limits.",
        "details": "Implementation:\n- In coderun-template init step, prepare a base repo clone and a unique worktree per taskId/PR:\n  - git clone --no-checkout https://github.com/$OWNER/$REPO.git /work/base\n  - git -C /work/base fetch origin $REF\n  - git -C /work/base worktree add /work/trees/${TASK_ID} $REF\n  - Set workspace.path in CodeRun spec to the worktree path\n- For complete isolation option, mount separate PVC per parallel task:\n  - Use volumeClaimTemplates in Workflow spec to create per-pod PVCs; gate behind a parameter usePVC=true.\n- Concurrency controls:\n  - Set spec.parallelism on workflows; add per-repo mutex via Argo Workflow Semaphore or ConfigMap-based lock to limit concurrent writes per repo/branch.\n  - Apply Sensors rate limiting and debounce windows.\n- Cleanup: delete worktrees post-run, prune refs; ensure finalizers clean PVCs.\nPseudocode:\nTASK_ID=${PRNR:-$(date +%s)}\nmkdir -p /work/trees\n# create worktree, set env WORKSPACE=/work/trees/$TASK_ID\n\n",
        "testStrategy": "Spawn N parallel workflows against the same repo/branch and verify each runs in a distinct worktree directory; ensure no file handle collisions. Validate semaphore limits when set to 1, only one writer proceeds. PVC mode: confirm persistent volume attaches and is cleaned post-run. Measure performance vs full clones.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Init base clone and per-task git worktree",
            "description": "Create a reusable init step that prepares a shared base clone and a unique git worktree per taskId/PR under /work/trees/${TASK_ID}.",
            "dependencies": [],
            "details": "Implementation notes:\n- Directory layout: /work/base (shared clone), /work/trees/${TASK_ID} (per-task worktree)\n- Exact commands (bash):\n  set -euxo pipefail\n  OWNER=${OWNER:?}\n  REPO=${REPO:?}\n  REF=${REF:-\"refs/heads/main\"}\n  TASK_ID=${TASK_ID:-${PRNR:-$(date +%s)}}\n  mkdir -p /work/base /work/trees\n  if [ ! -d /work/base/.git ]; then\n    git clone --no-checkout https://github.com/${OWNER}/${REPO}.git /work/base\n  fi\n  git -C /work/base fetch --no-tags --depth=1 origin \"$REF\"\n  git -C /work/base worktree add \"/work/trees/${TASK_ID}\" FETCH_HEAD\n  git config --global --add safe.directory /work/base\n  git config --global --add safe.directory \"/work/trees/${TASK_ID}\"\n  echo \"/work/trees/${TASK_ID}\" > /work/workspace_path\n- Argo template example (init):\n  templates:\n  - name: init-worktree\n    inputs:\n      parameters:\n      - {name: owner}\n      - {name: repo}\n      - {name: ref}\n      - {name: taskId}\n    script:\n      image: alpine/git:2.44.0\n      command: [sh, -c]\n      source: |\n        OWNER={{inputs.parameters.owner}}\n        REPO={{inputs.parameters.repo}}\n        REF={{inputs.parameters.ref}}\n        TASK_ID={{inputs.parameters.taskId}}\n        set -euxo pipefail\n        mkdir -p /work/base /work/trees\n        if [ ! -d /work/base/.git ]; then\n          git clone --no-checkout https://github.com/${OWNER}/${REPO}.git /work/base\n        fi\n        git -C /work/base fetch --no-tags --depth=1 origin \"$REF\"\n        git -C /work/base worktree add \"/work/trees/${TASK_ID}\" FETCH_HEAD\n        git config --global --add safe.directory /work/base\n        git config --global --add safe.directory \"/work/trees/${TASK_ID}\"\n        echo \"/work/trees/${TASK_ID}\" > /work/workspace_path\n      volumeMounts:\n      - name: work\n        mountPath: /work\n- Acceptance criteria:\n  - Given OWNER/REPO/REF/TASK_ID, init step creates /work/trees/${TASK_ID} and checks out the ref via worktree.\n  - Running N instances in parallel creates N distinct directories with no collisions.\n  - /work/workspace_path file contains the expected path.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Parameterize TASK_ID/REF and wire workspace.path in CodeRun",
            "description": "Expose parameters for owner, repo, ref, taskId; compute sane defaults; set CodeRun spec.workspace.path to the worktree path.",
            "dependencies": [
              "8.1"
            ],
            "details": "Parameters:\n- owner (required), repo (required)\n- ref (default: refs/heads/main)\n- taskId (default: {{workflow.parameters.prNumber}} or timestamp)\n- workspacePath derived: /work/trees/{{inputs.parameters.taskId}}\nExact WorkflowTemplate snippet:\n  apiVersion: argoproj.io/v1alpha1\n  kind: WorkflowTemplate\n  metadata:\n    name: coderun-template\n  spec:\n    arguments:\n      parameters:\n      - {name: owner}\n      - {name: repo}\n      - {name: ref, value: \"refs/heads/main\"}\n      - {name: taskId, value: \"{{=sprig.default(nowEpoch, workflow.parameters.prNumber)}}\"}\n      - {name: github-app}\n      - {name: usePVC, value: \"false\"}\n      - {name: parallelism, value: \"5\"}\n    parallelism: \"{{workflow.parameters.parallelism}}\"\n    templates:\n    - name: coderun-main\n      inputs:\n        parameters:\n        - {name: owner}\n        - {name: repo}\n        - {name: ref}\n        - {name: taskId}\n        - {name: github-app}\n      dag:\n        tasks:\n        - name: init\n          template: init-worktree\n          arguments:\n            parameters:\n            - {name: owner, value: \"{{inputs.parameters.owner}}\"}\n            - {name: repo,  value: \"{{inputs.parameters.repo}}\"}\n            - {name: ref,   value: \"{{inputs.parameters.ref}}\"}\n            - {name: taskId,value: \"{{inputs.parameters.taskId}}\"}\n        - name: run\n          dependencies: [init]\n          template: create-coderun\n          arguments:\n            parameters:\n            - {name: workspacePath, value: \"/work/trees/{{inputs.parameters.taskId}}\"}\n            - {name: github-app, value: \"{{inputs.parameters.github-app}}\"}\n    - name: create-coderun\n      inputs:\n        parameters:\n        - {name: workspacePath}\n        - {name: github-app}\n      resource:\n        action: create\n        manifest: |\n          apiVersion: platform.example.io/v1alpha1\n          kind: CodeRun\n          metadata:\n            generateName: coderun-\n          spec:\n            githubApp: {{inputs.parameters.github-app}}\n            workspace:\n              path: {{inputs.parameters.workspacePath}}\n- Acceptance criteria:\n  - workspace.path equals the init worktree path for the same taskId.\n  - Ref and taskId are overridable via parameters and default sensibly.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Optional PVC isolation via volumeClaimTemplates gated by usePVC",
            "description": "Provide per-pod PVC option to isolate /work using volumeClaimTemplates when usePVC=true; default to emptyDir when false.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Volume specs:\n- PVC template (10Gi, RWO, storageClass configurable):\n  spec:\n    volumeClaimTemplates:\n    - metadata:\n        name: work\n        labels:\n          workflow: {{workflow.name}}\n      spec:\n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 10Gi\n        storageClassName: fast-ssd\n- Ephemeral fallback:\n  spec:\n    volumes:\n    - name: work\n      emptyDir: {}\nGating approach using podSpecPatch parameter:\n- Add parameter pvcPodSpecPatch computed from usePVC.\n- Example template usage:\n  templates:\n  - name: init-worktree\n    podSpecPatch: \"{{workflow.parameters.pvcPodSpecPatch}}\"\n    ...\n- Example patch for PVC mode:\n  pvcPodSpecPatch (string parameter value):\n  |\n    {\n      \"volumes\": [\n        {\"name\": \"work\", \"persistentVolumeClaim\": {\"claimName\": \"work\"}}\n      ],\n      \"containers\": [{\n        \"name\": \"main\",\n        \"volumeMounts\": [{\"name\": \"work\", \"mountPath\": \"/work\"}]\n      }]\n    }\n- Example patch for emptyDir mode:\n  |\n    {\n      \"volumes\": [\n        {\"name\": \"work\", \"emptyDir\": {}}\n      ],\n      \"containers\": [{\n        \"name\": \"main\",\n        \"volumeMounts\": [{\"name\": \"work\", \"mountPath\": \"/work\"}]\n      }]\n    }\nController-side:\n- For usePVC=true workflows, include volumeClaimTemplates as above at Workflow (or WorkflowTemplate) spec level.\n- For usePVC=false, omit volumeClaimTemplates and rely on emptyDir via podSpecPatch.\nAcceptance criteria:\n- When usePVC=true, pods mount a unique PVC named work and /work persists within pod lifecycle; PVC labeled workflow={{workflow.name}} exists during run.\n- When usePVC=false, /work is emptyDir and no PVC resource is created.\n- Both modes successfully run init-worktree and subsequent steps.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Concurrency controls: parallelism and per-repo/branch semaphore",
            "description": "Set spec.parallelism and enforce a per-repo/branch mutex using Argo Workflows synchronization via ConfigMap-based semaphore.",
            "dependencies": [
              "8.2"
            ],
            "details": "Workflow parallelism:\n- WorkflowTemplate.spec.parallelism: \"{{workflow.parameters.parallelism}}\"\nPer-repo/branch semaphore (ConfigMap):\n- Create ConfigMap to hold semaphore limits:\n  apiVersion: v1\n  kind: ConfigMap\n  metadata:\n    name: workflow-semaphores\n    namespace: argo\n  data:\n    # key format: owner-repo-branch (sanitized)\n    exampleorg-sample-main: \"1\"\n- Ensure key exists for each repo/branch (command):\n  BRANCH_SAFE=$(echo \"$REF\" | sed -E 's#^refs/(heads|tags)/##; s#[^a-zA-Z0-9_.-]#-#g' | tr '[:upper:]' '[:lower:]')\n  KEY=\"${OWNER}-${REPO}-${BRANCH_SAFE}\"\n  kubectl -n argo get configmap workflow-semaphores >/dev/null 2>&1 || kubectl -n argo create configmap workflow-semaphores\n  kubectl -n argo patch configmap workflow-semaphores --type merge -p \"{\\\"data\\\":{\\\"${KEY}\\\":\\\"1\\\"}}\"\nWorkflowTemplate synchronization snippet:\n  templates:\n  - name: coderun-main\n    synchronization:\n      semaphore:\n        configMapKeyRef:\n          name: workflow-semaphores\n          key: \"{{=sprig.lower (regexReplaceAll \"[^a-zA-Z0-9_.-]\" (replace (replace inputs.parameters.owner \\\"\\\" \\\"\\\") | cat \\\"-\\\" inputs.parameters.repo | cat \\\"-\\\" (regexReplaceAll \\\"^refs/(heads|tags)/\\\" inputs.parameters.ref \\\"\\\") ) \\\"-\\\")}}\"\nAcceptance criteria:\n- With semaphore key limit set to 1, only one workflow referencing the same repo/branch proceeds concurrently; additional ones wait.\n- Increasing the key value increases concurrency accordingly.\n- spec.parallelism caps overall parallel pods as configured.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Cleanup: delete worktrees and prune refs; PVC cleanup on completion",
            "description": "Add onExit cleanup to remove worktrees, prune refs, and ensure PVCs are cleaned when enabled.",
            "dependencies": [
              "8.1",
              "8.3"
            ],
            "details": "Cleanup commands (bash):\n  set -euxo pipefail\n  TASK_ID=${TASK_ID:?}\n  BASE=/work/base\n  TREE=/work/trees/${TASK_ID}\n  if [ -d \"$TREE/.git\" ] || [ -d \"$TREE\" ]; then\n    git -C \"$BASE\" worktree remove --force \"$TREE\" || true\n  fi\n  git -C \"$BASE\" worktree prune || true\n  git -C \"$BASE\" remote prune origin || true\n  git -C \"$BASE\" gc --prune=now --aggressive || true\n  rm -rf \"$TREE\" || true\nPVC cleanup:\n- Label PVC in volumeClaimTemplates with workflow={{workflow.name}}.\n- onExit template deletes PVCs only when usePVC=true:\n  kubectl delete pvc -l workflow={{workflow.name}} || true\nWorkflow onExit wiring example:\n  spec:\n    onExit: cleanup\n  templates:\n  - name: cleanup\n    inputs:\n      parameters:\n      - {name: taskId}\n      - {name: usePVC}\n    script:\n      image: alpine/git:2.44.0\n      command: [sh, -c]\n      source: |\n        TASK_ID={{inputs.parameters.taskId}}\n        {{- if eq inputs.parameters.usePVC \"true\" -}}\n        kubectl delete pvc -l workflow={{workflow.name}} || true\n        {{- end -}}\n        set -euxo pipefail\n        BASE=/work/base\n        TREE=/work/trees/${TASK_ID}\n        git -C \"$BASE\" worktree remove --force \"$TREE\" || true\n        git -C \"$BASE\" worktree prune || true\n        git -C \"$BASE\" remote prune origin || true\n        git -C \"$BASE\" gc --prune=now || true\n      volumeMounts:\n      - name: work\n        mountPath: /work\nAcceptance criteria:\n- After workflow completion, no /work/trees/${TASK_ID} directory remains.\n- Base repo has pruned worktree metadata; subsequent runs succeed.\n- When usePVC=true, the PVC(s) created for the run are deleted automatically by onExit.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Sensors: rate limiting and debounce windows",
            "description": "Configure Argo Events Sensor to limit trigger rate and debounce bursts of events for the same repo/ref.",
            "dependencies": [
              "8.4"
            ],
            "details": "Sensor YAML (example):\n  apiVersion: argoproj.io/v1alpha1\n  kind: Sensor\n  metadata:\n    name: repo-workflow-sensor\n    namespace: argo-events\n  spec:\n    eventBusName: default\n    rateLimit:\n      unit: minute\n      requestsPerUnit: 30\n    template:\n      serviceAccountName: argo-events-sa\n    eventDependencies:\n    - name: github-pr\n      eventSourceName: github\n      eventName: pull_request\n      filters:\n        data:\n        - path: body.action\n          type: string\n          value: [opened, synchronize, reopened]\n        # Debounce: only pass an event if at least 15s since the last accepted one per repo/ref (requires CEL filter support)\n        expr:\n          expression: \"debounce(event.repo.full_name + ':' + event.body.pull_request.base.ref, duration('15s'))\"\n    triggers:\n    - template:\n        name: submit-workflow\n        k8s:\n          group: argoproj.io\n          version: v1alpha1\n          resource: workflows\n          operation: create\n          source:\n            resource:\n              apiVersion: argoproj.io/v1alpha1\n              kind: Workflow\n              metadata:\n                generateName: pr-validate-\n              spec:\n                workflowTemplateRef:\n                  name: coderun-template\n                arguments:\n                  parameters:\n                  - name: owner\n                    value: \"{{(jsonpath \"$.body.repository.owner.login\")}}\"\n                  - name: repo\n                    value: \"{{(jsonpath \"$.body.repository.name\")}}\"\n                  - name: ref\n                    value: \"refs/heads/{{(jsonpath \"$.body.pull_request.base.ref\")}}\"\n                  - name: taskId\n                    value: \"pr-{{(jsonpath \"$.body.pull_request.number\")}}-{{(jsonpath \"$.headers.X-GitHub-Delivery\")}}\"\nAcceptance criteria:\n- Sensor enforces max 30 workflow submissions per minute.\n- Multiple rapid synchronize events on the same PR are collapsed so at most one workflow is created in a 15s window.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Performance and correctness testing under N parallel runs",
            "description": "Benchmark worktree approach vs full clones and validate correctness under high parallelism and semaphore limits.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4",
              "8.5",
              "8.6"
            ],
            "details": "Test plan:\n- Correctness tests:\n  - Submit N parallel workflows (e.g., N=20) with the same repo/ref and distinct taskIds.\n  - Verify each workflow uses a unique path and no file descriptor collisions occur.\n  - With semaphore limit=1 for the repo/ref, confirm only one active writer; others wait.\n- Performance benchmark (worktree vs full clone):\n  - Worktree time: measure duration of init-worktree step.\n  - Full clone time: run `time git clone --depth=1 https://github.com/${OWNER}/${REPO}.git /tmp/full-${TASK_ID}` as a control.\n  - Record CPU, network bytes, and wall clock for M runs (M>=10) and compute averages.\n- Automation commands:\n  OWNER=exampleorg; REPO=sample; REF=refs/heads/main; N=20\n  for i in $(seq 1 $N); do \\\n    argo submit --from workflowtemplate/coderun-template \\\n      -p owner=$OWNER -p repo=$REPO -p ref=$REF -p taskId=\"bench-$i-$(date +%s)\" \\\n      -p github-app=rex -p usePVC=false &\n  done; wait\n  # Set semaphore to 1 and repeat to validate mutex\n  kubectl -n argo patch configmap workflow-semaphores --type merge -p \"{\\\"data\\\":{\\\"${OWNER}-${REPO}-main\\\":\\\"1\\\"}}\"\nAcceptance criteria:\n- With N parallel runs, all succeed with distinct worktree paths and without git index corruption.\n- Worktree init is measurably faster (>2x) and transfers fewer bytes than full clones on average.\n- With semaphore=1, at most one active workflow step enters the critical section concurrently.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Documentation and operational runbook",
            "description": "Document setup, parameters, failure modes, and SRE runbook for isolation, concurrency, and cleanup.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4",
              "8.5",
              "8.6",
              "8.7"
            ],
            "details": "Content outline:\n- Overview: rationale for git worktrees, optional PVCs, and concurrency controls.\n- Setup steps:\n  - Install/upgrade coderun-template WorkflowTemplate.\n  - Create workflow-semaphores ConfigMap and how to add keys (commands provided in subtask 4).\n  - Configure Sensor (rateLimit and debounce) and GitHub webhook secrets.\n- Parameters and defaults: owner, repo, ref, taskId, github-app, usePVC, parallelism.\n- Volume modes: when to usePVC; storageClass guidance; default sizes.\n- Concurrency: how to set parallelism; how to tune semaphore limits per repo/branch.\n- Cleanup behavior: onExit logic; how to recover stuck PVCs or orphaned worktrees.\n- Troubleshooting:\n  - git safe.directory errors; permissions; shallow fetch issues; worktree remove force.\n  - Semaphore key missing or mis-sanitized; how to inspect waiting workflows.\n  - Sensor rate limits and debounce tuning.\n- Acceptance criteria:\n  - Docs enable a new operator to deploy and operate the flow in a fresh namespace within 30 minutes.\n  - Runbook contains concrete kubectl/argo commands for common ops (scale up/down, drain, cleanup).",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 9,
        "title": "Observability: OTEL traces/metrics and correlated logging",
        "description": "Emit OpenTelemetry spans/metrics for each agent step with correlation labels (repo, prNumber, taskId, agent) and surface links to PRs, Actions, and deployments as workflow outputs.",
        "details": "Implementation:\n- Inject OTEL environment variables into workflow pods: OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317, OTEL_SERVICE_NAME=agent-steps.\n- Wrap agent and verification steps with a lightweight tracer shim (sidecar or entrypoint wrapper) that:\n  - Starts a span per step with attributes: repo, prNumber, ref, taskId, agent, workflowName, nodeId.\n  - Emits counters: agent_step_duration_ms, agent_step_success{agent=...} using OTLP metrics if supported, or Prometheus sidecar.\n- Configure Argo Workflows to annotate pods with labels for correlation (workflows.argoproj.io/workflow, repo, pr), and ensure logs include these fields.\n- Add workflow.outputs.parameters for URLs: prHtmlUrl, actionsRunUrl (from event), previewUrl (from deploy step).\n- Update Grafana dashboards to include new metrics and exemplars linking to traces.\nPseudocode (bash wrapper):\nstart_span --name \"$AGENT/$STEP\" --attrs repo=$REPO pr=$PR task=$TASK\ntrap 'end_span $?; exit' EXIT\nexec \"$@\"",
        "testStrategy": "Run sample workflows and verify spans appear in the tracing backend with correct attributes and timing. Confirm metrics scraped/exported. Check logs include correlation labels and can be queried by repo/pr. Validate workflow outputs include clickable links. Chaos test: restart controller/pods mid-run and ensure traces continue for resumed steps.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Tracer shim/entrypoint wrapper for OTEL spans",
            "description": "Build a lightweight shim (entrypoint wrapper or sidecar) that starts and ends an OpenTelemetry span per agent step with required attributes.",
            "dependencies": [],
            "details": "- Deliverable: small wrapper (bash + otel-cli or tiny Go binary) usable as entrypoint for agent and verification steps.\n- Span behavior: start on process launch, end on normal exit or signal; set status=ERROR on non-zero exit; include child spans if needed.\n- Span naming: agentName/stepName (e.g., clippy/verify).\n- Attribute keys (span attributes): repo, prNumber, ref, taskId, agent, workflowName, nodeId. Optional extras: commitSha, stepName, namespace.\n- Resource attributes (OTEL_RESOURCE_ATTRIBUTES): service.name=agent-steps, deployment.environment, k8s.namespace, k8s.pod.name.\n- Context propagation: read/write W3C traceparent; export trace_id and span_id to env; print a one-line JSON with traceId/spanId at start for log correlation.\n- Integration: wrapper accepts the real command via exec \"$@\"; minimal overhead; packaged container image and/or script.\n- Acceptance criteria:\n  - For a sample workflow step, a span appears in tracing backend with the exact name and attributes above.\n  - Erroring step marks span status=ERROR and records exit code.\n  - trace_id and span_id are accessible to the process (env) and printed once to stdout.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Metrics emission: duration and success counters",
            "description": "Expose per-step metrics via OTLP Metrics if available, else via Prometheus sidecar/exporter.",
            "dependencies": [
              "9.1"
            ],
            "details": "- Metric set:\n  - agent_step_duration_ms: histogram (unit=ms), labels: repo, prNumber, taskId, agent, workflowName, stepName, outcome.\n  - agent_step_success_total: counter, labels: agent, repo, prNumber, stepName; increment 1 on success only.\n  - agent_step_fail_total: counter, same labels; increment 1 on failure only.\n- Emission path:\n  - Primary: OTLP metrics (grpc) from shim using OTEL SDK or otel-cli timer.\n  - Fallback: expose Prometheus /metrics via a tiny sidecar or pushgateway pattern disabled; ensure scrape annotations.\n- Exemplars: attach trace_id exemplar to duration observations when supported.\n- Units and cardinality: bound prNumber and taskId labels to active runs only; consider bucketing on prNumber hash if needed.\n- Acceptance criteria:\n  - Duration histogram and success/fail counters visible in Prometheus (or OTEL metrics backend) with labels.\n  - At least one duration sample carries exemplars linking to traces.\n  - No high-cardinality alert triggered during a test run of 100 steps.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Inject OTEL env vars into workflow pods and verify collector",
            "description": "Configure Argo templates to set OTEL environment and validate connectivity to the collector endpoint.",
            "dependencies": [],
            "details": "- Env var list (baseline):\n  - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317\n  - OTEL_EXPORTER_OTLP_PROTOCOL=grpc\n  - OTEL_SERVICE_NAME=agent-steps\n  - OTEL_RESOURCE_ATTRIBUTES=service.name=agent-steps,deployment.environment=${ENV},k8s.namespace=${NAMESPACE}\n  - OTEL_TRACES_SAMPLER=parentbased_traceidratio\n  - OTEL_TRACES_SAMPLER_ARG=0.5 (tune per env)\n  - OTEL_METRICS_EXPORTER=otlp\n  - OTEL_LOGS_EXPORTER=none\n  - OTEL_EXPORTER_OTLP_TIMEOUT=10000\n- Template changes: add env to all agent/verification steps via WorkflowTemplate or PodSpecPatch.\n- Network/policy: ensure DNS and NetworkPolicy allow egress to otel-collector:4317.\n- Health check: add initContainer that runs a quick gRPC dial (or tcp check) to the collector and logs status.\n- Acceptance criteria:\n  - All relevant pods have the env vars set.\n  - Collector endpoint is reachable from pods (init check passes) in dev/stage.\n  - If collector is down, steps still run and shim buffers/drops gracefully without failing business logic.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Pod annotations/labels and log correlation",
            "description": "Ensure pods are labeled/annotated for correlation and logs include fields for repo/pr and trace IDs.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "- Pod labels: workflows.argoproj.io/workflow, repo, pr, taskId, agent, stepName.\n- Annotations (optional): trace.context=traceparent at start (wrapper writes), commitSha.\n- Logging pipeline: configure Fluent Bit/Fluentd to enrich logs with k8s labels; parse the wrapper's initial JSON line to capture traceId and spanId into structured fields.\n- Query patterns: ability to query logs by repo, pr, taskId, agent and pivot to a trace using traceId.\n- Privacy: avoid logging secrets; add drop filters for known sensitive envs.\n- Acceptance criteria:\n  - From logging UI, user can filter logs by repo and pr and see only relevant pod logs.\n  - Each step's log stream includes traceId/spanId fields matching the tracing backend.\n  - Labels are present on all workflow pods created by the templates.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Workflow outputs: PR, Actions run, and preview URLs",
            "description": "Expose key URLs as workflow.outputs.parameters for downstream linking.",
            "dependencies": [],
            "details": "- Output parameters:\n  - prHtmlUrl: from event payload (e.g., {{workflow.parameters.github.event.pull_request.html_url}}).\n  - actionsRunUrl: from event/run context (e.g., {{workflow.parameters.github.run_url}}) or constructed from repo, runId.\n  - previewUrl: emitted by deploy step via parameter artifact or file (e.g., write to /tmp/preview_url and pass via output parameter).\n- Template wiring: ensure upstream steps set parameters and DAG outputs propagate to workflow.outputs.parameters.\n- Validation: parameters show in Argo UI and are exported as annotations for external systems if needed.\n- Acceptance criteria:\n  - All three URLs are present, correct, and clickable in the Argo UI and exposed via CLI/json output.\n  - For PR-triggered runs, prHtmlUrl matches the actual PR; for preview deployments, previewUrl resolves (HTTP 200/302).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Grafana dashboards with exemplars and correlations",
            "description": "Add/modify Grafana dashboards to visualize new metrics with exemplars linking to traces.",
            "dependencies": [
              "9.1",
              "9.2"
            ],
            "details": "- Data sources: Prometheus for metrics, Tempo/Jaeger for traces, Loki/Elastic for logs (if available).\n- Dashboard panels:\n  - Step duration (P50/P90/P99) by agent and repo (histogram/heatmap).\n  - Success rate and failure count by agent, with annotations for deployments.\n  - Active PRs and tasks in-flight (gauge) per repo.\n  - Errors by stepName with quick links to traces via exemplars.\n  - Top slow PRs (by prNumber) and top agents by latency.\n  - Correlated logs panel (if Loki): logs for selected traceId/taskId.\n- Variables: repo, prNumber, agent, workflowName, taskId, environment.\n- Exemplars: enable exemplars on duration panel, map trace exemplar label to traceId in Tempo/Jaeger.\n- Permissions: read access for devs; no sensitive labels exposed.\n- Acceptance criteria:\n  - Dashboards load with data for sample runs; selecting a time bucket shows exemplar links that open traces.\n  - Variable filters work and reduce series without errors.\n  - Panels refresh within 15s and stay within target Prometheus query costs.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Resiliency and validation tests",
            "description": "Chaos and reliability testing for tracing/metrics/logs across failures and restarts; validate data in backends.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3",
              "9.4"
            ],
            "details": "- Scenarios:\n  - Kill agent pod mid-step; verify span ends with error and partial logs correlate; retries create new spans with link/parent preserved if applicable.\n  - Restart argoexec/controller during workflow; ensure spans for resumed steps are present and metrics not double-counted.\n  - Collector outage (simulate by scaling to 0 or blocking egress); confirm app continues, spans buffered/dropped without step failure.\n  - High concurrency burst (e.g., 50 parallel steps) to check cardinality and scrape performance.\n- Validation:\n  - No orphan child spans without parents for a standard run.\n  - Counters equal number of successes/failures observed in Argo.\n  - Logs for a given taskId can pivot to a trace via traceId.\n- Acceptance criteria:\n  - All scenarios pass with documented observations and no critical data loss beyond expected sampling/drop policies.\n  - Sampling rate and retries tuned to meet SLOs (e.g., >95% span coverage in dev).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Documentation and runbook",
            "description": "Produce user/dev docs covering setup, env vars, attributes, dashboards, and troubleshooting.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3",
              "9.4",
              "9.5",
              "9.6",
              "9.7"
            ],
            "details": "- Content:\n  - Overview of observability architecture and data flow (textual description) and components (Argo, shim, OTEL collector, Prometheus, Grafana, tracing backend).\n  - Environment variable list and meanings; recommended sampler settings per environment.\n  - Attribute keys and when they appear (span vs resource vs log fields).\n  - How to read workflow outputs (PR, Actions, preview) and where they are surfaced.\n  - Dashboard guide: panels, variables, exemplars, common queries.\n  - Troubleshooting: collector connectivity, missing spans, high-cardinality mitigation, log correlation gotchas.\n  - Acceptance criteria for the overall feature set.\n- Acceptance criteria:\n  - Docs published in repo (docs/observability.md) and linked from README; reviewed by at least one SRE and one developer.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 10,
        "title": "QA Kubernetes verification and PR approval action (no auto-merge)",
        "description": "Implement strict QA verification in Kubernetes with evidence collection and allow QA agent to approve PRs via GitHub Review API while blocking merges.",
        "details": "Implementation:\n- In qa-testing (from DAGs), instruct agent via system prompt to run tests only and collect artifacts under /artifacts/qa/proof.\n- Add a post-QA step approve-pr (container) that, when verify-k8s-proof passed, posts an APPROVE review using GitHub App token:\n  - POST /repos/{owner}/{repo}/pulls/{pr}/reviews with event=APPROVE\n- Enforce no merge: do not call merge endpoints; rely on branch protection to require human review as needed.\n- Evidence collection:\n  - kubectl logs, kubectl get, curl responses saved to artifacts and uploaded to object store if configured.\n  - Attach a summary comment with links to artifacts.\n- Compliance enforcement reminder: ensure verify-compliance step is a required dependency before approve-pr.\nPseudocode (approve-pr):\nif [ -f /artifacts/qa/proof/summary.json ]; then\n  curl -H \"Authorization: Bearer $GITHUB_TOKEN\" \\\n    -d '{\"body\":\"QA verification passed with evidence.\",\"event\":\"APPROVE\"}' \\\n    https://api.github.com/repos/$OWNER/$REPO/pulls/$PR/reviews\nelse\n  echo \"Missing QA proof\"; exit 1\nfi",
        "testStrategy": "Open a PR and run the PR flow. Ensure that when QA proof exists, the review is submitted as APPROVE by the QA GitHub App account. If proof is missing, the approval step fails and the workflow fails. Verify that the PR is not merged automatically and branch protection remains intact. Validate artifact links are present in the PR comment.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define QA agent prompt and artifact contract for Kubernetes proof",
            "description": "Refine the QA agent system prompt and specify the artifact contract under /artifacts/qa/proof, including required files and summary.json schema.",
            "dependencies": [],
            "details": "System prompt (essentials):\n- Purpose: Run tests only; do not modify code or trigger merges. Collect evidence to /artifacts/qa/proof.\n- Required outputs:\n  - /artifacts/qa/proof/summary.json (mandatory)\n  - /artifacts/qa/proof/logs/* (kubectl logs, test logs)\n  - /artifacts/qa/proof/k8s/* (kubectl get resources)\n  - /artifacts/qa/proof/http/* (HTTP checks/curl responses)\n- Failure semantics: If tests fail or critical checks fail, set qa.passed=false in summary.json and exit non-zero.\n\nDirectory conventions:\n- /artifacts/qa/proof/logs/{pod}-{container}.log\n- /artifacts/qa/proof/k8s/{resource}.yaml (pods.yaml, deployments.yaml, events.yaml, services.yaml)\n- /artifacts/qa/proof/http/{name}.json and/or {name}.txt\n\nsummary.json minimum schema:\n{\n  \"version\": \"1.0\",\n  \"pr\": {\"owner\": \"string\", \"repo\": \"string\", \"number\": 0, \"headSha\": \"string\"},\n  \"qa\": {\"passed\": true, \"startedAt\": \"RFC3339\", \"finishedAt\": \"RFC3339\"},\n  \"environment\": {\"k8sContext\": \"string\", \"namespace\": \"string\"},\n  \"artifacts\": [\n    {\"name\": \"pods\", \"path\": \"k8s/pods.yaml\", \"contentType\": \"application/yaml\", \"bytes\": 0, \"url\": \"optional\"}\n  ],\n  \"evidence\": {\n    \"k8s\": {\"resources\": [\"pods\",\"deployments\",\"events\",\"services\"]},\n    \"logs\": [{\"pod\": \"string\", \"container\": \"string\", \"path\": \"logs/...\"}],\n    \"httpChecks\": [{\"name\":\"string\",\"url\":\"string\",\"status\":200,\"latencyMs\":0,\"bodyPath\":\"http/...\"}]\n  }\n}\n\nRequired env vars exposed to agent: OWNER, REPO, PR_NUMBER, K8S_NAMESPACE, SERVICE_ENDPOINTS (optional JSON), ARTIFACTS_DIR=/artifacts/qa/proof.\nAcceptance criteria:\n- Agent produces the required directory structure and summary.json matching the schema.\n- On success qa.passed=true; on failure qa.passed=false and non-zero exit.\n- File paths in summary.json are relative to /artifacts/qa/proof and exist.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement verify-k8s-proof gate and compliance enforcement",
            "description": "Add a verify-k8s-proof step that validates presence and schema of summary.json and enforce verify-compliance as a required dependency before approve-pr.",
            "dependencies": [
              "10.1"
            ],
            "details": "Gate logic (container/script):\n- Inputs: ARTIFACTS_DIR=/artifacts/qa/proof, SUMMARY=$ARTIFACTS_DIR/summary.json.\n- Checks: file exists; parse via jq; ensure .qa.passed is boolean and required keys exist; list required artifacts files referenced in summary.json and ensure they exist.\n- Exit 0 only if summary.json exists, validates, and qa.passed==true.\n- On failure: echo cause and exit 1.\n\nExample command:\n- test -f \"$SUMMARY\" || { echo \"missing summary\"; exit 1; }\n- jq -e '.qa.passed == true and .pr.number and .environment.namespace' \"$SUMMARY\" > /dev/null || exit 1\n\nDAG enforcement:\n- Ensure approve-pr has dependencies: [verify-compliance, verify-k8s-proof].\n- Ensure verify-k8s-proof depends on qa-testing.\n\nAcceptance criteria:\n- Pipeline fails when summary.json missing/invalid or qa.passed=false.\n- approve-pr cannot run unless verify-compliance and verify-k8s-proof succeeded.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement approve-pr step using GitHub App token (POST review APPROVE, no merge)",
            "description": "Create a container/script that posts an APPROVE review via GitHub Review API upon successful gates using a GitHub App installation token.",
            "dependencies": [
              "10.2"
            ],
            "details": "Inputs/env:\n- OWNER, REPO, PR_NUMBER (required)\n- GITHUB_TOKEN or GITHUB_TOKEN_PATH (installation token) \n- SUMMARY_PATH=/artifacts/qa/proof/summary.json\n\nBehavior:\n- Verify SUMMARY_PATH exists before proceeding; else exit 1.\n- Read token from GITHUB_TOKEN or file path into header.\n- POST review:\n  - Method: POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews\n  - Headers: Authorization: Bearer $GITHUB_TOKEN; Accept: application/vnd.github+json; X-GitHub-Api-Version: 2022-11-28\n  - Body: {\"event\":\"APPROVE\",\"body\":\"QA verification passed with evidence. See summary.json in artifacts.\"}\n- Do not call any merge endpoints.\n- Handle 403/404/422 gracefully with clear logs; retry on 502/503 with backoff.\n\nExample curl:\n- curl -sS -X POST \"https://api.github.com/repos/$OWNER/$REPO/pulls/$PR_NUMBER/reviews\" \\\n  -H \"Authorization: Bearer $GITHUB_TOKEN\" \\\n  -H \"Accept: application/vnd.github+json\" \\\n  -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n  -d '{\"event\":\"APPROVE\",\"body\":\"QA verification passed with evidence.\"}'\n\nAcceptance criteria:\n- When gates pass and summary exists, an APPROVE review is posted by the QA GitHub App account.\n- Step fails if summary.json is missing or token is invalid.\n- No merge API is invoked; logs confirm only review POST occurs.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement evidence collection and optional artifact upload to object store",
            "description": "Enhance qa-testing to collect kubectl logs/gets and HTTP responses, store under /artifacts/qa/proof, and optionally upload to an object store with links recorded in summary.json.",
            "dependencies": [
              "10.1"
            ],
            "details": "Collection commands (examples):\n- mkdir -p \"$ARTIFACTS_DIR\"/logs \"$ARTIFACTS_DIR\"/k8s \"$ARTIFACTS_DIR\"/http\n- kubectl -n \"$K8S_NAMESPACE\" get pods -o yaml > \"$ARTIFACTS_DIR\"/k8s/pods.yaml\n- kubectl -n \"$K8S_NAMESPACE\" get deploy -o yaml > \"$ARTIFACTS_DIR\"/k8s/deployments.yaml\n- kubectl -n \"$K8S_NAMESPACE\" get events --sort-by=.lastTimestamp -o yaml > \"$ARTIFACTS_DIR\"/k8s/events.yaml\n- for p in $(kubectl -n \"$K8S_NAMESPACE\" get pods -o name); do kubectl -n \"$K8S_NAMESPACE\" logs \"$p\" --all-containers=true > \"$ARTIFACTS_DIR\"/logs/\"${p##*/}\".log || true; done\n- curl -sS -w '\\n%{http_code} %{time_total}\\n' \"$HEALTH_URL\" -o \"$ARTIFACTS_DIR\"/http/health.json > \"$ARTIFACTS_DIR\"/http/health.meta\n\nOptional upload (S3/MinIO/GCS):\n- Env: OBJECT_STORE_UPLOAD=true|false, OBJECT_STORE_PROVIDER=s3|gcs, OBJECT_STORE_BUCKET, OBJECT_STORE_PREFIX, OBJECT_STORE_ENDPOINT (for MinIO), AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, GCS_SERVICE_ACCOUNT_JSON (path).\n- S3 example: aws s3 cp \"$ARTIFACTS_DIR\" \"s3://$OBJECT_STORE_BUCKET/$OBJECT_STORE_PREFIX/\" --recursive\n- Generate presigned URLs for key artifacts and inject into summary.json .artifacts[].url.\n\nAcceptance criteria:\n- Artifacts directory contains logs, k8s resources, and HTTP outputs as specified.\n- If upload enabled, files appear in the bucket and summary.json includes valid URLs.\n- summary.json accurately references all collected files.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Post PR summary comment with artifact links and context",
            "description": "Create a step that posts a concise PR issue comment summarizing QA results and linking to artifacts/object-store URLs.",
            "dependencies": [
              "10.2",
              "10.4"
            ],
            "details": "Inputs/env:\n- OWNER, REPO, PR_NUMBER, SUMMARY_PATH=/artifacts/qa/proof/summary.json\n- GITHUB_TOKEN or GITHUB_TOKEN_PATH\n\nAPI call:\n- POST /repos/{owner}/{repo}/issues/{issue_number}/comments\n- Headers: Authorization: Bearer $GITHUB_TOKEN; Accept: application/vnd.github+json; X-GitHub-Api-Version: 2022-11-28\n- Body template: includes qa.passed, namespace, counts of artifacts, and top links (from summary.json .artifacts[].url). Fallback to path references if no URLs.\n\nBehavior:\n- Parse summary.json with jq to build message.\n- Post one comment per run; optionally update if a prior bot comment exists (GET comments, PATCH if desired).\n\nAcceptance criteria:\n- A PR issue comment appears with pass/fail status and at least 1 link or path to artifacts.\n- On missing summary.json, step fails and logs clear reason.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Verify branch protection and enforce no auto-merge policy",
            "description": "Confirm repository branch protection prevents auto-merge and ensure pipeline never calls merge endpoints.",
            "dependencies": [
              "10.3"
            ],
            "details": "Verification steps:\n- Ensure codebase contains no calls to merge endpoints (e.g., grep for \"/merges\" and \"/pulls/{}/merge\").\n- Query protection (if token has scope): GET /repos/{owner}/{repo}/branches/{branch}/protection; verify required status checks or required reviews include human review as policy dictates.\n- After an approval by QA App, confirm PR remains open and unmerged until human action.\n\nEnv/inputs: OWNER, REPO, BRANCH, GITHUB_TOKEN.\nAcceptance criteria:\n- Approvals by QA App do not merge the PR.\n- Branch protection is intact (endpoint returns protection settings or manual verification documented).\n- No merge API calls executed by any step.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "End-to-end tests (pass/fail paths) and documentation",
            "description": "Create E2E tests for both successful and failing QA proof scenarios and write documentation covering setup, env vars, API usage, and artifact schema.",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4",
              "10.5",
              "10.6"
            ],
            "details": "Test scenarios:\n- Success: qa-testing produces valid summary.json with qa.passed=true; verify-k8s-proof passes; approve-pr posts APPROVE; comment posted; PR not merged.\n- Failure: summary.json missing or qa.passed=false; verify-k8s-proof fails; approve-pr and comment steps do not run; workflow fails.\n\nImplementation:\n- Use a sandbox repo/PR. Inject tokens via secrets. Optionally mock GitHub API with a test server for reliability.\n- Assertions: review presence by QA App identity; comment content includes links; PR merge state unchanged; artifacts uploaded when enabled.\n\nDocs:\n- README: architecture, DAG dependencies, required env vars (OWNER, REPO, PR_NUMBER, BRANCH, GITHUB_TOKEN[_PATH], ARTIFACTS_DIR, OBJECT_STORE_*), API endpoints used, summary.json schema, troubleshooting.\n\nAcceptance criteria:\n- Automated E2E runs pass deterministically for both paths.\n- Documentation reviewed and usable for setup without external guidance.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-16T01:50:33.797Z",
      "updated": "2025-08-16T01:50:33.797Z",
      "description": "Tasks for master context"
    }
  }
}