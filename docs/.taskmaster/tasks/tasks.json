{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Analyze Existing CodeRun Controller Architecture",
        "description": "Perform comprehensive discovery and documentation of the existing CodeRun controller implementation, CRD structure, template system, and agent pod creation flow - COMPLETED with 47-page technical analysis",
        "status": "completed",
        "dependencies": [],
        "priority": "high",
        "details": "DISCOVERY PHASE COMPLETE: Comprehensive analysis documented in task-1-discovery-report.md (47 pages). Key findings: 1) CRD fully supports multi-agent scenarios with github_app field and agent-specific env/secrets 2) Controller has solid reconciliation patterns with status-first idempotency and TTL safety 3) Handlebars template system ready for agent-specific customization with conditional logic support 4) Argo Events infrastructure working (rate-limited but functional) 5) GitHub App authentication flow production-ready in container.sh.hbs (1120+ lines). Infrastructure confirmed ready for multi-agent implementation with clear modification priorities identified.",
        "testStrategy": "Documentation validated through actual CodeRun submissions and controller log analysis. Test CRDs confirmed the documented flow matches observed behavior. kubectl describe and controller logs verified understanding of reconciliation patterns, finalizer logic, and status updates. All compatibility requirements for existing Rex/Blaze workflows documented.",
        "subtasks": [
          {
            "id": 1,
            "title": "Document CRD Structure Analysis",
            "description": "Complete analysis of CodeRun CRD with focus on multi-agent support capabilities",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Analyze Controller Reconciliation Logic",
            "description": "Document reconciliation patterns, status-first idempotency, and TTL safety mechanisms",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Map Template System Architecture",
            "description": "Document Handlebars template system with conditional logic capabilities for agent customization",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Verify Argo Events Infrastructure",
            "description": "Confirm Argo Events working status and document rate-limiting considerations",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Document GitHub App Authentication",
            "description": "Map production-ready authentication flow in container.sh.hbs template",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Identify Required Modifications",
            "description": "Prioritize modifications: PVC naming, agent templates, conditionals, workflows, sensors",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Confirm Technical Feasibility",
            "description": "Validate suspend/resume, event correlation, agent isolation, and template customization",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Generate Discovery Report",
            "description": "Create comprehensive 47-page technical analysis document (task-1-discovery-report.md)",
            "status": "completed",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 2,
        "title": "Setup Argo Events Infrastructure",
        "description": "Create and configure Argo Events Sensors for multi-agent workflow orchestration using existing EventBus and EventSource infrastructure",
        "status": "in-progress",
        "dependencies": [],
        "priority": "high",
        "details": "Infrastructure (EventBus, EventSource, test sensor) is already deployed and functional. Create four specialized Sensors for agent coordination: 1) Multi-agent workflow resume sensor to handle PR creation events and resume workflows after Rex completes, 2) Ready-for-QA label sensor to detect PR labeling and resume after Cleo, 3) PR approval sensor to handle approval events and resume after Tess, 4) Rex remediation sensor to detect Rex pushes and cancel/restart the QA pipeline. All sensors should use the existing 'github' EventSource and 'argo' EventBus. Reference github-demo-sensor.yaml for patterns. Focus on proper webhook payload field correlation and workflow label selectors for targeting specific suspended workflows.",
        "testStrategy": "Verify each Sensor is deployed with kubectl get sensors -n argo. Test webhook event processing by triggering actual GitHub events (PR creation, labeling, approval, push). Confirm Sensors correctly correlate events using kubectl logs. Validate workflow resumption with suspended test workflows. Test remediation sensor properly cancels running workflows and restarts pipeline. Monitor for rate limiting issues.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create multi-agent workflow resume sensor",
            "description": "Build Sensor for PR created events to resume workflows after Rex",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create ready-for-QA label sensor",
            "description": "Build Sensor for PR labeled events to resume workflows after Cleo",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Create PR approval sensor",
            "description": "Build Sensor for PR approved events to resume workflows after Tess",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Create Rex remediation sensor",
            "description": "Build Sensor to detect Rex pushes, cancel Cleo/Tess workflows, and restart QA pipeline",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Design Multi-Agent Workflow DAG Structure",
        "description": "Create the core Argo Workflow template with parameterized agent selection, DAG task dependencies, and suspend points for event-driven transitions",
        "details": "Design play-workflow template with configurable parameters: implementation-agent, quality-agent, testing-agent (no hardcoded names). Structure DAG with tasks: implementation-work → wait-pr-created (suspend) → quality-work → wait-ready-for-qa (suspend) → testing-work → wait-pr-approved (suspend) → complete-task. Set activeDeadlineSeconds: 1209600 (14 days). Add workflow labels for correlation: workflow-type=play-orchestration, task-id={{task-id}}, current-stage={{stage}}. Use Argo Workflows v3.5+ for enhanced suspend/resume capabilities.",
        "testStrategy": "Deploy workflow template and validate DAG visualization in Argo UI. Test parameter propagation through workflow steps. Verify suspend points pause execution correctly. Confirm workflow can run for extended periods without timing out.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Base Workflow Template Structure",
            "description": "Design and implement the foundational Argo Workflow template with parameterized agent selection and core DAG structure",
            "dependencies": [],
            "details": "Create play-workflow.yaml template with ConfigMap or WorkflowTemplate resource. Define workflow parameters: implementation-agent, quality-agent, testing-agent as strings. Set workflow metadata including generateName, labels (workflow-type=play-orchestration), and annotations. Configure spec.activeDeadlineSeconds: 1209600. Define entrypoint pointing to main DAG template. Add volumeClaimTemplates for shared workspace between tasks.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Implementation-Work Task",
            "description": "Create the first DAG task that submits CodeRun CRD for implementation agent execution",
            "dependencies": [
              "3.1"
            ],
            "details": "Define implementation-work task using resource template type. Create CodeRun CRD manifest with agent parameter {{workflow.parameters.implementation-agent}}. Set task-id label from workflow parameter. Configure resource action: create. Add outputs to capture CodeRun name and status. Set retry strategy with backoff. Include failure handling with onExit hooks.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Add Wait-PR-Created Suspend Point",
            "description": "Implement the first suspension point that waits for PR creation event",
            "dependencies": [
              "3.2"
            ],
            "details": "Create suspend template with name wait-pr-created. Add correlation labels: task-id={{workflow.parameters.task-id}}, current-stage=pr-creation. Configure suspend.duration as optional timeout (e.g., 4h). Add parameters to receive PR URL and number on resume. Store resume data in workflow parameters for next tasks. Include status message for UI visibility.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Create Quality-Work Task",
            "description": "Implement quality assurance task that invokes the QA agent after PR creation",
            "dependencies": [
              "3.3"
            ],
            "details": "Define quality-work task dependent on wait-pr-created completion. Submit CodeRun CRD with quality-agent parameter. Pass PR information from previous suspend point as environment variables. Configure task to use PR URL from workflow parameters. Add output parameters for QA results. Set appropriate resource limits and timeout.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Add Wait-Ready-for-QA Suspend Point",
            "description": "Implement suspension point for QA readiness confirmation",
            "dependencies": [
              "3.4"
            ],
            "details": "Create wait-ready-for-qa suspend template after quality-work. Update current-stage label to qa-ready. Configure correlation with same task-id. Add parameters for QA approval status and comments. Implement validation logic for resume data. Store QA feedback in workflow parameters for audit trail.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Implement Testing-Work Task",
            "description": "Create testing task that executes test agent after QA approval",
            "dependencies": [
              "3.5"
            ],
            "details": "Define testing-work task using testing-agent parameter. Submit CodeRun CRD with test configuration. Pass PR and QA information from previous stages. Configure test-specific environment variables and secrets. Add test result outputs including pass/fail status and reports. Implement conditional logic based on QA feedback.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Add Wait-PR-Approved Suspend Point",
            "description": "Implement final suspension point for PR approval",
            "dependencies": [
              "3.6"
            ],
            "details": "Create wait-pr-approved suspend template as final gate. Update current-stage label to pr-approval. Add parameters for approval status and merge commit SHA. Configure longer timeout (e.g., 48h) for human review. Store approval metadata including approver and timestamp. Add validation to ensure PR is mergeable.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Design Complete-Task with Cleanup",
            "description": "Implement workflow completion task with resource cleanup and notifications",
            "dependencies": [
              "3.7"
            ],
            "details": "Create complete-task as final DAG node. Implement cleanup logic: delete temporary CodeRun CRDs, clean workspace volumes. Send completion notifications via webhook or events. Update task status in external system if configured. Archive workflow artifacts to S3/MinIO. Generate workflow summary report with all stage outcomes.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Configure Workflow Labels and Correlation",
            "description": "Set up comprehensive labeling system for event correlation and monitoring",
            "dependencies": [
              "3.8"
            ],
            "details": "Apply workflow-level labels: workflow-type=play-orchestration, task-id={{workflow.parameters.task-id}}. Implement dynamic stage label updates using Argo expressions. Add correlation-id for distributed tracing. Configure label selectors for resume operations. Set up label-based monitoring queries. Ensure labels propagate to child resources (CodeRuns, PVCs).",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Agent-Specific PVC Naming",
        "description": "Modify the Rust controller to extract agent names from github_app field and implement workspace-{service}-{agent} PVC naming pattern",
        "details": "Update controller/src/tasks/code/resources.rs to parse github_app field (e.g., '5DLabs-Rex' → 'rex'). Implement extract_agent_name() function using regex or string manipulation. Modify PVC creation logic to use format!('workspace-{}-{}', code_run.spec.service, agent_name). Ensure backward compatibility by checking for existing PVCs with old naming. Update controller reconciliation to handle both naming patterns during transition period. Consider using kube-rs PersistentVolumeClaim API for idempotent creation.",
        "testStrategy": "Unit test extract_agent_name() with various GitHub App formats. Integration test PVC creation with different agents. Verify workspace isolation between Rex, Cleo, and Tess. Confirm existing workflows continue working with legacy PVC names.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Create GitHub Webhook Correlation Logic",
        "description": "Implement Argo Events Sensor logic to extract task IDs from webhook payloads and correlate with suspended workflows using label selectors",
        "details": "Create Sensor with webhook event processing using JQ expressions: '.pull_request.labels[] | select(.name | startswith(\"task-\")) | .name | split(\"-\")[1]'. Implement correlation logic using labelSelector: 'workflow-type=play-orchestration,task-id={{extracted-task-id}},current-stage={{target-stage}}'. Handle multiple event types: pull_request (opened/labeled), pull_request_review (submitted). Use Argo Events v1.9+ parameterization features for dynamic targeting. Implement fallback to branch name parsing if labels missing.",
        "testStrategy": "Test JQ extraction with sample webhook payloads. Verify correlation finds correct suspended workflow. Test with multiple concurrent workflows. Validate edge cases: missing labels, malformed task IDs, duplicate labels.",
        "priority": "high",
        "dependencies": [
          2,
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Develop Agent-Specific Handlebars Templates",
        "description": "Create specialized container scripts for Rex/Blaze, Cleo, and Tess agents with template selection logic based on github_app parameter",
        "status": "pending",
        "dependencies": [
          1,
          4
        ],
        "priority": "medium",
        "details": "Implement simplified architecture using agent-specific container scripts instead of complex template conditionals. Create in infra/charts/controller/claude-templates/: container-rex.sh.hbs (documentation workflow - pulls docs, copies task files), container-cleo.sh.hbs (code quality workflow - focuses on formatting, Clippy, PR labeling with 'ready-for-qa'), container-tess.sh.hbs (testing workflow - deployment validation, test coverage, PR approval). Implement template selection logic in the controller to choose correct container script based on github_app field ('5DLabs-Rex', '5DLabs-Cleo', '5DLabs-Tess'). Keep system prompts simple and focused on each agent's core responsibilities. This approach avoids complex Rust controller modifications while maintaining clean separation of agent workflows.",
        "testStrategy": "Test template selection logic with different github_app values. Verify correct container script is selected for each agent. Test each container script executes its specific workflow correctly. Validate agent-specific behaviors: Rex pulls documentation, Cleo runs formatting/Clippy, Tess focuses on testing. Ensure clean handoff between agents through workflow stages.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create container-rex.sh.hbs template",
            "description": "Implement Rex/Blaze container script for documentation workflow",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create container-cleo.sh.hbs template",
            "description": "Implement Cleo container script for code quality workflow",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Create container-tess.sh.hbs template",
            "description": "Implement Tess container script for testing workflow",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement template selection logic",
            "description": "Add logic to select correct container script based on github_app field",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Update template loading mechanism",
            "description": "Modify controller to load agent-specific container scripts",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Workflow Stage Transitions",
        "description": "Create workflow template logic to update current-stage labels and handle transitions between agent phases",
        "details": "Implement label update mechanism after each DAG task completes. Use Argo Workflows resource template to patch workflow labels via Kubernetes API. Stage progression: waiting-pr-created → waiting-ready-for-qa → waiting-pr-approved. Ensure atomic label updates to prevent race conditions. Use workflow.labels for dynamic label management. Implement using inline script or resource operation with kubectl patch commands.",
        "testStrategy": "Verify label updates occur at correct workflow stages. Test concurrent label updates don't cause conflicts. Confirm Sensor correctly targets workflows based on stage labels. Monitor for label update failures in workflow logs.",
        "priority": "medium",
        "dependencies": [
          3,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Build Rex Remediation Sensor",
        "description": "Create dedicated Argo Events Sensor to detect Rex push events and trigger QA pipeline restart with downstream cancellation",
        "details": "Create rex-remediation-restart Sensor filtering push events where sender.login='5DLabs-Rex[bot]' or configured implementation agent. Implement trigger to delete running Cleo/Tess CodeRun CRDs using labelSelector: 'task-id={{task-id}},github-app!=5DLabs-Rex'. Restart workflow from quality-work stage. Use Argo Events data filters and conditional triggers. Implement idempotency to prevent duplicate restarts. Consider using Kubernetes owner references for cascade deletion.",
        "testStrategy": "Simulate Rex push events and verify Cleo/Tess work cancellation. Test labelSelector correctly excludes Rex's own work. Verify QA pipeline restarts cleanly. Test rapid sequential pushes don't cause issues.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Configure External Secrets for Agent Apps",
        "description": "Setup External Secrets resources for Cleo and Tess GitHub Apps with proper secret store integration",
        "details": "Create ExternalSecret resources for github-app-5dlabs-cleo and github-app-5dlabs-tess following existing patterns. Configure ClusterSecretStore references using AWS Secrets Manager or configured backend. Map secret keys: app_id, private_key, client_id for GitHub App authentication. Set refreshInterval: 1h for automatic rotation. Ensure secrets mounted correctly in agent pods. Reference existing toolman-external-secrets.yaml pattern.",
        "testStrategy": "Verify secrets created in correct namespace. Test GitHub App authentication using stored credentials. Validate secret rotation doesn't disrupt running agents. Check pod volume mounts contain expected keys.",
        "priority": "medium",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement Ready-for-QA Label Logic",
        "description": "Add logic for Cleo to add 'ready-for-qa' label to PRs through container-cleo.sh.hbs script as explicit handoff signal to Tess",
        "status": "pending",
        "dependencies": [
          6,
          7
        ],
        "priority": "medium",
        "details": "Implement ready-for-qa labeling directly in container-cleo.sh.hbs script. Workflow sequence: 1) Run code quality checks (Clippy, rustfmt) 2) Push fixes to same branch 3) Wait for CI tests to pass 4) Add 'ready-for-qa' label via GitHub API 5) Complete successfully. This label serves as explicit handoff signal to trigger Tess stage in multi-agent workflow. Include GitHub API authentication and label management directly in Cleo's container script. Create Sensor trigger for pull_request.labeled events where label.name='ready-for-qa'. Resume workflow at waiting-ready-for-qa suspend point. Ensure idempotent label addition (check before adding).",
        "testStrategy": "Verify container-cleo.sh.hbs successfully adds label after quality checks and CI pass. Test that script waits for CI tests before labeling. Confirm GitHub API authentication works in container context. Test Sensor correctly detects label addition event. Confirm workflow resumes at correct suspension point. Test duplicate label addition handling. Validate explicit handoff to Tess stage.",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Setup Tess Kubernetes RBAC",
        "description": "Configure comprehensive RBAC permissions for Tess agent to perform live Kubernetes testing and deployments",
        "details": "Create ServiceAccount 'coderun-tess' in agent-platform namespace. Define ClusterRole with extensive permissions for testing (initially cluster-admin for lab, refine later). Create ClusterRoleBinding linking ServiceAccount to ClusterRole. Configure controller to use agent-specific ServiceAccounts based on github_app. Update CodeRun CRD spec to reference serviceAccountName. Consider using Kubernetes RBAC aggregation for maintainability.",
        "testStrategy": "Test Tess can create/read/update/delete test resources. Verify other agents don't have excessive permissions. Validate ServiceAccount token mounting in pods. Test permission boundaries with various K8s operations.",
        "priority": "low",
        "dependencies": [
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Create MCP Documentation Server Integration",
        "description": "Setup MCP documentation server and configure Rex/Blaze container scripts to query documentation before implementation",
        "status": "pending",
        "dependencies": [
          6
        ],
        "priority": "low",
        "details": "Deploy rustdocs-mcp server (existing in infra/charts/rustdocs-mcp/). Configure container-rex.sh.hbs and container-blaze.sh.hbs templates to include rustdocs_query_rust_docs tool in their environments. Implement documentation-first workflow specifically in Rex/Blaze container scripts that queries MCP documentation server before any implementation. Add documentation-first instructions to container scripts. Setup service discovery for MCP server endpoints. Configure authentication if required. Implement retry logic for documentation queries. Note: Cleo and Tess agents don't require documentation queries as they focus on code quality and testing respectively.",
        "testStrategy": "Verify MCP server accessible from Rex/Blaze agent containers. Test documentation queries return relevant results through container script execution. Validate Rex/Blaze use documentation in implementation workflow. Monitor query performance and success rates. Verify Cleo/Tess containers operate without documentation dependencies.",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Implement Task Progression Logic",
        "description": "Build workflow logic to move completed tasks to .completed directory and discover next pending task",
        "details": "Add workflow step after PR merge to move task directory: 'mv docs/.taskmaster/docs/task-X/ docs/.taskmaster/docs/.completed/'. Implement task discovery using: 'find docs/.taskmaster/docs/ -maxdepth 1 -name \"task-*\" -type d | grep -v \".completed\" | sort -V | head -1'. Create workflow loop to continue with next task if found. Handle edge cases: no more tasks, invalid task structure. Use Argo Workflows loops or recursive templates.",
        "testStrategy": "Test task movement after successful completion. Verify next task discovery with various directory structures. Test edge cases: last task, missing tasks, corrupted structure. Validate workflow continues seamlessly.",
        "priority": "low",
        "dependencies": [
          3,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Build Workflow Resume Operations",
        "description": "Implement robust workflow resume operations for each suspension point with proper event correlation",
        "details": "Implement resume operations using Argo Workflows API or kubectl. Each resume must validate: correct workflow (by labels), correct stage, valid event data. Add retry logic with exponential backoff for resume failures. Log all resume attempts for debugging. Consider using Argo Workflows SDK for programmatic control. Implement circuit breaker pattern for repeated failures.",
        "testStrategy": "Test resume operations at each suspension point. Verify only correct workflows resume. Test concurrent resume attempts. Validate retry logic under API failures. Monitor resume latency and success rates.",
        "priority": "medium",
        "dependencies": [
          5,
          7,
          10
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Create Workflow Monitoring Dashboard",
        "description": "Develop Grafana dashboard to monitor multi-agent workflow progress, agent performance, and system health",
        "details": "Create Grafana dashboard using existing telemetry stack (Victoria Metrics). Track metrics: workflow duration by stage, agent success rates, suspension wait times, task completion rates. Use PromQL queries against Argo Workflows metrics. Add alerts for stuck workflows (>24h at same stage). Visualize agent-specific performance (Rex vs Blaze comparison). Include GitHub webhook processing metrics. Reference existing infra/telemetry/telemetry-dashboards/.",
        "testStrategy": "Verify metrics collected from all workflow stages. Test dashboard updates in real-time. Validate alerts trigger correctly. Load test with multiple concurrent workflows. Check dashboard performance with historical data.",
        "priority": "low",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement Controller Template Loading",
        "description": "Update Rust controller to select agent-specific container scripts based on github_app field for different workflow types",
        "status": "pending",
        "dependencies": [
          4,
          6
        ],
        "priority": "medium",
        "details": "Modify controller/src/tasks/code/templates.rs to implement simple script selection based on agent name extracted from github_app field. Map agents to their specific container scripts: '5DLabs-Rex' or '5DLabs-Blaze' → container-rex.sh.hbs (current implementation workflow), '5DLabs-Cleo' → container-cleo.sh.hbs (code quality workflow), '5DLabs-Tess' → container-tess.sh.hbs (testing workflow). This approach avoids complex Handlebars conditionals and keeps agent workflows cleanly separated. Each container script template will contain the complete workflow logic for that specific agent.",
        "testStrategy": "Unit test script selection logic for each agent type (Rex, Blaze, Cleo, Tess). Verify correct template file is loaded based on github_app value. Test fallback behavior for unknown agents. Validate that each container script template loads and compiles correctly. Test edge cases like missing templates or malformed github_app values.",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Setup Multi-Task Processing",
        "description": "Extend workflow to handle multiple tasks in sequence with proper state management and progress tracking",
        "details": "Implement workflow parameter for task list or task range. Create loop template to iterate through tasks. Maintain workflow state between tasks using Argo parameters. Implement checkpointing for long-running multi-task workflows. Add task progress reporting to workflow status. Consider using Argo Workflows memoization for completed steps. Handle partial failures with retry policies.",
        "testStrategy": "Test workflow with multiple sequential tasks. Verify state maintained between tasks. Test failure recovery mid-sequence. Validate checkpoint restoration. Monitor resource usage over extended runs.",
        "priority": "low",
        "dependencies": [
          13,
          14
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Create Test Coverage Requirements",
        "description": "Implement test coverage enforcement workflow for Tess agent integrated directly into container-tess.sh.hbs script with automated PR approval based on coverage metrics",
        "status": "pending",
        "dependencies": [
          6,
          11
        ],
        "priority": "low",
        "details": "Implement comprehensive test coverage workflow in container-tess.sh.hbs template. Workflow sequence: 1) Review code against acceptance criteria using Tess analysis 2) Execute existing test suite to verify functionality 3) Analyze coverage with cargo llvm-cov integrated into container environment 4) Automatically generate missing unit/integration tests to achieve ~100% coverage 5) Re-run full test suite with new tests 6) Generate coverage reports in HTML and Cobertura formats 7) Use GitHub API to approve PR when coverage meets thresholds (95% existing, 100% new code). Include coverage tools installation, report generation logic, and GitHub API integration for automated approval directly in Tess container script. Implement coverage trend analysis and PR comment updates.",
        "testStrategy": "Verify container-tess.sh.hbs correctly installs and configures cargo llvm-cov. Test full workflow sequence from code review to PR approval. Validate Tess generates appropriate tests for uncovered code paths. Test GitHub API approval integration with various coverage scenarios. Verify coverage report generation and accuracy. Test threshold enforcement (95% existing, 100% new). Validate workflow handles edge cases: test failures, coverage regressions, API errors.",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup cargo llvm-cov in container-tess.sh.hbs",
            "description": "Add coverage tool installation and configuration to Tess container initialization",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement acceptance criteria review logic",
            "description": "Create code review step that validates against defined acceptance criteria",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Add test execution and coverage analysis",
            "description": "Integrate test running and coverage measurement into workflow sequence",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement test generation for uncovered code",
            "description": "Add logic for Tess to automatically create tests for code paths with insufficient coverage",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Configure coverage report generation",
            "description": "Setup HTML and Cobertura report generation with proper output paths",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Integrate GitHub API for PR approval",
            "description": "Add GitHub API calls to approve PR when coverage thresholds are met",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Add coverage trend analysis",
            "description": "Implement logic to track and report coverage trends across commits",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 19,
        "title": "Implement PR Approval Workflow",
        "description": "Build automated PR approval flow triggered by Tess validation completion with human review gate",
        "details": "Configure Tess to use GitHub API for PR approval after 120% satisfaction. Implement Sensor for pull_request_review events where review.state='approved' and user='5DLabs-Tess[bot]'. Resume workflow at waiting-pr-approved suspension. Add human review checkpoint before merge. Implement approval criteria validation (tests passing, coverage met, no conflicts). Use GitHub branch protection rules for enforcement.",
        "testStrategy": "Test Tess approval triggers workflow resume. Verify human review gate functions correctly. Test approval with various PR states. Validate branch protection enforcement. Test approval revocation scenarios.",
        "priority": "low",
        "dependencies": [
          10,
          18
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Setup Workflow Failure Handling",
        "description": "Implement comprehensive error handling, retry logic, and failure recovery for all workflow stages",
        "details": "Define retry strategies per workflow stage (exponential backoff). Implement failure notifications (Slack, email) for critical failures. Create failure analysis templates to identify root causes. Add manual intervention points for unrecoverable errors. Implement workflow rollback for partial completions. Use Argo Workflows retry, retryStrategy, and onExit handlers. Consider dead letter queue pattern for failed events.",
        "testStrategy": "Test retry logic with transient failures. Verify notifications sent for critical errors. Test rollback scenarios. Validate manual intervention workflow. Simulate various failure modes (network, API limits, resource constraints).",
        "priority": "medium",
        "dependencies": [
          14,
          17
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Create End-to-End Testing Suite",
        "description": "Develop comprehensive E2E tests covering entire multi-agent workflow from trigger to completion",
        "details": "Create test scenarios: happy path, feedback loops, agent failures, concurrent tasks. Use GitHub API to create test PRs and events. Implement workflow assertions using Argo CLI or API. Test with synthetic tasks of varying complexity. Measure end-to-end latency and identify bottlenecks. Create chaos testing scenarios (pod failures, network issues). Use property-based testing for event correlation logic.",
        "testStrategy": "Run full workflow with test tasks. Verify each stage completes correctly. Test feedback loops with multiple iterations. Validate performance under load. Test recovery from various failure modes. Monitor for race conditions.",
        "priority": "medium",
        "dependencies": [
          17,
          19
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Comprehensive Test Scenarios",
            "description": "Create detailed test scenarios covering happy path workflows, multi-iteration feedback loops, agent failure recovery, and concurrent task execution patterns",
            "dependencies": [],
            "details": "Define test cases for: successful end-to-end flow with Rex/Blaze/Tess agents, feedback loop scenarios with 3+ iterations, agent timeout and failure recovery, concurrent PR processing, workflow suspension/resume cycles, edge cases like malformed webhooks and missing labels. Document expected outcomes and assertions for each scenario.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement GitHub API Test Infrastructure",
            "description": "Build test harness for creating synthetic PRs, labels, reviews, and webhook events using GitHub API to simulate real workflow triggers",
            "dependencies": [
              "21.1"
            ],
            "details": "Create test utilities for: generating test repositories and PRs with configurable labels (task-*), simulating PR review events and status updates, creating webhook payloads matching production format, managing test data cleanup after runs. Implement rate limiting handling and API authentication. Support both GitHub.com and GitHub Enterprise.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Develop Argo Workflow Assertion Framework",
            "description": "Create assertion library using Argo CLI/API to verify workflow state transitions, suspension points, and completion status",
            "dependencies": [
              "21.1"
            ],
            "details": "Build assertions for: workflow creation and initialization, correct stage transitions (rex -> blaze -> tess), suspension state verification at each stage, label selector validation (workflow-type, task-id, current-stage), parameter passing between stages, workflow completion and artifact validation. Implement retry logic for eventual consistency.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Build Synthetic Task Generator",
            "description": "Create configurable task generators producing varying complexity levels to stress-test the multi-agent system under different loads",
            "dependencies": [
              "21.2"
            ],
            "details": "Generate tasks with: simple code changes (single file edits), complex refactoring (multi-file changes), test generation requirements, varying PR sizes (10-1000 lines), different language contexts (Python, Go, TypeScript). Support configurable complexity levels and task distribution patterns. Include realistic code patterns from production usage.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Implement Chaos Testing Scenarios",
            "description": "Develop chaos engineering tests simulating pod failures, network partitions, and resource exhaustion to validate system resilience",
            "dependencies": [
              "21.3"
            ],
            "details": "Implement chaos scenarios: random pod termination during agent execution, network delays between Argo and agents, CPU/memory resource limits triggering OOM, EventSource/Sensor failures and restarts, Victoria Metrics unavailability, GitHub API rate limiting. Use tools like Chaos Mesh or Litmus. Verify graceful degradation and recovery.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Create Property-Based Testing for Event Correlation",
            "description": "Implement property-based tests validating event correlation logic handles all valid webhook payload variations and label formats",
            "dependencies": [
              "21.2",
              "21.3"
            ],
            "details": "Test properties: any valid task-* label format extracts correct ID, correlation finds unique suspended workflow, duplicate events are idempotent, malformed payloads don't crash system, label selector matching is deterministic. Use hypothesis or similar framework. Generate thousands of test cases automatically. Verify JQ expressions handle edge cases.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Build Performance Measurement Suite",
            "description": "Implement comprehensive latency measurement and bottleneck identification across all workflow stages and agent interactions",
            "dependencies": [
              "21.3",
              "21.4"
            ],
            "details": "Measure: end-to-end workflow completion time, individual stage durations (Rex, Blaze, Tess), webhook to workflow correlation latency, suspension/resume overhead, agent startup and initialization time, artifact passing between stages. Create performance baselines and regression detection. Generate flame graphs and trace analysis. Identify optimization opportunities.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Setup Continuous E2E Test Execution",
            "description": "Configure automated test execution pipeline running full E2E suite on schedule and PR triggers with result reporting",
            "dependencies": [
              "21.1",
              "21.2",
              "21.3",
              "21.4",
              "21.5",
              "21.6",
              "21.7"
            ],
            "details": "Create Argo Workflow or GitHub Actions pipeline: run E2E tests every 4 hours and on PR changes, execute test scenarios in parallel where possible, collect and aggregate test results and metrics, publish results to Grafana dashboard, send alerts on test failures, maintain test history and trend analysis. Integrate with existing CI/CD pipeline.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 22,
        "title": "Implement Resource Management",
        "description": "Configure resource limits, quotas, and autoscaling for agent pods and workflow components",
        "details": "Set resource requests/limits for agent pods (CPU: 2-4 cores, Memory: 8-16Gi based on model). Configure PVC size limits per agent (start with 10Gi). Implement workflow-level resource quotas. Setup HPA for controller deployment. Configure pod priority classes for critical workflows. Implement resource monitoring and alerting. Consider using Kubernetes VPA for right-sizing.",
        "testStrategy": "Test agents run within resource limits. Verify OOM handling and recovery. Test autoscaling under load. Validate quota enforcement. Monitor resource utilization patterns. Test priority scheduling under contention.",
        "priority": "low",
        "dependencies": [
          15
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Setup Workflow Archival",
        "description": "Implement workflow archival and cleanup policies for completed workflows",
        "details": "Configure Argo Workflows artifact repository (S3/MinIO) for workflow archival. Set TTL for completed workflows (30 days). Implement workflow GC (garbage collection) policies. Archive workflow logs and artifacts before deletion. Create workflow history API for querying archived workflows. Implement compliance-based retention policies. Consider using Workflow Archive for long-term storage.",
        "testStrategy": "Verify workflows archived after completion. Test artifact storage and retrieval. Validate TTL-based cleanup. Test GC doesn't delete active workflows. Verify archived workflow queryability. Test restoration from archive.",
        "priority": "low",
        "dependencies": [
          19
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "Create Operations Runbook",
        "description": "Document operational procedures, troubleshooting guides, and maintenance tasks for the multi-agent system",
        "details": "Document common issues and resolutions (stuck workflows, failed events, agent errors). Create troubleshooting decision trees. Document manual intervention procedures. Provide kubectl commands for common operations. Include architecture diagrams and data flow. Document backup/restore procedures. Create incident response playbooks. Include performance tuning guidelines.",
        "testStrategy": "Validate procedures with operational team. Test troubleshooting guides with real issues. Verify documentation completeness. Test restore procedures in staging. Review with SRE team. Conduct operational readiness review.",
        "priority": "low",
        "dependencies": [
          21,
          23
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 25,
        "title": "Production Deployment Pipeline",
        "description": "Create GitOps deployment pipeline for rolling out multi-agent workflow system to production",
        "details": "Setup ArgoCD applications for all components (controller, Argo Workflows, Argo Events). Implement progressive rollout strategy with canary deployments. Create rollback procedures with version pinning. Configure production-specific parameters (timeouts, retries, resources). Implement feature flags for gradual enablement. Setup production monitoring and alerting. Use Flux or ArgoCD for GitOps automation.",
        "testStrategy": "Test deployment in staging environment. Verify rollback procedures work correctly. Test canary deployment with traffic splitting. Validate monitoring in production. Test feature flag toggles. Perform load testing before production rollout.",
        "priority": "medium",
        "dependencies": [
          24
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 26,
        "title": "Implement comprehensive task association validation using multi-method approach",
        "description": "Create a robust validation system that correlates workflows with tasks using three complementary methods (PR labels, branch naming, and marker files) with mandatory agreement between all methods to prevent workflow execution errors.",
        "details": "Implement a three-tier validation approach for task-workflow association:\n\n1. **Primary Method - PR Labels**: Extract task ID from PR labels using pattern 'task-{id}'. Implement in Sensor using JQ: '.pull_request.labels[] | select(.name | startswith(\"task-\")) | .name | split(\"-\")[1]'.\n\n2. **Secondary Method - Branch Naming**: Parse branch names following pattern 'task-{id}-{description}' or 'feature/task-{id}'. Use regex: '^(?:feature/)?task-(\\d+)(?:-.*)?$'. Extract task ID from pull_request.head.ref field.\n\n3. **Fallback Method - Marker File**: Read docs/.taskmaster/current-task.json containing: {\"task_id\": \"26\", \"started_at\": \"2024-01-15T10:00:00Z\", \"agent\": \"rex\"}.\n\n**Validation Logic Implementation**:\n```yaml\n# In Sensor trigger logic\nvalidation:\n  - name: extract-from-label\n    template: '{{.Input.pull_request.labels | tojson | fromjson | map(select(.name | startswith(\"task-\"))) | first | .name | split(\"-\")[1]}}'\n  - name: extract-from-branch\n    template: '{{.Input.pull_request.head.ref | capture(\"task-(\\\\d+)\") | .1}}'\n  - name: read-marker-file\n    resource:\n      action: get\n      manifest: |\n        apiVersion: v1\n        kind: ConfigMap\n        metadata:\n          name: task-marker-{{.Input.pull_request.head.sha}}\n```\n\n**Validation Enforcement**:\n- All three methods must return the same task ID or workflow fails\n- Implement comparison logic in Sensor using CEL expressions or Lua script\n- On mismatch, create GitHub comment with validation error details\n- Block workflow progression until validation passes\n\n**Workflow Template Enhancement**:\n```yaml\nspec:\n  entrypoint: validate-and-execute\n  templates:\n  - name: validate-and-execute\n    steps:\n    - - name: create-marker-file\n        template: marker-file-creator\n        arguments:\n          parameters:\n          - name: task-id\n            value: \"{{workflow.parameters.task-id}}\"\n    - - name: validate-association\n        template: validation-checker\n        arguments:\n          parameters:\n          - name: pr-label-id\n            value: \"{{tasks.extract-from-label.outputs.result}}\"\n          - name: branch-id\n            value: \"{{tasks.extract-from-branch.outputs.result}}\"\n          - name: marker-id\n            value: \"{{tasks.read-marker-file.outputs.result}}\"\n```\n\n**Marker File Creation Template**:\n```yaml\n- name: marker-file-creator\n  container:\n    image: alpine/git\n    command: [sh, -c]\n    args:\n    - |\n      cat > /workspace/docs/.taskmaster/current-task.json <<EOF\n      {\n        \"task_id\": \"{{inputs.parameters.task-id}}\",\n        \"started_at\": \"$(date -Iseconds)\",\n        \"agent\": \"{{workflow.parameters.implementation-agent}}\",\n        \"workflow_id\": \"{{workflow.name}}\",\n        \"commit_sha\": \"$(git rev-parse HEAD)\"\n      }\n      EOF\n      git add docs/.taskmaster/current-task.json\n      git commit -m \"chore: Set current task marker for task-{{inputs.parameters.task-id}}\"\n```\n\n**Error Handling**:\n- If validation fails, post GitHub comment with discrepancy details\n- Log validation attempts to workflow annotations\n- Implement retry mechanism with 3 attempts before permanent failure\n- Create ValidationError CRD to track validation failures for debugging",
        "testStrategy": "1. **Unit Testing**: Create test cases with various combinations of label/branch/marker values. Test scenarios: all match (pass), label missing (fail), branch mismatch (fail), marker file absent (fail), all different (fail).\n\n2. **Integration Testing**: Submit test PRs with deliberate mismatches. Verify workflow suspension and error reporting. Test with concurrent PRs for same task ID.\n\n3. **Validation Logic Testing**: Mock webhook payloads with different label configurations. Test regex patterns with edge cases: 'task-1-fix', 'feature/task-123-description', 'hotfix/task-45'.\n\n4. **Marker File Testing**: Verify marker file creation at workflow start. Test file persistence across workflow stages. Validate JSON structure and required fields.\n\n5. **Error Recovery Testing**: Test retry mechanism after validation failures. Verify GitHub comment creation with proper error details. Test workflow cleanup after validation rejection.\n\n6. **Performance Testing**: Measure validation latency with large label sets. Test marker file I/O performance. Monitor Sensor processing time for validation logic.\n\n7. **Security Testing**: Verify no sensitive data exposed in validation errors. Test injection attempts in branch names and labels. Validate marker file permissions and access controls.",
        "status": "pending",
        "dependencies": [
          5,
          3,
          7
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 27,
        "title": "Configure Comprehensive Admin Access for Tess Agent",
        "description": "Setup full infrastructure admin access for Tess agent including database credentials, Argo CD admin rights, and additional secret mounts for live deployment testing beyond standard Kubernetes RBAC",
        "details": "Create dedicated External Secrets for Tess admin credentials including Postgres superuser (host, port, username, password, database), Redis admin (host, port, password, cluster endpoints), and Argo CD admin token. Configure secret store mappings in AWS Secrets Manager or Vault under paths like '/infrastructure/tess-admin/postgres', '/infrastructure/tess-admin/redis', '/infrastructure/tess-admin/argocd'. Mount secrets as environment variables in Tess pod spec with names like POSTGRES_ADMIN_URL, REDIS_ADMIN_URL, ARGOCD_TOKEN. Create ConfigMap for non-sensitive configs (endpoints, ports). Implement secret rotation policy with 24h refresh interval. Add volume mounts for TLS certificates needed for database connections. Configure Argo CD AppProject with admin permissions for Tess service account. Create RBAC policies in Postgres and Redis granting full admin rights to Tess credentials. Implement secret validation init container to verify connectivity before main container starts. Use Kubernetes CSI Secret Store for dynamic secret injection. Configure audit logging for all admin operations performed by Tess. Set up break-glass access procedures for emergency scenarios. Document all access paths and permissions in security matrix.",
        "testStrategy": "Verify Tess can connect to Postgres with admin rights by creating/dropping test databases. Test Redis admin operations including FLUSHDB, CONFIG SET, and cluster management. Validate Argo CD access by creating/modifying/deleting test applications. Check secret rotation by forcing refresh and verifying new credentials work. Test TLS certificate validation for encrypted connections. Verify audit logs capture Tess admin operations. Simulate credential compromise and test revocation procedures. Validate init container blocks pod startup on invalid credentials. Test break-glass access with temporary elevated permissions. Monitor for credential leaks in logs or environment dumps. Verify other agents cannot access Tess admin secrets. Test failover scenarios with multiple database replicas.",
        "status": "pending",
        "dependencies": [
          11,
          9
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "Implement comprehensive monitoring and alerting for long-running multi-agent workflows",
        "description": "Build a robust monitoring system for multi-agent workflows that run over extended periods (days/weeks), including health checks, stuck workflow detection, resource tracking, and automated cleanup strategies for completed workflows.",
        "details": "Develop a comprehensive monitoring solution addressing operational concerns for long-running multi-agent workflows:\n\n1. **Health Check System**:\n   - Implement Kubernetes liveness/readiness probes for agent pods with custom health endpoints\n   - Create workflow heartbeat mechanism using Argo Workflows metrics (workflow.status.progress)\n   - Deploy synthetic health check workflows every 6 hours to verify system functionality\n   - Implement dead letter queue pattern for failed health checks\n   - Use Prometheus BlackBox exporter for external endpoint monitoring\n\n2. **Stuck Workflow Detection**:\n   - Configure Prometheus alerts for workflows stuck at same stage >6 hours (customizable per stage)\n   - Implement workflow age monitoring with graduated thresholds (warning at 7 days, critical at 10 days)\n   - Create AlertManager rules with PagerDuty/Slack integration for critical stuck workflows\n   - Build automatic workflow annotation with stuck reason analysis using controller logs\n   - Implement workflow recovery suggestions based on stuck patterns\n\n3. **Resource Consumption Tracking**:\n   - Deploy Kubernetes Metrics Server and collect pod-level metrics (CPU, memory, disk I/O)\n   - Implement PVC usage monitoring with alerts at 80% capacity\n   - Track GitHub API rate limits per agent using custom metrics\n   - Monitor network egress for cost optimization\n   - Create resource usage forecasting using historical data\n   - Implement cost allocation tags for multi-tenant scenarios\n\n4. **Automated Cleanup Strategies**:\n   - Configure graduated cleanup policies: active (no cleanup), completed (7 days), failed (3 days), stuck (14 days)\n   - Implement workflow archival to S3/MinIO before deletion with compression\n   - Create cleanup exemption mechanism via workflow annotations\n   - Build PVC cleanup for orphaned volumes using CronJob\n   - Implement log aggregation to centralized storage before pod deletion\n   - Create compliance-aware retention policies (30 days minimum for audit)\n\n5. **Monitoring Infrastructure**:\n   - Extend existing Grafana dashboards with long-running workflow panels\n   - Create SLO/SLI definitions: 99% workflow completion rate, <1% stuck rate\n   - Implement distributed tracing using OpenTelemetry for cross-agent correlation\n   - Build workflow timeline visualization showing all stage transitions\n   - Create agent performance comparison dashboard (Rex vs Cleo vs Tess)\n\n6. **Alerting Configuration**:\n   - Define alert severity levels: P1 (workflow stuck >24h), P2 (resource exhaustion), P3 (health check failures)\n   - Implement alert suppression during maintenance windows\n   - Create runbook automation for common issues (restart stuck workflow, cleanup PVC)\n   - Build alert correlation to reduce noise from cascading failures\n\n7. **Operational Tools**:\n   - Create kubectl plugin for workflow diagnostics: 'kubectl workflow-health'\n   - Implement workflow pause/resume CLI for maintenance\n   - Build bulk workflow operations API (pause all, cleanup completed)\n   - Create workflow migration tool for controller upgrades",
        "testStrategy": "Comprehensive testing approach for monitoring and alerting system:\n\n1. **Health Check Validation**:\n   - Deploy test workflow and verify health checks report correctly\n   - Simulate agent pod crashes and confirm detection within 5 minutes\n   - Test synthetic workflow execution and metric collection\n   - Validate health check endpoints return proper HTTP status codes\n\n2. **Stuck Workflow Testing**:\n   - Create workflow with artificial suspension >6 hours\n   - Verify Prometheus alert fires with correct labels\n   - Test AlertManager routing to appropriate channels\n   - Validate stuck reason analysis captures root cause\n   - Test recovery suggestions for common stuck patterns\n\n3. **Resource Monitoring Verification**:\n   - Run resource-intensive workflow and verify metrics collection\n   - Test PVC usage alerts at 80% threshold\n   - Validate GitHub API rate limit tracking\n   - Verify resource forecasting with historical data\n   - Test cost allocation tag propagation\n\n4. **Cleanup Strategy Testing**:\n   - Create workflows in various states (completed, failed, stuck)\n   - Verify cleanup occurs at configured intervals\n   - Test archival to S3/MinIO with retrieval\n   - Validate cleanup exemption via annotations\n   - Test PVC orphan detection and cleanup\n   - Verify compliance retention policies enforced\n\n5. **Load Testing**:\n   - Run 100+ concurrent workflows for 72 hours\n   - Monitor system stability and resource consumption\n   - Verify no metric collection gaps\n   - Test alert storm suppression\n   - Validate dashboard performance with high cardinality\n\n6. **Failure Scenario Testing**:\n   - Simulate Prometheus outage and verify fallback monitoring\n   - Test AlertManager failure and backup notification paths\n   - Validate monitoring resilience during controller restarts\n   - Test recovery from S3/MinIO unavailability\n\n7. **Integration Testing**:\n   - Verify end-to-end alert flow from detection to notification\n   - Test runbook automation for common scenarios\n   - Validate distributed tracing across multiple agents\n   - Test bulk operations under various workflow states",
        "status": "pending",
        "dependencies": [
          3,
          15,
          22,
          23
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Create agent-specific container scripts implementing distinct workflows for each agent type",
        "description": "Develop three specialized container scripts (container-rex.sh.hbs, container-cleo.sh.hbs, container-tess.sh.hbs) that implement distinct workflows tailored to each agent's responsibilities while maintaining compatibility with the existing CRD structure",
        "details": "Implement three agent-specific container scripts in infra/charts/controller/claude-templates/:\n\n**1. container-rex.sh.hbs (Documentation-Driven Implementation)**\n- Query MCP documentation server before implementation using rustdocs_query_rust_docs\n- Pull relevant documentation into context (API docs, architecture guides, existing patterns)\n- Implement documentation-first approach with inline comments referencing source docs\n- Create implementation plan based on documented patterns\n- Generate comprehensive inline documentation for new code\n- Use git commands to stage changes with descriptive commit messages\n- Include documentation validation step to ensure code matches documented behavior\n\n**2. container-cleo.sh.hbs (Code Quality and Formatting Workflow)**\n- Run cargo fmt with --check first to identify formatting issues\n- Apply cargo fmt to auto-fix formatting problems\n- Execute cargo clippy with strict warning levels (deny warnings)\n- Generate clippy fix suggestions and apply them automatically\n- Run additional linters (if configured): rustfmt, prettier for configs\n- Perform import organization and dead code detection\n- Create quality report summarizing all fixes applied\n- Label PR with 'ready-for-qa' after successful quality checks\n- Use git commit with message detailing quality improvements\n\n**3. container-tess.sh.hbs (Testing and Deployment Validation)**\n- Execute comprehensive test suite: cargo test --all-features\n- Run integration tests with cargo test --test '*' \n- Generate coverage reports using cargo llvm-cov or tarpaulin\n- Validate coverage meets thresholds (95% existing, 100% new code)\n- Perform deployment validation: cargo build --release\n- Run performance benchmarks if available: cargo bench\n- Execute property-based tests using proptest or quickcheck\n- Generate test report with coverage metrics and performance data\n- Approve PR if all tests pass and coverage requirements met\n- Create detailed test summary in PR comment\n\n**Common Script Structure:**\n- All scripts inherit base environment setup from shared template\n- Use consistent error handling with set -euo pipefail\n- Implement retry logic for transient failures (network, API calls)\n- Include telemetry hooks for workflow monitoring\n- Support dry-run mode for testing without commits\n- Use structured logging with timestamps and agent identification\n- Implement workspace isolation using agent-specific PVCs\n- Handle GitHub API interactions with proper authentication\n- Support both local and remote tool execution contexts\n\n**Template Variables:**\n- {{github_app}}: Agent identifier for conditional logic\n- {{task_id}}: Task reference for correlation\n- {{workspace_path}}: Agent-specific workspace location\n- {{github_token}}: Authentication for API calls\n- {{mcp_server_url}}: Documentation server endpoint (Rex only)\n- {{coverage_threshold}}: Test coverage requirements (Tess only)\n- {{quality_rules}}: Linting configuration (Cleo only)\n\n**Integration Points:**\n- Scripts must integrate with existing CodeRun CRD structure\n- Support status updates via Kubernetes API\n- Emit metrics for Grafana dashboard monitoring\n- Handle workflow stage transitions with label updates\n- Implement proper cleanup on failure or timeout",
        "testStrategy": "**Unit Testing:**\n- Test each script in isolation with mock environments\n- Verify Rex correctly queries and uses documentation\n- Confirm Cleo applies all formatting and linting fixes\n- Validate Tess runs complete test suite and calculates coverage\n- Test error handling paths with simulated failures\n\n**Integration Testing:**\n- Submit test CodeRun CRDs for each agent type\n- Verify correct script selection based on github_app field\n- Test workflow execution from start to completion\n- Validate GitHub PR updates (labels, comments, approvals)\n- Confirm workspace isolation between concurrent agents\n\n**Workflow Testing:**\n- Test Rex → Cleo → Tess pipeline with real tasks\n- Verify stage transitions trigger correctly\n- Test feedback loops when Rex makes changes\n- Validate Cleo/Tess cancellation on Rex updates\n- Monitor resource usage and performance metrics\n\n**Edge Case Testing:**\n- Test with missing dependencies or tools\n- Verify behavior with invalid GitHub tokens\n- Test timeout handling and cleanup\n- Validate behavior with conflicting git states\n- Test concurrent execution of same task by different agents\n\n**Regression Testing:**\n- Ensure backward compatibility with existing workflows\n- Verify legacy PVC naming still works\n- Test with various CRD configurations\n- Validate all existing integrations remain functional",
        "status": "pending",
        "dependencies": [
          6,
          4,
          12
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-17T02:13:07.385Z",
      "updated": "2025-08-17T02:36:26.728Z",
      "description": "Tasks for master context"
    }
  }
}