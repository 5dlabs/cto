{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Rust Watcher Project Setup and Config",
        "description": "Initialize the Rust sidecar watcher with async runtime, config loading, and CLI/env wiring to meet MVP deliverables.",
        "details": "Implementation outline:\n- Tech stack: Rust 1.78+, tokio, serde/serde_json, reqwest (HTTP), tracing (logs), anyhow/thiserror (errors), clap (CLI), config + envy (env), notify/inotify (file tailing), similar (diff), regex, bytes, tokio-util, axum (for optional input bridge later)\n- Config sources (priority): CLI flags > env > config file. Env keys per PRD: DISCORD_WEBHOOK_URL, WORKSPACE_PATH, POLL_INTERVAL_MS (default 100), BATCH_SIZE (default 10), PARITY_MODE (default false), FILTERS (includeTools/includePatterns/minStdoutLength), STATS toggles, MODEL_COSTS (map)\n- Define Config struct:\n  struct Config { webhook_url: Option<String>, workspace_path: PathBuf, poll_interval_ms: u64, batch_size: usize, parity_mode: bool, filters: Filters, stats: StatsCfg, resources: ResourceHints, }\n- Provide a discovery function for transcript file path override via CLI: --transcript <path>, else discover latest ~/.claude/projects/<encoded-workspace>/<session>.jsonl\n- Establish structured logging via tracing_subscriber with JSON logs for clusters\n- Prepare crate layout:\n  - bin/watcher.rs (main)\n  - lib modules: config.rs, tail.rs, parse.rs, embeds.rs, webhook.rs, stats.rs, trunc.rs, diff.rs, filters.rs, health.rs\n- Pseudo-code main:\n  fn main(){\n    let cfg = load_config(); init_tracing();\n    let tx = spawn_webhook_sender(cfg.webhook_url, cfg.batch_size);\n    let tail = Tail::new(discover_path(cfg.workspace_path)?, cfg.poll_interval_ms);\n    loop { for line in tail.next_line().await { if let Some(ev)=parse_event(&line,cfg.parity_mode,&cfg.filters){ let embeds = build_embeds(ev, &mut stats); tx.send(Message{embeds, attachments}).await; } } }\n  }\n- Ensure binary size small: build with strip, LTO; run with low memory via small allocations\n",
        "testStrategy": "- Unit tests for config parsing precedence (CLI > env > file) using temp env and clap mock args\n- Verify default values match PRD (poll 100ms, batch 10)\n- Smoke run with no webhook_url (Phase 1: static pre-created) and with webhook_url set\n- Benchmark binary memory (<64Mi) via cargo-criterion or valgrind massif in CI\n- Lint/clippy and fmt; ensure MSRV gates and release profile (lto=true, codegen-units=1)",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Crate and workspace skeleton with bin/lib layout",
            "description": "Create the Rust project skeleton matching the specified module layout and minimal compile-ready stubs.",
            "dependencies": [],
            "details": "Deliverables:\n- Cargo.toml with baseline deps: tokio, serde/serde_json, tracing, tracing-subscriber, anyhow, thiserror, clap, config, envy, reqwest (optional feature \"webhook\"), notify/inotify (optional feature \"inotify\"), similar, regex, bytes, tokio-util, axum (optional feature \"bridge\"). Default features minimal to keep binary small.\n- bin/watcher.rs entrypoint and src/lib with modules: config.rs, tail.rs, parse.rs, embeds.rs, webhook.rs, stats.rs, trunc.rs, diff.rs, filters.rs, health.rs; each module exports stub types/functions used by main.\n- Feature flags wired so non-MVP modules compile as stubs when disabled.\n- README with high-level overview and run instructions.\nAcceptance Criteria:\n- `cargo build` and `cargo run -- --help` succeed on Rust 1.78+.\n- Directory/file layout matches outline and compiles with stubbed modules.\n- No unused mandatory dependencies; optional deps behind features.\nRisks:\n- Early dependency bloat increases binary size. Mitigate via optional features and minimal default features.\nOwner: Rust Engineer A\nEstimate: 0.5 day",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Async runtime init (tokio) and graceful shutdown plumbing",
            "description": "Initialize tokio runtime, main loop skeleton, and implement graceful shutdown on SIGINT/SIGTERM with task coordination.",
            "dependencies": [
              "1.1"
            ],
            "details": "Deliverables:\n- tokio::main entrypoint; initialize runtime with sensible worker/thread settings.\n- Graceful shutdown: listen for Ctrl+C and SIGTERM; broadcast shutdown via watch or broadcast channel; join tasks with a bounded timeout; ensure webhook sender channel drains with a deadline.\n- Main loop skeleton per pseudo-code: create config (stub), init_tracing (stub), spawn_webhook_sender (stub), Tail::new (stub), and an async loop that reads lines and no-ops parse when stubs are in place.\n- Backpressure-aware mpsc channel between parser and webhook sender; bounded size with metrics counters placeholders.\nAcceptance Criteria:\n- On SIGINT, process exits within 5s, logs shutdown start/complete, and no task leaks (all JoinHandles resolve).\n- Running with no webhook_url does not spawn HTTP client; with webhook_url set, a stub sender task is spawned and drained.\n- No panics when no transcript is available (pending later discovery implementation).\nRisks:\n- Task leaks or deadlocks during shutdown. Mitigate with timeouts and cancellation propagation.\nOwner: Rust Engineer B\nEstimate: 0.5 day",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Config struct and precedence (CLI > env > file)",
            "description": "Implement Config loading with clap, config, and envy; define defaults and environment key mapping per PRD.",
            "dependencies": [
              "1.1"
            ],
            "details": "Deliverables:\n- Define Config struct: webhook_url: Option<String>, workspace_path: PathBuf, poll_interval_ms: u64 (default 100), batch_size: usize (default 10), parity_mode: bool (default false), filters: Filters, stats: StatsCfg, resources: ResourceHints.\n- CLI flags via clap: --webhook-url, --workspace <path>, --poll-interval-ms, --batch-size, --parity-mode, --filters.* (includeTools, includePatterns, minStdoutLength), --stats.* toggles, --model-costs <JSON or path>, --config <file>.\n- Env mapping via envy/config: DISCORD_WEBHOOK_URL, WORKSPACE_PATH, POLL_INTERVAL_MS, BATCH_SIZE, PARITY_MODE, FILTERS (JSON or CSV), STATS_* toggles, MODEL_COSTS (JSON).\n- Config file support (TOML/YAML/JSON), loaded if --config provided or default watcher.(toml|yaml|json) present; implement merge order: defaults < file < env < CLI.\n- Provide load_config() returning fully merged Config with validation (paths exist when required; positive intervals/sizes; sane bounds).\nAcceptance Criteria:\n- Precedence behaves exactly as CLI > env > file; unspecified fields fall back to defaults.\n- Invalid inputs yield clear errors (e.g., negative values rejected, invalid JSON in FILTERS/ MODEL_COSTS).\n- `--help` shows all flags with defaults.\nRisks:\n- Ambiguous FILTERS/ MODEL_COSTS parsing. Mitigate by preferring JSON strings and documenting CSV fallback.\nOwner: Rust Engineer A\nEstimate: 1 day",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Transcript path discovery with --transcript override and fallback",
            "description": "Provide discovery function to resolve transcript JSONL path via CLI override or ~/.claude/projects/<encoded-workspace>/<session>.jsonl fallback.",
            "dependencies": [
              "1.3"
            ],
            "details": "Deliverables:\n- CLI flag: --transcript <path> to directly specify the transcript file.\n- discover_transcript_path(workspace_path): resolves to latest .jsonl by mtime under ~/.claude/projects/<encoded-workspace>/, where <encoded-workspace> is percent-encoding of the absolute workspace path.\n- Handles missing dirs and empty directories gracefully with actionable error messages; logs diagnostics.\n- Expose in config flow so main uses resolved path if not overridden.\nAcceptance Criteria:\n- If --transcript is provided and exists, it is used verbatim.\n- Without --transcript, discovery selects the most recently modified .jsonl file under the computed directory.\n- If nothing found, the app exits with a clear error and non-zero code without panic.\nRisks:\n- Encoding mismatch vs. upstream generator. Mitigate by allowing an override and logging the computed path for troubleshooting.\nOwner: Rust Engineer B\nEstimate: 0.5 day",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Structured JSON logging via tracing_subscriber with runId/channelId fields",
            "description": "Establish JSON-structured logging for cluster consumption with stable runId and optional channelId enrichment.",
            "dependencies": [
              "1.1",
              "1.3"
            ],
            "details": "Deliverables:\n- init_tracing(config): configure tracing-subscriber with JSON formatter to stdout; fields include ts, level, target, message, runId, channelId, component.\n- Generate a runId (ULID or UUID v4) at startup; attach as root span field and propagate via tracing.\n- Provide helper function to attach channelId to events where available; default null when unknown.\n- Log level configured via RUST_LOG and/or --log-level.\nAcceptance Criteria:\n- Logs are valid JSON; piping through `jq` works.\n- Every log line includes runId; channelId appears on events where present.\n- Switching log level at startup changes verbosity accordingly.\nRisks:\n- Excessive log volume impacting performance. Mitigate with sensible defaults and rate-limited debug logs.\nOwner: Rust Engineer C\nEstimate: 0.5 day",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Release profile tuning, MSRV gate, and lint/format CI",
            "description": "Optimize binary size and reliability: release profile (LTO, strip, codegen-units=1), set MSRV, and add clippy/fmt CI.",
            "dependencies": [
              "1.1"
            ],
            "details": "Deliverables:\n- Cargo.toml: [profile.release] lto = \"fat\", codegen-units = 1, strip = true, opt-level = \"z\" (or \"s\"); consider panic = \"abort\" behind feature flag \"tiny\".\n- rust-version = \"1.78\" in Cargo.toml to enforce MSRV.\n- GitHub Actions workflow(s): build, test, clippy -D warnings, fmt --check, MSRV matrix (1.78 + stable) on Linux.\n- Document release build steps; verify stripped binary size and note memory targets.\nAcceptance Criteria:\n- CI green on main: build, test, clippy, fmt for MSRV and stable.\n- `cargo build --release` produces a stripped binary; size reduction observed vs. debug; target binary size reasonable for MVP (<10 MB on x86_64-unknown-linux-gnu, indicative not hard-fail).\nRisks:\n- LTO and panic=abort may complicate backtraces. Mitigate by disabling panic=abort by default and using it only for size-sensitive builds.\nOwner: DevOps Engineer\nEstimate: 0.5 day",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Tests: config precedence/defaults and smoke runs (with/without webhook)",
            "description": "Add unit/integration tests for config precedence and defaults; smoke tests for runtime with and without webhook; basic logging and discovery tests.",
            "dependencies": [
              "1.2",
              "1.3",
              "1.4",
              "1.5",
              "1.6"
            ],
            "details": "Deliverables:\n- Unit tests: verify CLI > env > file for all primary fields; confirm defaults (poll 100ms, batch 10, parity false) when unspecified; validate FILTERS and MODEL_COSTS parsing.\n- Integration tests: smoke run without webhook_url (no HTTP attempts); with webhook_url using a local mock server if feature \"webhook\" enabled; ensure startup, log emission with runId, and graceful shutdown.\n- Discovery tests: temp directory with fake ~/.claude/projects structure; ensure latest mtime selection and override behavior.\n- Optional (ignored) memory check: ensure idle RSS under ~64 MiB on Linux by sampling /proc/self/status.\nAcceptance Criteria:\n- `cargo test` passes on MSRV and stable in CI; no flaky sleeps (use tokio time::pause where applicable).\n- Tests assert precedence, default values, and presence of runId in logs; discovery selects expected file.\n- Smoke tests exit cleanly within timeout and without panics.\nRisks:\n- Env leakage between tests and platform differences. Mitigate with tempdirs, serializing env tests, and conditional cfg for Linux-only checks.\nOwner: QA Engineer\nEstimate: 1 day",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 2,
        "title": "Low-latency JSONL Tailer (≤100ms) with Inotify + Fallback",
        "description": "Implement append-only JSONL tailing from Claude transcript with ≤100ms average latency and low CPU.",
        "details": "- Use Linux inotify (inotify-rs) for write/close_write/modify events; fall back to polling every poll_interval_ms when inotify unsupported\n- Handle file rotation and session discovery: watch directory ~/.claude/projects/<encoded-workspace>/ for new <session>.jsonl; pick latest mtime\n- Maintain an async file reader with an internal offset; when notified, read to EOF, splitting by newline; tolerate partial lines\n- Backpressure-safe channel to downstream parser\n- Pseudo-code:\n  struct Tail { file: File, path: PathBuf, pos: u64, watcher: Option<InotifyWatcher>, poll: Interval }\n  impl Tail { async fn next_line(&mut self)->Option<String>{ loop { if let Some(line)=read_if_available(){ return Some(line) } if let Some(evt)=self.watcher.next_event().await { if evt.is_write(){ continue } if evt.is_move_or_rename(){ reopen_latest()? } } else { self.poll.tick().await; continue } } }}\n- Optimize reads with BufReader and read_to_end chunking; ensure minimal allocations\n- Ensure CPU usage <1% by event-driven approach; when idle, sleep\n",
        "testStrategy": "- Integration test: write N JSONL lines in a temp file with random intervals; assert tailer emits each within ≤100ms on average; use tokio time::pause for deterministic timing\n- Rotation test: move file and create new file; ensure Tail reopens and continues\n- Large line test: long JSON line (>10KB) to ensure no truncation before parse\n- Linux-only inotify test gated by cfg(target_os)\n- Measure CPU usage with a load test and ensure budget met",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Tail core: async reader and offset management",
            "description": "Define Tail struct and core async logic to read from an append-only JSONL file while tracking an internal byte offset.",
            "dependencies": [],
            "details": "- Implement struct Tail { file: tokio::fs::File, path: PathBuf, pos: u64, poll: Option<tokio::time::Interval>, watcher: Option<InotifyHandle>, buf: Vec<u8>, line_buf: Vec<u8> }\n- Provide async methods: Tail::open(path), Tail::reopen(path), Tail::read_available() -> Reads from current pos to EOF without blocking when no data\n- Ensure pos advances only by bytes successfully consumed into complete lines; partial trailing bytes remain in line_buf\n- Do not spin when idle: yield on no data; integrate with event/poll signals (wired in subtasks 2/3)\n- Config: poll_interval_ms, max_read_chunk (e.g., 64–256 KiB), workspace_dir\n- Acceptance: Can open an existing file, start at EOF, and read new appends without re-reading old content; no busy-loop when idle",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Inotify watcher for write/close/rename",
            "description": "Integrate inotify-rs to receive low-latency notifications for file and directory events that indicate new data or rotation.",
            "dependencies": [
              "2.1"
            ],
            "details": "- Use inotify (or notify crate with inotify backend) on Linux; masks: MODIFY, CLOSE_WRITE, MOVED_TO, MOVED_FROM, MOVE_SELF, DELETE_SELF, CREATE\n- Watch both the active file and its parent directory to catch rotations and new sessions\n- Map events to actions: write/close_write => read_available; move/rename/delete => trigger reopen discovery\n- Handle queue overflow (IN_Q_OVERFLOW): fall back to a full resync by stat/reopen latest and fast-forward pos safely\n- If inotify init fails, set watcher=None so polling fallback (Subtask 3) drives progress\n- Acceptance: On a single append, an event arrives and triggers a read cycle within one wake; errors are surfaced but do not crash the loop",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Polling fallback with tokio Interval",
            "description": "Provide a low-CPU polling path when inotify is unavailable or disabled.",
            "dependencies": [
              "2.1"
            ],
            "details": "- Create tokio::time::Interval with configurable poll_interval_ms (default 50ms) to check for file growth or rotation\n- On each tick, stat file size/inode; if size > pos, read_available; if inode changed or size < pos, treat as rotation/truncate and reopen\n- Ensure sleep when idle; no tight loops; jitter option (+/- 10%) to avoid phase lock across many instances\n- Acceptance: With only polling enabled, average end-to-end line latency ≤100ms when poll_interval_ms ≤50ms; idle CPU <1%",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Session discovery and latest-by-mtime selection",
            "description": "Discover and track the current session JSONL file under ~/.claude/projects/<encoded-workspace>/, switching to the most recent by mtime.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3"
            ],
            "details": "- Monitor the workspace directory for new *.jsonl files (inotify CREATE/MOVED_TO) and maintain a sorted view by mtime\n- On startup, pick the latest mtime file; when new session appears or active file is moved/deleted, reopen the latest\n- Normalize and resolve symlinks; ensure permissions and existence checks\n- Provide helper: fn latest_session(dir) -> Option<PathBuf>\n- Acceptance: When a new session file is created, tailer switches within ≤100ms (inotify) or within one poll tick (polling fallback); always selects the newest mtime",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Robust JSONL line splitting with partial buffering and minimal allocations",
            "description": "Implement efficient newline-delimited parsing that tolerates partial lines and large JSON strings.",
            "dependencies": [
              "2.1"
            ],
            "details": "- Use tokio::io::BufReader<File> with a tuned capacity (e.g., 64–256 KiB); read_to_end-style chunking into a reusable Vec<u8>\n- Maintain a reusable line_buf for partial trailing data; scan for '\\n' and emit complete lines; retain remainder across reads/rotations\n- Support very large lines (>10 KiB, up to several MB) without quadratic copies; grow buffers with amortized strategy\n- Validate UTF-8; if invalid, buffer until newline and attempt lossy decode or drop with error metric (configurable)\n- Acceptance: No panics on long lines; per-line allocations minimized (≤2 Vec growths on average for typical lines); preserves partial lines until completion",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Backpressure-safe channel to downstream parser",
            "description": "Expose a bounded mpsc channel for lines, ensuring producer backpressure and bounded memory.",
            "dependencies": [
              "2.1",
              "2.5"
            ],
            "details": "- Use tokio::sync::mpsc::channel with configurable capacity (e.g., 1024)\n- Producer awaits send when full; optionally expose try_send with metrics for drops if a drop policy is enabled by config\n- Surface a graceful shutdown signal; on receiver drop, tailer stops reading and closes cleanly\n- Emit metrics: queue depth, send wait time, dropped count (if enabled)\n- Acceptance: Under a slow consumer, memory remains bounded, no busy-waiting, and CPU stays <1% idle",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "File rotation and truncate handling",
            "description": "Detect and handle file moves/renames/truncates without duplicating or losing lines.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3",
              "2.4",
              "2.5"
            ],
            "details": "- On MOVE/RENAME/DELETE or inode change/size shrink, flush any complete lines from buffers, then reopen latest session\n- If the same path is recreated, detect new inode; reset pos to 0; if truncated (size < pos), reset pos accordingly\n- Preserve partial trailing bytes logically only if the same inode continues; on rotation to a new file, discard incomplete fragment (configurable) to avoid corrupt JSON\n- Ensure duplicate-suppression: do not re-emit already read bytes; verify via inode+pos tracking\n- Acceptance: Rotation test passes with zero duplicates/loss; switching happens within ≤100ms (inotify) or one poll tick; handles rapid successive rotations",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Tests and benchmarks: latency, rotation, large lines, Linux-gated inotify",
            "description": "Build comprehensive tests and simple benches to validate latency, correctness, and resource usage; gate inotify tests to Linux.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3",
              "2.4",
              "2.5",
              "2.6",
              "2.7"
            ],
            "details": "- Integration: write N JSONL lines to a temp file with random 10–50ms intervals; assert average end-to-end latency ≤100ms; measure from write completion to receive\n- Rotation: move active file, create a new one, continue writing; assert no duplicates/misses and fast switch\n- Large line: emit >10 KiB and >1 MiB lines; ensure memory remains bounded and no panic\n- Inotify gating: cfg(target_os=\"linux\") for inotify-specific tests; ensure polling path tests run on all platforms\n- CPU idle check: when idle for 30s, process CPU <1% (approximate via /proc sampling on Linux or coarse wall-clock vs CPU time)\n- Benchmark sanity: sustained 100 lines/sec for 10s without backlog; queue depth stays below capacity\n- Acceptance: All tests green; metrics meet latency ≤100ms avg and idle CPU <1%",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Event Parser, Filtering, and Embed Builder",
        "description": "Parse transcript JSONL into typed events, apply filters/parity mode, and build Discord embed payloads with code fences, diffs, truncation, and batching.",
        "details": "- Define serde models with flexible fields:\n  enum EventKind { ToolUse{tool:String, cmd:Option<String>, file:Option<String>, patch:Option<String>, cwd:Option<String>}, Assistant{text:String}, ToolResult{stdout:Option<String>, stderr:Option<String>}, Summary{result:Option<String>} , Error{message:String}}\n  #[derive(Deserialize)] struct TranscriptLine{ timestamp: DateTime<Utc>, event: String, model:Option<String>, tokens_in:Option<u64>, tokens_out:Option<u64>, cost_usd:Option<f64>, tool:Option<String>, data:serde_json::Value }\n- Map event strings to kinds: tool_use (Bash/Write/Edit/Read/WebSearch), assistant, tool_result, result/summary, error\n- Filters: includeTools, includePatterns, minStdoutLength; Parity mode bypasses filters and truncation thresholds (within Discord hard limits)\n- Truncation and sanitization:\n  - Enforce Discord limits: description ≤4096 chars, ≤25 fields, ≤10 embeds/message; message content ≤2000 chars\n  - Sanitize code blocks: escape triple backticks within content by zero-width joiner or by slicing into safe chunks\n  - For stdout/stderr: render in ```text blocks, truncate beyond ~1000 chars with “(truncated)” appended and prepare attachment\n  - For diffs: prefer event-provided patch; else compute inline diff via similar crate, include contextual hunk up to 60 lines; attach full diff if larger\n- Embed templates per PRD with colors:\n  - ⚡ Bash tool_use: title, fields (Command fenced as ```bash), Working Dir, Tool Count\n  - 📝 Write/Edit/👁️ Read: fields File, Summary, Tool Count\n  - 💭 Assistant: description trimmed, fields Tokens In/Out, Cost, Model\n  - ❌ Error: description code-fenced stderr, field Total Errors\n  - ✅ Complete: fields Cost, Duration, Tokens total, Tools Used\n- Batching: collect embeds; flush when size==batch_size or 250ms idle; produce optional attachments array for overflows\n- Pseudo-code build_embeds(ev): match ev { ToolUse{..} => vec![embed]; ToolResult{..} => vec![embed]; Assistant{..} => maybe split across 2 embeds if >4096; Summary => vec![final_embed] }\n",
        "testStrategy": "- Unit tests: sample JSONL lines for each event type -> expected embed structure (title, fields, colors)\n- Truncation tests: inputs at boundaries 2000/4096/25 fields and ensure no panic; verify attachments prepared when exceeding limits\n- Diff tests: ensure inline hunk length cap; validate diff fenced with ```diff and +/-\n- Parity mode test: confirm minimal truncation and all events passed\n- Fuzz test parser with random JSON objects to ensure robustness",
        "priority": "medium",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Serde models and tolerant JSONL parsing",
            "description": "Define flexible serde models and a resilient JSONL reader to deserialize transcript lines into typed events.",
            "dependencies": [],
            "details": "- Define enum EventKind { ToolUse{tool, cmd?, file?, patch?, cwd?}, Assistant{text}, ToolResult{stdout?, stderr?}, Summary{result?}, Error{message} }.\n- Define TranscriptLine { timestamp: DateTime<Utc>, event: String, model?, tokens_in?, tokens_out?, cost_usd?, tool?, data: Value } with serde default/flatten where appropriate.\n- Implement tolerant parsing: accept RFC3339 timestamps; default Option fields to None; collect unknown keys under data.\n- Provide JSONL reader that streams lines, deserializes per-line, logs and skips invalid rows without crashing.\n- Expose conversion helper: TranscriptLine -> CanonicalEvent { ts, meta {model, tokens_in/out, cost}, kind: EventKind }.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Event string mapping to enum kinds",
            "description": "Map event string values to EventKind variants and extract fields from data with fallbacks.",
            "dependencies": [
              "3.1"
            ],
            "details": "- Map event: \"tool_use\" (tools: Bash/Write/Edit/Read/WebSearch), \"assistant\", \"tool_result\", \"result\"|\"summary\", \"error\".\n- Extract fields from data: ToolUse {cmd, file, patch, cwd}; Assistant {text}; ToolResult {stdout, stderr}; Summary {result}; Error {message}.\n- Normalize tool names and accept case-insensitive aliases.\n- Robust error handling: if mapping fails, produce Error variant with message; never panic.\n- Provide EventMapper with fn map(line: TranscriptLine) -> CanonicalEvent.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Filtering engine (includeTools, includePatterns, minStdoutLength)",
            "description": "Implement configurable predicates to include/exclude events before embed building.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "- Config schema: includeTools: Option<Vec<String>>; includePatterns: Option<Vec<String>> (compiled to Regex); minStdoutLength: Option<usize>.\n- For ToolUse/ToolResult/Assistant/Summary/Error, define predicates:\n  - includeTools matches ToolUse.tool (case-insensitive) and ToolResult inferred tool chain.\n  - includePatterns apply to concatenated textual fields (cmd/file/stdout/stderr/text/result/message).\n  - minStdoutLength gate ToolResult.stdout length.\n- Pre-compile regexes; on invalid pattern, log and skip that pattern.\n- Expose fn allow(event: &CanonicalEvent, filters: &Filters) -> bool.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Parity mode bypass switch",
            "description": "Add a global parity mode that bypasses filters and soft truncation thresholds while still respecting Discord hard limits.",
            "dependencies": [
              "3.3"
            ],
            "details": "- Add ParityMode(bool) to pipeline context.\n- When enabled: skip Filters.allow, ignore minStdoutLength and diff/stdout soft truncation caps (~1000), but enforce Discord 2000/4096/25/10 limits.\n- Ensure attachments are always produced for over-limit content in parity mode.\n- Provide fn parity_wrap<T>(ctx, content, enforce_hard_limits_only: bool) to gate truncation behavior.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Discord limits enforcement utilities",
            "description": "Implement character/field/embed limit enforcement and safe splitting/chunking helpers.",
            "dependencies": [
              "3.1"
            ],
            "details": "- Constants: MESSAGE_MAX=2000, EMBED_DESC_MAX=4096, EMBED_FIELDS_MAX=25, EMBEDS_PER_MESSAGE_MAX=10.\n- Safe trimming by Unicode scalar values (avoid breaking multi-byte); consider unicode-segmentation for grapheme-safe cuts.\n- Helpers:\n  - fn trim_message_content(s) -> String\n  - fn trim_embed_description(s) -> String\n  - fn cap_fields(fields) -> (Vec<Field>, overflow_count)\n  - fn split_embeds(embeds) -> Vec<Vec<Embed>> sized to <=10 each\n- Attachment overflow producer: when content is trimmed, return AttachmentSpec { filename, bytes, note }.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Code fence sanitization and escaping",
            "description": "Create robust code block wrapper that escapes internal triple backticks and guarantees balanced fences.",
            "dependencies": [
              "3.5"
            ],
            "details": "- Implement sanitize_code_block(lang: &str, content: &str) -> String.\n- Strategy: escape ``` sequences by injecting zero-width joiner or by slicing into chunks between fences; ensure closing fence always present.\n- Normalize line endings to \\n; strip trailing whitespace that could break fences.\n- Provide specialized wrappers: code_text(content), code_bash(cmd), code_diff(patch_snippet).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Diff generation with hunk cap and attachment fallback",
            "description": "Prefer provided patch; else compute inline diff with similar crate, cap context to 60 lines, and attach full diff if larger.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "- Input: file path, optional provided patch, optional before/after text from data.\n- If patch provided: validate minimal structure; use as full attachment; derive inline snippet by truncating to <=60 lines with hunk headers.\n- Else compute diff via similar::{TextDiff,...}, generate unified-like snippet, cap total visible lines to 60.\n- Return structure: { inline_snippet (for embed using code_diff), full_attachment (Option<bytes>), truncated: bool, filename_hint }.\n- Handle large outputs gracefully; never exceed embed limits after sanitization.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Embed templates and builders per event type",
            "description": "Implement embed construction matching PRD templates and colors for all event kinds.",
            "dependencies": [
              "3.2",
              "3.3",
              "3.4",
              "3.5",
              "3.6",
              "3.7"
            ],
            "details": "- ToolUse (⚡ Bash): title with icon, fields: Command (```bash), Working Dir, Tool Count; color per PRD.\n- ToolUse (📝 Write/✏️ Edit/👁️ Read): fields: File, Summary (from data if present), Tool Count.\n- ToolResult: stdout/stderr rendered in ```text, truncate beyond ~1000 chars unless parity; produce attachment when truncated; include tool reference.\n- Assistant (💭): description trimmed to 4096; split into multiple embeds if >4096; fields: Tokens In/Out, Cost, Model.\n- Error (❌): description fenced stderr/message; field Total Errors.\n- Summary/Complete (✅): fields: Cost, Duration (if derivable), Tokens total, Tools Used; ensure final embed appearance.\n- All text through sanitize_code_block and Discord limits helpers; collect attachments for overflows and diffs.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Batching, idle flush, and attachment aggregation",
            "description": "Collect embeds into batches, flush on size or 250ms idle, and aggregate attachments for oversized content.",
            "dependencies": [
              "3.8",
              "3.5"
            ],
            "details": "- Queue builder outputs; flush when queue.len()==batch_size or idle_timer==250ms.\n- While flushing, split embeds into groups of <=10; attach per-group attachments; ensure message content stays <=2000.\n- Preserve event order; do not interleave different runs (if applicable) within a batch.\n- Provide backpressure-safe async interface; ready for webhook posting later.\n- Emit metrics hooks (counts/bytes) placeholders for Task 10.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 10,
            "title": "Comprehensive tests: parsing, limits, diffs, parity",
            "description": "Add unit/property tests covering parser resilience, boundary truncation, diff correctness, batching, and parity pass-through.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3",
              "3.4",
              "3.5",
              "3.6",
              "3.7",
              "3.8",
              "3.9"
            ],
            "details": "- Parsing: sample JSONL for each event; fuzz malformed lines; ensure graceful skip with logs.\n- Limits: inputs at 2000/4096/25/10 boundaries; verify trimming without panic and attachment generation when over.\n- Code fences: strings containing triple backticks and unbalanced fences; ensure sanitized output renders correctly.\n- Diffs: validate 60-line cap, inline snippet format, and attachment fallback; parity mode disables soft caps.\n- Filters: includeTools/patterns/minStdoutLength matrix; ensure correct inclusion/exclusion.\n- Batching: size and idle flush behavior; embed splitting into <=10 per message; attachment aggregation.\n- Snapshot tests for embed JSON to catch regressions.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "Webhook Sender with Rate Limiting, Backoff, and Attachments",
        "description": "Implement robust Discord webhook posting with batching, 429 handling, retry_with_jitter, and file attachments.",
        "details": "- Build a sender task with bounded mpsc channel receiving Message{embeds:Vec<Embed>, attachments:Vec<FilePart>}\n- Discord webhook endpoint: POST https://discord.com/api/v10/webhooks/{id}/{token}?wait=true (use returned message id if needed). For attachments, use multipart/form-data with files as file[0], file[1], and payload_json including embeds and attachment metadata\n- Respect 10 embeds per message; if more, split across multiple messages\n- Rate limit handling: on 429, read JSON {retry_after: seconds/ms, global}, and X-RateLimit-* headers; sleep for retry_after + jitter; also inspect X-RateLimit-Remaining to preemptively slow\n- Backoff policy: exponential with decorrelated jitter; max backoff 10s; cap retries per message (e.g., 5) then DLQ/log\n- Network resiliency: timeouts (connect 2s, total 10s), retries on 5xx/timeout; idempotency not required for webhook\n- Pseudo-code:\n  loop { msg = rx.recv().await; let chunks = chunk_embeds(msg.embeds, 10); for c in chunks { let res = post_webhook(c, msg.attachments).await; match res { Ok => continue, Err(RateLimit{retry_after})=>sleep(retry_after+jitter), Err(e)=>retry/backoff } } }\n- Ensure sender doesn’t block parser: channel size tuning; drop oldest attachments if pressure high and log warning\n",
        "testStrategy": "- Mock Discord API with test server returning 429 and X-RateLimit-*; assert sender obeys retry_after\n- Test multipart payload correctness; verify attachments arrive in a real Discord test channel (manual/integration)\n- Stress test with 1000 embeds over 60s to ensure batching and throughput; no ordering issues\n- Chaos tests: inject timeouts, DNS failures; confirm retries and no panics",
        "priority": "medium",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Bounded Message Queue and Sender Task Skeleton",
            "description": "Create a bounded mpsc channel and a dedicated async sender task to consume Message items and drive webhook posting.",
            "dependencies": [],
            "details": "Implement in Rust with tokio. Define core types: struct Message { embeds: Vec<Embed>, attachments: Vec<FilePart> }. FilePart { filename: String, bytes: bytes::Bytes, content_type: Option<String>, description: Option<String> }. Build tokio::sync::mpsc::channel(capacity from config, e.g., WEBHOOK_QUEUE_CAP default 100). Expose enqueue API that uses try_send where possible. Spawn a sender task: loop { if let Some(msg) = rx.recv().await { process_message(msg).await } }. process_message will chunk embeds and post via post_webhook. Wire webhook URL: https://discord.com/api/v10/webhooks/{id}/{token}?wait=true and build a reqwest::Client once and reuse. Add tracing logs for enqueue/dequeue and message ids returned (if used).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Embed Chunking (≤10 per request)",
            "description": "Implement utility to split embeds into chunks of up to 10 for Discord webhook limits.",
            "dependencies": [
              "4.1"
            ],
            "details": "Provide fn chunk_embeds(embeds: Vec<Embed>, max_per: usize) -> Vec<Vec<Embed>> with max_per default 10. Preserve order; return contiguous chunks; handle empty list. In the sender loop: let chunks = chunk_embeds(msg.embeds, 10); for each chunk, call post_webhook(chunk, msg.attachments.clone()). Keep attachments unchanged per chunk per the pseudocode. Unit test: 0, 1..9, 10, 11, 20 embeds produce expected chunk counts and sizes.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Multipart Builder for Attachments and payload_json",
            "description": "Build multipart/form-data bodies with files as file[n] and payload_json containing embeds and attachment metadata.",
            "dependencies": [
              "4.2"
            ],
            "details": "Implement fn build_multipart(chunk: &[Embed], attachments: &[FilePart]) -> reqwest::multipart::Form. For each attachment i: add part named format!(\"file[{}]\", i) (per requirement) with Part::bytes(bytes.clone()).file_name(filename).mime_str(content_type or application/octet-stream). Build payload_json as a JSON string field: { \"embeds\": [..], \"attachments\": [{\"id\": i, \"filename\": filename, \"description\": optional}] }. Add .text(\"payload_json\", serde_json::to_string(&payload).unwrap()). In post_webhook, send POST to ...?wait=true with this Form. Parse success JSON to capture returned message id (string) if needed for logging. Validate that when attachments are empty, still send payload_json without files.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Rate Limit Handling (429 + X-RateLimit-* preemption)",
            "description": "On 429, honor retry_after plus jitter; use X-RateLimit-* headers to preempt when remaining is 0.",
            "dependencies": [
              "4.3"
            ],
            "details": "Extend post_webhook to inspect responses: if status==429, parse body JSON { retry_after: number, global: bool }. Prefer X-RateLimit-Reset-After header (seconds.fraction) when present; else use retry_after (which may be seconds or ms per upstream; if >1000, treat as ms). Sleep for computed delay + small jitter (random 0..250ms). If global==true, apply a shared rate_limit_until Instant for all requests. Preemptive slow path: if X-RateLimit-Remaining==\"0\" and Reset-After present on a non-429 response, sleep Reset-After + jitter before next request in this sender. Track bucket key by URL (single webhook) and serialize sends accordingly.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Retry Policy with Decorrelated Jitter and Caps",
            "description": "Implement transient error retries using decorrelated jitter, with max 10s backoff and max 5 attempts per chunk.",
            "dependencies": [
              "4.4"
            ],
            "details": "Adopt the decorrelated jitter algorithm (AWS). Parameters: base=250ms, max_backoff=10s, attempts_max=5. Pseudocode: sleep = base; for attempt in 1..=attempts_max { let delay = min(max_backoff, rand(base..(sleep*3))); sleep = delay; wait(delay); try request; on success break }. Integrate with 429 handling: if 429, always sleep retry_after(+jitter) and count toward attempts. Retry on 5xx and timeouts; do not retry on non-429 4xx (400/401/403/404/413/415, etc.)—treat as permanent. On exhaust, DLQ/log: emit tracing::error with summary (embed count, attachment names) and store to an optional dead-letter channel/file if configured.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "HTTP Client Timeouts and Transient Error Mapping",
            "description": "Configure reqwest client timeouts and map timeouts/5xx to retryable errors.",
            "dependencies": [
              "4.5"
            ],
            "details": "Create a single reqwest::Client with .connect_timeout(Duration::from_secs(2)) and .timeout(Duration::from_secs(10)). Set a descriptive User-Agent. Implement fn post_webhook(chunk, attachments) -> Result<ResponseOk, PostError>. Map reqwest timeouts (is_timeout()) and network errors to PostError::Transient. Map HTTP 5xx to Transient; 429 to RateLimited{retry_after, global, headers}; other 4xx to Permanent. Ensure response body parsing is resilient with its own small timeout; log bodies for 4xx (without leaking large payloads).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Backpressure Policy: Drop-Oldest Attachments with Logging",
            "description": "Implement a pressure policy so the sender never blocks the parser: when pressure is high, drop oldest attachments and warn.",
            "dependencies": [
              "4.1",
              "4.6"
            ],
            "details": "Introduce an intermediate bounded VecDeque<Message> buffer in front of the mpsc::Sender to implement custom pressure control. Producer enqueues into the deque; a background mover task drains the deque into the mpsc channel (try_send with yield). When deque length exceeds a high-water mark (configurable, default 2x channel capacity) or when try_send persistently fails, apply shedding: iterate from front and remove attachments (set msg.attachments = vec![]) on the oldest messages first until under threshold. Log tracing::warn with counts and filenames dropped; increment a metric counter. Never drop embeds. Ensure all operations are non-blocking (use async Mutex for the deque) and document the degradation policy.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Test Harness: Mock Discord Server and Stress Tests",
            "description": "Build a mock server to validate 429 handling, X-RateLimit preemption, and multipart correctness; add stress tests.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4",
              "4.5",
              "4.6",
              "4.7"
            ],
            "details": "Use axum or wiremock to stand up a local HTTP server emulating Discord endpoints. Tests: (1) 429 path returns {retry_after: 1.5, global:false} with X-RateLimit-*; assert client delays ≈1.5s + jitter before retry. (2) Preemptive RL: respond with X-RateLimit-Remaining: 0 and X-RateLimit-Reset-After: 0.75; assert next send sleeps that long. (3) Multipart verification: inspect incoming multipart parts to ensure file[0], file[1], and payload_json exist; payload_json embeds and attachments metadata ids/filenames match files. (4) Transient 5xx then 200: verify decorrelated jitter backoff caps at 10s and attempts ≤5. (5) Timeout: delay server beyond 10s to trigger client timeout and retry. (6) Stress: enqueue 1000 embeds over 60s; assert requests == ceil(1000/10); no panics; throughput and no starvation. (7) Backpressure: simulate slow server; fill buffers; assert oldest attachments are dropped and warnings emitted. Optionally include a manual integration test against a real Discord test webhook (behind feature flag).",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 5,
        "title": "Statistics Aggregation and Final Summary Embed",
        "description": "Track tokens, estimated cost, tools used, errors, duration; emit a final ✅ summary embed on completion or end-of-stream.",
        "details": "- Maintain a Stats struct updated per event:\n  struct Stats { tokens_in:u64, tokens_out:u64, est_cost:f64, tool_counts:HashMap<String,u64>, error_count:u64, started_at:Instant, model:Option<String> }\n- Cost estimation: configurable per-model $/1K tokens; default table in config (overrideable) e.g., {\"claude-3.5-sonnet\":{\"input\":3.0,\"output\":15.0}}; compute cost = in/1000*input + out/1000*output; avoid vendor lock-in by making this config-driven\n- Increment tool_counts on tool_use; error_count on error/tool_result stderr non-empty\n- On Summary or when tail ends, build the ✅ Complete embed with fields: Cost, Duration, Tokens (total/in/out), Tools Used (aggregated), Model; color=0x27AE60\n- Include footer with runId/shortId and timestamps\n- Pseudo-code:\n  on_event(ev){ stats.update(ev); if matches Summary|Completion { let embeds = build_summary(stats); tx.send(embeds).await; } }\n",
        "testStrategy": "- Unit tests for aggregation math including rounding; verify cost matches config tables\n- Test tools/error counting with mixed events\n- Simulate premature end-of-stream without explicit summary; ensure finalizer emits summary on drop\n- Snapshot test of final embed fields/formatting",
        "priority": "medium",
        "dependencies": [
          3,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Stats struct and per-event update logic",
            "description": "Define a Stats aggregate and implement incremental update logic for all relevant stream events.",
            "dependencies": [],
            "details": "- Data model: struct Stats { tokens_in: u64, tokens_out: u64, est_cost: f64, tool_counts: HashMap<String,u64>, error_count: u64, started_at: Instant, model: Option<String> }\n- API: Stats::new(started_at: Instant, model: Option<String>) -> Self; Stats::apply_event(&mut self, ev: EventRef);\n- Event mapping (non-exhaustive):\n  - ModelSelected(name) -> set self.model = Some(name)\n  - TokensIn(n) -> self.tokens_in = self.tokens_in.saturating_add(n)\n  - TokensOut(n) -> self.tokens_out = self.tokens_out.saturating_add(n)\n  - ToolUse { name } -> increment tool_counts[name]\n  - ToolResult { name, stderr } -> increment tool_counts[name] if desired (count attempts on ToolUse; see subtask 3); if stderr not empty increment error_count\n  - Error { .. } -> increment error_count\n  - Summary | Completion | StreamEnd -> no direct stat change; finalizer will react\n- Helpers: Stats::total_tokens() -> u64; Stats::duration(now: Instant) -> Duration\n- Safety: use saturating arithmetic for u64; ignore negative/invalid token deltas; tolerate missing fields.\n- Keep est_cost updated by calling a provided estimator (subtask 2) after token changes.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Config-driven cost estimation with rounding policy",
            "description": "Implement per-model input/output $/1K token rates loaded from config and compute estimated cost.",
            "dependencies": [
              "5.1"
            ],
            "details": "- Config shape (overrideable): { \"pricing\": { \"claude-3.5-sonnet\": { \"input\": 3.0, \"output\": 15.0 }, \"default\": { \"input\": 0.0, \"output\": 0.0 } } }\n- API: CostTable::from_config(cfg) -> Self; CostTable::estimate(model: Option<&str>, in_tokens: u64, out_tokens: u64) -> f64\n- Formula: cost = (in_tokens as f64 / 1000.0) * input_rate + (out_tokens as f64 / 1000.0) * output_rate\n- Model lookup: exact match -> rates; else fall back to \"default\" if present; else use zeros and log a warning.\n- Precision policy: store full-precision f64 in Stats.est_cost; presentation rounding occurs in embed (subtask 4). For tests, allow tolerance 1e-9.\n- Thread-safety: CostTable is Arc<CostTable> sharable; estimation is pure and lock-free.\n- Integrate: Stats::apply_event calls estimator after any token delta to refresh est_cost.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Tool usage aggregation and error counting rules",
            "description": "Define consistent rules for counting tool invocations and errors across event types and implement them in Stats updates.",
            "dependencies": [
              "5.1"
            ],
            "details": "- Tool counting:\n  - On ToolUse { name }: increment tool_counts[name] by 1 (counts attempts, including retries)\n  - On ToolResult { name }: do not increment tool_counts (avoids double count), unless ToolUse is absent in the stream (then increment defensively if needed)\n- Error counting:\n  - Increment error_count on any Error event\n  - Increment on ToolResult if stderr is non-empty or status indicates failure\n  - Optionally treat events with level=\"error\" as errors\n- Normalization: trim and lowercase tool names for map keys; keep original case only for display aggregation if desired.\n- Idempotency: avoid double-incrementing on duplicate/replayed events by relying on event semantics (no de-dup here) and tests to verify expected counts.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Summary embed builder",
            "description": "Build the ✅ completion embed from Stats with required fields, colors, and footer metadata.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3"
            ],
            "details": "- API: build_summary_embed(stats: &Stats, run_id: &str, short_id: &str, finished_at: SystemTime) -> Embed\n- Formatting:\n  - Title: \"✅ Run Complete\"\n  - Color: 0x27AE60\n  - Fields:\n    - Cost: render as USD rounded to 4 decimals (e.g., \"$0.0123\"); also include rate source if useful\n    - Duration: humanized (e.g., \"1m 23.456s\"), rounded to milliseconds\n    - Tokens: \"total=XYZ (in=A, out=B)\"\n    - Tools Used: aggregated \"name×count\" comma-separated; render \"—\" if none\n    - Model: model name or \"unknown\"\n  - Footer: text \"runId:<run_id> • shortId:<short_id> • started:<iso8601>\"; set embed timestamp to finished_at\n- Robustness: cap field lengths to Discord limits; truncate Tools field if too long and add \"+N more\" suffix.\n- Output type: compatible with webhook sender (existing Embed struct in project).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Finalizer guard for Summary or end-of-stream emission",
            "description": "Emit the summary embed on Summary/Completion event or on drop/end-of-stream to handle premature termination.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "- Design: SummaryFinalizer holds Arc<Mutex<Stats>>, tx: Sender<Embed>, run_id, short_id, and an AtomicBool sent flag.\n- API:\n  - on_event(ev): update stats (delegates to Stats::apply_event); if ev matches Summary|Completion, call maybe_emit(now)\n  - maybe_emit(now): if sent.swap(true) == false, build embed via build_summary_embed and tx.send(embed).await (or try_send with retry policy)\n  - Drop: if not sent, call maybe_emit(now) to ensure EOS emission\n- Concurrency:\n  - Make maybe_emit idempotent; guard against double-send under race (multiple Summary events or Drop + event)\n  - Handle channel closed gracefully (log, no panic)\n- Integration: wire into the event processing loop so all events pass through finalizer.\n- Time sources: started_at from Stats; finished_at is now at emission for timestamp and duration.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Tests: aggregation math, finalization, and embed snapshot",
            "description": "Comprehensive unit/integration tests for math correctness, lifecycle finalization, and embed rendering.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4",
              "5.5"
            ],
            "details": "- Math tests:\n  - Given pricing table and known in/out tokens, assert estimated cost matches formula within tolerance and rounds to 4 decimals in embed\n  - Verify token totals and duration formatting boundaries (sub-second, multi-hour)\n  - Unknown model fallback behavior\n- Tool/error tests:\n  - Mixed ToolUse/ToolResult with stderr cases; verify counts and error_count rules\n- Finalization tests:\n  - Summary event triggers exactly one embed\n  - Premature end-of-stream (no Summary) -> Drop emits embed exactly once\n  - Race: multiple Summary events + Drop do not double-send\n- Snapshot tests:\n  - Use insta (or similar) to snapshot embed JSON for stable fields/formatting (title, color, fields, footer)\n- Channel tests:\n  - Closed tx is handled without panic; log captured.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Discord Bot Service: Channel Lifecycle and Webhook Provisioning",
        "description": "Build a Discord bot that creates per-run channels in the “Agent Runs” category, provisions one webhook per run, and returns {channelId, webhookUrl}.",
        "details": "- Tech stack: Node.js 20+, discord.js v14, fastify/express for REST API, node-fetch/axios; persistent store (Redis or SQLite) for run mapping and retention\n- Bot permissions: Manage Channels, Manage Webhooks, Read/Send Messages, Create Public Threads (optional)\n- REST endpoints:\n  - POST /runs {taskId, attempt, shortId, guildId, categoryName=\"Agent Runs\", retentionHours, bridgeUrl?, bridgeToken?} -> creates channel name run-{taskId}-{attempt}-{shortId} under category; creates webhook via POST /channels/{channel.id}/webhooks; stores mapping {runId, channelId, webhookId, webhookToken, expiresAt, bridgeUrl?, bridgeToken?}; returns {channelId, webhookUrl}\n  - POST /runs/{runId}/archive -> archive/move channel to “Archived Runs” or delete\n- Channel/category logic: find or create category by name\n- Security: bot token remains server-side only; do not emit to pods. Webhook URL is scoped per-channel\n- Rate limits: discord.js handles major RL; still respect retry_after in REST\n- Pseudo-code create:\n  const cat = findOrCreateCategory(guild, \"Agent Runs\");\n  const ch = await guild.channels.create({ name, parent: cat.id, type: 0 });\n  const hook = await ch.createWebhook({ name: `run-${shortId}` });\n  save({runId, ch.id, hook.id, hook.token, retention});\n  return { channelId: ch.id, webhookUrl: `https://discord.com/api/v10/webhooks/${hook.id}/${hook.token}` };\n- Post initial header embed via webhook with run metadata\n- Retention worker: cron job to archive/delete after TTL\n",
        "testStrategy": "- Integration test against a Discord test guild: create, verify channel in category, verify webhook works, then cleanup\n- Unit tests for naming collisions and idempotency (same runId returns existing channel)\n- Retention test: advance time and ensure archive/delete occurs\n- Security check: ensure webhook URL is the only value exposed to pods",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "REST API scaffold with Fastify and auth",
            "description": "Initialize Fastify REST server with config, JSON schema validation, and API key authentication.",
            "dependencies": [],
            "details": "- Stack: Node.js 20+, Fastify, dotenv/config. Add structured logging.\n- Config: DISCORD_BOT_TOKEN (server-only), API_KEY, DEFAULT_CATEGORY=\"Agent Runs\", ARCHIVE_CATEGORY=\"Archived Runs\", TEST_GUILD_ID?, STORAGE_BACKEND=redis|sqlite.\n- Security: never log or expose DISCORD_BOT_TOKEN; keep it on the server only, not emitted to pods or clients.\n- Middleware: API key auth via header (e.g., Authorization: Bearer <API_KEY>), request body validation via Fastify schemas.\n- Endpoints scaffold: POST /runs, POST /runs/:runId/archive, GET /healthz.\n- Error handling: consistent error envelope with HTTP codes and safe messages.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Discord client initialization and permission checks",
            "description": "Set up discord.js v14 client, log in, and verify required permissions on target guilds.",
            "dependencies": [
              "6.1"
            ],
            "details": "- Initialize Client with minimal intents (Guilds) sufficient for channel/webhook management.\n- On ready: validate bot permissions on specified guild(s): Manage Channels, Manage Webhooks, Read/Send Messages.\n- Build utility to fetch guild by ID; fail fast if missing perms.\n- Add graceful shutdown (SIGINT/SIGTERM) to destroy client.\n- Security: never expose token in logs; redact sensitive headers.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Persistence layer and run schema with TTL",
            "description": "Implement storage abstraction (Redis or SQLite) for run mapping, TTL, and status.",
            "dependencies": [
              "6.1"
            ],
            "details": "- Storage selector: Redis client with TTL (EXPIRE) or SQLite (better-sqlite3/knex) with schema + cron cleanup.\n- Schema Run: { runId (pk), taskId, attempt, shortId, guildId, categoryId, channelId, webhookId, webhookToken, bridgeUrl?, bridgeToken?, createdAt, expiresAt, status: active|archived|deleted }.\n- Indices: unique(runId), index(channelId), index(expiresAt).\n- API: getByRunId(runId), getByChannelName/guild, upsertRun(run), markArchived(runId), markDeleted(runId), dueForRetention(now), with transactional/idempotent semantics.\n- Concurrency: unique constraints to prevent duplicate runs; retries on conflict.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Guild category discovery/creation utilities",
            "description": "Implement find-or-create for categories: Agent Runs and Archived Runs.",
            "dependencies": [
              "6.2"
            ],
            "details": "- Function: findOrCreateCategory(guild, name): search by name (type: GuildCategory), create if not found; return categoryId.\n- Handle optional categoryName override from request; default to config.\n- Cache category IDs per guild for short TTL to reduce API calls.\n- Error mapping: permission issues -> clear 403 for API layer.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Deterministic channel creation and idempotency",
            "description": "Create per-run text channels with deterministic naming and ensure idempotent behavior.",
            "dependencies": [
              "6.3",
              "6.4"
            ],
            "details": "- Name format: run-{taskId}-{attempt}-{shortId}; sanitize to [a-z0-9-], max 100 chars; collapse dashes.\n- Derive runId = `${taskId}:${attempt}:${shortId}`; if run exists in storage, return existing {channelId}.\n- If not exists: create channel under category with type 0 (text) and proper topic metadata.\n- Handle race: use storage unique(runId) to prevent dupes; on create conflict, fetch stored mapping and return it.\n- Store mapping (run -> channel) with expiresAt = now + retentionHours.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Webhook provisioning and initial header embed",
            "description": "Create a per-run webhook, store credentials, construct URL, and post initial metadata embed.",
            "dependencies": [
              "6.5"
            ],
            "details": "- Create webhook on the channel with name `run-{shortId}`; store {webhookId, webhookToken}.\n- Construct webhookUrl: https://discord.com/api/v10/webhooks/{webhookId}/{webhookToken}.\n- Post initial header embed via webhook with run metadata: taskId, attempt, shortId, runId, retention, timestamp, optional bridge presence.\n- Respect Discord limits: 1 embed initially, <= 6000 chars; redact secrets.\n- Update persistence with webhook info.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Rate limit and retry utilities",
            "description": "Add centralized wrappers to respect Discord REST rate limits and retry_after semantics.",
            "dependencies": [
              "6.2"
            ],
            "details": "- Wrap REST calls not covered by discord.js convenience methods (e.g., webhook POSTs) to handle 429 JSON retry_after and X-RateLimit-* headers.\n- Implement exponential backoff with jitter, max retries, and idempotent safeguards.\n- Log RL events with correlation IDs; surface retry-after to callers when appropriate.\n- Integrate wrappers into channel/webhook/create and embed posting paths.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Retention worker (cron) to archive/delete",
            "description": "Implement scheduled job to enforce TTL by archiving/moving or deleting run channels.",
            "dependencies": [
              "6.3",
              "6.4",
              "6.7"
            ],
            "details": "- Scheduler: node-cron or setInterval; runs every N minutes.\n- Query storage for dueForRetention(now): for each run, either move channel to Archived Runs category or delete per policy.\n- Use rate-limit wrappers; handle missing channels/webhooks gracefully; update status archived|deleted.\n- Ensure idempotency: safe to retry; skip if already archived/deleted.\n- Audit log actions; do not expose secrets.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "End-to-end and unit tests (create/idempotency/webhook/retention)",
            "description": "Write tests against a Discord test guild plus unit tests for naming/idempotency and retention.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4",
              "6.5",
              "6.6",
              "6.7",
              "6.8"
            ],
            "details": "- E2E: create run via POST /runs; assert channel under category, webhook URL works (send test message), returns {channelId, webhookUrl}. Cleanup: archive/delete.\n- Idempotency: same payload twice returns same resources.\n- Retention: set short TTL; wait/advance time; assert archive/delete and status updated.\n- RL: simulate 429 (mock or burst) to validate retry behavior.\n- Security: ensure API never returns bot token or secrets; only channelId and webhookUrl.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 7,
        "title": "Pod-local Input Bridge (Sidecar HTTP → Agent FIFO/stdin)",
        "description": "Implement an optional HTTP bridge in the sidecar that accepts JSON POST /input and writes streaming JSONL to agent FIFO/stdin without blocking the agent.",
        "details": "- Add an axum server in the Rust sidecar, listening on 0.0.0.0:8088 (configurable), with route POST /input; disabled by default via config\n- Request payload schema: { runId: string, channelId: string, userId: string, username: string, content: string, timestamp: string, token?: string }\n- Security: require a shared per-run token (HMAC or random) set by bot on /runs; reject if missing/invalid; optionally restrict to cluster network via NetworkPolicy (K8s)\n- Writing to agent: support two modes via config: FIFO path (AGENT_INPUT_FIFO) or inherit agent stdin (file descriptor). Implement non-blocking open on FIFO and spawn a writer task with bounded queue; write one line per message as compact JSON followed by newline\n- Backpressure: if agent not reading, buffer up to N messages (config); drop-oldest with warning beyond that to avoid deadlock\n- Pseudo-code handler:\n  async fn input(Json(msg)): -> Status { if !auth(msg.token) || !validate_channel(msg.channelId) { return 403 }\n    let line = serde_json::to_string(&msg)? + \"\\n\"; input_tx.try_send(line).map_err(|_| 503)?; 202 }\n- Observability: counters for messages forwarded, dropped, bytes written\n",
        "testStrategy": "- Unit tests for auth token validation and schema validation\n- Integration test: create a temp FIFO, start reader, POST to /input, assert line arrives intact\n- Load test: 100 msgs/sec for 10s; verify no deadlocks and bounded memory\n- Failure test: reader paused; verify backpressure and drop policy works as configured",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Bot Message Forwarding and Cross-run Validation",
        "description": "Extend the bot to forward messages from the run’s channel to the pod-local bridge with strict run/channel mapping validation.",
        "details": "- Listen to MESSAGE_CREATE events in discord.js; only accept messages from channels registered for runs and ignore bot/self messages\n- Validation: map channelId -> runId; ensure message.channelId matches stored runId; prevent cross-run injection by refusing DMs or other channels\n- Payload build: { runId, channelId, userId, username, content, timestamp, token } where token is the per-run secret stored by the bot\n- Forward via HTTP POST to bridgeUrl with timeouts and retry on 5xx; exponential backoff; log failures\n- Slash commands (optional future): register /note and /input; for MVP, plain text messages only; respond with ephemeral ack via reply in channel if forwarding succeeded/failed\n- Respect content size; truncate if >4k chars and include a note; attachments: include URLs/filenames in payload array\n- Pseudo-code:\n  client.on('messageCreate', async (m)=>{ const run = runsByChannel.get(m.channel.id); if(!run) return; const body = {runId: run.id, channelId: m.channel.id, userId: m.author.id, username: m.author.username, content: m.content, timestamp: m.createdAt, token: run.bridgeToken}; await fetch(run.bridgeUrl+'/input',{method:'POST',headers:{'content-type':'application/json'},body:JSON.stringify(body)}); });\n",
        "testStrategy": "- Unit tests: messages in non-run channels are ignored; run channel messages are forwarded\n- Integration test with local bridge server: verify payload schema and auth token\n- Error handling test: simulate bridge 500/timeout and ensure retries with backoff and user feedback\n- Security test: attempt spoofed channelId in payload (should not be possible as bot constructs payload); ensure mapping prevents cross-run injection",
        "priority": "medium",
        "dependencies": [
          6,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement messageCreate listener and base filters",
            "description": "Add a discord.js v14 client.on('messageCreate') handler and filter out ineligible messages.",
            "dependencies": [],
            "details": "Scope: Listen to MESSAGE_CREATE and immediately ignore messages from bots/webhooks/self, system messages, and DMs. Ensure channel is a guild text channel or thread under a run channel if desired policy, but do not accept DMs. Prepare a safe message envelope (author, channelId, guildId, timestamps) to pass downstream.\nImplementation notes:\n- Check m.author?.bot, m.webhookId, m.system\n- Reject if !m.guildId (DM) or channel is not text-based\n- Do not mutate or reply here; simply emit to the next stage if eligible\n- Add structured logging for ignored cases for observability",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Run/channel mapping validation layer",
            "description": "Validate channelId → run mapping and prevent cross-run injection.",
            "dependencies": [
              "8.1"
            ],
            "details": "Scope: Build/consume a runsByChannel Map<string, RunInfo> (populated by Task 6) and validate that the message.channelId is registered for a specific run. Enforce strict matching and refuse any message from unregistered channels or mismatched runs.\nImplementation notes:\n- Access runsByChannel.get(m.channel.id); if absent, return early\n- Confirm run.bridgeUrl and run.bridgeToken exist; if missing, log and ignore\n- Optionally support thread messages only if parent channel is registered (configuration-controlled)\n- Ensure no state leakage across runs; never infer run from content or username\n- Provide helper validateRunForMessage(message): RunInfo | null",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Payload builder with token, truncation, and attachments",
            "description": "Construct the JSON payload to send to the bridge with content policy and attachment references.",
            "dependencies": [
              "8.2"
            ],
            "details": "Scope: Build the request body { runId, channelId, userId, username, content, timestamp, token, attachments? } per schema. Handle content > 4000 chars by truncating and appending a note. Include attachment URLs and filenames.\nImplementation notes:\n- content: m.content || \"\"\n- Truncate if content.length > 4000; keep first 4000, append \" [truncated N chars]\"\n- timestamp: m.createdAt.toISOString()\n- attachments: map m.attachments to array of { name, url, size, contentType }\n- token: run.bridgeToken; NEVER log token\n- Return { body, wasTruncated } for downstream feedback",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "HTTP forwarder with timeouts and exponential backoff",
            "description": "POST payloads to run.bridgeUrl+'/input' with robust retry on 5xx/timeouts.",
            "dependencies": [
              "8.3"
            ],
            "details": "Scope: Implement forwardToBridge(run, body) with fetch/axios. Configure request timeout and retry policy with exponential backoff and jitter. Only retry on network errors/timeouts and 5xx; never on 4xx.\nImplementation notes:\n- Endpoint: `${run.bridgeUrl.replace(/\\/$/, '')}/input`\n- Headers: { 'content-type': 'application/json' }\n- Timeout: e.g., 5s per attempt (configurable)\n- Retry: maxAttempts=5, baseDelay=250ms, factor=2, jitter=±20%\n- Success: 2xx -> return ok\n- Failure: on 5xx/timeout -> retry; on 4xx -> fail fast\n- Log outcomes and final failures without sensitive data; include runId/channelId/messageId correlation IDs",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "User feedback (ack/fail) and message lifecycle",
            "description": "Reply in channel with success/failure and truncation notice; delete ack after short delay.",
            "dependencies": [
              "8.3",
              "8.4"
            ],
            "details": "Scope: After forwarding, reply to the user with an ephemeral-like acknowledgement. On success: short message indicating delivered (and whether truncated). On failure: notify and suggest retry; avoid leaking internal reasons or tokens. Delete ack after N seconds.\nImplementation notes:\n- Use message.reply({ content, allowedMentions: { parse: [] } })\n- Success: \"Received and forwarded to agent.\" + \" Note: content was truncated to 4000 characters.\" if wasTruncated\n- Failure: \"Forwarding failed. Please try again shortly.\" Add correlation ID for support in logs\n- Delete ack after e.g., 5–10s if bot has Manage Messages; ignore errors\n- Ensure this behavior is disabled in DMs (already filtered) and respects channel permissions",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Test suite: forwarding and cross-run validation",
            "description": "Add unit/integration tests for filters, mapping, payload, retries, and user feedback.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4",
              "8.5"
            ],
            "details": "Coverage:\n- Non-run channel ignored: message in unrelated channel triggers no POST and no reply\n- Forwarding success: valid run channel posts correct payload (including attachments), ack sent\n- Retry on 5xx/timeout: simulate server errors; assert exponential backoff attempts and final outcome\n- Mapping prevents cross-run: attempts from other channels/DMs are rejected; no POST\n- Truncation policy: >4k content truncated with note; payload reflects truncated content\n- Token presence: payload includes token; ensure token never logged\n- Use mocked fetch/axios and stub discord.js message objects; add an integration test against a local test HTTP server",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 9,
        "title": "Kubernetes Sidecar Template and Helm Packaging",
        "description": "Provide K8s manifests and Helm values to deploy the watcher as a sidecar and configure bot integration, filters, and resources.",
        "details": "- K8s sidecar container spec:\n  - image: discord-monitor:latest\n  - env: DISCORD_WEBHOOK_URL (Phase 1), WORKSPACE_PATH, POLL_INTERVAL_MS=100, BATCH_SIZE=10, PARITY_MODE, FILTERS JSON, STATS toggles, AGENT_INPUT_FIFO, BRIDGE_PORT\n  - resources: requests {cpu: 10m, memory: 32Mi}, limits {cpu: 100m, memory: 64Mi}\n  - probes: liveness/readiness on /healthz (to be added in Task 10)\n- Helm chart values matching PRD sketch under discord.monitoring.* including filters and stats\n- Template example sidecar for a Job/Pod spec: inject env from a Secret/ConfigMap; bot service returns webhookUrl which the orchestrator places into the pod env before start\n- Optional NetworkPolicy to restrict bridge endpoint to bot egress IPs or cluster internal\n- Provide chart for bot service (separate deployment + Service) with secrets (BOT_TOKEN), Redis, and retention worker CronJob\n- Documentation snippet for architecture.md and deploy steps\n",
        "testStrategy": "- Helm template unit tests with helm unittest or chart-testing; render manifests with provided values\n- Dry-run apply in a test cluster; verify sidecar starts, envs present, and watcher can read transcript path\n- Resource verification: measure memory/CPU in a sample run to confirm limits are sufficient\n- Security review: ensure no bot token ever appears in sidecar envs or logs",
        "priority": "medium",
        "dependencies": [
          1,
          4,
          6,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Helm values schema and base library chart for watcher sidecar",
            "description": "Create a Helm library chart that defines the values model under discord.monitoring.* to configure the watcher sidecar.",
            "dependencies": [],
            "details": "Deliverables:\n- Library chart name: discord-watcher-sidecar (type: library). Directory skeleton: Chart.yaml, values.yaml, values.schema.json, templates/_sidecar.tpl, templates/_helpers.tpl.\n- Values namespace: discord.monitoring.sidecar.* with defaults:\n  - image: repository, tag=discord-monitor:latest, pullPolicy\n  - env: webhookUrl: (string, optional), webhookUrlSecretRef: {name, key}, workspacePath (default: /workspace), pollIntervalMs (default: 100), batchSize (default: 10), parityMode (enum: full|parity), filters (object/JSON), stats: {enabled: bool, tokens: bool, costs: bool}\n  - bridge: {enabled: bool (default: false), port: 8088}\n  - resources: requests {cpu: 10m, memory: 32Mi}, limits {cpu: 100m, memory: 64Mi}\n  - securityContext defaults: runAsNonRoot=true, runAsUser=65532, readOnlyRootFilesystem=true, allowPrivilegeEscalation=false, capabilities.drop=[\"ALL\"]\n  - probes: {enabled: true, path: /healthz, port: 8088, initialDelaySeconds: 5, periodSeconds: 10, timeoutSeconds: 2, failureThreshold: 3, startupProbe: {enabled: true, failureThreshold: 30, periodSeconds: 5}}\n  - networkPolicy: {enabled: false, allowFromBotSelector: {namespaceSelector: {}, podSelector: {}}, allowedIngressCIDRs: [], allowedEgressCIDRs: [], restrictIngressToCluster: true}\n- values.schema.json:\n  - Types and validation for all above keys; enums for parityMode; integer ranges (pollIntervalMs >= 50, batchSize 1..50); conditionals for webhookUrl vs webhookUrlSecretRef.\n- Document mapping between values and container envs: DISCORD_WEBHOOK_URL, WORKSPACE_PATH, POLL_INTERVAL_MS, BATCH_SIZE, PARITY_MODE, FILTERS, STATS_*, AGENT_INPUT_FIFO, BRIDGE_PORT.\n- Ensure no fields reference bot token; webhook URL only.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Sidecar container template with resources and securityContext",
            "description": "Implement the reusable container spec template that consumes the values schema and sets resources and hardened securityContext.",
            "dependencies": [
              "9.1"
            ],
            "details": "Deliverables:\n- templates/_sidecar.tpl: define a Helm include that renders a complete sidecar container:\n  - name: discord-watcher\n  - image, imagePullPolicy from values\n  - env:\n    - DISCORD_WEBHOOK_URL from value or secretRef\n    - WORKSPACE_PATH, POLL_INTERVAL_MS, BATCH_SIZE, PARITY_MODE\n    - FILTERS (as JSON string from .Values or configMap key), STATS_* booleans\n    - AGENT_INPUT_FIFO (optional), BRIDGE_PORT (if bridge.enabled)\n  - ports: containerPort for bridge/health (name: health, port from values) exposed regardless of bridge.enabled to support probes\n  - volumeMounts: mount shared workspace volume at WORKSPACE_PATH (value-driven mountPath); do not mount any credentials except webhook secret if used\n  - resources from values defaults; allow override per workload via values\n  - securityContext per values (runAsNonRoot, readOnlyRootFilesystem, drop ALL caps, no privilege escalation)\n  - terminationMessagePolicy=FallbackToLogsOnError\n- Helper to easily inject this container into Pod/Job specs via include.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Wire liveness/readiness/startup probes to /healthz",
            "description": "Add configurable HTTP probes on /healthz using the designated port; safe defaults anticipating Task 10 implementation.",
            "dependencies": [
              "9.2"
            ],
            "details": "Deliverables:\n- In _sidecar.tpl, conditionally render probes when .Values.discord.monitoring.sidecar.probes.enabled is true:\n  - readinessProbe: httpGet path=/healthz, port from values; initialDelaySeconds, periodSeconds, timeoutSeconds, failureThreshold from values\n  - livenessProbe: same path/port; slightly larger initialDelaySeconds if needed\n  - startupProbe: optional; enabled via values; generous failureThreshold/period to avoid flapping until /healthz is implemented in Task 10\n- Ensure the container exposes the health port even if bridge.enabled=false, so probes can bind.\n- Notes: /healthz endpoint will be implemented in Task 10; set defaults to avoid false restarts (e.g., startupProbe enabled by default).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Secrets/Config injection and example Job/Pod templates",
            "description": "Provide Secret/ConfigMap templates and example workload manifests demonstrating sidecar injection and env sourcing.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3"
            ],
            "details": "Deliverables:\n- Template(s):\n  - secret-watcher-webhook.yaml: optionally create a Secret with webhookUrl when .Values provides secretData; otherwise support referencing an existing secret via webhookUrlSecretRef\n  - configmap-watcher.yaml: optional ConfigMap to hold FILTERS JSON and STATS toggles; sidecar env can source via valueFrom configMapKeyRef\n- Example library templates:\n  - _job-with-watcher.tpl and _pod-with-watcher.tpl: show how to include the sidecar container next to an app container; mount a shared emptyDir volume at WORKSPACE_PATH for both containers\n  - Demonstrate envFrom secretRef/configMapRef for filters/stats; DISCORD_WEBHOOK_URL sourced only from Secret or direct value if orchestrator supplies it\n- Usage examples in comments for two patterns:\n  - Orchestrator sets DISCORD_WEBHOOK_URL directly in Pod env prior to start\n  - Orchestrator writes the webhook URL into a Secret which the Pod references\n- Security note: explicitly prohibit injecting BOT_TOKEN into these pods; validate in schema/docs that only webhook URL is accepted.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Optional NetworkPolicy to restrict bridge ingress",
            "description": "Create a NetworkPolicy that limits ingress to the sidecar bridge port to bot service egress IPs or cluster-internal traffic.",
            "dependencies": [
              "9.1",
              "9.2"
            ],
            "details": "Deliverables:\n- networkpolicy-bridge.yaml: rendered only if .Values.discord.monitoring.sidecar.bridge.enabled and .Values.discord.monitoring.sidecar.networkPolicy.enabled\n- Policy behavior:\n  - Ingress allowed to the sidecar's bridge/health port from either:\n    - namespaceSelector/podSelector matching the bot service (values: allowFromBotSelector)\n    - allowedIngressCIDRs (optional)\n    - if restrictIngressToCluster=true, allow only same-namespace traffic unless selectors override\n  - Deny all other ingress to the bridge port\n- Egress:\n  - Optionally render an egress policy allowing traffic to allowedEgressCIDRs for Discord webhook endpoints; if empty, do not render egress rules to avoid unintentionally blocking outbound webhooks\n- Label selectors: base on a stable label (e.g., app.kubernetes.io/name for the workload that includes the sidecar) with clear documentation on how to set it.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Separate bot service chart with Redis and retention CronJob",
            "description": "Provide a standalone Helm chart for the bot service, its secrets, optional Redis, and a retention worker CronJob.",
            "dependencies": [
              "9.1"
            ],
            "details": "Deliverables:\n- New chart: discord-bot (application chart)\n  - Deployment: bot container image, env for BOT_TOKEN (from Secret), bridge and API configs, resource and securityContext hardening\n  - Service: ClusterIP if needed (for internal diagnostics or readiness)\n  - Secret: bot-token (stringData.BOT_TOKEN), mounted only in bot pods; never referenced by watcher pods (security review)\n  - Redis: add as dependency (e.g., bitnami/redis) or lightweight StatefulSet, with values to enable/disable and to use an existing external Redis\n  - CronJob: retention worker that prunes Redis keys/channels based on retention policy in values\n  - NetworkPolicy (optional): egress to watcher bridge ports via namespace/pod selectors consistent with subtask 5\n- Values and schema:\n  - discord.bot.* including image, resources, securityContext, redis.enabled/external, retention.schedule, retention.ttl, networkPolicy settings\n- Security review:\n  - Ensure BOT_TOKEN is scoped to bot namespace and pods only\n  - Validate that watcher sidecar charts have no references to BOT_TOKEN\n  - Recommendation to separate namespaces and limit RBAC to prevent secret leakage.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Chart testing, validation, and deployment documentation",
            "description": "Set up chart unit tests and chart-testing, and write deploy steps and architecture notes.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3",
              "9.4",
              "9.5",
              "9.6"
            ],
            "details": "Deliverables:\n- Tests:\n  - helm-unittest suites for sidecar library: validate env mapping, probes rendered, securityContext, resources, and NetworkPolicy selectors\n  - helm-unittest for bot chart: ensure BOT_TOKEN secret is only mounted in bot pods; Redis and CronJob toggles\n  - ct configuration (chart-testing) with lint and template checks; optional kind-based install test using sample values\n- Sample values files:\n  - examples/sidecar-values.yaml with filters/stats, bridge enabled, networkPolicy enabled\n  - examples/bot-values.yaml with redis.enabled, retention schedule, and networkPolicy to reach sidecars\n- Deployment docs (architecture.md snippet and deploy steps):\n  - Explain sidecar pattern, envs, filters/stats, parity mode, and bridge flow\n  - Security considerations: no bot token in worker pods; webhook URL only; how NetworkPolicy confines bridge access\n  - Step-by-step:\n    1) Install bot chart and create bot-token Secret\n    2) Install or integrate the sidecar library into workloads; set DISCORD_WEBHOOK_URL via orchestrator or Secret\n    3) Optionally enable bridge and NetworkPolicy\n    4) Verify with helm template/dry-run and kubectl get pods; check envs and resources\n    5) After Task 10, confirm /healthz reports OK\n- CI snippet for running ct and helm-unittest on PRs.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 10,
        "title": "Observability, Health Checks, and Hardening",
        "description": "Add metrics, logging, health endpoints, and resilience features to meet non-functional requirements and risks.",
        "details": "- Watcher metrics (Prometheus via metrics + prometheus_exporter): events_processed_total, embeds_sent_total, rate_limit_hits_total, webhook_retries_total, latency_ms (append->post), queue_depth, bytes_sent, truncations_total, cpu_mem_gauges\n- Health endpoints: /healthz (ready when webhook sender alive and tailer reading), /metrics for Prometheus; expose on localhost:9090\n- Robust error logging with tracing spans per runId and channelId; sample stack traces for unexpected errors\n- Reliability: auto-reconnect tail on errors; ensure independent restarts won’t impact agent; gracefully handle missing webhook (buffer for short time)\n- Backoff configurations centralized; jitter applied; DLQ/log file for permanently failed posts\n- Bot service: add basic metrics (forwarded_messages_total, bridge_errors_total), health route, and structured logs\n- Load/latency tests: measure end-to-end ≤100ms avg from append to post (network permitting); optimize if needed (e.g., coalesce small sleeps)\n- Risk mitigations: rate limit backoff already in Task 4; add discovery retry loop for transcript path variance\n",
        "testStrategy": "- Unit tests for health state transitions (tailer disconnected -> not ready)\n- Benchmark end-to-end latency using a synthetic transcript appending tool and capturing post times\n- Metrics scrape test: ensure Prometheus can scrape /metrics\n- Failure injection tests: kill webhook network, rotate transcript file; validate automatic recovery\n- Verify no measurable slowdown on agent by comparing run times with/without watcher under load",
        "priority": "medium",
        "dependencies": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Metrics Registry and Prometheus Exporter",
            "description": "Introduce a metrics registry and Prometheus exporter with well-defined counters, gauges, and histograms for watcher and bot services.",
            "dependencies": [],
            "details": "- Use metrics + prometheus_exporter to expose /metrics on localhost:9090.\n- Define watcher metrics: counters events_processed_total, embeds_sent_total, rate_limit_hits_total, webhook_retries_total, truncations_total; gauges queue_depth, cpu_mem_gauges, bytes_sent; histogram latency_ms (append->post) with buckets [5,10,20,50,100,200,500,1000].\n- Define bot service metrics: counters forwarded_messages_total, bridge_errors_total; reuse cpu_mem_gauges.\n- Add low-cardinality labels where safe (e.g., component=\"watcher|bot\", outcome=\"ok|error\"). Avoid high-cardinality labels like runId/channelId on metrics.\n- Implement process CPU/memory gauges via sysinfo or equivalent.\n- Document metric names, units, and semantics; add a sample Prometheus scrape config.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Structured Tracing and Error Sampling",
            "description": "Add tracing spans with runId/channelId fields and robust, structured error logging with sampling of unexpected stack traces.",
            "dependencies": [],
            "details": "- Use tracing/tracing-subscriber with JSON formatter; include fields: runId, channelId, event_kind, attempt, error.kind.\n- Define span lifecycle across pipeline stages: tail->parse->build_embed->send_webhook. Propagate trace context through async tasks.\n- Configure log levels via config/env; default info, with per-module overrides.\n- Sample unexpected errors (e.g., 1%) with captured backtraces enabled; always log full context for fatal paths.\n- Correlate logs to metrics via outcome fields; do not put high-cardinality fields into metric labels.\n- Provide log redaction for secrets (webhook URL, tokens).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Centralized Backoff and Jitter Configuration",
            "description": "Create a shared backoff module and configuration for retries with jitter for network, webhook, and discovery operations.",
            "dependencies": [],
            "details": "- Expose config: base_ms, max_ms, multiplier, jitter_pct, max_retries, per-category overrides (rate_limit, network, discovery, webhook_post).\n- Implement exponential backoff with full jitter; provide async sleep helper.\n- Emit metrics: backoff_attempts_total{category}, backoff_duration_ms histogram.\n- Use in retry wrappers so callers can compose: retry_async(category, op_fn).\n- Document defaults and guidance; ensure unit tests for bounds, jitter distribution, and max retry behavior.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Auto-Reconnect Tailer and Discovery Retry Loops",
            "description": "Harden the tailer to auto-reconnect on errors and add discovery retry loops to handle transcript path variance and rotations.",
            "dependencies": [
              "10.3"
            ],
            "details": "- Detect file handle invalidation, EOF stalls, and errors; auto-reopen with backoff from centralized config.\n- Implement directory discovery loop for ~/.claude/projects/<workspace>/ session files; pick latest mtime; retry with backoff on not-found.\n- Handle file rotation seamlessly: persist and restore read offsets where safe to avoid duplicates.\n- Emit metrics: tail_reconnects_total, discovery_retries_total; logs with reason and durations.\n- Ensure independent restarts do not disrupt the agent: idempotent initialization and safe resource cleanup.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Webhook Outage Buffering with Bounded Queue and DLQ",
            "description": "Gracefully handle missing/unreachable webhook by buffering with bounds and persisting permanently failed posts to a DLQ.",
            "dependencies": [
              "10.3"
            ],
            "details": "- Implement in-memory bounded queue sized by count and bytes; export queue_depth gauge; drop oldest or newest based on policy with truncations_total increments.\n- Retry sender with centralized backoff; apply jitter; respect rate-limit headers if present.\n- DLQ: append-only file for exhausted retries or payloads failing validation; include timestamp, reason; add DLQ rotation policy.\n- Background DLQ reprocessor with safe rate; metrics: dlq_writes_total, dlq_reprocess_total, webhook_retries_total{outcome}.\n- Guarantee at-least-once delivery semantics during transient outages; document trade-offs and ordering guarantees.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Health Endpoints and Readiness Logic",
            "description": "Expose /healthz and /metrics; mark ready only when tailer is reading and webhook sender is healthy; include liveness.",
            "dependencies": [
              "10.1",
              "10.4",
              "10.5"
            ],
            "details": "- Serve on localhost:9090 using the same HTTP server as /metrics; endpoints: /healthz (readiness), /livez (liveness), /metrics.\n- Readiness conditions: tailer connected and reading (recent activity or open handle), webhook sender not degraded (buffer below threshold, no sustained failures), config loaded.\n- Liveness: process responsive loop check.\n- Return JSON with component statuses and overall status; appropriate HTTP codes (200 ready, 503 not ready).\n- Unit tests for state transitions (tailer disconnect -> not ready; webhook outage -> not ready; recovery -> ready).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "End-to-End Latency Benchmark Tool and SLOs",
            "description": "Build a synthetic benchmark to measure append-to-post latency and enforce ≤100ms average SLO under normal conditions.",
            "dependencies": [
              "10.1",
              "10.4",
              "10.5",
              "10.6"
            ],
            "details": "- Create a tool that appends synthetic transcript lines and timestamps when webhook post completes; record latency into latency_ms histogram.\n- Run warm/cold scenarios; report p50/p90/p99 and average; fail test if average >100ms (network permitting) with configurable guard.\n- Emit metrics for runs; save JSON report artifact; add CI job to execute against a local mock webhook server.\n- Optimize if needed (coalesce small sleeps, reduce allocations); document tuning knobs.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Failure Injection and Resilience Tests",
            "description": "Systematically inject failures to validate recovery paths, buffering, and health signaling.",
            "dependencies": [
              "10.4",
              "10.5",
              "10.6",
              "10.7"
            ],
            "details": "- Scenarios: drop webhook connectivity, simulate HTTP 429/5xx, slow responses, kill/restart process, rotate transcript mid-write, corrupt line, missing path.\n- Verify: auto-reconnect works, retries backoff, health toggles to 503 then recovers, DLQ captures permanent failures, no data loss beyond policy.\n- Provide fault toggles in code or via proxy (toxiproxy) and scripts; gather metrics/logs snapshots for each scenario.\n- Add assertions on metrics deltas (rate_limit_hits_total increments, webhook_retries_total outcomes) and log markers.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Resource Monitoring and No-Slowdown Guardrails",
            "description": "Monitor CPU/memory and event-loop health to ensure observability features do not slow the agent.",
            "dependencies": [
              "10.1",
              "10.7"
            ],
            "details": "- Track cpu_mem_gauges over time during benchmarks; add event loop lag metric (tick_jitter_ms) via periodic heartbeat and measuring drift.\n- Define thresholds (e.g., CPU < 20% avg, memory < 64Mi, lag < 10ms p99) and fail CI job if exceeded.\n- Optimize exporters/logging to be non-blocking and backpressure-aware; cap log rate with sampling.\n- Produce a short report comparing baseline vs with observability enabled; recommend config defaults if needed.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-11T05:40:40.719Z",
      "updated": "2025-08-11T05:40:40.719Z",
      "description": "Tasks for master context"
    }
  }
}