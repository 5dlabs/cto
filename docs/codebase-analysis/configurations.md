# Configuration Files

## TOML Files

### dist-workspace.toml (dist-workspace.toml)

```toml
[workspace]
members = ["cargo:orchestrator/tools"]

# Config for 'dist'
[dist]
# The preferred dist version to use in CI (Cargo.toml SemVer syntax)
cargo-dist-version = "0.28.2"
# CI backends to support
ci = "github"
# The installers to generate for each app
installers = ["shell"]
# Target platforms to build apps for (Rust target-triple syntax)
targets = ["aarch64-apple-darwin", "aarch64-unknown-linux-gnu", "x86_64-apple-darwin", "x86_64-unknown-linux-gnu", "x86_64-pc-windows-msvc"]
# Path that installers should place binaries in
install-path = "CARGO_HOME"
# Where to host releases
hosting = "github"
# Whether to install an updater program
install-updater = false
# Allow manual customizations to release.yml
allow-dirty = ["ci"]

```

### Cargo.toml (orchestrator/Cargo.toml)

```toml
[workspace]
resolver = "2"
members = [
    "core",
    "tools",
    "common",
]

[workspace.package]
version = "0.1.0"
edition = "2021"
authors = ["5D team"]
license = "AGPL-3.0"
repository = "https://github.com/5dlabs/platform"

[workspace.dependencies]
# Web framework
axum = "0.8.4"
tokio = { version = "1.40", features = ["full"] }
tower = "0.5"
tower-http = { version = "0.5", features = ["trace", "cors", "limit", "timeout"] }

# Kubernetes
kube = { version = "0.93", features = ["runtime", "derive", "client", "ws"] }
kube-derive = "0.93"
k8s-openapi = { version = "0.22", features = ["v1_30"] }
schemars = "0.8"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"
toml = "0.8"

# Error handling
anyhow = "1.0"
thiserror = "2.0.12"

# Logging and tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# OpenTelemetry
opentelemetry = "0.30.0"
opentelemetry-otlp = { version = "0.17", features = ["tonic"] }
opentelemetry_sdk = { version = "0.24", features = ["rt-tokio"] }
tracing-opentelemetry = "0.31.0"

# CLI
clap = { version = "4.5", features = ["derive", "env", "cargo"] }
dialoguer = "0.11"
indicatif = "0.17"
colored = "3.0.0"

# HTTP Client
reqwest = { version = "0.12", features = ["json", "stream", "rustls-tls"], default-features = false }
eventsource-client = "0.15.0"

# Async utilities
futures = "0.3"
async-trait = "0.1"

# Time handling
chrono = { version = "0.4", features = ["serde"] }

# Text processing
regex = "1.10"
handlebars = "6.3.2"

# Testing
mockall = "0.13"
wiremock = "0.6"

# UUID generation
uuid = { version = "1.10", features = ["v4", "serde"] }

[profile.release]
lto = true
opt-level = 3
codegen-units = 1

# The profile that 'dist' will build with
[profile.dist]
inherits = "release"
lto = "thin"

```

### Cargo.toml (orchestrator/tools/Cargo.toml)

```toml
[package]
name = "fivedlabs-tools"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
description = "5D Labs platform tools: CLI and MCP server for AI development workflows"
homepage = "https://github.com/5dlabs/platform"

# CLI binary
[[bin]]
name = "fdl"
path = "src/cli/main.rs"

# MCP server binary
[[bin]]
name = "fdl-mcp"
path = "src/mcp/main.rs"

[dependencies]
# CLI
clap = { workspace = true }
colored = { workspace = true }

# HTTP Client
reqwest = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = { workspace = true }

# Error handling
anyhow = { workspace = true }

# Logging
tracing = { workspace = true }
tracing-subscriber = { workspace = true }

# Async runtime
tokio = { workspace = true }

# Time handling
chrono = { workspace = true }

# Internal dependencies
common = { path = "../common" }
```

### rustfmt.toml (orchestrator/rustfmt.toml)

```toml
# Rust formatting configuration
edition = "2021"
max_width = 100
use_small_heuristics = "Default"
```

### Cargo.toml (orchestrator/core/Cargo.toml)

```toml
[package]
name = "core"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
description = "5D Labs platform orchestrator core API server (for Kubernetes deployment)"
homepage = "https://github.com/5dlabs/platform"

[[bin]]
name = "orchestrator-core"
path = "src/main.rs"

[package.metadata.dist]
# Don't distribute this package - it's for Docker deployment, not end users
dist = false

[dependencies]
# Web framework
axum = { workspace = true }
tokio = { workspace = true }
tower = { workspace = true }
tower-http = { workspace = true }

# Kubernetes
kube = { workspace = true }
kube-derive = { workspace = true }
k8s-openapi = { workspace = true }
schemars = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = { workspace = true }
serde_yaml = { workspace = true }

# Error handling
anyhow = { workspace = true }
thiserror = { workspace = true }

# Logging and tracing
tracing = { workspace = true }
tracing-subscriber = { workspace = true }

# OpenTelemetry
opentelemetry = { workspace = true }
opentelemetry-otlp = { workspace = true }
opentelemetry_sdk = { workspace = true }
tracing-opentelemetry = { workspace = true }

# HTTP Client
reqwest = { workspace = true }

# Async utilities
futures = { workspace = true }
async-trait = { workspace = true }

# Time handling
chrono = { workspace = true }

# Text processing
regex = { workspace = true }
handlebars = { workspace = true }

# File system
tempfile = "3.8"

# Internal dependencies
common = { path = "../common" }

[dev-dependencies]
tokio-test = "0.4"
mockall = { workspace = true }
wiremock = { workspace = true }
uuid = { workspace = true }
```

### Cargo.toml (orchestrator/common/Cargo.toml)

```toml
[package]
name = "common"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[dependencies]
# Serialization
serde = { workspace = true }
serde_json = { workspace = true }

# Error handling
anyhow = { workspace = true }
thiserror = { workspace = true }

# Time handling
chrono = { workspace = true }

# Kubernetes types (for shared models)
k8s-openapi = { workspace = true }

# Async trait
async-trait = { workspace = true }

# UUID generation
uuid = { version = "1.10", features = ["v4", "serde"] }

[dev-dependencies]
serde_test = "1.0"
```

### clippy.toml (orchestrator/clippy.toml)

```toml
# Clippy configuration for consistent linting

# Set the maximum cognitive complexity allowed
cognitive-complexity-threshold = 30

# Set maximum function arguments
too-many-arguments-threshold = 7

# Set maximum lines for functions
too-many-lines-threshold = 100

# Disallow certain macros
disallowed-macros = [
    # We prefer tracing over println for logging
    { path = "std::println", reason = "use tracing::info! instead" },
    { path = "std::eprintln", reason = "use tracing::error! instead" },
]
```

## JSON Files

### engineering-metrics-dashboard.json (infra/telemetry/telemetry-dashboards/dashboards/engineering-metrics-dashboard.json)

```json
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "normal"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (operation) (rate(claude_code_lines_of_code_count{github_user=\"$github_user\",working_service=\"$service\"}[5m]))",
          "legendFormat": "{{operation}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Lines of Code Modified",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 0
      },
      "id": 2,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_pull_request_count{github_user=\"$github_user\",working_service=\"$service\"}[24h]))",
          "legendFormat": "Pull Requests",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Pull Requests (24h)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 0
      },
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_commit_count{github_user=\"$github_user\",working_service=\"$service\"}[24h]))",
          "legendFormat": "Commits",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Commits (24h)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "custom": {
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "scaleDistribution": {
              "type": "linear"
            }
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 4
      },
      "id": 4,
      "options": {
        "calculate": false,
        "cellGap": 1,
        "cellValues": {
          "unit": "short"
        },
        "color": {
          "exponent": 0.5,
          "fill": "dark-orange",
          "mode": "scheme",
          "reverse": false,
          "scale": "exponential",
          "scheme": "Oranges",
          "steps": 64
        },
        "exemplars": {
          "color": "rgba(255,0,255,0.7)"
        },
        "filterValues": {
          "le": 1e-9
        },
        "legend": {
          "show": true
        },
        "rowsFrame": {
          "layout": "auto"
        },
        "tooltip": {
          "show": true,
          "yHistogram": false
        },
        "yAxis": {
          "axisPlacement": "left",
          "reverse": false,
          "unit": "short"
        }
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (hour) (increase(claude_code_commit_count{github_user=\"$github_user\",working_service=\"$service\"}[1h]))",
          "format": "heatmap",
          "legendFormat": "{{hour}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Commit Patterns (Heatmap)",
      "type": "heatmap"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            }
          },
          "mappings": []
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 5,
      "options": {
        "displayLabels": ["name", "percent"],
        "legend": {
          "displayMode": "list",
          "placement": "right",
          "showLegend": true,
          "values": []
        },
        "pieType": "pie",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (tool) (claude_code_code_edit_tool_decision{github_user=\"$github_user\",working_service=\"$service\"})",
          "legendFormat": "{{tool}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Tool Usage Distribution",
      "type": "piechart"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 12
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (token_type) (rate(claude_code_token_usage{github_user=\"$github_user\",working_service=\"$service\"}[5m]))",
          "legendFormat": "{{token_type}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Token Usage by Type",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "victoriametrics-logs-datasource",
        "uid": "${logs_datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "auto"
            },
            "inspect": false
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "_time"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 180
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "github.user"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 150
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "working.service"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 150
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 16
      },
      "id": 7,
      "options": {
        "cellHeight": "sm",
        "footer": {
          "countRows": false,
          "fields": "",
          "reducer": ["sum"],
          "show": false
        },
        "showHeader": true
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "victoriametrics-logs-datasource",
            "uid": "${logs_datasource}"
          },
          "expr": "_msg:claude_code.user_prompt AND github.user:\"$github_user\" AND working.service:\"$service\" | fields _time, github.user, working.service, prompt_preview | sort by (_time desc) | limit 100",
          "refId": "A"
        }
      ],
      "title": "Developer Activity Timeline",
      "type": "table"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["claude-code", "engineering"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "VictoriaMetrics",
          "value": "VictoriaMetrics"
        },
        "hide": 0,
        "includeAll": false,
        "label": "Metrics Datasource",
        "multi": false,
        "name": "datasource",
        "options": [],
        "query": "prometheus",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      },
      {
        "current": {
          "selected": false,
          "text": "VictoriaLogs",
          "value": "VictoriaLogs"
        },
        "hide": 0,
        "includeAll": false,
        "label": "Logs Datasource",
        "multi": false,
        "name": "logs_datasource",
        "options": [],
        "query": "victoriametrics-logs-datasource",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      },
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "${datasource}"
        },
        "definition": "label_values(github.user)",
        "hide": 0,
        "includeAll": true,
        "label": "GitHub User",
        "multi": false,
        "name": "github_user",
        "options": [],
        "query": {
          "query": "label_values(github.user)",
          "refId": "PrometheusVariableQueryEditor-VariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "${datasource}"
        },
        "definition": "label_values(working.service)",
        "hide": 0,
        "includeAll": true,
        "label": "Service",
        "multi": false,
        "name": "service",
        "options": [],
        "query": {
          "query": "label_values(working.service)",
          "refId": "PrometheusVariableQueryEditor-VariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-24h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Claude Code - Engineering Metrics",
  "uid": "engineering-metrics",
  "version": 1,
  "weekStart": ""
}
```

### cost-management-dashboard.json (infra/telemetry/telemetry-dashboards/dashboards/cost-management-dashboard.json)

```json
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "red",
                "value": 100
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[1h]))",
          "legendFormat": "Current Hour Spend",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Current Hour Spend",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 500
              },
              {
                "color": "red",
                "value": 1000
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 6,
        "y": 0
      },
      "id": 2,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[24h]))",
          "legendFormat": "Today's Total",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Today's Total Spend",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 15000
              },
              {
                "color": "red",
                "value": 30000
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 12,
        "y": 0
      },
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[30d]))",
          "legendFormat": "Monthly Total",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Monthly Total Spend",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "continuous-GrYlRd"
          },
          "mappings": [],
          "max": 100,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 18,
        "y": 0
      },
      "id": 4,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "showThresholdLabels": true,
        "showThresholdMarkers": true,
        "text": {}
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "(sum(increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[24h])) / 1000) * 100",
          "legendFormat": "Budget Used %",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Daily Budget Burn Rate",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "normal"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 6
      },
      "id": 5,
      "options": {
        "legend": {
          "calcs": ["sum"],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (day) (increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[1d]))",
          "legendFormat": "Daily Cost",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Daily Cost Trend",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "fillOpacity": 80,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineWidth": 1,
            "scaleDistribution": {
              "type": "linear"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 6
      },
      "id": 6,
      "options": {
        "barRadius": 0,
        "barWidth": 0.97,
        "fullHighlight": false,
        "groupWidth": 0.7,
        "legend": {
          "calcs": ["sum"],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "orientation": "auto",
        "showValue": "auto",
        "stacking": "normal",
        "tooltip": {
          "mode": "single",
          "sort": "none"
        },
        "xTickLabelRotation": 0,
        "xTickLabelSpacing": 0
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (model) (increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[24h]))",
          "legendFormat": "{{model}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Cost by Model (24h)",
      "type": "barchart"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            }
          },
          "mappings": [],
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 14
      },
      "id": 7,
      "options": {
        "displayLabels": ["name", "value"],
        "legend": {
          "displayMode": "list",
          "placement": "right",
          "showLegend": true,
          "values": ["value"]
        },
        "pieType": "donut",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (working_service) (increase(claude_code_cost_usage{github_user=~\"$github_user\",working_service=~\"$service\"}[24h]))",
          "legendFormat": "{{working_service}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Cost by Service (24h)",
      "type": "piechart"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "color-text"
            },
            "inspect": false
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "red",
                "value": 100
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "GitHub User"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 200
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Service"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 200
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 14
      },
      "id": 8,
      "options": {
        "cellHeight": "sm",
        "footer": {
          "countRows": false,
          "fields": "",
          "reducer": ["sum"],
          "show": true
        },
        "showHeader": true,
        "sortBy": [
          {
            "desc": true,
            "displayName": "Cost (24h)"
          }
        ]
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "topk(20, sum by (github_user, working_service) (increase(claude_code_cost_usage[24h])))",
          "format": "table",
          "instant": true,
          "legendFormat": "__auto",
          "range": false,
          "refId": "A"
        }
      ],
      "title": "Top Spenders (24h)",
      "transformations": [
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "Time": true
            },
            "indexByName": {},
            "renameByName": {
              "Value": "Cost (24h)",
              "github_user": "GitHub User",
              "working_service": "Service"
            }
          }
        }
      ],
      "type": "table"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "color-background"
            },
            "inspect": false
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "yellow",
                "value": null
              },
              {
                "color": "red",
                "value": 100
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 24,
        "x": 0,
        "y": 22
      },
      "id": 9,
      "options": {
        "cellHeight": "sm",
        "footer": {
          "countRows": false,
          "fields": "",
          "reducer": ["sum"],
          "show": false
        },
        "showHeader": true
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (github_user, working_service) (increase(claude_code_cost_usage[1h])) > 100",
          "format": "table",
          "instant": true,
          "legendFormat": "__auto",
          "range": false,
          "refId": "A"
        }
      ],
      "title": "⚠️ Cost Anomalies - Users Spending >$100/hour",
      "transformations": [
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "Time": true
            },
            "indexByName": {},
            "renameByName": {
              "Value": "Hourly Cost",
              "github_user": "GitHub User",
              "working_service": "Service"
            }
          }
        }
      ],
      "type": "table"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["claude-code", "cost", "budget"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "VictoriaMetrics",
          "value": "VictoriaMetrics"
        },
        "hide": 0,
        "includeAll": false,
        "label": "Datasource",
        "multi": false,
        "name": "datasource",
        "options": [],
        "query": "prometheus",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      },
      {
        "current": {
          "selected": true,
          "text": ["All"],
          "value": ["$__all"]
        },
        "datasource": {
          "type": "prometheus",
          "uid": "${datasource}"
        },
        "definition": "label_values(claude_code_cost_usage, github_user)",
        "hide": 0,
        "includeAll": true,
        "label": "GitHub User",
        "multi": true,
        "name": "github_user",
        "options": [],
        "query": {
          "query": "label_values(claude_code_cost_usage, github_user)",
          "refId": "PrometheusVariableQueryEditor-VariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      },
      {
        "current": {
          "selected": true,
          "text": ["All"],
          "value": ["$__all"]
        },
        "datasource": {
          "type": "prometheus",
          "uid": "${datasource}"
        },
        "definition": "label_values(claude_code_cost_usage, working_service)",
        "hide": 0,
        "includeAll": true,
        "label": "Service",
        "multi": true,
        "name": "service",
        "options": [],
        "query": {
          "query": "label_values(claude_code_cost_usage, working_service)",
          "refId": "PrometheusVariableQueryEditor-VariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 1,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-24h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Claude Code - Cost Management",
  "uid": "cost-management",
  "version": 1,
  "weekStart": ""
}
```

### executive-overview.json (infra/telemetry/telemetry-dashboards/dashboards/executive-overview.json)

```json
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 0
      },
      "id": 2,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.0.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_session_count[24h]))",
          "refId": "A"
        }
      ],
      "title": "Sessions Today",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 0
      },
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.0.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "count(count by (user_account_uuid) (claude_code_session_count))",
          "refId": "A"
        }
      ],
      "title": "Active Users",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 1000
              },
              {
                "color": "red",
                "value": 5000
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 0
      },
      "id": 4,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.0.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_cost_usage[24h]))",
          "refId": "A"
        }
      ],
      "title": "Cost Today",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "decimals": 2,
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 10000
              },
              {
                "color": "red",
                "value": 50000
              }
            ]
          },
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 0
      },
      "id": 5,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.0.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum(increase(claude_code_cost_usage[30d]))",
          "refId": "A"
        }
      ],
      "title": "Monthly Cost",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 4
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "count(count by (user_account_uuid) (claude_code_session_count))",
          "legendFormat": "Active Users",
          "refId": "A"
        }
      ],
      "title": "Daily Active Users Trend",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            }
          },
          "mappings": [],
          "unit": "currencyUSD"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 4
      },
      "id": 7,
      "options": {
        "displayLabels": ["name", "percent"],
        "legend": {
          "displayMode": "list",
          "placement": "right",
          "showLegend": true,
          "values": ["value"]
        },
        "pieType": "pie",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ],
          "fields": ""
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "sum by (model) (claude_code_cost_usage)",
          "legendFormat": "{{model}}",
          "refId": "A"
        }
      ],
      "title": "Cost by Model",
      "type": "piechart"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "auto"
            },
            "inspect": false
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Cost"
            },
            "properties": [
              {
                "id": "unit",
                "value": "currencyUSD"
              },
              {
                "id": "decimals",
                "value": 2
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 12
      },
      "id": 8,
      "options": {
        "showHeader": true,
        "sortBy": [
          {
            "desc": true,
            "displayName": "Cost"
          }
        ]
      },
      "pluginVersion": "10.0.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "topk(10, sum by (user_account_uuid) (claude_code_cost_usage))",
          "format": "table",
          "refId": "A"
        }
      ],
      "title": "Top Users by Cost",
      "transformations": [
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "Time": true
            },
            "indexByName": {},
            "renameByName": {
              "Value": "Cost",
              "user_account_uuid": "User"
            }
          }
        }
      ],
      "type": "table"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["claude-code", "executive"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "VictoriaMetrics",
          "value": "VictoriaMetrics"
        },
        "hide": 0,
        "includeAll": false,
        "label": "Data Source",
        "multi": false,
        "name": "datasource",
        "options": [],
        "query": "prometheus",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      }
    ]
  },
  "time": {
    "from": "now-24h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Claude Code - Executive Overview",
  "uid": "claude-code-exec",
  "version": 1,
  "weekStart": ""
}
```

### operations-monitoring-dashboard.json (infra/telemetry/telemetry-dashboards/dashboards/operations-monitoring-dashboard.json)

```json
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "0": {
                  "color": "red",
                  "index": 1,
                  "text": "DOWN"
                },
                "1": {
                  "color": "green",
                  "index": 0,
                  "text": "UP"
                }
              },
              "type": "value"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "green",
                "value": 1
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "up{job=\"otel-collector\",namespace=\"telemetry\"}",
          "legendFormat": "OTLP Collector",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "OTLP Collector Health",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "0": {
                  "color": "red",
                  "index": 1,
                  "text": "DOWN"
                },
                "1": {
                  "color": "green",
                  "index": 0,
                  "text": "UP"
                }
              },
              "type": "value"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "green",
                "value": 1
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 0
      },
      "id": 2,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "up{job=\"victoria-metrics\"}",
          "legendFormat": "VictoriaMetrics",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "VictoriaMetrics Health",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "0": {
                  "color": "red",
                  "index": 1,
                  "text": "DOWN"
                },
                "1": {
                  "color": "green",
                  "index": 0,
                  "text": "UP"
                }
              },
              "type": "value"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "green",
                "value": 1
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 0
      },
      "id": 3,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "up{instance=~\"victoria-logs.*\"}",
          "legendFormat": "VictoriaLogs",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "VictoriaLogs Health",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 0
      },
      "id": 4,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "count(up == 1)",
          "legendFormat": "Healthy Services",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Total Healthy Services",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "area"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 1
              },
              {
                "color": "red",
                "value": 5
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 4
      },
      "id": 5,
      "options": {
        "legend": {
          "calcs": ["mean", "lastNotNull"],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "(rate(claude_code_api_error{github_user=\"$github_user\",working_service=\"$service\"}[5m]) / rate(claude_code_api_request{github_user=\"$github_user\",working_service=\"$service\"}[5m])) * 100",
          "legendFormat": "Error Rate %",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Claude Code Error Rate",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "bars",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 4
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "single",
          "sort": "none"
        }
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "histogram_quantile(0.95, sum(rate(api_request_duration_bucket{github_user=\"$github_user\",working_service=\"$service\"}[5m])) by (le))",
          "legendFormat": "p95 Response Time",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "histogram_quantile(0.99, sum(rate(api_request_duration_bucket{github_user=\"$github_user\",working_service=\"$service\"}[5m])) by (le))",
          "legendFormat": "p99 Response Time",
          "range": true,
          "refId": "B"
        }
      ],
      "title": "API Response Times",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 1000
              },
              {
                "color": "red",
                "value": 5000
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 12
      },
      "id": 7,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "rate(prometheus_tsdb_samples_appended_total[1m]) * 60",
          "legendFormat": "Metrics/min",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Metrics Ingestion Rate",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 10000
              },
              {
                "color": "red",
                "value": 50000
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 12
      },
      "id": 8,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": ["lastNotNull"],
          "fields": ""
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "rate(victoria_logs_rows_inserted_total[1m]) * 60",
          "legendFormat": "Logs/min",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Logs Ingestion Rate",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "color-text"
            },
            "inspect": false
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Pod"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 300
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 12
      },
      "id": 9,
      "options": {
        "cellHeight": "sm",
        "footer": {
          "countRows": false,
          "fields": "",
          "reducer": ["sum"],
          "show": false
        },
        "showHeader": true
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "editorMode": "code",
          "expr": "100 * (container_memory_working_set_bytes{namespace=\"telemetry\",container!=\"\"} / container_spec_memory_limit_bytes{namespace=\"telemetry\",container!=\"\"})",
          "format": "table",
          "instant": true,
          "legendFormat": "{{pod}} - {{container}}",
          "range": false,
          "refId": "A"
        }
      ],
      "title": "Component Memory Usage",
      "transformations": [
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "Time": true,
              "container": true,
              "endpoint": true,
              "id": true,
              "image": true,
              "instance": true,
              "job": true,
              "metrics_path": true,
              "name": true,
              "namespace": true,
              "service": true
            },
            "indexByName": {},
            "renameByName": {
              "Value": "Memory %",
              "pod": "Pod"
            }
          }
        }
      ],
      "type": "table"
    },
    {
      "datasource": {
        "type": "victoriametrics-logs-datasource",
        "uid": "${logs_datasource}"
      },
      "fieldConfig": {
        "defaults": {
          "custom": {
            "align": "auto",
            "cellOptions": {
              "type": "auto"
            },
            "inspect": false
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "_time"
            },
            "properties": [
              {
                "id": "custom.width",
                "value": 180
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 16
      },
      "id": 10,
      "options": {
        "cellHeight": "sm",
        "footer": {
          "countRows": false,
          "fields": "",
          "reducer": ["sum"],
          "show": false
        },
        "showHeader": true
      },
      "pluginVersion": "10.2.2",
      "targets": [
        {
          "datasource": {
            "type": "victoriametrics-logs-datasource",
            "uid": "${logs_datasource}"
          },
          "expr": "_msg:\"claude_code.api_error\" | fields _time, github.user, working.service, error_message, status_code | sort by (_time desc) | limit 50",
          "refId": "A"
        }
      ],
      "title": "Recent API Errors",
      "type": "table"
    }
  ],
  "refresh": "10s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["claude-code", "operations"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "VictoriaMetrics",
          "value": "VictoriaMetrics"
        },
        "hide": 0,
        "includeAll": false,
        "label": "Metrics Datasource",
        "multi": false,
        "name": "datasource",
        "options": [],
        "query": "prometheus",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      },
      {
        "current": {
          "selected": false,
          "text": "VictoriaLogs",
          "value": "VictoriaLogs"
        },
        "hide": 0,
        "includeAll": false,
        "label": "Logs Datasource",
        "multi": false,
        "name": "logs_datasource",
        "options": [],
        "query": "victoriametrics-logs-datasource",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      },
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "${datasource}"
        },
        "definition": "label_values(github.user)",
        "hide": 0,
        "includeAll": true,
        "label": "GitHub User",
        "multi": false,
        "name": "github_user",
        "options": [],
        "query": {
          "query": "label_values(github.user)",
          "refId": "PrometheusVariableQueryEditor-VariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "${datasource}"
        },
        "definition": "label_values(working.service)",
        "hide": 0,
        "includeAll": true,
        "label": "Service",
        "multi": false,
        "name": "service",
        "options": [],
        "query": {
          "query": "label_values(working.service)",
          "refId": "PrometheusVariableQueryEditor-VariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Claude Code - Operations Monitoring",
  "uid": "operations-monitoring",
  "version": 1,
  "weekStart": ""
}
```

### codebase-analysis.json (codebase-analysis.json)

```json
{
  "overview": {
    "name": "5D Labs Agent Platform",
    "description": "An AI-powered development platform that helps you generate documentation and implement code using Claude agents through simple MCP (Model Context Protocol) tools.",
    "architecture": "Kubernetes-based orchestrator with MCP integration",
    "technologies": [
      "Rust",
      "Kubernetes",
      "Helm",
      "MCP",
      "Docker"
    ],
    "statistics": {
      "rust_crates": 4,
      "total_rs_files": 40,
      "total_lines_of_code": 7687,
      "config_files": 52,
      "components_analyzed": 8
    }
  },
  "components": [
    {
      "name": "orchestrator",
      "path": "orchestrator",
      "component_type": "RustLibrary",
      "source_files": [
        {
          "path": "tools/src/mcp/tools.rs",
          "file_type": "rust",
          "line_count": 143,
          "key_definitions": [
            "4:pub fn get_all_tool_schemas() -> Value {"
          ],
          "content": "use serde_json::{json, Value};\n\n/// Get all tool schemas with descriptions and parameter definitions\npub fn get_all_tool_schemas() -> Value {\n    json!({\n        \"tools\": [\n            get_init_docs_schema(),\n            get_submit_implementation_task_schema()\n        ]\n    })\n}\n\nfn get_init_docs_schema() -> Value {\n    json!({\n        \"name\": \"docs\",\n        \"description\": \"Initialize documentation for Task Master tasks using Claude\",\n        \"inputSchema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"working_directory\": {\n                    \"type\": \"string\",\n                    \"description\": \"Working directory containing .taskmaster folder (required). Use relative paths like '_projects/simple-api'.\"\n                },\n                \"model\": {\n                    \"type\": \"string\",\n                    \"description\": \"Claude model to use (default: 'claude-opus-4-20250514')\",\n                    \"default\": \"claude-opus-4-20250514\"\n                },\n                \"github_user\": {\n                    \"type\": \"string\",\n                    \"description\": \"GitHub username for authentication (optional if FDL_DEFAULT_DOCS_USER environment variable is set, which takes precedence)\"\n                }\n            },\n            \"required\": [\"working_directory\"]\n        }\n    })\n}\n\nfn get_submit_implementation_task_schema() -> Value {\n    json!({\n        \"name\": \"task\",\n        \"description\": \"Submit a Task Master task for implementation using Claude with persistent workspace\",\n        \"inputSchema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"task_id\": {\n                    \"type\": \"integer\",\n                    \"description\": \"REQUIRED: Task ID to implement from tasks.json\",\n                    \"minimum\": 1\n                },\n                \"service\": {\n                    \"type\": \"string\",\n                    \"description\": \"REQUIRED: Target service name (creates workspace-{service} PVC)\",\n                    \"pattern\": \"^[a-z0-9-]+$\"\n                },\n                \"working_directory\": {\n                    \"type\": \"string\",\n                    \"description\": \"Working directory within target repository (required)\"\n                },\n                \"model\": {\n                    \"type\": \"string\",\n                    \"description\": \"Claude model to use (default: 'claude-sonnet-4-20250514')\",\n                    \"default\": \"claude-sonnet-4-20250514\"\n                },\n                \"docs_repository_url\": {\n                    \"type\": \"string\",\n                    \"description\": \"Documentation repository URL (where Task Master definitions come from)\"\n                },\n                \"docs_project_directory\": {\n                    \"type\": \"string\",\n                    \"description\": \"Project directory within docs repository (e.g. '_projects/simple-api')\"\n                },\n                \"github_user\": {\n                    \"type\": \"string\",\n                    \"description\": \"GitHub username for authentication (optional if FDL_DEFAULT_CODE_USER environment variable is set, which takes precedence)\"\n                },\n                \"local_tools\": {\n                    \"type\": \"string\",\n                    \"description\": \"Comma-separated list of local MCP tools/servers to enable (e.g., 'mcp-server-git,taskmaster')\"\n                },\n                \"remote_tools\": {\n                    \"type\": \"string\",\n                    \"description\": \"Comma-separated list of remote MCP tools/servers to enable (e.g., 'api-docs-tool')\"\n                },\n                \"context_version\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Context version for retry attempts (incremented on each retry, default: 1)\",\n                    \"minimum\": 1,\n                    \"default\": 1\n                },\n                \"prompt_modification\": {\n                    \"type\": \"string\",\n                    \"description\": \"Additional context for retry attempts\"\n                },\n                \"docs_branch\": {\n                    \"type\": \"string\",\n                    \"description\": \"Docs branch to use (e.g., 'main', 'feature/branch', default: 'main')\",\n                    \"default\": \"main\"\n                },\n                \"continue_session\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether to continue a previous session (auto-continue on retries or user-requested, default: false)\",\n                    \"default\": false\n                },\n                \"overwrite_memory\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether to overwrite memory before starting (default: false)\",\n                    \"default\": false\n                },\n                \"env\": {\n                    \"type\": \"object\",\n                    \"description\": \"Environment variables to set in the container (key-value pairs)\",\n                    \"additionalProperties\": {\n                        \"type\": \"string\"\n                    }\n                },\n                \"env_from_secrets\": {\n                    \"type\": \"array\",\n                    \"description\": \"Environment variables from secrets\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"name\": {\n                                \"type\": \"string\",\n                                \"description\": \"Name of the environment variable\"\n                            },\n                            \"secretName\": {\n                                \"type\": \"string\",\n                                \"description\": \"Name of the secret\"\n                            },\n                            \"secretKey\": {\n                                \"type\": \"string\",\n                                \"description\": \"Key within the secret\"\n                            }\n                        },\n                        \"required\": [\"name\", \"secretName\", \"secretKey\"]\n                    }\n                }\n            },\n            \"required\": [\"task_id\", \"service\", \"working_directory\"]\n        }\n    })\n}\n"
        },
        {
          "path": "tools/src/mcp/main.rs",
          "file_type": "rust",
          "line_count": 548,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - MCP Tools for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\nuse anyhow::{anyhow, Context, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{json, Value};\nuse std::collections::HashMap;\nuse std::process::{Command, Stdio};\nuse tokio::io::{AsyncBufReadExt, AsyncWriteExt, BufReader};\nuse tokio::runtime::Runtime;\n\nmod tools;\n\n// Custom error type for production-ready error handling.\n#[derive(Debug, Serialize)]\nstruct RpcError {\n    code: i32,\n    message: String,\n    data: Option<Value>,\n}\n\n// JSON-RPC Success Response structure.\n#[derive(Serialize)]\nstruct RpcSuccessResponse {\n    jsonrpc: String,\n    result: Value,\n    id: Option<Value>,\n}\n\n// JSON-RPC Error Response structure.\n#[derive(Serialize)]\nstruct RpcErrorResponse {\n    jsonrpc: String,\n    error: RpcError,\n    id: Option<Value>,\n}\n\n// JSON-RPC Request structure.\n#[derive(Deserialize)]\nstruct RpcRequest {\n    #[allow(dead_code)]\n    jsonrpc: String,\n    method: String,\n    params: Option<Value>,\n    id: Option<Value>,\n}\n\n/// Run the orchestrator CLI command\nfn run_orchestrator_cli(args: &[&str]) -> Result<String> {\n    // Use the local build in the same directory as this MCP binary\n    let mut cmd = Command::new(\"fdl\");\n    cmd.args(args);\n    cmd.stderr(Stdio::piped());\n    let output = cmd.output().context(\"Failed to execute orchestrator-cli\")?;\n    if !output.status.success() {\n        let err = String::from_utf8_lossy(&output.stderr).to_string();\n        return Err(anyhow!(\"orchestrator-cli failed: {}\", err));\n    }\n    Ok(String::from_utf8_lossy(&output.stdout).to_string())\n}\n\n// Capabilities advertised by the server with full MCP tool schemas.\nfn get_capabilities() -> Value {\n    tools::get_all_tool_schemas()\n}\n\n// Extract parameters from JSON value into HashMap\nfn extract_params(params: Option<&Value>) -> HashMap<String, Value> {\n    params\n        .and_then(|p| {\n            p.as_object()\n                .map(|o| o.iter().map(|(k, v)| (k.clone(), v.clone())).collect())\n        })\n        .unwrap_or_default()\n}\n\n// Handle MCP protocol methods\nfn handle_mcp_protocol_methods(\n    method: &str,\n    params_map: &HashMap<String, Value>,\n) -> Option<Result<Value>> {\n    match method {\n        \"initialize\" => {\n            // MCP initialization - validate required fields and return proper server capabilities\n            let _protocol_version = params_map\n                .get(\"protocolVersion\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"2025-06-18\");\n\n            // Validate that required fields are present (as per MCP schema)\n            if params_map.get(\"capabilities\").is_none()\n                || params_map.get(\"clientInfo\").is_none()\n                || params_map.get(\"protocolVersion\").is_none()\n            {\n                return Some(Err(anyhow!(\"Missing required initialize parameters: capabilities, clientInfo, and protocolVersion are required\")));\n            }\n\n            Some(Ok(json!({\n                \"protocolVersion\": \"2025-06-18\",\n                \"capabilities\": {\n                    \"tools\": {\n                        \"listChanged\": true\n                    }\n                },\n                \"serverInfo\": {\n                    \"name\": \"orchestrator-mcp\",\n                    \"title\": \"Orchestrator MCP Server\",\n                    \"version\": \"1.0.0\"\n                }\n            })))\n        }\n        \"notifications/initialized\" => {\n            // MCP initialized notification - no response should be sent\n            None\n        }\n        method if method.starts_with(\"notifications/\") => {\n            // Debug: catch any notifications we might be missing\n            None\n        }\n\n        \"tools/list\" => {\n            // Return list of available tools with schemas\n            let capabilities = get_capabilities();\n            // Debug output removed to satisfy clippy\n            Some(Ok(capabilities))\n        }\n        _ => None,\n    }\n}\n\n// Handle orchestrator tool methods\nfn handle_orchestrator_tools(\n    method: &str,\n    params_map: &HashMap<String, Value>,\n) -> Option<Result<Value>> {\n    match method {\n        \"docs\" => {\n            // Initialize documentation for Task Master tasks\n            // Debug output removed to satisfy clippy\n\n            // Extract required working directory parameter\n            let working_directory =\n                match params_map.get(\"working_directory\").and_then(|v| v.as_str()) {\n                    Some(wd) => wd,\n                    None => return Some(Err(anyhow!(\"working_directory parameter is required\"))),\n                };\n\n            // Extract model with default\n            let model = params_map\n                .get(\"model\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"claude-opus-4-20250514\");\n\n            // Get GitHub user from environment variable (takes precedence) or parameter\n            let env_user = std::env::var(\"FDL_DEFAULT_DOCS_USER\").ok();\n            let github_user = match env_user\n                .as_deref()\n                .or_else(|| params_map.get(\"github_user\").and_then(|v| v.as_str()))\n            {\n                Some(user) => user,\n                None => return Some(Err(anyhow!(\"github_user parameter is required or FDL_DEFAULT_DOCS_USER environment variable must be set\"))),\n            };\n\n            // Validate model parameter - allow any model that starts with \"claude-\"\n            if !model.starts_with(\"claude-\") {\n                return Some(Err(anyhow!(\"Invalid model '{}'. Must be a valid Claude model name (e.g., 'claude-opus-4-20250514')\", model)));\n            }\n\n            // Build CLI arguments\n            let mut args = vec![\"task\", \"docs\"];\n\n            // Add required parameters\n            args.extend(&[\"--model\", model]);\n            args.extend(&[\"--working-directory\", working_directory]);\n            args.extend(&[\"--github-user\", github_user]);\n\n            // Debug output removed to satisfy clippy\n\n            // Execute the CLI command\n            match run_orchestrator_cli(&args) {\n                Ok(output) => Some(Ok(json!({\n                    \"success\": true,\n                    \"message\": \"Documentation generation initiated successfully\",\n                    \"output\": output,\n                    \"parameters_used\": {\n                        \"model\": model,\n                        \"working_directory\": working_directory,\n                        \"github_user\": github_user\n                    }\n                }))),\n                Err(e) => Some(Err(anyhow!(\"Failed to execute docs command: {}\", e))),\n            }\n        }\n        \"task\" => {\n            // Submit a Task Master task for implementation\n            // Debug output removed to satisfy clippy\n\n            // Extract required parameters\n            let task_id = match params_map\n                .get(\"task_id\")\n                .and_then(serde_json::Value::as_u64)\n            {\n                Some(id) => id,\n                None => return Some(Err(anyhow!(\"Missing required parameter: task_id\"))),\n            };\n\n            let service = match params_map.get(\"service\").and_then(|v| v.as_str()) {\n                Some(s) => s,\n                None => return Some(Err(anyhow!(\"Missing required parameter: service\"))),\n            };\n\n            // Extract optional parameters with defaults\n            let docs_repository_url = params_map\n                .get(\"docs_repository_url\")\n                .and_then(|v| v.as_str());\n\n            let docs_project_directory = params_map\n                .get(\"docs_project_directory\")\n                .and_then(|v| v.as_str());\n\n            let working_directory = params_map.get(\"working_directory\").and_then(|v| v.as_str());\n\n            // Extract parameters with task-specific default\n            let model = params_map\n                .get(\"model\")\n                .and_then(|v| v.as_str())\n                .filter(|s| !s.is_empty());\n\n            let model = match model {\n                Some(m) => m,\n                None => return Some(Err(anyhow!(\"Model parameter is required. Please specify a model like 'claude-opus-4-20250514' or 'claude-sonnet-4-20250514'\"))),\n            };\n\n            let github_user = params_map.get(\"github_user\").and_then(|v| v.as_str());\n\n            // Get GitHub user from environment variable (takes precedence) or parameter\n            let env_code_user = std::env::var(\"FDL_DEFAULT_CODE_USER\").ok();\n            let github_user = env_code_user.as_deref().or(github_user);\n\n            let local_tools = params_map.get(\"local_tools\").and_then(|v| v.as_str());\n\n            let remote_tools = params_map.get(\"remote_tools\").and_then(|v| v.as_str());\n\n            let context_version = params_map\n                .get(\"context_version\")\n                .and_then(serde_json::Value::as_u64)\n                .and_then(|v| u32::try_from(v).ok())\n                .unwrap_or(1);\n\n            let prompt_modification = params_map\n                .get(\"prompt_modification\")\n                .and_then(|v| v.as_str());\n\n            let docs_branch = params_map\n                .get(\"docs_branch\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"main\");\n\n            let continue_session = params_map\n                .get(\"continue_session\")\n                .and_then(serde_json::Value::as_bool)\n                .unwrap_or(false);\n\n            let overwrite_memory = params_map\n                .get(\"overwrite_memory\")\n                .and_then(serde_json::Value::as_bool)\n                .unwrap_or(false);\n\n            let env = params_map.get(\"env\").and_then(|v| v.as_object());\n\n            let env_from_secrets = params_map\n                .get(\"env_from_secrets\")\n                .and_then(|v| v.as_array());\n\n            // Validate model parameter - allow any model that starts with \"claude-\"\n            if !model.starts_with(\"claude-\") {\n                return Some(Err(anyhow!(\"Invalid model '{}'. Must be a valid Claude model name (e.g., 'claude-sonnet-4-20250514')\", model)));\n            }\n\n            // Validate service name (must be valid for PVC naming)\n            if !service\n                .chars()\n                .all(|c| c.is_ascii_lowercase() || c.is_ascii_digit() || c == '-')\n            {\n                return Some(Err(anyhow!(\"Invalid service name '{}'. Must contain only lowercase letters, numbers, and hyphens\", service)));\n            }\n\n            // Build CLI arguments using the new CLI interface\n            let mut args = vec![\"task\", \"code\"];\n\n            // Add required parameters (task_id is positional, not a flag)\n            let task_id_str = task_id.to_string();\n            args.push(&task_id_str);\n            args.extend(&[\"--service\", service]);\n\n            // Add model parameter\n            args.extend(&[\"--model\", model]);\n\n            // Add docs repository URL if specified\n            if let Some(docs_repo) = docs_repository_url {\n                args.extend(&[\"--docs-repository-url\", docs_repo]);\n            }\n\n            // Add docs project directory if specified\n            if let Some(docs_proj_dir) = docs_project_directory {\n                args.extend(&[\"--docs-project-directory\", docs_proj_dir]);\n            }\n\n            // Add working directory if specified\n            if let Some(wd) = working_directory {\n                args.extend(&[\"--working-directory\", wd]);\n            }\n\n            // Add GitHub user if specified\n            if let Some(user) = github_user {\n                args.extend(&[\"--github-user\", user]);\n            }\n\n            // Add tool configuration parameters\n            if let Some(local) = local_tools {\n                args.extend(&[\"--local-tools\", local]);\n            }\n\n            if let Some(remote) = remote_tools {\n                args.extend(&[\"--remote-tools\", remote]);\n            }\n\n            // Add context version\n            let context_version_str = context_version.to_string();\n            args.extend(&[\"--context-version\", &context_version_str]);\n\n            // Add prompt modification if specified\n            if let Some(prompt_mod) = prompt_modification {\n                args.extend(&[\"--prompt-modification\", prompt_mod]);\n            }\n\n            // Add docs branch\n            args.extend(&[\"--docs-branch\", docs_branch]);\n\n            // Add session flags\n            if continue_session {\n                args.push(\"--continue-session\");\n            }\n\n            if overwrite_memory {\n                args.push(\"--overwrite-memory\");\n            }\n\n            // Prepare environment variables string if specified\n            #[allow(unused_assignments)]\n            let mut env_string = String::new();\n            if let Some(env_obj) = env {\n                let mut env_pairs = Vec::new();\n                for (key, value) in env_obj {\n                    if let Some(val_str) = value.as_str() {\n                        env_pairs.push(format!(\"{key}={val_str}\"));\n                    }\n                }\n                if !env_pairs.is_empty() {\n                    env_string = env_pairs.join(\",\");\n                    args.extend(&[\"--env\", &env_string]);\n                }\n            }\n\n            // Prepare environment variables from secrets string if specified\n            #[allow(unused_assignments)]\n            let mut secrets_string = String::new();\n            if let Some(env_secrets_arr) = env_from_secrets {\n                let mut secret_specs = Vec::new();\n                for secret in env_secrets_arr {\n                    if let Some(secret_obj) = secret.as_object() {\n                        if let (Some(name), Some(secret_name), Some(secret_key)) = (\n                            secret_obj.get(\"name\").and_then(|v| v.as_str()),\n                            secret_obj.get(\"secretName\").and_then(|v| v.as_str()),\n                            secret_obj.get(\"secretKey\").and_then(|v| v.as_str()),\n                        ) {\n                            secret_specs.push(format!(\"{name}:{secret_name}:{secret_key}\"));\n                        }\n                    }\n                }\n                if !secret_specs.is_empty() {\n                    secrets_string = secret_specs.join(\",\");\n                    args.extend(&[\"--env-from-secrets\", &secrets_string]);\n                }\n            }\n\n            // Debug output removed to satisfy clippy\n\n            // Execute the CLI command\n            match run_orchestrator_cli(&args) {\n                Ok(output) => Some(Ok(json!({\n                    \"success\": true,\n                    \"message\": \"Implementation task submitted successfully\",\n                    \"output\": output,\n                    \"parameters_used\": {\n                        \"task_id\": task_id,\n                        \"service\": service,\n                        \"docs_repository_url\": docs_repository_url,\n                        \"docs_project_directory\": docs_project_directory,\n                        \"working_directory\": working_directory,\n                        \"model\": model,\n                        \"github_user\": github_user,\n                        \"local_tools\": local_tools,\n                        \"remote_tools\": remote_tools,\n                        \"context_version\": context_version,\n                        \"prompt_modification\": prompt_modification,\n                        \"docs_branch\": docs_branch,\n                        \"continue_session\": continue_session,\n                        \"overwrite_memory\": overwrite_memory,\n                        \"env\": env,\n                        \"env_from_secrets\": env_from_secrets\n                    }\n                }))),\n                Err(e) => Some(Err(anyhow!(\"Failed to execute submit task: {}\", e))),\n            }\n        }\n        _ => None,\n    }\n}\n\n// Handle tool invocation\nfn handle_tool_invocation(params_map: &HashMap<String, Value>) -> Result<Value> {\n    let name = params_map\n        .get(\"name\")\n        .and_then(|v| v.as_str())\n        .ok_or(anyhow!(\"Missing tool name\"))?;\n    let default_args = json!({});\n    let arguments = params_map.get(\"arguments\").unwrap_or(&default_args);\n\n    // Extract arguments as a map for the tool handlers\n    let args_map = extract_params(Some(arguments));\n\n    // Try orchestrator tools\n    if let Some(result) = handle_orchestrator_tools(name, &args_map) {\n        match result {\n            Ok(content) => Ok(json!({\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": serde_json::to_string_pretty(&content).unwrap_or_else(|_| content.to_string())\n                    }\n                ]\n            })),\n            Err(e) => Err(e),\n        }\n    } else {\n        Err(anyhow!(\"Unknown tool: {}\", name))\n    }\n}\n\n// Handle core MCP methods (including tool calls)\nfn handle_core_methods(method: &str, params_map: &HashMap<String, Value>) -> Option<Result<Value>> {\n    match method {\n        \"tools/call\" => Some(handle_tool_invocation(params_map)),\n        _ => None,\n    }\n}\n\n// Handler for each method (following MCP specification).\nfn handle_method(method: &str, params: Option<&Value>) -> Option<Result<Value>> {\n    let params_map = extract_params(params);\n\n    // Try MCP protocol methods FIRST (ping, initialize, tools/list, etc.)\n    if let Some(result) = handle_mcp_protocol_methods(method, &params_map) {\n        return Some(result); // Found a matching MCP method\n    }\n\n    // Special handling for notifications that should return None\n    if method.starts_with(\"notifications/\") {\n        return None; // Notifications should not have responses\n    }\n\n    // Try core methods (tools/call)\n    if let Some(result) = handle_core_methods(method, &params_map) {\n        return Some(result);\n    }\n\n    // Try orchestrator tools directly (for debugging)\n    if let Some(result) = handle_orchestrator_tools(method, &params_map) {\n        return Some(result);\n    }\n\n    Some(Err(anyhow!(\"Unknown method: {}\", method)))\n}\n\n// Main async RPC loop over stdio (from MCP specification).\nasync fn rpc_loop() -> Result<()> {\n    let stdin = tokio::io::stdin();\n    let reader = BufReader::new(stdin);\n    let mut lines = reader.lines();\n    let mut stdout = tokio::io::stdout();\n\n    while let Some(line) = lines.next_line().await? {\n        let request: RpcRequest = serde_json::from_str(&line).context(\"Invalid JSON request\")?;\n\n        let result = handle_method(&request.method, request.params.as_ref());\n        if let Some(method_result) = result {\n            let resp_json = match method_result {\n                Ok(res) => {\n                    let response = RpcSuccessResponse {\n                        jsonrpc: \"2.0\".to_string(),\n                        result: res,\n                        id: request.id,\n                    };\n                    serde_json::to_string(&response)?\n                }\n                Err(err) => {\n                    let response = RpcErrorResponse {\n                        jsonrpc: \"2.0\".to_string(),\n                        error: RpcError {\n                            code: -32600,\n                            message: err.to_string(),\n                            data: None,\n                        },\n                        id: request.id,\n                    };\n                    serde_json::to_string(&response)?\n                }\n            };\n            stdout.write_all((resp_json + \"\\n\").as_bytes()).await?;\n            stdout.flush().await?;\n        }\n        // If result is None, it's a notification - no response should be sent\n    }\n    Ok(())\n}\n\nfn main() -> Result<()> {\n    let rt = Runtime::new()?;\n    rt.block_on(rpc_loop())?;\n\n    Ok(())\n}\n"
        },
        {
          "path": "tools/src/cli/analyzer.rs",
          "file_type": "rust",
          "line_count": 810,
          "key_definitions": [
            "8:pub struct CodebaseAnalysis {",
            "16:pub struct ProjectOverview {",
            "25:pub struct ProjectStatistics {",
            "34:pub struct Component {",
            "45:pub enum ComponentType {",
            "55:pub struct SourceFile {",
            "64:pub struct ApiDefinition {",
            "72:pub struct ApiEndpoint {",
            "80:pub struct DataModel {",
            "88:pub struct ConfigFile {",
            "95:pub struct CodebaseAnalyzer {",
            "100:impl CodebaseAnalyzer {",
            "101:pub fn new(workspace_root: PathBuf, include_source: bool) -> Self {",
            "108:pub fn analyze(&self) -> Result<CodebaseAnalysis> {",
            "614:pub fn generate_modular_markdown(&self, analysis: &CodebaseAnalysis, output_dir: &str) -> Result<()> {",
            "779:pub fn generate_single_markdown(&self, analysis: &CodebaseAnalysis) -> Result<String> {"
          ],
          "content": "use anyhow::Result;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::fs;\nuse std::path::{Path, PathBuf};\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct CodebaseAnalysis {\n    pub overview: ProjectOverview,\n    pub components: Vec<Component>,\n    pub apis: Vec<ApiDefinition>,\n    pub configurations: Vec<ConfigFile>,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ProjectOverview {\n    pub name: String,\n    pub description: String,\n    pub architecture: String,\n    pub technologies: Vec<String>,\n    pub statistics: ProjectStatistics,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ProjectStatistics {\n    pub rust_crates: usize,\n    pub total_rs_files: usize,\n    pub total_lines_of_code: usize,\n    pub config_files: usize,\n    pub components_analyzed: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct Component {\n    pub name: String,\n    pub path: String,\n    pub component_type: ComponentType,\n    pub source_files: Vec<SourceFile>,\n    pub dependencies: Vec<String>,\n    pub description: String,\n    pub line_count: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub enum ComponentType {\n    RustBinary,\n    RustLibrary,\n    HelmChart,\n    KubernetesConfig,\n    Documentation,\n    Scripts,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct SourceFile {\n    pub path: String,\n    pub file_type: String,\n    pub line_count: usize,\n    pub key_definitions: Vec<String>,\n    pub content: Option<String>, // Only included if include_source is true\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ApiDefinition {\n    pub name: String,\n    pub file_path: String,\n    pub endpoints: Vec<ApiEndpoint>,\n    pub data_models: Vec<DataModel>,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ApiEndpoint {\n    pub method: String,\n    pub path: String,\n    pub handler: String,\n    pub line_number: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct DataModel {\n    pub name: String,\n    pub model_type: String,\n    pub fields: Vec<String>,\n    pub file_path: String,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ConfigFile {\n    pub name: String,\n    pub path: String,\n    pub config_type: String,\n    pub content: Option<String>,\n}\n\npub struct CodebaseAnalyzer {\n    workspace_root: PathBuf,\n    include_source: bool,\n}\n\nimpl CodebaseAnalyzer {\n    pub fn new(workspace_root: PathBuf, include_source: bool) -> Self {\n        Self {\n            workspace_root,\n            include_source,\n        }\n    }\n\n        pub fn analyze(&self) -> Result<CodebaseAnalysis> {\n        println!(\"🔍 Analyzing codebase at: {}\", self.workspace_root.display());\n\n        let mut overview = self.analyze_project_overview()?;\n        let components = self.analyze_components()?;\n        let apis = self.analyze_apis()?;\n        let configurations = self.analyze_configurations()?;\n\n        // Update the components analyzed count\n        overview.statistics.components_analyzed = components.len();\n\n        Ok(CodebaseAnalysis {\n            overview,\n            components,\n            apis,\n            configurations,\n        })\n    }\n\n    fn analyze_project_overview(&self) -> Result<ProjectOverview> {\n        println!(\"📋 Analyzing project overview...\");\n\n        let readme_path = self.workspace_root.join(\"README.md\");\n        let mut description = String::new();\n        let mut name = \"Unknown Project\".to_string();\n\n        if readme_path.exists() {\n            let content = fs::read_to_string(&readme_path)?;\n            if let Some(first_line) = content.lines().find(|line| !line.starts_with('#') && !line.trim().is_empty()) {\n                description = first_line.to_string();\n            }\n            if let Some(header) = content.lines().find(|line| line.starts_with(\"# \")) {\n                name = header.trim_start_matches(\"# \").to_string();\n            }\n        }\n\n        // Calculate statistics\n        let rust_crates = self.count_cargo_files()?;\n        let (total_rs_files, total_lines_of_code) = self.count_rust_files()?;\n        let config_files = self.count_config_files()?;\n\n        Ok(ProjectOverview {\n            name,\n            description,\n            architecture: \"Kubernetes-based orchestrator with MCP integration\".to_string(),\n            technologies: vec![\n                \"Rust\".to_string(),\n                \"Kubernetes\".to_string(),\n                \"Helm\".to_string(),\n                \"MCP\".to_string(),\n                \"Docker\".to_string(),\n            ],\n            statistics: ProjectStatistics {\n                rust_crates,\n                total_rs_files,\n                total_lines_of_code,\n                config_files,\n                components_analyzed: 0, // Will be set correctly in analyze()\n            },\n        })\n    }\n\n    fn analyze_components(&self) -> Result<Vec<Component>> {\n        println!(\"🔧 Analyzing components...\");\n\n        let mut components = Vec::new();\n\n        // Analyze Rust components\n        self.analyze_rust_components(&mut components)?;\n\n        // Analyze infrastructure components\n        self.analyze_infra_components(&mut components)?;\n\n        println!(\"✅ Found {} components\", components.len());\n        Ok(components)\n    }\n\n    fn analyze_rust_components(&self, components: &mut Vec<Component>) -> Result<()> {\n        let cargo_files = self.find_files_by_name(\"Cargo.toml\")?;\n\n        for cargo_path in cargo_files {\n            if cargo_path.to_string_lossy().contains(\"target/\") {\n                continue;\n            }\n\n            let component_dir = cargo_path.parent().unwrap();\n            let rel_path = component_dir.strip_prefix(&self.workspace_root)\n                .unwrap_or(component_dir)\n                .to_string_lossy()\n                .to_string();\n\n            let cargo_content = fs::read_to_string(&cargo_path)?;\n            let component_name = self.extract_cargo_name(&cargo_content)\n                .unwrap_or_else(|| component_dir.file_name().unwrap().to_string_lossy().to_string());\n\n            let component_type = if component_dir.join(\"src/main.rs\").exists() {\n                ComponentType::RustBinary\n            } else {\n                ComponentType::RustLibrary\n            };\n\n            let source_files = self.analyze_rust_source_files(component_dir)?;\n            let dependencies = self.extract_dependencies(&cargo_content);\n            let line_count = source_files.iter().map(|f| f.line_count).sum();\n\n            components.push(Component {\n                name: component_name,\n                path: rel_path,\n                component_type,\n                source_files,\n                dependencies,\n                description: self.extract_description(&cargo_content),\n                line_count,\n            });\n        }\n\n        Ok(())\n    }\n\n    fn analyze_rust_source_files(&self, component_dir: &Path) -> Result<Vec<SourceFile>> {\n        let mut source_files = Vec::new();\n\n        self.walk_directory(component_dir, &mut |path| {\n            if path.extension().and_then(|s| s.to_str()) == Some(\"rs\") {\n                if let Ok(content) = fs::read_to_string(path) {\n                    let rel_path = path.strip_prefix(component_dir)\n                        .unwrap_or(path)\n                        .to_string_lossy()\n                        .to_string();\n\n                    let line_count = content.lines().count();\n                    let key_definitions = self.extract_key_definitions(&content);\n\n                    source_files.push(SourceFile {\n                        path: rel_path,\n                        file_type: \"rust\".to_string(),\n                        line_count,\n                        key_definitions,\n                        content: if self.include_source { Some(content) } else { None },\n                    });\n                }\n            }\n        })?;\n\n        Ok(source_files)\n    }\n\n    fn analyze_infra_components(&self, components: &mut Vec<Component>) -> Result<()> {\n        let infra_components = vec![\n            (\"helm-charts\", \"infra/charts\", ComponentType::HelmChart),\n            (\"kubernetes-config\", \"infra/cluster-config\", ComponentType::KubernetesConfig),\n            (\"scripts\", \"infra/scripts\", ComponentType::Scripts),\n            (\"documentation\", \"docs\", ComponentType::Documentation),\n        ];\n\n        for (name, path, comp_type) in infra_components {\n            let full_path = self.workspace_root.join(path);\n            if full_path.exists() {\n                let source_files = self.analyze_config_files(&full_path)?;\n                let line_count = source_files.iter().map(|f| f.line_count).sum();\n\n                components.push(Component {\n                    name: name.to_string(),\n                    path: path.to_string(),\n                    component_type: comp_type,\n                    source_files,\n                    dependencies: Vec::new(),\n                    description: format!(\"{} configuration and files\", name),\n                    line_count,\n                });\n            }\n        }\n\n        Ok(())\n    }\n\n    fn analyze_config_files(&self, dir: &Path) -> Result<Vec<SourceFile>> {\n        let mut source_files = Vec::new();\n\n        self.walk_directory(dir, &mut |path| {\n            if let Some(ext) = path.extension().and_then(|s| s.to_str()) {\n                if matches!(ext, \"yaml\" | \"yml\" | \"toml\" | \"json\" | \"md\" | \"sh\") {\n                    if let Ok(content) = fs::read_to_string(path) {\n                        let rel_path = path.strip_prefix(dir)\n                            .unwrap_or(path)\n                            .to_string_lossy()\n                            .to_string();\n\n                        let line_count = content.lines().count();\n\n                        source_files.push(SourceFile {\n                            path: rel_path,\n                            file_type: ext.to_string(),\n                            line_count,\n                            key_definitions: Vec::new(),\n                            content: if self.include_source { Some(content) } else { None },\n                        });\n                    }\n                }\n            }\n        })?;\n\n        Ok(source_files)\n    }\n\n        fn analyze_apis(&self) -> Result<Vec<ApiDefinition>> {\n        println!(\"🌐 Analyzing API surface...\");\n\n        let mut apis = Vec::new();\n\n        // Look for route definitions in main.rs files and handler files\n        let mut api_files = Vec::new();\n\n        // Find main.rs files that define routes\n        let main_files = self.find_files_by_name(\"main.rs\")?;\n        for file in main_files {\n            if file.to_string_lossy().contains(\"orchestrator\") && !file.to_string_lossy().contains(\"target\") {\n                api_files.push(file);\n            }\n        }\n\n        // Find handler files\n        let handler_files = self.find_files_in_path(\"handlers\")?;\n        for file in handler_files {\n            if file.extension().and_then(|s| s.to_str()) == Some(\"rs\") {\n                api_files.push(file);\n            }\n        }\n\n        for file in api_files {\n            let content = fs::read_to_string(&file)?;\n            let endpoints = self.extract_api_endpoints(&content);\n\n            if !endpoints.is_empty() {\n                let file_name = if file.file_name().unwrap().to_string_lossy() == \"main.rs\" {\n                    \"routes\".to_string()\n                } else {\n                    file.file_stem().unwrap().to_string_lossy().to_string()\n                };\n\n                apis.push(ApiDefinition {\n                    name: file_name,\n                    file_path: file.strip_prefix(&self.workspace_root)\n                        .unwrap_or(&file)\n                        .to_string_lossy()\n                        .to_string(),\n                    endpoints,\n                    data_models: Vec::new(), // Could be enhanced\n                });\n            }\n        }\n\n        Ok(apis)\n    }\n\n    fn analyze_configurations(&self) -> Result<Vec<ConfigFile>> {\n        println!(\"⚙️  Analyzing configurations...\");\n\n        let mut configs = Vec::new();\n\n        let extensions = vec![\"yaml\", \"yml\", \"toml\", \"json\"];\n        for ext in extensions {\n            let files = self.find_files_by_extension(ext)?;\n            for file in files {\n                let rel_path = file.strip_prefix(&self.workspace_root)\n                    .unwrap_or(&file)\n                    .to_string_lossy()\n                    .to_string();\n\n                if rel_path.contains(\"target/\") || rel_path.contains(\".git/\") {\n                    continue;\n                }\n\n                let content = if self.include_source {\n                    fs::read_to_string(&file).ok()\n                } else {\n                    None\n                };\n\n                configs.push(ConfigFile {\n                    name: file.file_name().unwrap().to_string_lossy().to_string(),\n                    path: rel_path,\n                    config_type: ext.to_string(),\n                    content,\n                });\n            }\n        }\n\n        Ok(configs)\n    }\n\n    // Helper methods\n    fn count_cargo_files(&self) -> Result<usize> {\n        Ok(self.find_files_by_name(\"Cargo.toml\")?\n            .into_iter()\n            .filter(|p| !p.to_string_lossy().contains(\"target/\"))\n            .count())\n    }\n\n    fn count_rust_files(&self) -> Result<(usize, usize)> {\n        let rust_files = self.find_files_by_extension(\"rs\")?;\n        let file_count = rust_files.len();\n        let mut total_lines = 0;\n\n        for file in rust_files {\n            if let Ok(content) = fs::read_to_string(&file) {\n                total_lines += content.lines().count();\n            }\n        }\n\n        Ok((file_count, total_lines))\n    }\n\n    fn count_config_files(&self) -> Result<usize> {\n        let mut count = 0;\n        for ext in &[\"yaml\", \"yml\", \"toml\", \"json\"] {\n            count += self.find_files_by_extension(ext)?.len();\n        }\n        Ok(count)\n    }\n\n    fn find_files_by_name(&self, name: &str) -> Result<Vec<PathBuf>> {\n        let mut files = Vec::new();\n        self.walk_directory(&self.workspace_root, &mut |path| {\n            if path.file_name().and_then(|s| s.to_str()) == Some(name) {\n                files.push(path.to_path_buf());\n            }\n        })?;\n        Ok(files)\n    }\n\n    fn find_files_by_extension(&self, ext: &str) -> Result<Vec<PathBuf>> {\n        let mut files = Vec::new();\n        self.walk_directory(&self.workspace_root, &mut |path| {\n            if path.extension().and_then(|s| s.to_str()) == Some(ext) {\n                files.push(path.to_path_buf());\n            }\n        })?;\n        Ok(files)\n    }\n\n    fn find_files_in_path(&self, subpath: &str) -> Result<Vec<PathBuf>> {\n        let mut files = Vec::new();\n        self.walk_directory(&self.workspace_root, &mut |path| {\n            if path.to_string_lossy().contains(subpath) && path.is_file() {\n                files.push(path.to_path_buf());\n            }\n        })?;\n        Ok(files)\n    }\n\n    fn walk_directory<F>(&self, dir: &Path, callback: &mut F) -> Result<()>\n    where\n        F: FnMut(&Path),\n    {\n        if dir.is_dir() {\n            for entry in fs::read_dir(dir)? {\n                let entry = entry?;\n                let path = entry.path();\n\n                if let Some(name) = path.file_name().and_then(|s| s.to_str()) {\n                    if name == \"target\" || name == \".git\" || name.starts_with('.') {\n                        continue;\n                    }\n                }\n\n                callback(&path);\n\n                if path.is_dir() {\n                    self.walk_directory(&path, callback)?;\n                }\n            }\n        }\n        Ok(())\n    }\n\n    fn extract_cargo_name(&self, content: &str) -> Option<String> {\n        for line in content.lines() {\n            if line.starts_with(\"name =\") {\n                return line.split('=').nth(1)\n                    .map(|s| s.trim().trim_matches('\"').to_string());\n            }\n        }\n        None\n    }\n\n    fn extract_dependencies(&self, content: &str) -> Vec<String> {\n        let mut deps = Vec::new();\n        let mut in_deps_section = false;\n\n        for line in content.lines() {\n            if line.starts_with(\"[dependencies]\") {\n                in_deps_section = true;\n                continue;\n            }\n            if line.starts_with('[') && in_deps_section {\n                break;\n            }\n            if in_deps_section && line.contains('=') && !line.starts_with('#') {\n                if let Some(dep_name) = line.split('=').next() {\n                    deps.push(dep_name.trim().to_string());\n                }\n            }\n        }\n\n        deps\n    }\n\n    fn extract_description(&self, content: &str) -> String {\n        for line in content.lines() {\n            if line.starts_with(\"description =\") {\n                return line.split('=').nth(1)\n                    .unwrap_or(\"\")\n                    .trim()\n                    .trim_matches('\"')\n                    .to_string();\n            }\n        }\n        \"No description available\".to_string()\n    }\n\n    fn extract_key_definitions(&self, content: &str) -> Vec<String> {\n        let mut definitions = Vec::new();\n\n        for (line_num, line) in content.lines().enumerate() {\n            if line.trim().starts_with(\"pub struct\")\n                || line.trim().starts_with(\"pub enum\")\n                || line.trim().starts_with(\"pub fn\")\n                || line.trim().starts_with(\"impl \")\n                || line.trim().starts_with(\"pub trait\") {\n                definitions.push(format!(\"{}:{}\", line_num + 1, line.trim()));\n            }\n        }\n\n        definitions\n    }\n\n        fn extract_api_endpoints(&self, content: &str) -> Vec<ApiEndpoint> {\n        let mut endpoints = Vec::new();\n\n        for (line_num, line) in content.lines().enumerate() {\n            let trimmed = line.trim();\n\n            // Look for axum route definitions\n            if trimmed.contains(\".route(\") {\n                // Handle .route(\"/path\", method(handler)) syntax\n                if let Some(path) = self.extract_route_path(trimmed) {\n                    let method = if trimmed.contains(\"post(\") { \"POST\" }\n                    else if trimmed.contains(\"get(\") { \"GET\" }\n                    else if trimmed.contains(\"put(\") { \"PUT\" }\n                    else if trimmed.contains(\"delete(\") { \"DELETE\" }\n                    else { \"ANY\" };\n\n                    endpoints.push(ApiEndpoint {\n                        method: method.to_string(),\n                        path,\n                        handler: trimmed.to_string(),\n                        line_number: line_num + 1,\n                    });\n                }\n            }\n            // Also look for direct method calls like .get(\"/path\", handler)\n            else if trimmed.contains(\".get(\") || trimmed.contains(\".post(\")\n                || trimmed.contains(\".put(\") || trimmed.contains(\".delete(\") {\n                if let Some(method) = self.extract_http_method(trimmed) {\n                    if let Some(path) = self.extract_route_path(trimmed) {\n                        endpoints.push(ApiEndpoint {\n                            method,\n                            path,\n                            handler: trimmed.to_string(),\n                            line_number: line_num + 1,\n                        });\n                    }\n                }\n            }\n        }\n\n        endpoints\n    }\n\n    fn extract_http_method(&self, line: &str) -> Option<String> {\n        if line.contains(\".get(\") { Some(\"GET\".to_string()) }\n        else if line.contains(\".post(\") { Some(\"POST\".to_string()) }\n        else if line.contains(\".put(\") { Some(\"PUT\".to_string()) }\n        else if line.contains(\".delete(\") { Some(\"DELETE\".to_string()) }\n        else { Some(\"ROUTE\".to_string()) }\n    }\n\n    fn extract_route_path(&self, line: &str) -> Option<String> {\n        // Look for quoted strings that look like routes (start with /)\n        let mut start_pos = 0;\n        while let Some(start) = line[start_pos..].find('\"') {\n            let actual_start = start_pos + start;\n            if let Some(end) = line[actual_start + 1..].find('\"') {\n                let path = &line[actual_start + 1..actual_start + 1 + end];\n                if path.starts_with('/') {\n                    return Some(path.to_string());\n                }\n                start_pos = actual_start + 1 + end + 1;\n            } else {\n                break;\n            }\n        }\n        None\n    }\n\n    pub fn generate_modular_markdown(&self, analysis: &CodebaseAnalysis, output_dir: &str) -> Result<()> {\n        println!(\"📝 Generating modular markdown documentation...\");\n\n        let output_path = Path::new(output_dir);\n        fs::create_dir_all(output_path)?;\n\n        // Generate master index\n        self.generate_index_file(analysis, output_path)?;\n\n        // Generate component files\n        for component in &analysis.components {\n            self.generate_component_file(component, output_path)?;\n        }\n\n        // Generate API documentation\n        if !analysis.apis.is_empty() {\n            self.generate_api_file(&analysis.apis, output_path)?;\n        }\n\n        // Generate configuration summary\n        self.generate_config_file(&analysis.configurations, output_path)?;\n\n        println!(\"✅ Modular documentation generated in: {}\", output_dir);\n        Ok(())\n    }\n\n    fn generate_index_file(&self, analysis: &CodebaseAnalysis, output_path: &Path) -> Result<()> {\n        let index_file = output_path.join(\"README.md\");\n        let mut content = String::new();\n\n        content.push_str(&format!(\"# {} - Codebase Analysis\\n\\n\", analysis.overview.name));\n        content.push_str(&format!(\"**Generated:** {}\\n\\n\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\")));\n\n        content.push_str(\"## Overview\\n\\n\");\n        content.push_str(&format!(\"**Description:** {}\\n\\n\", analysis.overview.description));\n        content.push_str(&format!(\"**Architecture:** {}\\n\\n\", analysis.overview.architecture));\n        content.push_str(&format!(\"**Technologies:** {}\\n\\n\", analysis.overview.technologies.join(\", \")));\n\n        content.push_str(\"## Statistics\\n\\n\");\n        let stats = &analysis.overview.statistics;\n        content.push_str(&format!(\"- **Rust Crates:** {}\\n\", stats.rust_crates));\n        content.push_str(&format!(\"- **Rust Files:** {}\\n\", stats.total_rs_files));\n        content.push_str(&format!(\"- **Lines of Code:** {}\\n\", stats.total_lines_of_code));\n        content.push_str(&format!(\"- **Config Files:** {}\\n\", stats.config_files));\n        content.push_str(&format!(\"- **Components:** {}\\n\\n\", analysis.components.len()));\n\n        content.push_str(\"## Components\\n\\n\");\n        for component in &analysis.components {\n            content.push_str(&format!(\"- [{}](./{}.md) - `{}` ({} lines)\\n\",\n                component.name,\n                component.name.replace(' ', \"-\").to_lowercase(),\n                component.path,\n                component.line_count\n            ));\n        }\n\n        if !analysis.apis.is_empty() {\n            content.push_str(\"\\n- [API Surface](./api-surface.md) - REST endpoints and data models\\n\");\n        }\n        content.push_str(\"- [Configurations](./configurations.md) - All configuration files\\n\");\n\n        fs::write(index_file, content)?;\n        Ok(())\n    }\n\n    fn generate_component_file(&self, component: &Component, output_path: &Path) -> Result<()> {\n        let filename = format!(\"{}.md\", component.name.replace(' ', \"-\").to_lowercase());\n        let file_path = output_path.join(filename);\n        let mut content = String::new();\n\n        content.push_str(&format!(\"# {} Analysis\\n\\n\", component.name));\n        content.push_str(&format!(\"**Path:** `{}`\\n\", component.path));\n        content.push_str(&format!(\"**Type:** {:?}\\n\", component.component_type));\n        content.push_str(&format!(\"**Lines of Code:** {}\\n\", component.line_count));\n        content.push_str(&format!(\"**Description:** {}\\n\\n\", component.description));\n\n        if !component.dependencies.is_empty() {\n            content.push_str(\"## Dependencies\\n\\n\");\n            for dep in &component.dependencies {\n                content.push_str(&format!(\"- {}\\n\", dep));\n            }\n            content.push_str(\"\\n\");\n        }\n\n        content.push_str(\"## Source Files\\n\\n\");\n        for source_file in &component.source_files {\n            content.push_str(&format!(\"### {} ({} lines)\\n\\n\", source_file.path, source_file.line_count));\n\n            if !source_file.key_definitions.is_empty() {\n                content.push_str(\"**Key Definitions:**\\n```rust\\n\");\n                for def in &source_file.key_definitions {\n                    content.push_str(&format!(\"{}\\n\", def));\n                }\n                content.push_str(\"```\\n\\n\");\n            }\n\n            if let Some(file_content) = &source_file.content {\n                content.push_str(\"**Full Content:**\\n```\");\n                content.push_str(&source_file.file_type);\n                content.push_str(\"\\n\");\n                content.push_str(file_content);\n                content.push_str(\"\\n```\\n\\n\");\n            }\n        }\n\n        fs::write(file_path, content)?;\n        Ok(())\n    }\n\n    fn generate_api_file(&self, apis: &[ApiDefinition], output_path: &Path) -> Result<()> {\n        let file_path = output_path.join(\"api-surface.md\");\n        let mut content = String::new();\n\n        content.push_str(\"# API Surface Analysis\\n\\n\");\n\n        for api in apis {\n            content.push_str(&format!(\"## {} ({})\\n\\n\", api.name, api.file_path));\n\n            if !api.endpoints.is_empty() {\n                content.push_str(\"### Endpoints\\n\\n\");\n                for endpoint in &api.endpoints {\n                    content.push_str(&format!(\"- **{}** `{}` - Line {}\\n\",\n                        endpoint.method, endpoint.path, endpoint.line_number));\n                    content.push_str(&format!(\"  ```rust\\n  {}\\n  ```\\n\\n\", endpoint.handler));\n                }\n            }\n        }\n\n        fs::write(file_path, content)?;\n        Ok(())\n    }\n\n    fn generate_config_file(&self, configs: &[ConfigFile], output_path: &Path) -> Result<()> {\n        let file_path = output_path.join(\"configurations.md\");\n        let mut content = String::new();\n\n        content.push_str(\"# Configuration Files\\n\\n\");\n\n        let mut configs_by_type: HashMap<String, Vec<&ConfigFile>> = HashMap::new();\n        for config in configs {\n            configs_by_type.entry(config.config_type.clone())\n                .or_insert_with(Vec::new)\n                .push(config);\n        }\n\n        for (config_type, type_configs) in configs_by_type {\n            content.push_str(&format!(\"## {} Files\\n\\n\", config_type.to_uppercase()));\n\n            for config in type_configs {\n                content.push_str(&format!(\"### {} ({})\\n\\n\", config.name, config.path));\n\n                if let Some(file_content) = &config.content {\n                    content.push_str(\"```\");\n                    content.push_str(&config.config_type);\n                    content.push_str(\"\\n\");\n                    content.push_str(file_content);\n                    content.push_str(\"\\n```\\n\\n\");\n                }\n            }\n        }\n\n        fs::write(file_path, content)?;\n        Ok(())\n    }\n\n    pub fn generate_single_markdown(&self, analysis: &CodebaseAnalysis) -> Result<String> {\n        let mut content = String::new();\n\n        content.push_str(&format!(\"# {} - Complete Codebase Analysis\\n\\n\", analysis.overview.name));\n        content.push_str(&format!(\"**Generated:** {}\\n\\n\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\")));\n\n        content.push_str(\"## Project Overview\\n\\n\");\n        content.push_str(&format!(\"**Description:** {}\\n\\n\", analysis.overview.description));\n        content.push_str(&format!(\"**Architecture:** {}\\n\\n\", analysis.overview.architecture));\n        content.push_str(&format!(\"**Technologies:** {}\\n\\n\", analysis.overview.technologies.join(\", \")));\n\n        content.push_str(\"## Components\\n\\n\");\n        for component in &analysis.components {\n            content.push_str(&format!(\"### {} ({})\\n\\n\", component.name, component.path));\n            content.push_str(&format!(\"**Type:** {:?} | **Lines:** {}\\n\\n\", component.component_type, component.line_count));\n            content.push_str(&format!(\"{}\\n\\n\", component.description));\n\n            for source_file in &component.source_files {\n                if let Some(file_content) = &source_file.content {\n                    content.push_str(&format!(\"#### {}\\n\\n\", source_file.path));\n                    content.push_str(\"```\");\n                    content.push_str(&source_file.file_type);\n                    content.push_str(\"\\n\");\n                    content.push_str(file_content);\n                    content.push_str(\"\\n```\\n\\n\");\n                }\n            }\n        }\n\n        Ok(content)\n    }\n}"
        },
        {
          "path": "tools/src/cli/docs_generator.rs",
          "file_type": "rust",
          "line_count": 207,
          "key_definitions": [
            "11:pub struct DocsGenerator;",
            "13:impl DocsGenerator {",
            "15:pub fn prepare_for_submission("
          ],
          "content": "//! Minimal documentation generator for preparing local files before submission\n\nuse anyhow::{Context, Result};\nuse serde_json::Value;\nuse std::fs;\nuse std::path::Path;\nuse std::process::Command;\nuse tracing::info;\n\n/// Simple docs generator that handles local file preparation\npub struct DocsGenerator;\n\nimpl DocsGenerator {\n    /// Prepare documentation files and return git info for submission\n    pub fn prepare_for_submission(\n        working_directory: Option<&str>,\n    ) -> Result<(String, String, String, String)> {\n        info!(\"Preparing documentation files for submission...\");\n\n        // Auto-detect git repository URL\n        let repo_url = Self::get_git_remote_url()?;\n\n        // Auto-detect working directory (relative path from repo root to current dir)\n        let working_dir = Self::get_working_directory(working_directory)?;\n\n        // Auto-detect source branch\n        let source_branch = Self::get_current_branch()?;\n\n        // Generate unique target branch name with timestamp\n        let timestamp = chrono::Utc::now().format(\"%Y%m%d-%H%M%S\");\n        let target_branch = format!(\"docs-generation-{timestamp}\");\n\n        info!(\"Repository: {}\", repo_url);\n        info!(\"Working directory: {}\", working_dir);\n        info!(\"Source branch: {}\", source_branch);\n        info!(\"Target branch: {}\", target_branch);\n\n        // Check and commit .taskmaster changes if needed\n        Self::check_and_commit_taskmaster_changes(&working_dir, &source_branch)?;\n\n        // Create documentation directory structure and copy task files\n        Self::create_docs_structure(&working_dir)?;\n\n        Ok((repo_url, working_dir, source_branch, target_branch))\n    }\n\n    fn get_git_remote_url() -> Result<String> {\n        let output = Command::new(\"git\")\n            .args([\"remote\", \"get-url\", \"origin\"])\n            .output()\n            .context(\"Failed to get git remote URL\")?;\n\n        if !output.status.success() {\n            anyhow::bail!(\n                \"Failed to detect git repository URL. Please specify with --repository-url\"\n            );\n        }\n\n        Ok(String::from_utf8(output.stdout)?.trim().to_string())\n    }\n\n    fn get_working_directory(working_directory: Option<&str>) -> Result<String> {\n        if let Some(wd) = working_directory {\n            return Ok(wd.to_string());\n        }\n\n        let current_dir = std::env::current_dir()?;\n        let repo_root = Command::new(\"git\")\n            .args([\"rev-parse\", \"--show-toplevel\"])\n            .output()\n            .context(\"Failed to get git repo root\")?\n            .stdout;\n        let repo_root_string = String::from_utf8(repo_root)?;\n        let repo_root = repo_root_string.trim();\n\n        let rel_path = current_dir\n            .strip_prefix(repo_root)\n            .context(\"Current directory is not in repo\")?\n            .to_string_lossy()\n            .to_string();\n\n        Ok(if rel_path.is_empty() {\n            \".\".to_string()\n        } else {\n            rel_path\n        })\n    }\n\n    fn get_current_branch() -> Result<String> {\n        let output = Command::new(\"git\")\n            .args([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])\n            .output()\n            .context(\"Failed to get current git branch\")?;\n\n        if !output.status.success() {\n            return Ok(\"main\".to_string());\n        }\n\n        Ok(String::from_utf8(output.stdout)?.trim().to_string())\n    }\n\n    fn check_and_commit_taskmaster_changes(working_dir: &str, source_branch: &str) -> Result<()> {\n        let taskmaster_path = format!(\"{working_dir}/.taskmaster\");\n\n        if !Path::new(&taskmaster_path).exists() {\n            anyhow::bail!(\"No .taskmaster directory found in {}\", working_dir);\n        }\n\n        info!(\"Checking for uncommitted .taskmaster changes...\");\n\n        let status_output = Command::new(\"git\")\n            .args([\"status\", \"--porcelain\", &taskmaster_path])\n            .output()\n            .context(\"Failed to check git status\")?;\n\n        if status_output.stdout.is_empty() {\n            info!(\"No uncommitted changes in .taskmaster directory\");\n        } else {\n            info!(\"Found uncommitted changes in .taskmaster directory\");\n\n            Command::new(\"git\")\n                .args([\"add\", &taskmaster_path])\n                .status()\n                .context(\"Failed to add .taskmaster files\")?;\n\n            Command::new(\"git\")\n                .args([\n                    \"commit\",\n                    \"-m\",\n                    \"chore: auto-commit .taskmaster directory for documentation generation\",\n                ])\n                .status()\n                .context(\"Failed to commit .taskmaster files\")?;\n\n            info!(\"Pushing commit to remote...\");\n            let push_result = Command::new(\"git\")\n                .args([\"push\", \"origin\", source_branch])\n                .status()\n                .context(\"Failed to push commits\")?;\n\n            if !push_result.success() {\n                anyhow::bail!(\"Failed to push .taskmaster commit\");\n            }\n\n            info!(\"✓ Auto-committed and pushed .taskmaster directory\");\n        }\n\n        Ok(())\n    }\n\n    fn create_docs_structure(working_dir: &str) -> Result<()> {\n        info!(\"Creating documentation directory structure...\");\n\n        let taskmaster_path = format!(\"{working_dir}/.taskmaster\");\n        let tasks_json_path = format!(\"{taskmaster_path}/tasks/tasks.json\");\n\n        if !Path::new(&tasks_json_path).exists() {\n            anyhow::bail!(\"No tasks.json found at {}\", tasks_json_path);\n        }\n\n        let content = fs::read_to_string(&tasks_json_path).context(\"Failed to read tasks.json\")?;\n\n        let json: Value = serde_json::from_str(&content).context(\"Failed to parse tasks.json\")?;\n\n        let tasks = json\n            .get(\"master\")\n            .and_then(|m| m.get(\"tasks\"))\n            .and_then(|t| t.as_array())\n            .context(\"No tasks found in tasks.json\")?;\n\n        let docs_dir = format!(\"{taskmaster_path}/docs\");\n        fs::create_dir_all(&docs_dir).context(\"Failed to create docs directory\")?;\n\n        let mut created_count = 0;\n        for task in tasks {\n            if let Some(task_id) = task.get(\"id\").and_then(serde_json::Value::as_u64) {\n                if let Some(title) = task.get(\"title\").and_then(|t| t.as_str()) {\n                    let task_dir = format!(\"{docs_dir}/task-{task_id}\");\n                    fs::create_dir_all(&task_dir)\n                        .context(format!(\"Failed to create directory for task {task_id}\"))?;\n\n                    let source_file = format!(\"{taskmaster_path}/tasks/task_{task_id:03}.txt\");\n                    let dest_file = format!(\"{task_dir}/task.txt\");\n\n                    if Path::new(&source_file).exists() {\n                        fs::copy(&source_file, &dest_file)\n                            .context(format!(\"Failed to copy task file for task {task_id}\"))?;\n                        info!(\"✓ Copied task file for task {}: {}\", task_id, title);\n                    } else {\n                        info!(\n                            \"⚠ No task file found for task {} (expected: {})\",\n                            task_id, source_file\n                        );\n                    }\n\n                    created_count += 1;\n                }\n            }\n        }\n\n        info!(\n            \"✓ Created documentation structure for {} tasks\",\n            created_count\n        );\n        Ok(())\n    }\n}\n"
        },
        {
          "path": "tools/src/cli/commands.rs",
          "file_type": "rust",
          "line_count": 388,
          "key_definitions": [
            "355:pub fn handle_analyze_command("
          ],
          "content": "use anyhow::Result;\nuse common::models::{CodeRequest, DocsRequest};\nuse std::path::PathBuf;\n\nuse crate::api::ApiClient;\nuse crate::docs_generator::DocsGenerator;\nuse crate::output::OutputManager;\n\n/// Handle task command routing\npub async fn handle_task_command(\n    command: crate::TaskCommands,\n    api_url: &str,\n    _output_format: &str,\n) -> Result<()> {\n    let api_client = ApiClient::new(api_url.to_string());\n    let output = OutputManager::new();\n\n    match command {\n        crate::TaskCommands::Docs {\n            working_directory,\n            model,\n            repository_url,\n            source_branch,\n            github_user,\n        } => {\n            handle_docs_command(\n                &api_client,\n                &output,\n                working_directory.as_deref(),\n                model.as_deref(),\n                repository_url.as_deref(),\n                source_branch.as_deref(),\n                &github_user,\n            )\n            .await\n        }\n        crate::TaskCommands::Code {\n            task_id,\n            service,\n            repository_url,\n            docs_repository_url,\n            docs_project_directory,\n            github_user,\n            working_directory,\n            model,\n            local_tools,\n            remote_tools,\n            context_version,\n            prompt_modification,\n            docs_branch,\n            continue_session,\n            overwrite_memory,\n            env,\n            env_from_secrets,\n        } => {\n            handle_code_command(\n                &api_client,\n                &output,\n                task_id,\n                &service,\n                repository_url.as_deref(),\n                docs_repository_url.as_deref(),\n                docs_project_directory.as_deref(),\n                &github_user,\n                working_directory.as_deref(),\n                model.as_deref(),\n                local_tools.as_deref(),\n                remote_tools.as_deref(),\n                context_version,\n                prompt_modification.as_deref(),\n                &docs_branch,\n                continue_session,\n                overwrite_memory,\n                env.as_deref(),\n                env_from_secrets.as_deref(),\n            )\n            .await\n        }\n    }\n}\n\n/// Handle docs command - does local file prep then submits docs generation job\nasync fn handle_docs_command(\n    api_client: &ApiClient,\n    output: &OutputManager,\n    working_directory: Option<&str>,\n    model: Option<&str>,\n    repository_url: Option<&str>,\n    source_branch: Option<&str>,\n    github_user: &str,\n) -> Result<()> {\n    output.info(\"Initializing documentation generator...\");\n\n    // Do local file preparation and get git info (used as fallbacks)\n    let (detected_repo_url, detected_working_dir, detected_source_branch, _generated_docs_branch) =\n        DocsGenerator::prepare_for_submission(working_directory)?;\n\n    // Use provided parameters or fall back to auto-detected values\n    let final_repo_url = repository_url.unwrap_or(&detected_repo_url);\n    let final_working_dir = working_directory.unwrap_or(&detected_working_dir);\n    let final_source_branch = source_branch.unwrap_or(&detected_source_branch);\n\n    // Create documentation generation request\n    let request = DocsRequest {\n        repository_url: final_repo_url.to_string(),\n        working_directory: final_working_dir.to_string(),\n        source_branch: final_source_branch.to_string(),\n        model: model.map(|s| s.to_string()),\n        github_user: github_user.to_string(),\n    };\n\n    output.info(\"Submitting documentation generation job...\");\n\n    match api_client.submit_docs_generation(&request).await {\n        Ok(response) => {\n            if response.success {\n                output.success(&response.message);\n\n                if let Some(data) = response.data {\n                    if let Some(taskrun_name) = data.get(\"taskrun_name\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"TaskRun name: {taskrun_name}\"));\n                    }\n                    if let Some(namespace) = data.get(\"namespace\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"Namespace: {namespace}\"));\n                        output.info(\"You can monitor the job with:\");\n                        output.info(&format!(\"  kubectl -n {namespace} get taskrun\"));\n                    }\n                }\n            } else {\n                output.error(&response.message);\n                anyhow::bail!(response.message);\n            }\n        }\n        Err(e) => {\n            output.error(&format!(\n                \"Failed to submit documentation generation job: {e}\"\n            ));\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Handle code command - submits code task directly\n#[allow(clippy::too_many_arguments)]\nasync fn handle_code_command(\n    api_client: &ApiClient,\n    output: &OutputManager,\n    task_id: u32,\n    service: &str,\n    repository_url: Option<&str>,\n    docs_repository_url: Option<&str>,\n    docs_project_directory: Option<&str>,\n    github_user: &str,\n    working_directory: Option<&str>,\n    model: Option<&str>,\n    local_tools: Option<&str>,\n    remote_tools: Option<&str>,\n    context_version: u32,\n    prompt_modification: Option<&str>,\n    docs_branch: &str,\n    continue_session: bool,\n    overwrite_memory: bool,\n    env: Option<&str>,\n    env_from_secrets: Option<&str>,\n) -> Result<()> {\n    output.info(&format!(\n        \"Submitting code task {task_id} for service '{service}'...\"\n    ));\n\n    // Auto-detect target repository URL if not provided\n    let repo_url = match repository_url {\n        Some(url) => url.to_string(),\n        None => get_git_remote_url()?,\n    };\n\n    // Auto-detect docs repository URL if not provided\n    let docs_repo_url = match docs_repository_url {\n        Some(url) => url.to_string(),\n        None => get_git_remote_url()?, // TODO: This should be configurable\n    };\n\n    // Use provided GitHub user (now required)\n    let github_user_name = github_user.to_string();\n\n    // Auto-detect working directory if not provided\n    let working_dir = match working_directory {\n        Some(wd) => wd.to_string(),\n        None => get_working_directory()?,\n    };\n\n    // Parse environment variables\n    let env_map = parse_env_vars(env)?;\n    let env_from_secrets_vec = parse_env_from_secrets(env_from_secrets)?;\n\n    // Create code task request\n    let request = CodeRequest {\n        task_id,\n        service: service.to_string(),\n        repository_url: repo_url.clone(),\n        docs_repository_url: docs_repo_url.clone(),\n        docs_project_directory: docs_project_directory.map(std::string::ToString::to_string),\n        working_directory: Some(working_dir.clone()),\n        model: model.map(|s| s.to_string()),\n        github_user: github_user_name.clone(),\n        local_tools: local_tools.map(std::string::ToString::to_string),\n        remote_tools: remote_tools.map(std::string::ToString::to_string),\n        context_version,\n        prompt_modification: prompt_modification.map(std::string::ToString::to_string),\n        docs_branch: docs_branch.to_string(),\n        continue_session,\n        overwrite_memory,\n        env: env_map,\n        env_from_secrets: env_from_secrets_vec,\n    };\n\n    output.info(&format!(\"Target repository: {repo_url}\"));\n    output.info(&format!(\"Docs repository: {docs_repo_url}\"));\n    output.info(&format!(\"Docs branch: {docs_branch}\"));\n    output.info(&format!(\"Working directory: {working_dir}\"));\n    output.info(&format!(\"Context version: {context_version}\"));\n    output.info(&format!(\"GitHub user: {github_user_name}\"));\n\n    match api_client.submit_code_task(&request).await {\n        Ok(response) => {\n            if response.success {\n                output.success(&response.message);\n\n                if let Some(data) = response.data {\n                    if let Some(coderun_name) = data.get(\"coderun_name\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"CodeRun name: {coderun_name}\"));\n                    }\n                    if let Some(namespace) = data.get(\"namespace\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"Namespace: {namespace}\"));\n                        output.info(\"You can monitor the job with:\");\n                        output.info(&format!(\"  kubectl -n {namespace} get coderun\"));\n                    }\n                }\n            } else {\n                output.error(&response.message);\n                anyhow::bail!(response.message);\n            }\n        }\n        Err(e) => {\n            output.error(&format!(\"Failed to submit code task: {e}\"));\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Helper functions for git operations\nfn get_git_remote_url() -> Result<String> {\n    use std::process::Command;\n\n    let output = Command::new(\"git\")\n        .args([\"remote\", \"get-url\", \"origin\"])\n        .output()?;\n\n    if !output.status.success() {\n        anyhow::bail!(\"Failed to get git remote URL\");\n    }\n\n    Ok(String::from_utf8(output.stdout)?.trim().to_string())\n}\n\nfn get_working_directory() -> Result<String> {\n    use std::process::Command;\n\n    let current_dir = std::env::current_dir()?;\n    let repo_root = Command::new(\"git\")\n        .args([\"rev-parse\", \"--show-toplevel\"])\n        .output()?\n        .stdout;\n    let repo_root_string = String::from_utf8(repo_root)?;\n    let repo_root = repo_root_string.trim();\n\n    let rel_path = current_dir\n        .strip_prefix(repo_root)?\n        .to_string_lossy()\n        .to_string();\n\n    Ok(if rel_path.is_empty() {\n        \".\".to_string()\n    } else {\n        rel_path\n    })\n}\n\n/// Parse environment variables from comma-separated key=value string\nfn parse_env_vars(env_str: Option<&str>) -> Result<std::collections::HashMap<String, String>> {\n    use std::collections::HashMap;\n\n    let mut env_map = HashMap::new();\n\n    if let Some(env_str) = env_str {\n        for pair in env_str.split(',') {\n            let pair = pair.trim();\n            if pair.is_empty() {\n                continue;\n            }\n\n            let mut parts = pair.splitn(2, '=');\n            let key = parts\n                .next()\n                .ok_or_else(|| anyhow::anyhow!(\"Invalid env format: {}\", pair))?;\n            let value = parts\n                .next()\n                .ok_or_else(|| anyhow::anyhow!(\"Invalid env format: {}\", pair))?;\n\n            env_map.insert(key.to_string(), value.to_string());\n        }\n    }\n\n    Ok(env_map)\n}\n\n/// Parse environment variables from secrets in format: name:secretName:secretKey,...\nfn parse_env_from_secrets(\n    env_secrets_str: Option<&str>,\n) -> Result<Vec<common::models::code_request::SecretEnvVar>> {\n    use common::models::code_request::SecretEnvVar;\n\n    let mut secrets = Vec::new();\n\n    if let Some(secrets_str) = env_secrets_str {\n        for secret_spec in secrets_str.split(',') {\n            let secret_spec = secret_spec.trim();\n            if secret_spec.is_empty() {\n                continue;\n            }\n\n            let parts: Vec<&str> = secret_spec.split(':').collect();\n            if parts.len() != 3 {\n                anyhow::bail!(\n                    \"Invalid secret env format: {}. Expected name:secretName:secretKey\",\n                    secret_spec\n                );\n            }\n\n            secrets.push(SecretEnvVar {\n                name: parts[0].to_string(),\n                secret_name: parts[1].to_string(),\n                secret_key: parts[2].to_string(),\n            });\n        }\n    }\n\n    Ok(secrets)\n}\n\n/// Handle analyze command\npub fn handle_analyze_command(\n    output: String,\n    format: String,\n    working_directory: Option<String>,\n    include_source: bool,\n) -> Result<()> {\n    use crate::analyzer::CodebaseAnalyzer;\n\n    let work_dir = working_directory\n        .map(PathBuf::from)\n        .unwrap_or_else(|| std::env::current_dir().expect(\"Failed to get current directory\"));\n\n    let analyzer = CodebaseAnalyzer::new(work_dir, include_source);\n    let analysis = analyzer.analyze()?;\n\n    match format.as_str() {\n        \"json\" => {\n            let json_output = serde_json::to_string_pretty(&analysis)?;\n            std::fs::write(&output, json_output)?;\n            println!(\"✅ Codebase analysis written to: {} (JSON format)\", output);\n        }\n        \"single\" => {\n            let markdown_output = analyzer.generate_single_markdown(&analysis)?;\n            std::fs::write(&output, markdown_output)?;\n            println!(\"✅ Codebase analysis written to: {} (Single Markdown)\", output);\n        }\n        \"modular\" | _ => {\n            analyzer.generate_modular_markdown(&analysis, &output)?;\n            println!(\"✅ Modular codebase analysis written to: {}/\", output);\n        }\n    }\n\n    Ok(())\n}\n"
        },
        {
          "path": "tools/src/cli/output.rs",
          "file_type": "rust",
          "line_count": 26,
          "key_definitions": [
            "8:pub struct OutputManager;",
            "10:impl OutputManager {",
            "11:pub fn new() -> Self {",
            "15:pub fn info(&self, message: &str) {",
            "19:pub fn success(&self, message: &str) {",
            "23:pub fn error(&self, message: &str) {"
          ],
          "content": "//! Simple output formatting for the CLI\n\n#![allow(clippy::disallowed_macros)]\n\nuse colored::Colorize;\n\n/// Simple output manager for consistent formatting\npub struct OutputManager;\n\nimpl OutputManager {\n    pub fn new() -> Self {\n        Self\n    }\n\n    pub fn info(&self, message: &str) {\n        println!(\"{} {}\", \"INFO:\".blue().bold(), message);\n    }\n\n    pub fn success(&self, message: &str) {\n        println!(\"{} {}\", \"✓\".green().bold(), message);\n    }\n\n    pub fn error(&self, message: &str) {\n        eprintln!(\"{} {}\", \"✗\".red().bold(), message);\n    }\n}\n"
        },
        {
          "path": "tools/src/cli/main.rs",
          "file_type": "rust",
          "line_count": 191,
          "key_definitions": [
            "79:pub enum TaskCommands {"
          ],
          "content": "/*\n * 5D Labs Agent Platform - CLI Tools for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Orchestrator CLI - Simplified with just docs and code task submission\n\nmod analyzer;\nmod api;\nmod commands;\nmod docs_generator;\nmod output;\nuse anyhow::Result;\nuse clap::{Parser, Subcommand};\n\n#[derive(Parser)]\n#[command(name = \"orchestrator\")]\n#[command(about = \"CLI for Orchestrator Service\", long_about = None)]\n#[command(version)]\nstruct Cli {\n    #[command(subcommand)]\n    command: Commands,\n\n    /// API endpoint URL\n    #[arg(\n        long,\n        env = \"ORCHESTRATOR_API_URL\",\n        default_value = \"http://orchestrator.orchestrator.svc.cluster.local/api/v1\"\n    )]\n    api_url: String,\n\n    /// Output format (table, json, yaml)\n    #[arg(long, short, default_value = \"table\")]\n    output: String,\n}\n\n#[derive(Subcommand)]\nenum Commands {\n    /// Task operations\n    Task {\n        #[command(subcommand)]\n        command: TaskCommands,\n    },\n    /// Analyze codebase and generate documentation for Task Master PRD\n    Analyze {\n        /// Output directory (default: docs/codebase-analysis)\n        #[arg(short, long, default_value = \"docs/codebase-analysis\")]\n        output: String,\n\n        /// Output format: modular, single, json (default: modular)\n        #[arg(short, long, default_value = \"modular\")]\n        format: String,\n\n        /// Working directory to analyze (default: current directory)\n        #[arg(short, long)]\n        working_directory: Option<String>,\n\n        /// Include full source code (default: true)\n        #[arg(long, default_value = \"true\")]\n        include_source: bool,\n    },\n}\n\n#[derive(Subcommand)]\n#[allow(clippy::large_enum_variant)]\npub enum TaskCommands {\n    /// Generate documentation for Task Master tasks\n    Docs {\n        /// Working directory containing .taskmaster folder\n        #[arg(long, short = 'w')]\n        working_directory: Option<String>,\n\n        /// Claude model to use (required) - e.g., 'claude-opus-4-20250514' or 'claude-sonnet-4-20250514'\n        #[arg(long)]\n        model: Option<String>,\n\n        /// Documentation repository URL\n        #[arg(long)]\n        repository_url: Option<String>,\n\n        /// Source branch to use\n        #[arg(long)]\n        source_branch: Option<String>,\n\n        /// GitHub username for authentication (required)\n        #[arg(long)]\n        github_user: String,\n    },\n\n    /// Submit implementation task to orchestrator\n    Code {\n        /// Task ID to implement\n        task_id: u32,\n\n        /// Target service name\n        #[arg(long, short = 's')]\n        service: String,\n\n        /// Target project repository URL (where implementation work happens)\n        #[arg(long)]\n        repository_url: Option<String>,\n\n        /// Documentation repository URL (where Task Master definitions come from)\n        #[arg(long)]\n        docs_repository_url: Option<String>,\n\n        /// Project directory within docs repository (e.g. \"_projects/simple-api\")\n        #[arg(long)]\n        docs_project_directory: Option<String>,\n\n        /// GitHub username for authentication (required)\n        #[arg(long)]\n        github_user: String,\n\n        /// Working directory within target repository\n        #[arg(long, short = 'w')]\n        working_directory: Option<String>,\n\n        /// Claude model to use (required) - e.g., 'claude-opus-4-20250514' or 'claude-sonnet-4-20250514'\n        #[arg(long)]\n        model: Option<String>,\n\n        /// Local MCP tools to enable (comma-separated)\n        #[arg(long)]\n        local_tools: Option<String>,\n\n        /// Remote MCP tools to enable (comma-separated)\n        #[arg(long)]\n        remote_tools: Option<String>,\n\n        /// Context version for retry attempts (incremented on each retry)\n        #[arg(long, default_value = \"1\")]\n        context_version: u32,\n\n        /// Additional context for retry attempts\n        #[arg(long)]\n        prompt_modification: Option<String>,\n\n        /// Docs branch to use (e.g., \"main\", \"feature/branch\")\n        #[arg(long, default_value = \"main\")]\n        docs_branch: String,\n\n        /// Whether to continue a previous session\n        #[arg(long)]\n        continue_session: bool,\n\n        /// Whether to overwrite memory before starting\n        #[arg(long)]\n        overwrite_memory: bool,\n\n        /// Environment variables (format: KEY=value,KEY2=value2)\n        #[arg(long)]\n        env: Option<String>,\n\n        /// Environment variables from secrets (format: name:secretName:secretKey,...)\n        #[arg(long)]\n        env_from_secrets: Option<String>,\n    },\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Initialize tracing\n    tracing_subscriber::fmt::init();\n\n    let cli = Cli::parse();\n\n    match cli.command {\n        Commands::Task { command } => {\n            commands::handle_task_command(command, &cli.api_url, &cli.output).await?;\n        }\n        Commands::Analyze { output, format, working_directory, include_source } => {\n            commands::handle_analyze_command(output, format, working_directory, include_source)?;\n        }\n    }\n\n    Ok(())\n}\n"
        },
        {
          "path": "tools/src/cli/api.rs",
          "file_type": "rust",
          "line_count": 100,
          "key_definitions": [
            "12:pub struct ApiResponse {",
            "21:pub struct ApiClient {",
            "26:impl ApiClient {",
            "28:pub fn new(base_url: String) -> Self {"
          ],
          "content": "//! HTTP API client for orchestrator `TaskRun` submissions\n\nuse anyhow::{Context, Result};\nuse common::models::{CodeRequest, DocsRequest};\nuse reqwest::{Client, Response};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse tracing::{debug, info};\n\n/// API response structure used by PM endpoints\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApiResponse {\n    pub success: bool,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option<Value>,\n}\n\n/// API client for the orchestrator service\n#[derive(Clone)]\npub struct ApiClient {\n    client: Client,\n    base_url: String,\n}\n\nimpl ApiClient {\n    /// Create a new API client\n    pub fn new(base_url: String) -> Self {\n        Self {\n            client: Client::new(),\n            base_url,\n        }\n    }\n\n    /// Submit a code task\n    pub async fn submit_code_task(&self, request: &CodeRequest) -> Result<ApiResponse> {\n        info!(\n            \"Submitting code task: {} for service: {}\",\n            request.task_id, request.service\n        );\n        debug!(\"Code task request: {:?}\", request);\n\n        let response = self\n            .client\n            .post(format!(\"{}/pm/tasks\", self.base_url))\n            .json(request)\n            .send()\n            .await\n            .context(\"Failed to send code task submission request\")?;\n\n        self.handle_response(response).await\n    }\n\n    /// Submit a documentation generation job\n    pub async fn submit_docs_generation(&self, request: &DocsRequest) -> Result<ApiResponse> {\n        info!(\n            \"Submitting documentation generation job for repository: {}\",\n            request.repository_url\n        );\n        debug!(\"Docs generation request: {:?}\", request);\n\n        let response = self\n            .client\n            .post(format!(\"{}/pm/docs/generate\", self.base_url))\n            .json(request)\n            .send()\n            .await\n            .context(\"Failed to send documentation generation request\")?;\n\n        self.handle_response(response).await\n    }\n\n    /// Generic response handler for API responses\n    async fn handle_response(&self, response: Response) -> Result<ApiResponse> {\n        let status = response.status();\n        let response_text = response\n            .text()\n            .await\n            .context(\"Failed to read response body\")?;\n\n        debug!(\"API response status: {}\", status);\n        debug!(\"API response body: {}\", response_text);\n\n        if status.is_success() {\n            serde_json::from_str(&response_text)\n                .with_context(|| format!(\"Failed to parse successful response: {response_text}\"))\n        } else {\n            // Try to parse as error response first\n            if let Ok(error_response) = serde_json::from_str::<ApiResponse>(&response_text) {\n                Ok(error_response)\n            } else {\n                Err(anyhow::anyhow!(\n                    \"API request failed with status {}: {}\",\n                    status,\n                    response_text\n                ))\n            }\n        }\n    }\n}\n"
        },
        {
          "path": "core/src/crds/mod.rs",
          "file_type": "rust",
          "line_count": 5,
          "key_definitions": [],
          "content": "pub mod coderun;\npub mod docsrun;\n\npub use coderun::*;\npub use docsrun::*;\n"
        },
        {
          "path": "core/src/crds/coderun.rs",
          "file_type": "rust",
          "line_count": 181,
          "key_definitions": [
            "10:pub struct SecretEnvVar {",
            "51:pub struct CodeRunSpec {",
            "121:pub struct CodeRunStatus {",
            "162:pub struct CodeRunCondition {"
          ],
          "content": "//! `CodeRun` Custom Resource Definition for code implementation tasks\n\nuse kube::CustomResource;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Reference to a secret for environment variable\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub struct SecretEnvVar {\n    /// Name of the environment variable\n    pub name: String,\n    /// Name of the secret\n    #[serde(rename = \"secretName\")]\n    pub secret_name: String,\n    /// Key within the secret\n    #[serde(rename = \"secretKey\")]\n    pub secret_key: String,\n}\n\n/// Default function for `context_version` field\nfn default_context_version() -> u32 {\n    1\n}\n\n/// Default function for `docs_branch` field\nfn default_docs_branch() -> String {\n    \"main\".to_string()\n}\n\n/// Default function for `continue_session` field\nfn default_continue_session() -> bool {\n    false\n}\n\n/// Default function for `overwrite_memory` field\nfn default_overwrite_memory() -> bool {\n    false\n}\n\n/// `CodeRun` CRD for code implementation tasks\n#[derive(CustomResource, Deserialize, Serialize, Clone, Debug, JsonSchema)]\n#[kube(group = \"orchestrator.platform\", version = \"v1\", kind = \"CodeRun\")]\n#[kube(namespaced)]\n#[kube(status = \"CodeRunStatus\")]\n#[kube(printcolumn = r#\"{\"name\":\"Task\",\"type\":\"integer\",\"jsonPath\":\".spec.taskId\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Service\",\"type\":\"string\",\"jsonPath\":\".spec.service\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Model\",\"type\":\"string\",\"jsonPath\":\".spec.model\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Phase\",\"type\":\"string\",\"jsonPath\":\".status.phase\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Age\",\"type\":\"date\",\"jsonPath\":\".metadata.creationTimestamp\"}\"#)]\npub struct CodeRunSpec {\n    /// Task ID to implement\n    #[serde(rename = \"taskId\")]\n    pub task_id: u32,\n\n    /// Target service name\n    pub service: String,\n\n    /// Target project repository URL (where implementation work happens)\n    #[serde(rename = \"repositoryUrl\")]\n    pub repository_url: String,\n\n    /// Documentation repository URL (where Task Master definitions come from)\n    #[serde(rename = \"docsRepositoryUrl\")]\n    pub docs_repository_url: String,\n\n    /// Project directory within docs repository (e.g. \"_projects/simple-api\")\n    #[serde(default, rename = \"docsProjectDirectory\")]\n    pub docs_project_directory: Option<String>,\n\n    /// Working directory within target repository (defaults to service name)\n    #[serde(default, rename = \"workingDirectory\")]\n    pub working_directory: Option<String>,\n\n    /// Claude model to use (sonnet, opus)\n    pub model: String,\n\n    /// GitHub username for authentication and commits\n    #[serde(rename = \"githubUser\")]\n    pub github_user: String,\n\n    /// Local MCP tools/servers to enable (comma-separated)\n    #[serde(default, rename = \"localTools\")]\n    pub local_tools: Option<String>,\n\n    /// Remote MCP tools/servers to enable (comma-separated)\n    #[serde(default, rename = \"remoteTools\")]\n    pub remote_tools: Option<String>,\n\n    /// Context version for retry attempts (incremented on each retry)\n    #[serde(default = \"default_context_version\", rename = \"contextVersion\")]\n    pub context_version: u32,\n\n    /// Additional context for retry attempts\n    #[serde(default, rename = \"promptModification\")]\n    pub prompt_modification: Option<String>,\n\n    /// Docs branch to use (e.g., \"main\", \"feature/branch\")\n    #[serde(default = \"default_docs_branch\", rename = \"docsBranch\")]\n    pub docs_branch: String,\n\n    /// Whether to continue a previous session (auto-continue on retries or user-requested)\n    #[serde(default = \"default_continue_session\", rename = \"continueSession\")]\n    pub continue_session: bool,\n\n    /// Whether to overwrite memory before starting\n    #[serde(default = \"default_overwrite_memory\", rename = \"overwriteMemory\")]\n    pub overwrite_memory: bool,\n\n    /// Environment variables to set in the container\n    #[serde(default)]\n    pub env: HashMap<String, String>,\n\n    /// Environment variables from secrets\n    #[serde(default, rename = \"envFromSecrets\")]\n    pub env_from_secrets: Vec<SecretEnvVar>,\n}\n\n/// Status of the `CodeRun`\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub struct CodeRunStatus {\n    /// Current phase of the code implementation\n    pub phase: String,\n\n    /// Human-readable message about the current state\n    pub message: Option<String>,\n\n    /// Timestamp when this phase was reached\n    pub last_update: Option<String>,\n\n    /// Associated Kubernetes Job name\n    pub job_name: Option<String>,\n\n    /// Pull request URL if created\n    pub pull_request_url: Option<String>,\n\n    /// Current retry attempt (if applicable)\n    pub retry_count: Option<u32>,\n\n    /// Conditions for the `CodeRun`\n    pub conditions: Option<Vec<CodeRunCondition>>,\n\n    /// Name of the `ConfigMap` containing the prompt and context\n    pub configmap_name: Option<String>,\n\n    /// Version of the context and prompt used\n    pub context_version: Option<u32>,\n\n    /// Modification to the prompt if any\n    pub prompt_modification: Option<String>,\n\n    /// Mode of prompt (e.g., \"direct\", \"indirect\")\n    pub prompt_mode: Option<String>,\n\n    /// Session ID for tracking\n    pub session_id: Option<String>,\n}\n\n/// Condition for the `CodeRun`\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct CodeRunCondition {\n    /// Type of condition\n    #[serde(rename = \"type\")]\n    pub condition_type: String,\n\n    /// Status of the condition (True, False, or Unknown)\n    pub status: String,\n\n    /// Last time the condition transitioned (RFC3339 format)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub last_transition_time: Option<String>,\n\n    /// Reason for the condition's last transition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub reason: Option<String>,\n\n    /// Human-readable message about the condition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub message: Option<String>,\n}\n"
        },
        {
          "path": "core/src/crds/docsrun.rs",
          "file_type": "rust",
          "line_count": 73,
          "key_definitions": [
            "13:pub struct DocsRunSpec {",
            "26:pub struct DocsRunStatus {",
            "39:pub struct DocsRunCondition {",
            "62:pub enum DocsRunPhase {"
          ],
          "content": "//! `DocsRun` Custom Resource Definition for documentation generation\n\nuse kube::CustomResource;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\n\n#[derive(CustomResource, Deserialize, Serialize, Clone, Debug, JsonSchema)]\n#[kube(group = \"orchestrator.platform\", version = \"v1\", kind = \"DocsRun\")]\n#[kube(namespaced)]\n#[kube(status = \"DocsRunStatus\")]\n#[kube(printcolumn = r#\"{\"name\":\"Phase\",\"type\":\"string\",\"jsonPath\":\".status.phase\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Age\",\"type\":\"date\",\"jsonPath\":\".metadata.creationTimestamp\"}\"#)]\npub struct DocsRunSpec {\n    #[serde(rename = \"repositoryUrl\")]\n    pub repository_url: String,\n    #[serde(rename = \"workingDirectory\")]\n    pub working_directory: String,\n    #[serde(rename = \"sourceBranch\")]\n    pub source_branch: String,\n    pub model: String,\n    #[serde(rename = \"githubUser\")]\n    pub github_user: String,\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub struct DocsRunStatus {\n    pub phase: String,\n    pub message: Option<String>,\n    pub last_update: Option<String>,\n    pub job_name: Option<String>,\n    pub pull_request_url: Option<String>,\n    pub conditions: Option<Vec<DocsRunCondition>>,\n    pub configmap_name: Option<String>,\n}\n\n/// Condition for the `DocsRun`\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct DocsRunCondition {\n    /// Type of condition\n    #[serde(rename = \"type\")]\n    pub condition_type: String,\n\n    /// Status of the condition (True, False, or Unknown)\n    pub status: String,\n\n    /// Last time the condition transitioned (RFC3339 format)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub last_transition_time: Option<String>,\n\n    /// Reason for the condition's last transition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub reason: Option<String>,\n\n    /// Human-readable message about the condition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub message: Option<String>,\n}\n\n/// Phase of `DocsRun` execution\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub enum DocsRunPhase {\n    /// `DocsRun` has been created but not yet processed\n    Pending,\n    /// Documentation generation is in progress\n    Running,\n    /// Documentation generation completed successfully\n    Succeeded,\n    /// Documentation generation failed\n    Failed,\n    /// `DocsRun` was manually cancelled\n    Cancelled,\n}\n"
        },
        {
          "path": "core/src/bin/test_templates.rs",
          "file_type": "rust",
          "line_count": 148,
          "key_definitions": [],
          "content": "#!/usr/bin/env cargo\n//! Template testing utility for local handlebars template validation\n//!\n//! Usage: cargo run --bin `test_templates`\n\n#![allow(clippy::disallowed_macros)]\n\nuse handlebars::Handlebars;\nuse serde_json::json;\nuse std::path::Path;\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"🧪 Testing Handlebars Templates...\\n\");\n\n    // Initialize handlebars engine\n    let mut handlebars = Handlebars::new();\n\n    // Template directory\n    let template_dir = Path::new(\"orchestrator-core/templates\");\n\n    // Test docs templates\n    test_docs_templates(&mut handlebars, template_dir)?;\n\n    // Test code templates\n    test_code_templates(&mut handlebars, template_dir)?;\n\n    println!(\"✅ All templates rendered successfully!\");\n    Ok(())\n}\n\nfn test_docs_templates(\n    handlebars: &mut Handlebars,\n    template_dir: &Path,\n) -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"📄 Testing Docs Templates:\");\n\n    // Mock DocsRunSpec data\n    let docs_data = json!({\n        \"repository_url\": \"https://github.com/5dlabs/platform\",\n        \"working_directory\": \"_projects/simple-api\",\n        \"source_branch\": \"feature/example-project-and-cli\",\n        \"model\": \"claude-3-5-sonnet-20241022\",\n        \"github_user\": \"pm0-5dlabs\"\n    });\n\n    // Test docs templates\n    let docs_templates = [\n        \"docs/claude.md.hbs\",\n        \"docs/settings.json.hbs\",\n        \"docs/container.sh.hbs\",\n    ];\n\n    for template_name in &docs_templates {\n        let template_path = template_dir.join(template_name);\n\n        if template_path.exists() {\n            println!(\"  Testing {template_name}...\");\n\n            // Register template\n            let template_content = std::fs::read_to_string(&template_path)?;\n            handlebars.register_template_string(template_name, &template_content)?;\n\n            // Render template\n            let result = handlebars.render(template_name, &docs_data)?;\n\n            println!(\"    ✅ Rendered successfully ({} chars)\", result.len());\n\n            // Show first few lines of output for verification\n            let lines: Vec<&str> = result.lines().take(3).collect();\n            for line in lines {\n                println!(\"    │ {line}\");\n            }\n\n            if result.lines().count() > 3 {\n                println!(\"    │ ... ({} total lines)\", result.lines().count());\n            }\n            println!();\n        } else {\n            println!(\"  ⚠️  Template not found: {}\", template_path.display());\n        }\n    }\n\n    Ok(())\n}\n\nfn test_code_templates(\n    handlebars: &mut Handlebars,\n    template_dir: &Path,\n) -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"💻 Testing Code Templates:\");\n\n    // Mock CodeRunSpec data\n    let code_data = json!({\n        \"task_id\": 42,\n        \"service\": \"simple-api\",\n        \"repository_url\": \"https://github.com/5dlabs/platform\",\n        \"platform_repository_url\": \"https://github.com/5dlabs/platform\",\n        \"branch\": \"feature/example-project-and-cli\",\n        \"working_directory\": \"_projects/simple-api\",\n        \"model\": \"claude-3-5-sonnet-20241022\",\n        \"github_user\": \"pm0-5dlabs\",\n        \"local_tools\": \"bash,edit,read\",\n        \"remote_tools\": \"github_create_issue\",\n        \"tool_config\": \"default\",\n        \"context_version\": 1,\n        \"prompt_modification\": null,\n        \"prompt_mode\": \"append\"\n    });\n\n    // Test code templates\n    let code_templates = [\n        \"code/claude.md.hbs\",\n        \"code/settings.json.hbs\",\n        \"code/container.sh.hbs\",\n    ];\n\n    for template_name in &code_templates {\n        let template_path = template_dir.join(template_name);\n\n        if template_path.exists() {\n            println!(\"  Testing {template_name}...\");\n\n            // Register template\n            let template_content = std::fs::read_to_string(&template_path)?;\n            handlebars.register_template_string(template_name, &template_content)?;\n\n            // Render template\n            let result = handlebars.render(template_name, &code_data)?;\n\n            println!(\"    ✅ Rendered successfully ({} chars)\", result.len());\n\n            // Show first few lines of output for verification\n            let lines: Vec<&str> = result.lines().take(3).collect();\n            for line in lines {\n                println!(\"    │ {line}\");\n            }\n\n            if result.lines().count() > 3 {\n                println!(\"    │ ... ({} total lines)\", result.lines().count());\n            }\n            println!();\n        } else {\n            println!(\"  ⚠️  Template not found: {}\", template_path.display());\n        }\n    }\n\n    Ok(())\n}\n"
        },
        {
          "path": "core/src/lib.rs",
          "file_type": "rust",
          "line_count": 31,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - Kubernetes Orchestrator for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Orchestrator core library\n//!\n//! This crate provides the core functionality for the unified orchestration service,\n//! including Kubernetes client wrapper, job orchestration, and request handling.\n\npub mod controllers;\npub mod crds;\npub mod handlers;\n\n// Re-export commonly used types\npub use controllers::task_controller::ControllerConfig;\npub use crds::{CodeRun, CodeRunSpec, CodeRunStatus, DocsRun, DocsRunSpec, DocsRunStatus};\npub use handlers::*;\n"
        },
        {
          "path": "core/src/main.rs",
          "file_type": "rust",
          "line_count": 159,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - Kubernetes Orchestrator for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Main entry point for the Orchestrator service\n\nuse anyhow::Result;\nuse axum::{\n    extract::State,\n    http::StatusCode,\n    response::Json,\n    routing::{get, post},\n    Router,\n};\nuse core::{\n    controllers::run_task_controller,\n    handlers::{code_handler::submit_code_task, common::AppState, docs_handler::generate_docs},\n};\nuse kube::Client;\nuse serde_json::{json, Value};\nuse tokio::signal;\nuse tower::ServiceBuilder;\nuse tower_http::{cors::CorsLayer, trace::TraceLayer};\nuse tracing::{error, info};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\nasync fn create_app_state() -> Result<AppState> {\n    // Initialize Kubernetes client\n    let k8s_client = Client::try_default()\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to create K8s client: {}\", e))?;\n\n    // Get namespace from environment or use default\n    let namespace =\n        std::env::var(\"KUBERNETES_NAMESPACE\").unwrap_or_else(|_| \"orchestrator\".to_string());\n\n    info!(\"Initialized orchestrator for namespace: {}\", namespace);\n\n    Ok(AppState {\n        k8s_client,\n        namespace,\n    })\n}\n\n/// Health check endpoint\nasync fn health_check(State(_state): State<AppState>) -> Result<Json<Value>, StatusCode> {\n    Ok(Json(json!({\n        \"status\": \"healthy\",\n        \"version\": env!(\"CARGO_PKG_VERSION\"),\n        \"timestamp\": chrono::Utc::now().to_rfc3339()\n    })))\n}\n\n/// Create API routes\nfn api_routes() -> Router<AppState> {\n    Router::new()\n        .route(\"/pm/tasks\", post(submit_code_task))\n        .route(\"/pm/docs/generate\", post(generate_docs))\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Initialize tracing with OpenTelemetry support\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| tracing_subscriber::EnvFilter::new(\"info\")),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    info!(\n        \"Starting Orchestrator service v{} with TaskRun CRD support\",\n        env!(\"CARGO_PKG_VERSION\")\n    );\n\n    // Initialize application state\n    let app_state = create_app_state().await?;\n\n    // Start task controller\n    let client = app_state.k8s_client.clone();\n    let namespace = app_state.namespace.clone();\n\n    info!(\"Starting task controller in namespace: {}\", namespace);\n\n    // Spawn the controller in the background\n    tokio::spawn(async move {\n        if let Err(e) = run_task_controller(client, namespace).await {\n            error!(\"Task controller error: {}\", e);\n        }\n    });\n\n    // Build the application with middleware layers\n    let app = Router::new()\n        .nest(\"/api/v1\", api_routes())\n        .route(\"/health\", get(health_check)) // Root health check for load balancers\n        .layer(\n            ServiceBuilder::new()\n                .layer(TraceLayer::new_for_http())\n                .layer(CorsLayer::permissive()), // Simplified for now\n        )\n        .with_state(app_state);\n\n    // Create TCP listener\n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:8080\")\n        .await\n        .expect(\"Failed to bind to address\");\n\n    info!(\"Server listening on {}\", listener.local_addr()?);\n\n    // Start server with graceful shutdown\n    axum::serve(listener, app)\n        .with_graceful_shutdown(shutdown_signal())\n        .await?;\n\n    info!(\"Server shutdown complete\");\n    Ok(())\n}\n\n/// Graceful shutdown signal handler\nasync fn shutdown_signal() {\n    let ctrl_c = async {\n        signal::ctrl_c()\n            .await\n            .expect(\"Failed to install Ctrl+C handler\");\n    };\n\n    #[cfg(unix)]\n    let terminate = async {\n        signal::unix::signal(signal::unix::SignalKind::terminate())\n            .expect(\"Failed to install signal handler\")\n            .recv()\n            .await;\n    };\n\n    #[cfg(not(unix))]\n    let terminate = std::future::pending::<()>();\n\n    tokio::select! {\n        () = ctrl_c => {},\n        () = terminate => {},\n    }\n\n    info!(\"Shutdown signal received, starting graceful shutdown\");\n}\n"
        },
        {
          "path": "core/src/controllers/mod.rs",
          "file_type": "rust",
          "line_count": 8,
          "key_definitions": [],
          "content": "// TODO: Remove this old controller once new one is complete\n// pub mod taskrun_old;\n// pub use taskrun_old::run_taskrun_controller;\n\npub mod task_controller;\n\n// Re-export the main controller function for easy access\npub use task_controller::run_task_controller;\n"
        },
        {
          "path": "core/src/controllers/task_controller/types.rs",
          "file_type": "rust",
          "line_count": 212,
          "key_definitions": [
            "9:pub enum Error {",
            "37:pub enum TaskType {",
            "42:impl TaskType {",
            "43:pub fn name(&self) -> String {",
            "50:pub fn is_docs(&self) -> bool {",
            "54:pub fn service_name(&self) -> &str {",
            "61:pub fn model(&self) -> &str {",
            "68:pub fn github_user(&self) -> &str {",
            "75:pub fn repository_url(&self) -> &str {",
            "82:pub fn source_branch(&self) -> Option<&str> {",
            "90:pub fn working_directory(&self) -> &str {",
            "103:pub fn task_id(&self) -> Option<u32> {",
            "111:pub fn context_version(&self) -> u32 {",
            "118:pub fn retry_count(&self) -> u32 {",
            "125:pub fn session_id(&self) -> Option<&str> {",
            "132:pub fn prompt_modification(&self) -> Option<&str> {",
            "140:pub fn local_tools(&self) -> Option<&str> {",
            "147:pub fn remote_tools(&self) -> Option<&str> {",
            "155:pub fn docs_repository_url(&self) -> Option<&str> {",
            "163:pub fn uses_ssh() -> bool {",
            "168:pub fn ssh_secret_name(&self) -> String {",
            "173:pub fn github_token_secret_name(&self) -> String {",
            "178:pub fn docs_branch(&self) -> &str {",
            "187:pub fn continue_session(&self) -> bool {",
            "198:pub fn overwrite_memory(&self) -> bool {",
            "206:pub fn docs_project_directory(&self) -> Option<&str> {"
          ],
          "content": "use super::config::ControllerConfig;\nuse crate::crds::{CodeRun, DocsRun};\nuse kube::{Client, ResourceExt};\nuse std::sync::Arc;\n\n// Error type for the controller\n#[derive(Debug, thiserror::Error)]\n#[allow(clippy::enum_variant_names)]\npub enum Error {\n    #[error(\"Kubernetes API error: {0}\")]\n    KubeError(#[from] kube::Error),\n\n    #[error(\"Missing object key\")]\n    MissingObjectKey,\n\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(#[from] serde_json::Error),\n\n    #[error(\"Task configuration error: {0}\")]\n    ConfigError(String),\n}\n\npub type Result<T, E = Error> = std::result::Result<T, E>;\n\n// Context shared across controller operations\npub(crate) struct Context {\n    pub client: Client,\n    pub namespace: String,\n    pub config: Arc<ControllerConfig>,\n}\n\n// Finalizer names for cleanup\npub(crate) const DOCS_FINALIZER_NAME: &str = \"docsruns.orchestrator.io/finalizer\";\npub(crate) const CODE_FINALIZER_NAME: &str = \"coderuns.orchestrator.io/finalizer\";\n\n// Enum to represent either task type for shared functionality\npub enum TaskType {\n    Docs(Arc<DocsRun>),\n    Code(Arc<CodeRun>),\n}\n\nimpl TaskType {\n    pub fn name(&self) -> String {\n        match self {\n            TaskType::Docs(dr) => dr.name_any(),\n            TaskType::Code(cr) => cr.name_any(),\n        }\n    }\n\n    pub fn is_docs(&self) -> bool {\n        matches!(self, TaskType::Docs(_))\n    }\n\n    pub fn service_name(&self) -> &str {\n        match self {\n            TaskType::Docs(_) => \"docs-generator\", // Fixed service name for docs\n            TaskType::Code(cr) => &cr.spec.service,\n        }\n    }\n\n    pub fn model(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.model,\n            TaskType::Code(cr) => &cr.spec.model,\n        }\n    }\n\n    pub fn github_user(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.github_user,\n            TaskType::Code(cr) => &cr.spec.github_user,\n        }\n    }\n\n    pub fn repository_url(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.repository_url,\n            TaskType::Code(cr) => &cr.spec.repository_url,\n        }\n    }\n\n    pub fn source_branch(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(dr) => Some(&dr.spec.source_branch),\n            TaskType::Code(_) => None, // CodeRun uses platform_branch instead\n        }\n    }\n\n    /// Get working directory (defaults to service name if not specified)\n    pub fn working_directory(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.working_directory,\n            TaskType::Code(cr) => {\n                // Default to service name if working_directory is None or empty\n                match &cr.spec.working_directory {\n                    Some(wd) if !wd.is_empty() => wd,\n                    _ => &cr.spec.service,\n                }\n            }\n        }\n    }\n\n    pub fn task_id(&self) -> Option<u32> {\n        match self {\n            TaskType::Docs(_) => None, // Docs generation doesn't have a specific task ID\n            TaskType::Code(cr) => Some(cr.spec.task_id),\n        }\n    }\n\n    /// Get retry/versioning information for `CodeRun` (docs don't have retries)\n    pub fn context_version(&self) -> u32 {\n        match self {\n            TaskType::Docs(_) => 1, // Docs don't have context versions\n            TaskType::Code(cr) => cr.spec.context_version,\n        }\n    }\n\n    pub fn retry_count(&self) -> u32 {\n        match self {\n            TaskType::Docs(_) => 0, // Docs don't retry\n            TaskType::Code(cr) => cr.status.as_ref().map_or(0, |s| s.retry_count.unwrap_or(0)),\n        }\n    }\n\n    pub fn session_id(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => cr.status.as_ref().and_then(|s| s.session_id.as_deref()),\n        }\n    }\n\n    pub fn prompt_modification(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => cr.spec.prompt_modification.as_deref(),\n        }\n    }\n\n    /// Get tool configuration for the task\n    pub fn local_tools(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None, // Docs use fixed tool set\n            TaskType::Code(cr) => cr.spec.local_tools.as_deref(),\n        }\n    }\n\n    pub fn remote_tools(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None, // Docs use fixed tool set\n            TaskType::Code(cr) => cr.spec.remote_tools.as_deref(),\n        }\n    }\n\n    /// Get docs repository info (only for `CodeRun`)\n    pub fn docs_repository_url(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => Some(&cr.spec.docs_repository_url),\n        }\n    }\n\n    /// Always use SSH authentication (we're SSH-only now)\n    pub fn uses_ssh() -> bool {\n        true\n    }\n\n    /// Get SSH secret name for this GitHub user\n    pub fn ssh_secret_name(&self) -> String {\n        format!(\"github-ssh-{}\", self.github_user())\n    }\n\n    /// Get GitHub token secret name for this GitHub user\n    pub fn github_token_secret_name(&self) -> String {\n        format!(\"github-token-{}\", self.github_user())\n    }\n\n    /// Get docs branch (only for `CodeRun`)\n    pub fn docs_branch(&self) -> &str {\n        match self {\n            TaskType::Docs(_) => \"main\", // Docs use default branch\n            TaskType::Code(cr) => &cr.spec.docs_branch,\n        }\n    }\n\n    /// Get continue session flag - true for retries or user-requested continuation\n    #[allow(dead_code)]\n    pub fn continue_session(&self) -> bool {\n        match self {\n            TaskType::Docs(_) => false, // Docs don't continue sessions\n            TaskType::Code(cr) => {\n                // Continue if it's a retry attempt OR user explicitly requested it\n                self.retry_count() > 0 || cr.spec.continue_session\n            }\n        }\n    }\n\n    /// Get overwrite memory flag (only for `CodeRun`)\n    pub fn overwrite_memory(&self) -> bool {\n        match self {\n            TaskType::Docs(_) => true, // Docs always overwrite memory\n            TaskType::Code(cr) => cr.spec.overwrite_memory,\n        }\n    }\n\n    /// Get docs project directory (only for `CodeRun`)\n    pub fn docs_project_directory(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => cr.spec.docs_project_directory.as_deref(),\n        }\n    }\n}\n"
        },
        {
          "path": "core/src/controllers/task_controller/config.rs",
          "file_type": "rust",
          "line_count": 348,
          "key_definitions": [
            "12:pub struct ControllerConfig {",
            "38:pub struct JobConfig {",
            "46:pub struct AgentConfig {",
            "57:pub struct ImageConfig {",
            "67:pub struct SecretsConfig {",
            "79:pub struct PermissionsConfig {",
            "93:pub struct TelemetryConfig {",
            "116:pub struct StorageConfig {",
            "132:pub struct CleanupConfig {",
            "169:impl Default for CleanupConfig {",
            "180:impl ControllerConfig {",
            "182:pub fn validate(&self) -> Result<(), anyhow::Error> {",
            "195:pub fn from_mounted_file(config_path: &str) -> Result<Self, anyhow::Error> {",
            "226:impl Default for ControllerConfig {"
          ],
          "content": "//! Task Controller Configuration\n//!\n//! Simplified configuration structure for the new DocsRun/CodeRun controller.\n//! Contains only the essential configuration needed for our current implementation.\n\nuse k8s_openapi::api::core::v1::ConfigMap;\nuse kube::{api::Api, Client};\nuse serde::{Deserialize, Serialize};\n\n/// Main controller configuration structure\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ControllerConfig {\n    /// Job configuration\n    pub job: JobConfig,\n\n    /// Agent configuration\n    pub agent: AgentConfig,\n\n    /// Secrets configuration\n    pub secrets: SecretsConfig,\n\n    /// Tool permissions configuration\n    pub permissions: PermissionsConfig,\n\n    /// Telemetry configuration\n    pub telemetry: TelemetryConfig,\n\n    /// Storage configuration\n    pub storage: StorageConfig,\n\n    /// Cleanup configuration\n    #[serde(default)]\n    pub cleanup: CleanupConfig,\n}\n\n/// Job configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct JobConfig {\n    /// Job timeout in seconds\n    #[serde(rename = \"activeDeadlineSeconds\")]\n    pub active_deadline_seconds: i64,\n}\n\n/// Agent configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct AgentConfig {\n    /// Container image configuration\n    pub image: ImageConfig,\n\n    /// Image pull secrets for private registries\n    #[serde(default, rename = \"imagePullSecrets\")]\n    pub image_pull_secrets: Vec<String>,\n}\n\n/// Image configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ImageConfig {\n    /// Image repository (e.g., \"ghcr.io/5dlabs/claude\")\n    pub repository: String,\n\n    /// Image tag (e.g., \"latest\", \"v2.1.0\")\n    pub tag: String,\n}\n\n/// Secrets configuration - only what we actually use\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct SecretsConfig {\n    /// Anthropic API key secret name (for rotation)\n    #[serde(rename = \"apiKeySecretName\")]\n    pub api_key_secret_name: String,\n\n    /// Anthropic API key secret key\n    #[serde(rename = \"apiKeySecretKey\")]\n    pub api_key_secret_key: String,\n}\n\n/// Tool permissions configuration (used in templates)\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct PermissionsConfig {\n    /// Whether to override default tool permissions\n    #[serde(rename = \"agentToolsOverride\")]\n    pub agent_tools_override: bool,\n\n    /// Allowed tool patterns\n    pub allow: Vec<String>,\n\n    /// Denied tool patterns\n    pub deny: Vec<String>,\n}\n\n/// Telemetry configuration (used in templates)\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct TelemetryConfig {\n    /// Whether telemetry is enabled\n    pub enabled: bool,\n\n    /// OTLP endpoint URL\n    #[serde(rename = \"otlpEndpoint\")]\n    pub otlp_endpoint: String,\n\n    /// OTLP protocol (grpc/http)\n    #[serde(rename = \"otlpProtocol\")]\n    pub otlp_protocol: String,\n\n    /// Logs endpoint (for code tasks)\n    #[serde(rename = \"logsEndpoint\")]\n    pub logs_endpoint: String,\n\n    /// Logs protocol (for code tasks)\n    #[serde(rename = \"logsProtocol\")]\n    pub logs_protocol: String,\n}\n\n/// Storage configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct StorageConfig {\n    /// Storage class name for PVCs (e.g., \"local-path\" for local development)\n    #[serde(rename = \"storageClassName\")]\n    pub storage_class_name: Option<String>,\n\n    /// Storage size for workspace PVCs\n    #[serde(rename = \"workspaceSize\", default = \"default_workspace_size\")]\n    pub workspace_size: String,\n}\n\nfn default_workspace_size() -> String {\n    \"10Gi\".to_string()\n}\n\n/// Cleanup configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct CleanupConfig {\n    /// Whether automatic cleanup is enabled\n    #[serde(default = \"default_cleanup_enabled\")]\n    pub enabled: bool,\n\n    /// Minutes to wait before cleaning up completed (successful) jobs\n    #[serde(\n        rename = \"completedJobDelayMinutes\",\n        default = \"default_completed_delay\"\n    )]\n    pub completed_job_delay_minutes: u64,\n\n    /// Minutes to wait before cleaning up failed jobs\n    #[serde(rename = \"failedJobDelayMinutes\", default = \"default_failed_delay\")]\n    pub failed_job_delay_minutes: u64,\n\n    /// Whether to delete the ConfigMap when cleaning up the job\n    #[serde(rename = \"deleteConfigMap\", default = \"default_delete_configmap\")]\n    pub delete_configmap: bool,\n}\n\nfn default_cleanup_enabled() -> bool {\n    true\n}\n\nfn default_completed_delay() -> u64 {\n    5 // 5 minutes\n}\n\nfn default_failed_delay() -> u64 {\n    60 // 60 minutes (1 hour)\n}\n\nfn default_delete_configmap() -> bool {\n    true\n}\n\nimpl Default for CleanupConfig {\n    fn default() -> Self {\n        CleanupConfig {\n            enabled: default_cleanup_enabled(),\n            completed_job_delay_minutes: default_completed_delay(),\n            failed_job_delay_minutes: default_failed_delay(),\n            delete_configmap: default_delete_configmap(),\n        }\n    }\n}\n\nimpl ControllerConfig {\n    /// Validate that configuration has required fields\n    pub fn validate(&self) -> Result<(), anyhow::Error> {\n        if self.agent.image.repository == \"MISSING_IMAGE_CONFIG\"\n            || self.agent.image.tag == \"MISSING_IMAGE_CONFIG\"\n        {\n            return Err(anyhow::anyhow!(\n                \"Agent image configuration is missing! This indicates the controller ConfigMap was not loaded properly. \\\n                Please ensure the 'agent.image.repository' and 'agent.image.tag' are set in the Helm values.\"\n            ));\n        }\n        Ok(())\n    }\n\n    /// Load configuration from mounted ConfigMap file\n    pub fn from_mounted_file(config_path: &str) -> Result<Self, anyhow::Error> {\n        let config_str = std::fs::read_to_string(config_path)\n            .map_err(|e| anyhow::anyhow!(\"Failed to read config file {}: {}\", config_path, e))?;\n\n        let config: ControllerConfig = serde_yaml::from_str(&config_str)\n            .map_err(|e| anyhow::anyhow!(\"Failed to parse config YAML: {}\", e))?;\n\n        Ok(config)\n    }\n\n    /// Load configuration from a `ConfigMap` (legacy API-based method)\n    pub async fn from_configmap(\n        client: &Client,\n        namespace: &str,\n        name: &str,\n    ) -> Result<Self, anyhow::Error> {\n        let api: Api<ConfigMap> = Api::namespaced(client.clone(), namespace);\n        let cm = api.get(name).await?;\n\n        let data = cm\n            .data\n            .ok_or_else(|| anyhow::anyhow!(\"ConfigMap has no data\"))?;\n        let config_str = data\n            .get(\"config.yaml\")\n            .ok_or_else(|| anyhow::anyhow!(\"ConfigMap missing config.yaml\"))?;\n\n        let config: ControllerConfig = serde_yaml::from_str(config_str)?;\n        Ok(config)\n    }\n}\n\nimpl Default for ControllerConfig {\n    fn default() -> Self {\n        Self {\n            job: JobConfig {\n                active_deadline_seconds: 7200, // 2 hours\n            },\n            agent: AgentConfig {\n                image: ImageConfig {\n                    repository: \"MISSING_IMAGE_CONFIG\".to_string(),\n                    tag: \"MISSING_IMAGE_CONFIG\".to_string(),\n                },\n                image_pull_secrets: vec![\"ghcr-secret\".to_string()],\n            },\n            secrets: SecretsConfig {\n                api_key_secret_name: \"anthropic-api-key\".to_string(),\n                api_key_secret_key: \"api-key\".to_string(),\n            },\n            permissions: PermissionsConfig {\n                agent_tools_override: false,\n                allow: vec![\n                    \"Bash(*)\".to_string(),\n                    \"Edit(*)\".to_string(),\n                    \"Read(*)\".to_string(),\n                    \"Write(*)\".to_string(),\n                    \"MultiEdit(*)\".to_string(),\n                    \"Glob(*)\".to_string(),\n                    \"Grep(*)\".to_string(),\n                    \"LS(*)\".to_string(),\n                ],\n                deny: vec![\n                    \"Bash(npm:install*, yarn:install*, cargo:install*, docker:*, kubectl:*, rm:-rf*, git:*)\".to_string(),\n                ],\n            },\n            // Telemetry configuration with environment variable overrides:\n            // - OTLP_ENDPOINT: OTLP traces endpoint (default: http://localhost:4317)\n            // - LOGS_ENDPOINT: Logs endpoint (default: http://localhost:4318)\n            // - LOGS_PROTOCOL: Logs protocol (default: http)\n            telemetry: TelemetryConfig {\n                enabled: false,\n                otlp_endpoint: std::env::var(\"OTLP_ENDPOINT\")\n                    .unwrap_or_else(|_| \"http://localhost:4317\".to_string()),\n                otlp_protocol: \"grpc\".to_string(),\n                logs_endpoint: std::env::var(\"LOGS_ENDPOINT\")\n                    .unwrap_or_else(|_| \"http://localhost:4318\".to_string()),\n                logs_protocol: std::env::var(\"LOGS_PROTOCOL\")\n                    .unwrap_or_else(|_| \"http\".to_string()),\n            },\n            storage: StorageConfig {\n                storage_class_name: None, // Let K8s use default storage class\n                workspace_size: \"10Gi\".to_string(),\n            },\n            cleanup: CleanupConfig {\n                enabled: true,\n                completed_job_delay_minutes: 5,\n                failed_job_delay_minutes: 60,\n                delete_configmap: true,\n            },\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_deserialization() {\n        let yaml = r#\"\njob:\n  activeDeadlineSeconds: 3600\n\nagent:\n  image:\n    repository: \"test/image\"\n    tag: \"latest\"\n\nsecrets:\n  apiKeySecretName: \"test-secret\"\n  apiKeySecretKey: \"key\"\n\npermissions:\n  agentToolsOverride: true\n  allow: [\"*\"]\n  deny: []\n\ntelemetry:\n  enabled: true\n  otlpEndpoint: \"localhost:4317\"\n  otlpProtocol: \"grpc\"\n  logsEndpoint: \"localhost:4318\"\n  logsProtocol: \"http\"\n\nstorage:\n  storageClassName: \"local-path\"\n  workspaceSize: \"5Gi\"\n\ncleanup:\n  enabled: true\n  completedJobDelayMinutes: 5\n  failedJobDelayMinutes: 60\n  deleteConfigMap: true\n\"#;\n\n        let config: ControllerConfig = serde_yaml::from_str(yaml).unwrap();\n        assert_eq!(config.job.active_deadline_seconds, 3600);\n        assert_eq!(config.agent.image.repository, \"test/image\");\n        assert!(config.telemetry.enabled);\n        assert_eq!(config.permissions.allow, vec![\"*\"]);\n        assert!(config.cleanup.enabled);\n        assert_eq!(config.cleanup.completed_job_delay_minutes, 5);\n        assert_eq!(config.cleanup.failed_job_delay_minutes, 60);\n    }\n\n    #[test]\n    fn test_default_config() {\n        let config = ControllerConfig::default();\n        assert_eq!(config.job.active_deadline_seconds, 7200);\n        assert_eq!(config.agent.image.repository, \"MISSING_IMAGE_CONFIG\");\n        assert_eq!(config.secrets.api_key_secret_name, \"anthropic-api-key\");\n        assert!(!config.telemetry.enabled);\n        assert!(!config.permissions.agent_tools_override);\n    }\n}\n"
        },
        {
          "path": "core/src/controllers/task_controller/auth.rs",
          "file_type": "rust",
          "line_count": 31,
          "key_definitions": [
            "5:pub fn generate_ssh_volumes(task: &TaskType) -> Vec<serde_json::Value> {"
          ],
          "content": "use super::types::TaskType;\nuse serde_json::json;\n\n/// Generate SSH key volume configuration if needed\npub fn generate_ssh_volumes(task: &TaskType) -> Vec<serde_json::Value> {\n    if !TaskType::uses_ssh() {\n        return vec![];\n    }\n\n    let ssh_secret_name = task.ssh_secret_name();\n\n    vec![json!({\n        \"name\": \"ssh-key\",\n        \"secret\": {\n            \"secretName\": ssh_secret_name,\n            \"defaultMode\": 0o600,\n            \"items\": [\n                {\n                    \"key\": \"ssh-privatekey\",\n                    \"path\": \"id_ed25519\",\n                    \"mode\": 0o600\n                },\n                {\n                    \"key\": \"ssh-publickey\",\n                    \"path\": \"id_ed25519.pub\",\n                    \"mode\": 0o644\n                }\n            ]\n        }\n    })]\n}\n"
        },
        {
          "path": "core/src/controllers/task_controller/mod.rs",
          "file_type": "rust",
          "line_count": 19,
          "key_definitions": [],
          "content": "//! Task Controller\n//!\n//! Unified controller for both `DocsRun` and `CodeRun` resources.\n//! Handles job orchestration, resource management, and status tracking.\n\n// Public API - re-export the main controller function\npub use reconcile::run_task_controller;\n\n// Public types - re-export config for external use\npub use config::ControllerConfig;\n\n// Internal modules\npub(crate) mod auth;\npub(crate) mod config;\npub(crate) mod reconcile;\npub(crate) mod resources;\npub(crate) mod status;\npub(crate) mod templates;\npub(crate) mod types;\n"
        },
        {
          "path": "core/src/controllers/task_controller/reconcile.rs",
          "file_type": "rust",
          "line_count": 266,
          "key_definitions": [],
          "content": "use super::config::ControllerConfig;\nuse crate::crds::{CodeRun, DocsRun};\nuse futures::StreamExt;\nuse k8s_openapi::api::{\n    batch::v1::Job,\n    core::v1::{ConfigMap, PersistentVolumeClaim},\n};\nuse kube::{\n    api::Api,\n    runtime::{\n        controller::{Action, Controller},\n        finalizer::{finalizer, Event as FinalizerEvent},\n        watcher::Config,\n    },\n    Client,\n};\nuse std::sync::Arc;\nuse tokio::time::Duration;\nuse tracing::error;\n\nuse super::resources::{cleanup_resources, reconcile_create_or_update};\nuse super::status::monitor_job_status;\nuse super::types::{Context, Error, Result, TaskType, CODE_FINALIZER_NAME, DOCS_FINALIZER_NAME};\n\n/// Run the task controller for both `DocsRun` and `CodeRun` resources\npub async fn run_task_controller(client: Client, namespace: String) -> Result<()> {\n    error!(\n        \"🚀 AGGRESSIVE DEBUG: Starting task controller in namespace: {}\",\n        namespace\n    );\n\n    error!(\"🔧 AGGRESSIVE DEBUG: About to load controller configuration from mounted file...\");\n\n    // Load controller configuration from mounted file\n    let config = match ControllerConfig::from_mounted_file(\"/config/config.yaml\") {\n        Ok(cfg) => {\n            error!(\"✅ AGGRESSIVE DEBUG: Successfully loaded controller configuration from mounted file\");\n            error!(\n                \"🔧 AGGRESSIVE DEBUG: Configuration cleanup enabled = {}\",\n                cfg.cleanup.enabled\n            );\n\n            // Validate configuration has required fields\n            if let Err(validation_error) = cfg.validate() {\n                error!(\n                    \"❌ AGGRESSIVE DEBUG: Configuration validation failed: {}\",\n                    validation_error\n                );\n                return Err(Error::ConfigError(validation_error.to_string()));\n            }\n            error!(\"✅ AGGRESSIVE DEBUG: Configuration validation passed\");\n            cfg\n        }\n        Err(e) => {\n            error!(\n                \"❌ AGGRESSIVE DEBUG: Failed to load configuration from mounted file, using defaults: {}\",\n                e\n            );\n            error!(\"🔧 AGGRESSIVE DEBUG: About to create default configuration...\");\n            let default_config = ControllerConfig::default();\n\n            // Validate default configuration - this should fail if image config is missing\n            if let Err(validation_error) = default_config.validate() {\n                error!(\n                    \"❌ AGGRESSIVE DEBUG: Default configuration is invalid: {}\",\n                    validation_error\n                );\n                return Err(Error::ConfigError(validation_error.to_string()));\n            }\n            error!(\"✅ AGGRESSIVE DEBUG: Default configuration validation passed\");\n            default_config\n        }\n    };\n\n    error!(\"🏗️ AGGRESSIVE DEBUG: Creating controller context...\");\n    let context = Arc::new(Context {\n        client: client.clone(),\n        namespace: namespace.clone(),\n        config: Arc::new(config),\n    });\n\n    error!(\"✅ AGGRESSIVE DEBUG: Controller context created successfully\");\n\n    // Start controllers for both DocsRun and CodeRun\n    error!(\"🔗 AGGRESSIVE DEBUG: Creating API clients for DocsRun and CodeRun...\");\n    let docs_runs = Api::<DocsRun>::namespaced(client.clone(), &namespace);\n    let code_runs = Api::<CodeRun>::namespaced(client.clone(), &namespace);\n\n    error!(\"✅ AGGRESSIVE DEBUG: API clients created, starting controllers...\");\n\n    let docs_controller = Controller::new(docs_runs, Config::default())\n        .shutdown_on_signal()\n        .run(reconcile_docs, error_policy_docs, context.clone())\n        .filter_map(|x| async move { std::result::Result::ok(x) })\n        .for_each(|_| futures::future::ready(()));\n\n    let code_controller = Controller::new(code_runs, Config::default())\n        .shutdown_on_signal()\n        .run(reconcile_code, error_policy_code, context.clone())\n        .filter_map(|x| async move { std::result::Result::ok(x) })\n        .for_each(|_| futures::future::ready(()));\n\n    error!(\"🚀 AGGRESSIVE DEBUG: Both controllers started, entering main loop...\");\n\n    // Run both controllers concurrently\n    tokio::select! {\n        () = docs_controller => error!(\"DocsRun controller finished\"),\n        () = code_controller => error!(\"CodeRun controller finished\"),\n    }\n\n    Ok(())\n}\n\n/// Reconciliation logic for `DocsRun` resources\nasync fn reconcile_docs(docs_run: Arc<DocsRun>, ctx: Arc<Context>) -> Result<Action> {\n    error!(\n        \"📝 AGGRESSIVE DEBUG: Starting reconcile_docs for: {}\",\n        docs_run\n            .metadata\n            .name\n            .as_ref()\n            .unwrap_or(&\"unnamed\".to_string())\n    );\n\n    let task = TaskType::Docs(docs_run.clone());\n    error!(\"🔍 AGGRESSIVE DEBUG: Created task type, calling reconcile_common...\");\n\n    let result = reconcile_common(task, ctx, DOCS_FINALIZER_NAME).await;\n    error!(\n        \"🏁 AGGRESSIVE DEBUG: reconcile_common completed with result: {:?}\",\n        result.is_ok()\n    );\n\n    result\n}\n\n/// Reconcile function for `CodeRun` resources\nasync fn reconcile_code(cr: Arc<CodeRun>, ctx: Arc<Context>) -> Result<Action> {\n    let task = TaskType::Code(cr.clone());\n    reconcile_common(task, ctx, CODE_FINALIZER_NAME).await\n}\n\n/// Common reconciliation logic for both `DocsRun` and `CodeRun`\nasync fn reconcile_common(\n    task: TaskType,\n    ctx: Arc<Context>,\n    finalizer_name: &str,\n) -> Result<Action> {\n    error!(\n        \"🎯 AGGRESSIVE DEBUG: Starting reconcile_common for: {}\",\n        task.name()\n    );\n\n    let namespace = &ctx.namespace;\n    let client = &ctx.client;\n    let name = task.name();\n\n    error!(\n        \"🔄 AGGRESSIVE DEBUG: Reconciling {}: {}\",\n        if task.is_docs() { \"DocsRun\" } else { \"CodeRun\" },\n        name\n    );\n\n    // Create APIs\n    error!(\"🔗 AGGRESSIVE DEBUG: Creating Kubernetes API clients...\");\n    let jobs: Api<Job> = Api::namespaced(client.clone(), namespace);\n    let configmaps: Api<ConfigMap> = Api::namespaced(client.clone(), namespace);\n    let pvcs: Api<PersistentVolumeClaim> = Api::namespaced(client.clone(), namespace);\n    error!(\"✅ AGGRESSIVE DEBUG: API clients created successfully\");\n\n    // Handle finalizers for cleanup based on task type\n    let _result = match &task {\n        TaskType::Docs(dr) => {\n            let docsruns: Api<DocsRun> = Api::namespaced(client.clone(), namespace);\n            finalizer(&docsruns, finalizer_name, dr.clone(), |event| async {\n                match event {\n                    FinalizerEvent::Apply(dr) => {\n                        let task = TaskType::Docs(dr);\n                        reconcile_create_or_update(\n                            task,\n                            &jobs,\n                            &configmaps,\n                            &pvcs,\n                            &ctx.config,\n                            &ctx,\n                        )\n                        .await\n                    }\n                    FinalizerEvent::Cleanup(dr) => {\n                        let task = TaskType::Docs(dr);\n                        cleanup_resources(task, &jobs, &configmaps).await\n                    }\n                }\n            })\n            .await\n        }\n        TaskType::Code(cr) => {\n            let coderuns: Api<CodeRun> = Api::namespaced(client.clone(), namespace);\n            finalizer(&coderuns, finalizer_name, cr.clone(), |event| async {\n                match event {\n                    FinalizerEvent::Apply(cr) => {\n                        let task = TaskType::Code(cr);\n                        reconcile_create_or_update(\n                            task,\n                            &jobs,\n                            &configmaps,\n                            &pvcs,\n                            &ctx.config,\n                            &ctx,\n                        )\n                        .await\n                    }\n                    FinalizerEvent::Cleanup(cr) => {\n                        let task = TaskType::Code(cr);\n                        cleanup_resources(task, &jobs, &configmaps).await\n                    }\n                }\n            })\n            .await\n        }\n    };\n\n    // Handle finalizer errors\n    let _result = _result.map_err(|e| match e {\n        kube::runtime::finalizer::Error::ApplyFailed(err) => err,\n        kube::runtime::finalizer::Error::CleanupFailed(err) => err,\n        kube::runtime::finalizer::Error::AddFinalizer(e) => Error::KubeError(e),\n        kube::runtime::finalizer::Error::RemoveFinalizer(e) => Error::KubeError(e),\n        kube::runtime::finalizer::Error::UnnamedObject => Error::MissingObjectKey,\n        kube::runtime::finalizer::Error::InvalidFinalizer => {\n            Error::ConfigError(\"Invalid finalizer name\".to_string())\n        }\n    })?;\n\n    // Monitor running jobs\n    monitor_running_job(&task, &jobs, &ctx).await?;\n\n    // Requeue after 30 seconds to check status\n    Ok(Action::requeue(Duration::from_secs(30)))\n}\n\n/// Monitor running job status for both task types\nasync fn monitor_running_job(task: &TaskType, jobs: &Api<Job>, ctx: &Arc<Context>) -> Result<()> {\n    let is_running = match task {\n        TaskType::Docs(dr) => dr.status.as_ref().is_some_and(|s| s.phase == \"Running\"),\n        TaskType::Code(cr) => cr.status.as_ref().is_some_and(|s| s.phase == \"Running\"),\n    };\n\n    if is_running {\n        monitor_job_status(task, jobs, ctx).await?;\n    }\n\n    Ok(())\n}\n\n/// Error policy for `DocsRun` controller\nfn error_policy_docs(_dr: Arc<DocsRun>, error: &Error, _ctx: Arc<Context>) -> Action {\n    error!(\"DocsRun reconciliation error: {:?}\", error);\n    Action::requeue(Duration::from_secs(30))\n}\n\n/// Error policy for `CodeRun` controller\nfn error_policy_code(_cr: Arc<CodeRun>, error: &Error, _ctx: Arc<Context>) -> Action {\n    error!(\"CodeRun reconciliation error: {:?}\", error);\n    Action::requeue(Duration::from_secs(30))\n}\n"
        },
        {
          "path": "core/src/controllers/task_controller/status.rs",
          "file_type": "rust",
          "line_count": 347,
          "key_definitions": [],
          "content": "use k8s_openapi::api::batch::v1::Job;\nuse kube::api::{Api, Patch, PatchParams};\nuse serde_json::json;\nuse std::sync::Arc;\nuse tracing::{error, info, warn};\n\nuse super::types::{Context, Result, TaskType};\nuse crate::crds::{CodeRun, CodeRunCondition, DocsRun, DocsRunCondition};\n\n/// Monitor Job status and update CRD accordingly\npub async fn monitor_job_status(\n    task: &TaskType,\n    jobs: &Api<Job>,\n    ctx: &Arc<Context>,\n) -> Result<()> {\n    let job_name = get_current_job_name(task);\n\n    if let Some(job_name) = job_name {\n        // Get the current job\n        match jobs.get(&job_name).await {\n            Ok(job) => {\n                let (phase, message, pull_request_url) = analyze_job_status(&job);\n                update_task_status(task, ctx, &phase, &message, pull_request_url).await?;\n\n                // Schedule cleanup if job is complete and cleanup is enabled\n                if ctx.config.cleanup.enabled && (phase == \"Succeeded\" || phase == \"Failed\") {\n                    schedule_job_cleanup(task, ctx, &job_name, &phase).await?;\n                }\n            }\n            Err(kube::Error::Api(ae)) if ae.code == 404 => {\n                // Job doesn't exist yet, which is fine for newly created tasks\n                info!(\"Job {} not found yet for task {}\", job_name, task.name());\n            }\n            Err(e) => {\n                warn!(\n                    \"Failed to get job {} for task {}: {}\",\n                    job_name,\n                    task.name(),\n                    e\n                );\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Get the current job name for a task\nfn get_current_job_name(task: &TaskType) -> Option<String> {\n    match task {\n        TaskType::Docs(dr) => dr.status.as_ref().and_then(|s| s.job_name.clone()),\n        TaskType::Code(cr) => cr.status.as_ref().and_then(|s| s.job_name.clone()),\n    }\n}\n\n/// Analyze job status and return (phase, message, `pull_request_url`)\nfn analyze_job_status(job: &Job) -> (String, String, Option<String>) {\n    if let Some(status) = &job.status {\n        // Check completion time first\n        if status.completion_time.is_some() {\n            if let Some(conditions) = &status.conditions {\n                for condition in conditions {\n                    if condition.type_ == \"Complete\" && condition.status == \"True\" {\n                        return (\n                            \"Succeeded\".to_string(),\n                            \"Job completed successfully\".to_string(),\n                            None,\n                        );\n                    } else if condition.type_ == \"Failed\" && condition.status == \"True\" {\n                        let message = condition.message.as_deref().unwrap_or(\"Job failed\");\n                        return (\"Failed\".to_string(), message.to_string(), None);\n                    }\n                }\n            }\n        }\n\n        // Check if job is running\n        if let Some(active) = status.active {\n            if active > 0 {\n                return (\"Running\".to_string(), \"Job is running\".to_string(), None);\n            }\n        }\n\n        // Check for failure conditions\n        if let Some(failed) = status.failed {\n            if failed > 0 {\n                return (\"Failed\".to_string(), \"Job failed\".to_string(), None);\n            }\n        }\n    }\n\n    // Default to pending if we can't determine status\n    (\n        \"Pending\".to_string(),\n        \"Job status unknown\".to_string(),\n        None,\n    )\n}\n\n/// Update the task CRD status\nasync fn update_task_status(\n    task: &TaskType,\n    ctx: &Arc<Context>,\n    phase: &str,\n    message: &str,\n    pull_request_url: Option<String>,\n) -> Result<()> {\n    let namespace = &ctx.namespace;\n    let client = &ctx.client;\n    let name = task.name();\n\n    let current_time = chrono::Utc::now().to_rfc3339();\n\n    match task {\n        TaskType::Docs(_dr) => {\n            let docs_api: Api<DocsRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": phase,\n                    \"message\": message,\n                    \"lastUpdate\": current_time,\n                    \"pullRequestUrl\": pull_request_url,\n                    \"conditions\": build_docs_conditions(phase, message, &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            let pp = PatchParams::default();\n\n            match docs_api.patch_status(&name, &pp, &patch).await {\n                Ok(_) => {\n                    info!(\"Updated DocsRun status: {} -> {}\", name, phase);\n                }\n                Err(e) => {\n                    error!(\"Failed to update DocsRun status for {}: {}\", name, e);\n                }\n            }\n        }\n        TaskType::Code(cr) => {\n            let code_api: Api<CodeRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": phase,\n                    \"message\": message,\n                    \"lastUpdate\": current_time,\n                    \"pullRequestUrl\": pull_request_url,\n                    \"retryCount\": cr.status.as_ref().map_or(0, |s| s.retry_count.unwrap_or(0)),\n                    \"conditions\": build_code_conditions(phase, message, &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            let pp = PatchParams::default();\n\n            match code_api.patch_status(&name, &pp, &patch).await {\n                Ok(_) => {\n                    info!(\"Updated CodeRun status: {} -> {}\", name, phase);\n                }\n                Err(e) => {\n                    error!(\"Failed to update CodeRun status for {}: {}\", name, e);\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Build conditions for `DocsRun` status\nfn build_docs_conditions(phase: &str, message: &str, timestamp: &str) -> Vec<DocsRunCondition> {\n    vec![DocsRunCondition {\n        condition_type: \"Ready\".to_string(),\n        status: if phase == \"Succeeded\" {\n            \"True\"\n        } else {\n            \"False\"\n        }\n        .to_string(),\n        last_transition_time: Some(timestamp.to_string()),\n        reason: Some(phase.to_string()),\n        message: Some(message.to_string()),\n    }]\n}\n\n/// Build conditions for `CodeRun` status\nfn build_code_conditions(phase: &str, message: &str, timestamp: &str) -> Vec<CodeRunCondition> {\n    vec![CodeRunCondition {\n        condition_type: \"Ready\".to_string(),\n        status: if phase == \"Succeeded\" {\n            \"True\"\n        } else {\n            \"False\"\n        }\n        .to_string(),\n        last_transition_time: Some(timestamp.to_string()),\n        reason: Some(phase.to_string()),\n        message: Some(message.to_string()),\n    }]\n}\n\n/// Update task status when job starts (called from reconcile logic)\npub async fn update_job_started(\n    task: &TaskType,\n    ctx: &Arc<Context>,\n    job_name: &str,\n    configmap_name: &str,\n) -> Result<()> {\n    let namespace = &ctx.namespace;\n    let client = &ctx.client;\n    let name = task.name();\n    let current_time = chrono::Utc::now().to_rfc3339();\n\n    match task {\n        TaskType::Docs(_) => {\n            let docs_api: Api<DocsRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": \"Running\",\n                    \"message\": \"Job started\",\n                    \"lastUpdate\": current_time,\n                    \"jobName\": job_name,\n                    \"configmapName\": configmap_name,\n                    \"conditions\": build_docs_conditions(\"Running\", \"Job started\", &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            docs_api\n                .patch_status(&name, &PatchParams::default(), &patch)\n                .await?;\n        }\n        TaskType::Code(_) => {\n            let code_api: Api<CodeRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": \"Running\",\n                    \"message\": \"Job started\",\n                    \"lastUpdate\": current_time,\n                    \"jobName\": job_name,\n                    \"configmapName\": configmap_name,\n                    \"conditions\": build_code_conditions(\"Running\", \"Job started\", &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            code_api\n                .patch_status(&name, &PatchParams::default(), &patch)\n                .await?;\n        }\n    }\n\n    info!(\"Updated {} status to Running with job: {}\", name, job_name);\n    Ok(())\n}\n\n/// Schedule cleanup of completed job after configured delay\nasync fn schedule_job_cleanup(\n    task: &TaskType,\n    ctx: &Arc<Context>,\n    job_name: &str,\n    phase: &str,\n) -> Result<()> {\n    let delay_minutes = if phase == \"Succeeded\" {\n        ctx.config.cleanup.completed_job_delay_minutes\n    } else {\n        ctx.config.cleanup.failed_job_delay_minutes\n    };\n\n    let job_name = job_name.to_string();\n    let task_name = task.name();\n    let namespace = ctx.namespace.clone();\n    let client = ctx.client.clone();\n    let delete_configmap = ctx.config.cleanup.delete_configmap;\n\n    info!(\n        \"Scheduling cleanup for job {} in {} minutes (phase: {})\",\n        job_name, delay_minutes, phase\n    );\n\n    // Spawn background task to handle cleanup after delay\n    tokio::spawn(async move {\n        // Wait for the configured delay\n        tokio::time::sleep(tokio::time::Duration::from_secs(delay_minutes * 60)).await;\n\n        info!(\"Starting scheduled cleanup for job: {}\", job_name);\n\n        // Delete the job\n        let jobs_api: Api<Job> = Api::namespaced(client.clone(), &namespace);\n        match jobs_api\n            .delete(&job_name, &kube::api::DeleteParams::background())\n            .await\n        {\n            Ok(_) => info!(\"Successfully deleted job: {}\", job_name),\n            Err(kube::Error::Api(ae)) if ae.code == 404 => {\n                info!(\"Job {} already deleted\", job_name);\n            }\n            Err(e) => {\n                error!(\"Failed to delete job {}: {}\", job_name, e);\n            }\n        }\n\n        // Delete associated ConfigMap if enabled\n        if delete_configmap {\n            let configmaps_api: Api<k8s_openapi::api::core::v1::ConfigMap> =\n                Api::namespaced(client.clone(), &namespace);\n\n            // Find ConfigMap associated with this job\n            let labels_selector = \"app=orchestrator\".to_string();\n            let list_params = kube::api::ListParams::default().labels(&labels_selector);\n\n            match configmaps_api.list(&list_params).await {\n                Ok(cms) => {\n                    for cm in cms.items {\n                        if let Some(cm_name) = &cm.metadata.name {\n                            // Check if ConfigMap is associated with this job\n                            if cm_name.starts_with(&task_name.replace('_', \"-\")) {\n                                match configmaps_api\n                                    .delete(cm_name, &kube::api::DeleteParams::default())\n                                    .await\n                                {\n                                    Ok(_) => info!(\"Successfully deleted ConfigMap: {}\", cm_name),\n                                    Err(kube::Error::Api(ae)) if ae.code == 404 => {\n                                        info!(\"ConfigMap {} already deleted\", cm_name);\n                                    }\n                                    Err(e) => {\n                                        error!(\"Failed to delete ConfigMap {}: {}\", cm_name, e);\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Err(e) => {\n                    error!(\"Failed to list ConfigMaps for cleanup: {}\", e);\n                }\n            }\n        }\n\n        info!(\"Completed cleanup for job: {}\", job_name);\n    });\n\n    Ok(())\n}\n"
        },
        {
          "path": "core/src/controllers/task_controller/resources.rs",
          "file_type": "rust",
          "line_count": 612,
          "key_definitions": [],
          "content": "use super::config::ControllerConfig;\nuse k8s_openapi::api::{\n    batch::v1::Job,\n    core::v1::{ConfigMap, PersistentVolumeClaim},\n};\nuse k8s_openapi::apimachinery::pkg::apis::meta::v1::{ObjectMeta, OwnerReference};\nuse kube::api::{Api, DeleteParams, ListParams, PostParams};\nuse kube::runtime::controller::Action;\nuse serde_json::json;\nuse std::collections::BTreeMap;\nuse std::sync::Arc;\nuse tracing::info;\n\nuse super::auth::generate_ssh_volumes;\nuse super::status::update_job_started;\nuse super::templates::generate_templates;\nuse super::types::{Result, TaskType};\n\n/// Reconciliation logic for create/update operations\npub async fn reconcile_create_or_update(\n    task: TaskType,\n    jobs: &Api<Job>,\n    configmaps: &Api<ConfigMap>,\n    pvcs: &Api<PersistentVolumeClaim>,\n    config: &Arc<ControllerConfig>,\n    ctx: &Arc<super::types::Context>,\n) -> Result<Action> {\n    let name = task.name();\n    info!(\"Creating/updating resources for task: {}\", name);\n\n    // Ensure PVC exists for code tasks (docs use emptyDir)\n    if !task.is_docs() {\n        let service_name = task.service_name();\n        let pvc_name = format!(\"workspace-{service_name}\");\n        ensure_pvc_exists(pvcs, &pvc_name, service_name, config).await?;\n    }\n\n    // Clean up older versions for retries\n    cleanup_old_jobs(&task, jobs).await?;\n    cleanup_old_configmaps(&task, configmaps).await?;\n\n    // Create ConfigMap FIRST (without owner reference) so Job can mount it\n    let cm_name = generate_configmap_name(&task);\n    let configmap = create_configmap(&task, &cm_name, config, None)?;\n\n    match configmaps.create(&PostParams::default(), &configmap).await {\n        Ok(_) => info!(\"Created ConfigMap: {}\", cm_name),\n        Err(kube::Error::Api(ae)) if ae.code == 409 => {\n            info!(\"ConfigMap already exists: {}\", cm_name);\n        }\n        Err(e) => return Err(e.into()),\n    }\n\n    // Create Job SECOND (now it can successfully mount the existing ConfigMap)\n    let job_ref = create_job(&task, jobs, &cm_name, config, ctx).await?;\n\n    // Update ConfigMap with Job as owner (for automatic cleanup on job deletion)\n    if let Some(owner_ref) = job_ref {\n        update_configmap_owner(&task, configmaps, &cm_name, owner_ref).await?;\n    }\n\n    Ok(Action::await_change())\n}\n\n/// Generate a unique `ConfigMap` name for the task\nfn generate_configmap_name(task: &TaskType) -> String {\n    let task_id = task.task_id().unwrap_or(0); // Fallback for docs\n    let service_name = task.service_name().replace('_', \"-\");\n    let context_version = task.context_version();\n\n    if task.is_docs() {\n        format!(\"{service_name}-docs-v{context_version}-files\")\n    } else {\n        format!(\"{service_name}-task{task_id}-v{context_version}-files\")\n    }\n}\n\n/// Create `ConfigMap` with all template files\nfn create_configmap(\n    task: &TaskType,\n    name: &str,\n    config: &ControllerConfig,\n    owner_ref: Option<OwnerReference>,\n) -> Result<ConfigMap> {\n    let mut data = BTreeMap::new();\n\n    // Generate all templates for this task\n    let templates = generate_templates(task, config)?;\n    for (filename, content) in templates {\n        data.insert(filename, content);\n    }\n\n    let labels = create_task_labels(task);\n    let mut metadata = ObjectMeta {\n        name: Some(name.to_string()),\n        labels: Some(labels),\n        ..Default::default()\n    };\n\n    // Set owner reference if provided (for automatic cleanup)\n    if let Some(owner) = owner_ref {\n        metadata.owner_references = Some(vec![owner]);\n    }\n\n    Ok(ConfigMap {\n        metadata,\n        data: Some(data),\n        ..Default::default()\n    })\n}\n\n/// Create the main job for the task\nasync fn create_job(\n    task: &TaskType,\n    jobs: &Api<Job>,\n    cm_name: &str,\n    config: &ControllerConfig,\n    ctx: &Arc<super::types::Context>,\n) -> Result<Option<OwnerReference>> {\n    let job_name = generate_job_name(task);\n    let job = build_job_spec(task, &job_name, cm_name, config)?;\n\n    match jobs.create(&PostParams::default(), &job).await {\n        Ok(created_job) => {\n            info!(\"Created job: {}\", job_name);\n            update_job_started(task, ctx, &job_name, cm_name).await?;\n\n            // Return owner reference for the created job\n            if let (Some(uid), Some(name)) = (created_job.metadata.uid, created_job.metadata.name) {\n                Ok(Some(OwnerReference {\n                    api_version: \"batch/v1\".to_string(),\n                    kind: \"Job\".to_string(),\n                    name,\n                    uid,\n                    controller: Some(true),\n                    block_owner_deletion: Some(true),\n                }))\n            } else {\n                Ok(None)\n            }\n        }\n        Err(kube::Error::Api(ae)) if ae.code == 409 => {\n            info!(\"Job already exists: {}\", job_name);\n            // Try to get existing job for owner reference\n            match jobs.get(&job_name).await {\n                Ok(existing_job) => {\n                    if let (Some(uid), Some(name)) =\n                        (existing_job.metadata.uid, existing_job.metadata.name)\n                    {\n                        Ok(Some(OwnerReference {\n                            api_version: \"batch/v1\".to_string(),\n                            kind: \"Job\".to_string(),\n                            name,\n                            uid,\n                            controller: Some(true),\n                            block_owner_deletion: Some(true),\n                        }))\n                    } else {\n                        Ok(None)\n                    }\n                }\n                Err(_) => Ok(None),\n            }\n        }\n        Err(e) => Err(e.into()),\n    }\n}\n\n/// Generate a deterministic job name for the task (based on resource name, not timestamp)\nfn generate_job_name(task: &TaskType) -> String {\n    let resource_name = task.name().replace(['_', '.'], \"-\");\n    match task {\n        TaskType::Docs(_) => {\n            format!(\"docs-gen-{resource_name}\")\n        }\n        TaskType::Code(_) => {\n            let task_id = task.task_id().unwrap_or(0);\n            let context_version = task.context_version();\n            format!(\"code-impl-{resource_name}-task{task_id}-v{context_version}\")\n        }\n    }\n}\n\n/// Build the complete Job specification\nfn build_job_spec(\n    task: &TaskType,\n    job_name: &str,\n    cm_name: &str,\n    config: &ControllerConfig,\n) -> Result<Job> {\n    let labels = create_task_labels(task);\n\n    // Build volumes based on task type\n    let mut volumes = vec![];\n    let mut volume_mounts = vec![];\n\n    // ConfigMap volume (always needed)\n    volumes.push(json!({\n        \"name\": \"task-files\",\n        \"configMap\": {\n            \"name\": cm_name\n        }\n    }));\n    volume_mounts.push(json!({\n        \"name\": \"task-files\",\n        \"mountPath\": \"/config\"\n    }));\n\n    // Workspace volume (only for code tasks)\n    if !task.is_docs() {\n        let service_name = task.service_name();\n        let pvc_name = format!(\"workspace-{service_name}\");\n\n        volumes.push(json!({\n            \"name\": \"workspace\",\n            \"persistentVolumeClaim\": {\n                \"claimName\": pvc_name\n            }\n        }));\n        volume_mounts.push(json!({\n            \"name\": \"workspace\",\n            \"mountPath\": \"/workspace\"\n        }));\n    }\n\n    // SSH volumes if needed\n    if TaskType::uses_ssh() {\n        let ssh_volumes = generate_ssh_volumes(task);\n        volumes.extend(ssh_volumes);\n\n        volume_mounts.push(json!({\n            \"name\": \"ssh-key\",\n            \"mountPath\": \"/workspace/.ssh\",\n            \"readOnly\": true\n        }));\n    }\n\n    // Mount settings.json directly to /etc/claude-code/managed-settings.json\n    volume_mounts.push(json!({\n        \"name\": \"task-files\",\n        \"mountPath\": \"/etc/claude-code/managed-settings.json\",\n        \"subPath\": \"settings.json\",\n        \"readOnly\": true\n    }));\n\n    // Guidelines files will be copied from ConfigMap to working directory by container.sh\n    // No need to mount them separately since they need to be in the working directory\n\n    // Environment variables\n    let mut env_vars = vec![\n        json!({\"name\": \"ANTHROPIC_API_KEY\", \"valueFrom\": {\"secretKeyRef\": {\"name\": config.secrets.api_key_secret_name, \"key\": config.secrets.api_key_secret_key}}}),\n        json!({\"name\": \"TASK_TYPE\", \"value\": if task.is_docs() { \"docs\" } else { \"code\" }}),\n        json!({\"name\": \"MODEL\", \"value\": task.model()}),\n        json!({\"name\": \"GITHUB_USER\", \"value\": task.github_user()}),\n        json!({\"name\": \"REPOSITORY_URL\", \"value\": task.repository_url()}),\n        json!({\"name\": \"WORKING_DIRECTORY\", \"value\": task.working_directory()}),\n    ];\n\n    // Add GitHub token from secret for API operations (PR creation, etc.)\n    env_vars.push(json!({\n        \"name\": \"GH_TOKEN\",\n        \"valueFrom\": {\n            \"secretKeyRef\": {\n                \"name\": task.github_token_secret_name(),\n                \"key\": \"token\"\n            }\n        }\n    }));\n\n    // Add task-specific environment variables\n    match task {\n        TaskType::Docs(dr) => {\n            env_vars.push(json!({\"name\": \"SOURCE_BRANCH\", \"value\": dr.spec.source_branch}));\n        }\n        TaskType::Code(cr) => {\n            env_vars.push(json!({\"name\": \"TASK_ID\", \"value\": cr.spec.task_id.to_string()}));\n            env_vars.push(json!({\"name\": \"SERVICE_NAME\", \"value\": cr.spec.service}));\n            env_vars\n                .push(json!({\"name\": \"DOCS_REPOSITORY_URL\", \"value\": cr.spec.docs_repository_url}));\n            env_vars\n                .push(json!({\"name\": \"MCP_CLIENT_CONFIG\", \"value\": \"/.claude/client-config.json\"}));\n\n            if let Some(local_tools) = &cr.spec.local_tools {\n                env_vars.push(json!({\"name\": \"LOCAL_TOOLS\", \"value\": local_tools}));\n            }\n            if let Some(remote_tools) = &cr.spec.remote_tools {\n                env_vars.push(json!({\"name\": \"REMOTE_TOOLS\", \"value\": remote_tools}));\n            }\n\n            // Add toolman server URL for MCP integration\n            // Environment variable: TOOLMAN_SERVER_URL (default: http://toolman.mcp.svc.cluster.local:3000/mcp)\n            let toolman_url = std::env::var(\"TOOLMAN_SERVER_URL\")\n                .unwrap_or_else(|_| \"http://toolman.mcp.svc.cluster.local:3000/mcp\".to_string());\n            env_vars.push(json!({\"name\": \"TOOLMAN_SERVER_URL\", \"value\": toolman_url}));\n\n            // Add custom environment variables\n            for (name, value) in &cr.spec.env {\n                env_vars.push(json!({\"name\": name, \"value\": value}));\n            }\n\n            // Add environment variables from secrets\n            for secret_env in &cr.spec.env_from_secrets {\n                env_vars.push(json!({\n                    \"name\": secret_env.name,\n                    \"valueFrom\": {\n                        \"secretKeyRef\": {\n                            \"name\": secret_env.secret_name,\n                            \"key\": secret_env.secret_key\n                        }\n                    }\n                }));\n            }\n        }\n    }\n\n    // Job deadline from config\n    let job_deadline = config.job.active_deadline_seconds;\n\n    // Agent image from config\n    let agent_image = format!(\n        \"{}:{}\",\n        config.agent.image.repository, config.agent.image.tag\n    );\n\n    let job_spec = json!({\n        \"apiVersion\": \"batch/v1\",\n        \"kind\": \"Job\",\n        \"metadata\": {\n            \"name\": job_name,\n            \"labels\": labels\n        },\n        \"spec\": {\n            \"activeDeadlineSeconds\": job_deadline,\n            \"backoffLimit\": 0,\n            \"template\": {\n                \"metadata\": {\n                    \"labels\": labels\n                },\n                \"spec\": {\n                    \"restartPolicy\": \"Never\",\n                    \"securityContext\": {\n                        \"fsGroup\": 1000,\n                        \"runAsUser\": 1000,\n                        \"runAsGroup\": 1000\n                    },\n                    \"imagePullSecrets\": config.agent.image_pull_secrets.iter().map(|name| {\n                        json!({\"name\": name})\n                    }).collect::<Vec<_>>(),\n                    \"containers\": [{\n                        \"name\": \"claude\",\n                        \"image\": agent_image,\n                        \"command\": [\"/bin/bash\", \"/config/container.sh\"],\n                        \"env\": env_vars,\n                        \"volumeMounts\": volume_mounts,\n                        \"resources\": {\n                            \"requests\": {\n                                \"cpu\": \"100m\",\n                                \"memory\": \"256Mi\"\n                            },\n                            \"limits\": {\n                                \"cpu\": \"2\",\n                                \"memory\": \"4Gi\"\n                            }\n                        }\n                    }],\n                    \"volumes\": volumes\n                }\n            }\n        }\n    });\n\n    Ok(serde_json::from_value(job_spec)?)\n}\n\n/// Create standard labels for task resources\nfn create_task_labels(task: &TaskType) -> BTreeMap<String, String> {\n    let mut labels = BTreeMap::new();\n\n    labels.insert(\"app\".to_string(), \"orchestrator\".to_string());\n    labels.insert(\n        \"component\".to_string(),\n        if task.is_docs() {\n            \"docs-generator\"\n        } else {\n            \"code-runner\"\n        }\n        .to_string(),\n    );\n    labels.insert(\n        \"github-user\".to_string(),\n        sanitize_label_value(task.github_user()),\n    );\n    labels.insert(\n        \"context-version\".to_string(),\n        task.context_version().to_string(),\n    );\n\n    match task {\n        TaskType::Docs(_) => {\n            labels.insert(\"task-type\".to_string(), \"docs\".to_string());\n        }\n        TaskType::Code(_) => {\n            labels.insert(\"task-type\".to_string(), \"code\".to_string());\n            if let Some(task_id) = task.task_id() {\n                labels.insert(\"task-id\".to_string(), task_id.to_string());\n            }\n            labels.insert(\"service-name\".to_string(), task.service_name().to_string());\n        }\n    }\n\n    labels\n}\n\n/// Sanitize a string value for use as a Kubernetes label value\n/// Kubernetes labels must be an empty string or consist of alphanumeric characters, '-', '_' or '.',\n/// and must start and end with an alphanumeric character\nfn sanitize_label_value(input: &str) -> String {\n    if input.is_empty() {\n        return String::new();\n    }\n\n    // Replace spaces with hyphens, convert to lowercase\n    let mut sanitized = input.to_lowercase().replace([' ', '_'], \"-\"); // Normalize spaces and underscores to hyphens\n\n    // Remove any characters that aren't alphanumeric, hyphens, underscores, or dots\n    sanitized.retain(|c| c.is_alphanumeric() || c == '-' || c == '_' || c == '.');\n\n    // Ensure it starts with an alphanumeric character\n    while !sanitized.is_empty() && !sanitized.chars().next().unwrap().is_alphanumeric() {\n        sanitized.remove(0);\n    }\n\n    // Ensure it ends with an alphanumeric character\n    while !sanitized.is_empty() && !sanitized.chars().last().unwrap().is_alphanumeric() {\n        sanitized.pop();\n    }\n\n    // If we ended up with an empty string, provide a fallback\n    if sanitized.is_empty() {\n        \"unknown\".to_string()\n    } else {\n        sanitized\n    }\n}\n\n/// Ensure PVC exists for the given service\nasync fn ensure_pvc_exists(\n    pvcs: &Api<PersistentVolumeClaim>,\n    pvc_name: &str,\n    service_name: &str,\n    config: &ControllerConfig,\n) -> Result<()> {\n    match pvcs.get(pvc_name).await {\n        Ok(_) => {\n            info!(\"PVC already exists: {}\", pvc_name);\n            return Ok(());\n        }\n        Err(kube::Error::Api(ae)) if ae.code == 404 => {\n            // PVC doesn't exist, create it\n        }\n        Err(e) => return Err(e.into()),\n    }\n\n    let mut pvc_spec = json!({\n        \"apiVersion\": \"v1\",\n        \"kind\": \"PersistentVolumeClaim\",\n        \"metadata\": {\n            \"name\": pvc_name,\n            \"labels\": {\n                \"app\": \"orchestrator\",\n                \"service\": service_name\n            }\n        },\n        \"spec\": {\n            \"accessModes\": [\"ReadWriteOnce\"],\n            \"resources\": {\n                \"requests\": {\n                    \"storage\": config.storage.workspace_size\n                }\n            }\n        }\n    });\n\n    // Add storage class if specified\n    if let Some(storage_class) = &config.storage.storage_class_name {\n        pvc_spec[\"spec\"][\"storageClassName\"] = json!(storage_class);\n    }\n\n    let pvc: PersistentVolumeClaim = serde_json::from_value(pvc_spec)?;\n    pvcs.create(&PostParams::default(), &pvc).await?;\n    info!(\"Created PVC: {}\", pvc_name);\n\n    Ok(())\n}\n\n/// Clean up older job versions for retry attempts\nasync fn cleanup_old_jobs(task: &TaskType, jobs: &Api<Job>) -> Result<()> {\n    if let Some(task_id) = task.task_id() {\n        let current_version = task.context_version();\n\n        let job_list = jobs\n            .list(&ListParams::default().labels(&format!(\"task-id={task_id}\")))\n            .await?;\n\n        for job in job_list.items {\n            if let Some(version) = job\n                .metadata\n                .labels\n                .as_ref()\n                .and_then(|l| l.get(\"context-version\"))\n                .and_then(|v| v.parse::<u32>().ok())\n            {\n                if version < current_version {\n                    if let Some(job_name) = &job.metadata.name {\n                        jobs.delete(job_name, &DeleteParams::background()).await?;\n                        info!(\"Deleted older job version: {}\", job_name);\n                    }\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Clean up older configmap versions for retry attempts\nasync fn cleanup_old_configmaps(task: &TaskType, configmaps: &Api<ConfigMap>) -> Result<()> {\n    if let Some(task_id) = task.task_id() {\n        let current_version = task.context_version();\n\n        let cm_list = configmaps\n            .list(&ListParams::default().labels(&format!(\"task-id={task_id}\")))\n            .await?;\n\n        for cm in cm_list.items {\n            if let Some(version) = cm\n                .metadata\n                .labels\n                .as_ref()\n                .and_then(|l| l.get(\"context-version\"))\n                .and_then(|v| v.parse::<u32>().ok())\n            {\n                if version < current_version {\n                    if let Some(cm_name) = &cm.metadata.name {\n                        configmaps.delete(cm_name, &DeleteParams::default()).await?;\n                        info!(\"Deleted older configmap version: {}\", cm_name);\n                    }\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Update the owner reference of an existing `ConfigMap`\nasync fn update_configmap_owner(\n    _task: &TaskType,\n    configmaps: &Api<ConfigMap>,\n    cm_name: &str,\n    owner_ref: OwnerReference,\n) -> Result<()> {\n    let mut configmap = configmaps.get(cm_name).await?;\n    configmap.metadata.owner_references = Some(vec![owner_ref]);\n    configmaps\n        .replace(cm_name, &PostParams::default(), &configmap)\n        .await?;\n    info!(\"Updated ConfigMap owner reference for: {}\", cm_name);\n    Ok(())\n}\n\n/// Cleanup resources when task is deleted\npub async fn cleanup_resources(\n    task: TaskType,\n    jobs: &Api<Job>,\n    configmaps: &Api<ConfigMap>,\n) -> Result<Action> {\n    let task_label = if let Some(task_id) = task.task_id() {\n        format!(\"task-id={task_id}\")\n    } else {\n        format!(\n            \"task-type=docs,github-user={}\",\n            sanitize_label_value(task.github_user())\n        )\n    };\n\n    info!(\"Cleaning up resources for task: {}\", task.name());\n\n    // Delete all jobs for this task\n    let job_list = jobs\n        .list(&ListParams::default().labels(&task_label))\n        .await?;\n    for job in job_list.items {\n        if let Some(name) = &job.metadata.name {\n            jobs.delete(name, &DeleteParams::background()).await?;\n            info!(\"Deleted job: {}\", name);\n        }\n    }\n\n    // Delete all configmaps for this task\n    let cm_list = configmaps\n        .list(&ListParams::default().labels(&task_label))\n        .await?;\n    for cm in cm_list.items {\n        if let Some(name) = &cm.metadata.name {\n            configmaps.delete(name, &DeleteParams::default()).await?;\n            info!(\"Deleted configmap: {}\", name);\n        }\n    }\n\n    Ok(Action::await_change())\n}\n"
        },
        {
          "path": "core/src/controllers/task_controller/templates.rs",
          "file_type": "rust",
          "line_count": 541,
          "key_definitions": [
            "32:pub fn generate_templates("
          ],
          "content": "use super::config::ControllerConfig;\nuse super::types::{Result, TaskType};\nuse handlebars::Handlebars;\nuse serde_json::json;\nuse std::collections::BTreeMap;\nuse std::fs;\nuse std::path::Path;\nuse tracing::debug;\n\n// Template base path (mounted from ConfigMap)\nconst CLAUDE_TEMPLATES_PATH: &str = \"/claude-templates\";\n\n/// Load a template file from the mounted `ConfigMap`\nfn load_template(relative_path: &str) -> Result<String> {\n    // Convert path separators to underscores for ConfigMap key lookup\n    let configmap_key = relative_path.replace('/', \"_\");\n    let full_path = Path::new(CLAUDE_TEMPLATES_PATH).join(&configmap_key);\n    debug!(\n        \"Loading template from: {} (key: {})\",\n        full_path.display(),\n        configmap_key\n    );\n\n    fs::read_to_string(&full_path).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to load template {relative_path} (key: {configmap_key}): {e}\"\n        ))\n    })\n}\n\n/// Generate all template files for a task\npub fn generate_templates(\n    task: &TaskType,\n    config: &ControllerConfig,\n) -> Result<BTreeMap<String, String>> {\n    let mut templates = BTreeMap::new();\n\n    // Generate container startup script\n    templates.insert(\"container.sh\".to_string(), generate_container_script(task)?);\n\n    // Generate Claude memory\n    templates.insert(\"CLAUDE.md\".to_string(), generate_claude_memory(task)?);\n\n    // Generate Claude settings\n    templates.insert(\n        \"settings.json\".to_string(),\n        generate_claude_settings(task, config)?,\n    );\n\n    // Generate task-specific templates\n    if task.is_docs() {\n        // Generate docs prompt\n        templates.insert(\"prompt.md\".to_string(), generate_docs_prompt(task)?);\n    } else {\n        // Generate code-specific templates\n        templates.insert(\"mcp.json\".to_string(), generate_mcp_config(task, config)?);\n        templates.insert(\n            \"client-config.json\".to_string(),\n            generate_client_config(task, config)?,\n        );\n        templates.insert(\n            \"coding-guidelines.md\".to_string(),\n            generate_coding_guidelines(task)?,\n        );\n        templates.insert(\n            \"github-guidelines.md\".to_string(),\n            generate_github_guidelines(task)?,\n        );\n        templates.insert(\"mcp-tools.md\".to_string(), generate_mcp_tools_doc(task)?);\n    }\n\n    // Generate hook scripts\n    let hook_scripts = generate_hook_scripts(task)?;\n    for (filename, content) in hook_scripts {\n        // Use hooks- prefix to comply with ConfigMap key constraints\n        templates.insert(format!(\"hooks-{filename}\"), content);\n    }\n\n    Ok(templates)\n}\n\n/// Generate CLAUDE.md content from memory template\nfn generate_claude_memory(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template_path = if task.is_docs() {\n        \"docs/claude.md.hbs\"\n    } else {\n        \"code/claude.md.hbs\"\n    };\n\n    let template = load_template(template_path)?;\n\n    handlebars\n        .register_template_string(\"claude_memory\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register CLAUDE.md template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"repository\": json!({\n            \"url\": task.repository_url(),\n            \"githubUser\": task.github_user()\n        }),\n        \"working_directory\": task.working_directory(),\n        \"task_id\": task.task_id(),\n        \"docs_repository_url\": task.docs_repository_url()\n    });\n\n    handlebars.render(\"claude_memory\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render CLAUDE.md template: {e}\"\n        ))\n    })\n}\n\n/// Generate Claude Code settings.json for tool permissions\nfn generate_claude_settings(task: &TaskType, config: &ControllerConfig) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template_path = if task.is_docs() {\n        \"docs/settings.json.hbs\"\n    } else {\n        \"code/settings.json.hbs\"\n    };\n\n    let template = load_template(template_path)?;\n\n    handlebars\n        .register_template_string(\"settings\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register settings template: {e}\"\n            ))\n        })?;\n\n    let data = build_settings_template_data(task, config);\n\n    handlebars.render(\"settings\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render settings template: {e}\"\n        ))\n    })\n}\n\n/// Generate container startup script from template\nfn generate_container_script(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template_path = if task.is_docs() {\n        \"docs/container.sh.hbs\"\n    } else {\n        \"code/container.sh.hbs\"\n    };\n\n    let template = load_template(template_path)?;\n\n    handlebars\n        .register_template_string(\"container_script\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register container script template: {e}\"\n            ))\n        })?;\n\n    // Prompt content is now embedded inline in container script - no template needed\n\n    let data = json!({\n        \"repository_url\": task.repository_url(),\n        \"github_user\": task.github_user(),\n        \"working_directory\": task.working_directory(),\n        \"model\": task.model(),\n        \"service_name\": task.service_name(),\n        \"task_id\": task.task_id(),\n        \"source_branch\": task.source_branch(),\n        \"docs_repository_url\": task.docs_repository_url(),\n        \"docs_branch\": task.docs_branch(),\n        \"docs_project_directory\": task.docs_project_directory(),\n        \"overwrite_memory\": task.overwrite_memory(),\n        \"continue_session\": task.continue_session(),\n        \"user_requested\": match task {\n            crate::controllers::task_controller::types::TaskType::Code(cr) => cr.spec.continue_session,\n            _ => false\n        }\n    });\n\n    handlebars.render(\"container_script\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render container script template: {e}\"\n        ))\n    })\n}\n\n/// Generate MCP configuration for implementation tasks\nfn generate_mcp_config(task: &TaskType, config: &ControllerConfig) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/mcp.json.hbs\")?;\n\n    handlebars\n        .register_template_string(\"mcp\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register MCP template: {e}\"\n            ))\n        })?;\n\n    let data = build_settings_template_data(task, config);\n\n    handlebars.render(\"mcp\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render MCP template: {e}\"\n        ))\n    })\n}\n\n/// Generate MCP tools documentation based on task configuration\nfn generate_mcp_tools_doc(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/mcp-tools.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"mcp_tools\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register MCP tools template: {e}\"\n            ))\n        })?;\n\n    // Parse comma-separated tool strings into arrays\n    let local_tools: Vec<String> = task\n        .local_tools()\n        .unwrap_or_default()\n        .split(',')\n        .filter(|s| !s.trim().is_empty())\n        .map(|s| s.trim().to_string())\n        .collect();\n\n    let remote_tools: Vec<String> = task\n        .remote_tools()\n        .unwrap_or_default()\n        .split(',')\n        .filter(|s| !s.trim().is_empty())\n        .map(|s| s.trim().to_string())\n        .collect();\n\n    let data = json!({\n        \"localTools\": local_tools,\n        \"remoteTools\": remote_tools,\n        \"service\": task.service_name(),\n        \"task_id\": task.task_id()\n    });\n\n    handlebars.render(\"mcp_tools\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render MCP tools template: {e}\"\n        ))\n    })\n}\n\n/// Generate client configuration for dynamic tool selection\nfn generate_client_config(task: &TaskType, config: &ControllerConfig) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/client-config.json.hbs\")?;\n\n    handlebars\n        .register_template_string(\"client_config\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register client config template: {e}\"\n            ))\n        })?;\n\n    let data = build_settings_template_data(task, config);\n\n    handlebars.render(\"client_config\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render client config template: {e}\"\n        ))\n    })\n}\n\n/// Generate coding guidelines for implementation tasks\nfn generate_coding_guidelines(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/coding-guidelines.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"coding_guidelines\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register coding guidelines template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name()\n    });\n\n    handlebars.render(\"coding_guidelines\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render coding guidelines template: {e}\"\n        ))\n    })\n}\n\n/// Generate GitHub guidelines for implementation tasks\nfn generate_github_guidelines(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/github-guidelines.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"github_guidelines\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register GitHub guidelines template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"github_user\": task.github_user()\n    });\n\n    handlebars.render(\"github_guidelines\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render GitHub guidelines template: {e}\"\n        ))\n    })\n}\n\n/// Generate docs prompt for documentation generation tasks\nfn generate_docs_prompt(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"docs/prompt.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"docs_prompt\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register docs prompt template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"github_user\": task.github_user(),\n        \"working_directory\": task.working_directory(),\n        \"repository_url\": task.repository_url()\n    });\n\n    handlebars.render(\"docs_prompt\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render docs prompt template: {e}\"\n        ))\n    })\n}\n\n/// Build template data for settings/MCP/client config templates\nfn build_settings_template_data(task: &TaskType, config: &ControllerConfig) -> serde_json::Value {\n    let mut data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"model\": task.model(),\n        \"github_user\": task.github_user(),\n        \"repository\": {\n            \"url\": task.repository_url(),\n            \"githubUser\": task.github_user()\n        },\n        \"working_directory\": task.working_directory(),\n        \"agent_tools_override\": config.permissions.agent_tools_override,\n        \"permissions\": {\n            \"allow\": config.permissions.allow,\n            \"deny\": config.permissions.deny\n        },\n        \"telemetry\": {\n            \"enabled\": config.telemetry.enabled,\n            \"otlpEndpoint\": config.telemetry.otlp_endpoint,\n            \"otlpProtocol\": config.telemetry.otlp_protocol,\n            \"logs_endpoint\": config.telemetry.logs_endpoint,\n            \"logs_protocol\": config.telemetry.logs_protocol\n        }\n    });\n\n    // Add retry information for code tasks\n    if !task.is_docs() {\n        let retry_data = json!({\n            \"context_version\": task.context_version(),\n            \"prompt_modification\": task.prompt_modification(),\n            \"session_id\": task.session_id()\n        });\n        data[\"retry\"] = retry_data;\n\n        // Add tool configuration\n        let (local_tools, remote_tools) = parse_tool_configuration(task);\n        data[\"tools\"] = json!({\n            \"local\": local_tools,\n            \"remote\": remote_tools\n        });\n\n        // Add docs repository info\n        if let Some(docs_url) = task.docs_repository_url() {\n            data[\"docs_repository_url\"] = json!(docs_url);\n        }\n    }\n\n    data\n}\n\n/// Parse tool configuration into local and remote tool lists\nfn parse_tool_configuration(task: &TaskType) -> (Vec<String>, Vec<String>) {\n    let local_tools = task\n        .local_tools()\n        .map(|tools| tools.split(',').map(|s| s.trim().to_string()).collect())\n        .unwrap_or_default();\n\n    let remote_tools = task\n        .remote_tools()\n        .map(|tools| tools.split(',').map(|s| s.trim().to_string()).collect())\n        .unwrap_or_default();\n\n    (local_tools, remote_tools)\n}\n\n/// Generate hook scripts from the hooks directory\nfn generate_hook_scripts(task: &TaskType) -> Result<BTreeMap<String, String>> {\n    let mut hook_scripts = BTreeMap::new();\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    // Get hook templates based on task type\n    let hook_templates = get_hook_templates(task)?;\n\n    // Prepare template data\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"repository\": json!({\n            \"url\": task.repository_url(),\n            \"githubUser\": task.github_user()\n        }),\n        \"working_directory\": task.working_directory(),\n        \"attempts\": task.retry_count() + 1, // retry_count + 1 = attempt number\n        \"is_docs_generation\": task.is_docs(),\n        \"docs_repository_url\": task.docs_repository_url()\n    });\n\n    // Process each hook template\n    for (hook_name, template_content) in hook_templates {\n        handlebars\n            .register_template_string(&hook_name, &template_content)\n            .map_err(|e| {\n                crate::controllers::task_controller::types::Error::ConfigError(format!(\n                    \"Failed to register hook template {hook_name}: {e}\"\n                ))\n            })?;\n\n        let rendered = handlebars.render(&hook_name, &data).map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to render hook template {hook_name}: {e}\"\n            ))\n        })?;\n\n        // Remove .hbs extension for the final filename\n        let filename = hook_name.strip_suffix(\".hbs\").unwrap_or(&hook_name);\n        hook_scripts.insert(filename.to_string(), rendered);\n    }\n\n    Ok(hook_scripts)\n}\n\n/// Get all hook templates for a specific task type by scanning the filesystem\nfn get_hook_templates(task: &TaskType) -> Result<Vec<(String, String)>> {\n    let hooks_prefix = match task {\n        TaskType::Docs(_) => \"docs_hooks_\",\n        TaskType::Code(_) => \"code_hooks_\",\n    };\n\n    debug!(\"Scanning for hook templates with prefix: {}\", hooks_prefix);\n\n    let mut templates = Vec::new();\n\n    // Read the ConfigMap directory and find files with the hook prefix\n    match std::fs::read_dir(CLAUDE_TEMPLATES_PATH) {\n        Ok(entries) => {\n            for entry in entries.flatten() {\n                let path = entry.path();\n                if path.is_file() {\n                    if let Some(filename) = path.file_name().and_then(|n| n.to_str()) {\n                        // Check if this is a hook template for our task type\n                        if filename.starts_with(hooks_prefix) && filename.ends_with(\".hbs\") {\n                            // Extract just the hook filename (remove prefix and convert back)\n                            let hook_name = filename.strip_prefix(hooks_prefix).unwrap_or(filename);\n\n                            match fs::read_to_string(&path) {\n                                Ok(content) => {\n                                    debug!(\n                                        \"Loaded hook template: {} (from {})\",\n                                        hook_name, filename\n                                    );\n                                    templates.push((hook_name.to_string(), content));\n                                }\n                                Err(e) => {\n                                    debug!(\"Failed to load hook template {}: {}\", filename, e);\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        Err(e) => {\n            debug!(\n                \"Templates directory {} not found or not accessible: {}\",\n                CLAUDE_TEMPLATES_PATH, e\n            );\n            // Don't fail - hooks are optional\n        }\n    }\n\n    Ok(templates)\n}\n"
        },
        {
          "path": "core/src/handlers/code_handler.rs",
          "file_type": "rust",
          "line_count": 126,
          "key_definitions": [],
          "content": "//! Code task submission handler\n\nuse axum::{extract::State, http::StatusCode, Json};\nuse chrono::Utc;\nuse kube::Api;\nuse std::collections::HashMap;\nuse tracing::{error, info};\n\nuse crate::crds::{CodeRun, CodeRunSpec, CodeRunStatus};\nuse crate::handlers::common::{ApiResponse, AppState};\nuse common::models::CodeRequest;\n\npub async fn submit_code_task(\n    State(state): State<AppState>,\n    Json(request): Json<CodeRequest>,\n) -> Result<Json<ApiResponse>, StatusCode> {\n    info!(\n        \"Received code task request: task_id={}, service={}\",\n        request.task_id, request.service\n    );\n\n    let spec = CodeRunSpec {\n        task_id: request.task_id,\n        service: request.service.clone(),\n        repository_url: request.repository_url,\n        docs_repository_url: request.docs_repository_url,\n        docs_project_directory: request.docs_project_directory,\n        working_directory: request.working_directory,\n        model: request.model.unwrap_or_else(|| {\n            std::env::var(\"DEFAULT_CODE_MODEL\")\n                .unwrap_or_else(|_| \"claude-sonnet-4-20250514\".to_string())\n        }),\n        github_user: request.github_user,\n        local_tools: request.local_tools,\n        remote_tools: request.remote_tools,\n        context_version: request.context_version,\n        prompt_modification: request.prompt_modification,\n        docs_branch: request.docs_branch,\n        continue_session: request.continue_session,\n        overwrite_memory: request.overwrite_memory,\n        env: request.env,\n        env_from_secrets: request\n            .env_from_secrets\n            .into_iter()\n            .map(|s| crate::crds::coderun::SecretEnvVar {\n                name: s.name,\n                secret_name: s.secret_name,\n                secret_key: s.secret_key,\n            })\n            .collect(),\n    };\n\n    let coderun = CodeRun {\n        metadata: kube::api::ObjectMeta {\n            name: Some(format!(\n                \"code-{}-{}\",\n                request.task_id,\n                Utc::now().timestamp()\n            )),\n            namespace: Some(state.namespace.clone()),\n            ..Default::default()\n        },\n        spec,\n        status: Some(CodeRunStatus {\n            phase: \"Pending\".to_string(),\n            message: Some(\"CodeRun created successfully\".to_string()),\n            last_update: Some(Utc::now().to_rfc3339()),\n            job_name: None,\n            pull_request_url: None,\n            retry_count: Some(0),\n            conditions: None,\n            configmap_name: None,\n            context_version: Some(1),\n            prompt_modification: None,\n            prompt_mode: Some(\"direct\".to_string()),\n            session_id: None,\n        }),\n    };\n\n    let api: Api<CodeRun> = Api::namespaced(state.k8s_client.clone(), &state.namespace);\n\n    // Check if a CodeRun already exists for this task\n    let existing_name = format!(\"code-{}\", request.task_id);\n    if let Ok(_existing) = api.get(&existing_name).await {\n        error!(\"CodeRun already exists for task {}\", request.task_id);\n        return Ok(Json(ApiResponse {\n            success: false,\n            message: format!(\"CodeRun already exists for task {}\", request.task_id),\n            data: None,\n        }));\n    }\n\n    match api.create(&Default::default(), &coderun).await {\n        Ok(created) => {\n            info!(\"CodeRun created successfully: {:?}\", created.metadata.name);\n\n            let mut response_data = HashMap::new();\n            if let Some(name) = &created.metadata.name {\n                response_data.insert(\n                    \"coderun_name\".to_string(),\n                    serde_json::Value::String(name.clone()),\n                );\n            }\n            response_data.insert(\n                \"namespace\".to_string(),\n                serde_json::Value::String(state.namespace.clone()),\n            );\n\n            Ok(Json(ApiResponse {\n                success: true,\n                message: \"Code task submitted successfully\".to_string(),\n                data: Some(serde_json::Value::Object(\n                    response_data.into_iter().collect(),\n                )),\n            }))\n        }\n        Err(e) => {\n            error!(\"Failed to create CodeRun: {}\", e);\n            Ok(Json(ApiResponse {\n                success: false,\n                message: format!(\"Failed to create CodeRun: {e}\"),\n                data: None,\n            }))\n        }\n    }\n}\n"
        },
        {
          "path": "core/src/handlers/mod.rs",
          "file_type": "rust",
          "line_count": 9,
          "key_definitions": [],
          "content": "//! Request handlers for the orchestrator service\n\npub mod code_handler;\npub mod common;\npub mod docs_handler;\n\npub use code_handler::submit_code_task;\npub use common::{ApiResponse, AppError, AppState};\npub use docs_handler::generate_docs;\n"
        },
        {
          "path": "core/src/handlers/docs_handler.rs",
          "file_type": "rust",
          "line_count": 102,
          "key_definitions": [],
          "content": "//! Documentation generation handler\n\nuse axum::extract::State;\nuse axum::http::StatusCode;\nuse axum::Json;\nuse k8s_openapi::apimachinery::pkg::apis::meta::v1::ObjectMeta;\nuse kube::api::{Api, PostParams};\nuse serde_json::json;\nuse std::collections::BTreeMap;\nuse tracing::{error, info};\n\nuse crate::crds::{DocsRun, DocsRunSpec, DocsRunStatus};\nuse crate::handlers::common::{ApiResponse, AppError, AppState};\nuse common::models::DocsRequest;\n\n/// Generate documentation for Task Master tasks\npub async fn generate_docs(\n    State(state): State<AppState>,\n    Json(request): Json<DocsRequest>,\n) -> Result<(StatusCode, Json<ApiResponse>), (StatusCode, Json<ApiResponse>)> {\n    info!(\n        \"Generate documentation request received for repository: {}\",\n        request.repository_url\n    );\n\n    // Generate a unique DocsRun name using timestamp\n    let timestamp = std::time::SystemTime::now()\n        .duration_since(std::time::UNIX_EPOCH)\n        .unwrap()\n        .as_secs();\n    let docsrun_name = format!(\"docs-gen-{timestamp}\");\n\n    // Create DocsRun spec for documentation generation\n    let spec = DocsRunSpec {\n        repository_url: request.repository_url.clone(),\n        working_directory: request.working_directory.clone(),\n        source_branch: request.source_branch.clone(),\n        model: request.model.unwrap_or_else(|| {\n            std::env::var(\"DEFAULT_DOCS_MODEL\")\n                .unwrap_or_else(|_| \"claude-opus-4-20250514\".to_string())\n        }),\n        github_user: request.github_user.clone(),\n    };\n\n    // Create DocsRun\n    let docsrun = DocsRun {\n        metadata: ObjectMeta {\n            name: Some(docsrun_name.clone()),\n            namespace: Some(state.namespace.clone()),\n            labels: Some({\n                let mut labels = BTreeMap::new();\n                labels.insert(\"app\".to_string(), \"orchestrator\".to_string());\n                labels.insert(\"type\".to_string(), \"docs\".to_string());\n                labels\n            }),\n            ..Default::default()\n        },\n        spec,\n        status: Some(DocsRunStatus {\n            phase: \"Pending\".to_string(),\n            message: Some(\"DocsRun created successfully\".to_string()),\n            last_update: Some(chrono::Utc::now().to_rfc3339()),\n            job_name: None,\n            pull_request_url: None,\n            conditions: None,\n            configmap_name: None,\n        }),\n    };\n\n    // Create DocsRun in Kubernetes\n    let api: Api<DocsRun> = Api::namespaced(state.k8s_client.clone(), &state.namespace);\n\n    match api.create(&PostParams::default(), &docsrun).await {\n        Ok(created) => {\n            info!(\"Created documentation generation DocsRun: {}\", docsrun_name);\n            Ok((\n                StatusCode::CREATED,\n                Json(ApiResponse {\n                    success: true,\n                    message: \"Documentation generation job submitted successfully\".to_string(),\n                    data: Some(json!({\n                        \"docsrun_name\": docsrun_name,\n                        \"namespace\": state.namespace,\n                        \"repository_url\": created.spec.repository_url,\n                        \"model\": created.spec.model,\n                    })),\n                }),\n            ))\n        }\n        Err(e) => {\n            error!(\"Failed to create documentation generation DocsRun: {}\", e);\n            let status_code = StatusCode::from(AppError::from(e));\n            Err((\n                status_code,\n                Json(ApiResponse::error(&format!(\n                    \"Failed to submit documentation generation job: {}\",\n                    status_code.canonical_reason().unwrap_or(\"Unknown error\")\n                ))),\n            ))\n        }\n    }\n}\n"
        },
        {
          "path": "core/src/handlers/common.rs",
          "file_type": "rust",
          "line_count": 77,
          "key_definitions": [
            "9:pub struct AppState {",
            "16:pub enum AppError {",
            "22:impl std::fmt::Display for AppError {",
            "32:impl std::error::Error for AppError {}",
            "34:impl From<kube::Error> for AppError {",
            "40:impl From<AppError> for StatusCode {",
            "52:pub struct ApiResponse {",
            "59:impl ApiResponse {",
            "61:pub fn success(message: &str) -> Self {",
            "70:pub fn error(message: &str) -> Self {"
          ],
          "content": "//! Shared types and utilities for API handlers\n\nuse axum::http::StatusCode;\nuse kube::Client;\nuse serde_json::Value;\n\n/// Application state shared across handlers\n#[derive(Clone)]\npub struct AppState {\n    pub k8s_client: Client,\n    pub namespace: String,\n}\n\n/// Error type for API handlers\n#[derive(Debug)]\npub enum AppError {\n    BadRequest(String),\n    Conflict(String),\n    Internal(String),\n}\n\nimpl std::fmt::Display for AppError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            AppError::BadRequest(msg) => write!(f, \"Bad Request: {msg}\"),\n            AppError::Conflict(msg) => write!(f, \"Conflict: {msg}\"),\n            AppError::Internal(msg) => write!(f, \"Internal Error: {msg}\"),\n        }\n    }\n}\n\nimpl std::error::Error for AppError {}\n\nimpl From<kube::Error> for AppError {\n    fn from(e: kube::Error) -> Self {\n        AppError::Internal(e.to_string())\n    }\n}\n\nimpl From<AppError> for StatusCode {\n    fn from(err: AppError) -> Self {\n        match err {\n            AppError::BadRequest(_) => StatusCode::BAD_REQUEST,\n            AppError::Conflict(_) => StatusCode::CONFLICT,\n            AppError::Internal(_) => StatusCode::INTERNAL_SERVER_ERROR,\n        }\n    }\n}\n\n/// API response structure\n#[derive(serde::Serialize)]\npub struct ApiResponse {\n    pub success: bool,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option<Value>,\n}\n\nimpl ApiResponse {\n    #[must_use]\n    pub fn success(message: &str) -> Self {\n        Self {\n            success: true,\n            message: message.to_string(),\n            data: None,\n        }\n    }\n\n    #[must_use]\n    pub fn error(message: &str) -> Self {\n        Self {\n            success: false,\n            message: message.to_string(),\n            data: None,\n        }\n    }\n}\n"
        },
        {
          "path": "tests/simple_integration_test.rs",
          "file_type": "rust",
          "line_count": 91,
          "key_definitions": [],
          "content": "use std::env;\n\n#[tokio::test]\nasync fn test_basic_functionality() {\n    if env::var(\"SKIP_INTEGRATION_TESTS\").is_ok() {\n        println!(\"Skipping integration tests due to SKIP_INTEGRATION_TESTS environment variable\");\n        return;\n    }\n\n    println!(\"🧪 Running basic functionality test...\");\n\n    // Test that we can create a test JSON structure\n    let test_event = create_test_github_event(123, \"Test issue\", \"Test body\");\n    assert_eq!(test_event[\"issue\"][\"number\"], 123);\n    assert_eq!(test_event[\"issue\"][\"title\"], \"Test issue\");\n    assert_eq!(test_event[\"action\"], \"opened\");\n\n    println!(\"✅ JSON event creation works\");\n\n    // Test that Axum router can be created\n    use axum::Router;\n\n    let _app: Router<()> = Router::new().route(\"/health\", axum::routing::get(|| async { \"OK\" }));\n\n    println!(\"✅ Axum router creation works\");\n\n    // TODO: Fix configuration test when config module is available\n    // use core::config::Config;\n    // let _config = Config::default();\n\n    println!(\"✅ Basic tests completed (some functionality commented out)\");\n\n    println!(\"🎉 Basic integration test completed successfully!\");\n}\n\nfn create_test_github_event(\n    issue_number: i64,\n    title: &str,\n    body: &str,\n) -> serde_json::Value {\n    use serde_json::json;\n\n    serde_json::from_value(json!({\n        \"action\": \"opened\",\n        \"issue\": {\n            \"id\": 123456789,\n            \"number\": issue_number,\n            \"title\": title,\n            \"body\": body,\n            \"html_url\": format!(\"https://github.com/test-org/test-repo/issues/{}\", issue_number),\n            \"created_at\": \"2024-06-30T10:00:00Z\",\n            \"updated_at\": \"2024-06-30T10:00:00Z\",\n            \"labels\": [\n                {\n                    \"name\": \"enhancement\",\n                    \"color\": \"a2eeef\",\n                    \"description\": \"New feature or request\"\n                }\n            ],\n            \"user\": {\n                \"login\": \"testuser\",\n                \"id\": 12345,\n                \"avatar_url\": \"https://avatars.githubusercontent.com/u/12345?v=4\",\n                \"html_url\": \"https://github.com/testuser\"\n            },\n            \"state\": \"open\"\n        },\n        \"repository\": {\n            \"id\": 987654321,\n            \"name\": \"test-repo\",\n            \"full_name\": \"test-org/test-repo\",\n            \"owner\": {\n                \"login\": \"test-org\",\n                \"id\": 54321,\n                \"avatar_url\": \"https://avatars.githubusercontent.com/u/54321?v=4\",\n                \"html_url\": \"https://github.com/test-org\"\n            },\n            \"html_url\": \"https://github.com/test-org/test-repo\",\n            \"description\": \"A test repository for webhook testing\",\n            \"default_branch\": \"main\",\n            \"clone_url\": \"https://github.com/test-org/test-repo.git\"\n        },\n        \"sender\": {\n            \"login\": \"testuser\",\n            \"id\": 12345,\n            \"avatar_url\": \"https://avatars.githubusercontent.com/u/12345?v=4\",\n            \"html_url\": \"https://github.com/testuser\"\n        }\n    }))\n    .expect(\"Failed to create test GitHub event\")\n}\n"
        },
        {
          "path": "common/src/error.rs",
          "file_type": "rust",
          "line_count": 37,
          "key_definitions": [
            "6:pub enum Error {",
            "33:impl From<anyhow::Error> for Error {"
          ],
          "content": "//! Common error types for the orchestrator\n\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum Error {\n    #[error(\"Kubernetes operation failed: {0}\")]\n    Kubernetes(String),\n\n    #[error(\"Invalid request: {0}\")]\n    InvalidRequest(String),\n\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n\n    #[error(\"HTTP request failed: {0}\")]\n    Http(String),\n\n    #[error(\"Configuration error: {0}\")]\n    Config(String),\n\n    #[error(\"Task not found: {0}\")]\n    TaskNotFound(String),\n\n    #[error(\"Job failed: {0}\")]\n    JobFailed(String),\n\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\n// Implement conversion from anyhow::Error for easier error handling\nimpl From<anyhow::Error> for Error {\n    fn from(err: anyhow::Error) -> Self {\n        Error::Internal(err.to_string())\n    }\n}\n"
        },
        {
          "path": "common/src/lib.rs",
          "file_type": "rust",
          "line_count": 28,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - Common Types and Utilities\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Shared types and utilities for the Orchestrator project\n\npub mod error;\npub mod models;\n\npub use error::Error;\npub type Result<T> = std::result::Result<T, Error>;\n\n// Re-export commonly used types for convenience\npub use models::{AgentType, Job, JobStatus, JobType, Request, RequestSource, Task, TaskStatus};\n"
        },
        {
          "path": "common/src/models/response.rs",
          "file_type": "rust",
          "line_count": 239,
          "key_definitions": [
            "10:pub struct ApiResponse<T> {",
            "20:pub enum ResponseStatus {",
            "28:pub struct ErrorDetails {",
            "36:pub struct ResponseMetadata {",
            "45:pub struct TaskResponse {",
            "59:pub struct JobResponse {",
            "74:pub struct JobListResponse {",
            "83:pub struct TaskListResponse {",
            "92:pub struct HealthResponse {",
            "102:pub enum HealthStatus {",
            "110:pub struct ComponentHealth {",
            "118:pub struct WebhookResponse {",
            "127:pub fn success(data: T, request_id: String) -> Self {",
            "143:pub fn error(error: ErrorDetails, request_id: String) -> Self {",
            "158:pub fn with_duration(mut self, duration_ms: u64) -> Self {",
            "164:impl From<super::task::Task> for TaskResponse {",
            "180:impl From<super::job::Job> for JobResponse {"
          ],
          "content": "//! Response models for API endpoints\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Generic API response wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApiResponse<T> {\n    pub status: ResponseStatus,\n    pub data: Option<T>,\n    pub error: Option<ErrorDetails>,\n    pub metadata: ResponseMetadata,\n}\n\n/// Response status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ResponseStatus {\n    Success,\n    Error,\n    Partial,\n}\n\n/// Error details in response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ErrorDetails {\n    pub code: String,\n    pub message: String,\n    pub details: Option<Value>,\n}\n\n/// Response metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResponseMetadata {\n    pub request_id: String,\n    pub timestamp: DateTime<Utc>,\n    pub duration_ms: Option<u64>,\n    pub version: String,\n}\n\n/// Task response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskResponse {\n    pub id: String,\n    pub title: String,\n    pub description: String,\n    pub status: super::task::TaskStatus,\n    pub priority: super::task::TaskPriority,\n    pub microservice: String,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n    pub job_ids: Vec<String>,\n}\n\n/// Job response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JobResponse {\n    pub id: String,\n    pub task_id: String,\n    pub job_type: super::job::JobType,\n    pub status: super::job::JobStatus,\n    pub k8s_job_name: String,\n    pub namespace: String,\n    pub created_at: DateTime<Utc>,\n    pub started_at: Option<DateTime<Utc>>,\n    pub completed_at: Option<DateTime<Utc>>,\n    pub logs_url: Option<String>,\n}\n\n/// Job list response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JobListResponse {\n    pub jobs: Vec<JobResponse>,\n    pub total: usize,\n    pub page: usize,\n    pub page_size: usize,\n}\n\n/// Task list response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskListResponse {\n    pub tasks: Vec<TaskResponse>,\n    pub total: usize,\n    pub page: usize,\n    pub page_size: usize,\n}\n\n/// Health check response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HealthResponse {\n    pub status: HealthStatus,\n    pub version: String,\n    pub uptime_seconds: u64,\n    pub components: HashMap<String, ComponentHealth>,\n}\n\n/// Health status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum HealthStatus {\n    Healthy,\n    Degraded,\n    Unhealthy,\n}\n\n/// Component health status\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ComponentHealth {\n    pub status: HealthStatus,\n    pub message: Option<String>,\n    pub last_check: DateTime<Utc>,\n}\n\n/// Webhook processing response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WebhookResponse {\n    pub accepted: bool,\n    pub task_id: Option<String>,\n    pub job_ids: Vec<String>,\n    pub message: String,\n}\n\nimpl<T> ApiResponse<T> {\n    /// Create a success response\n    pub fn success(data: T, request_id: String) -> Self {\n        Self {\n            status: ResponseStatus::Success,\n            data: Some(data),\n            error: None,\n            metadata: ResponseMetadata {\n                request_id,\n                timestamp: Utc::now(),\n                duration_ms: None,\n                version: env!(\"CARGO_PKG_VERSION\").to_string(),\n            },\n        }\n    }\n\n    /// Create an error response\n    #[must_use]\n    pub fn error(error: ErrorDetails, request_id: String) -> Self {\n        Self {\n            status: ResponseStatus::Error,\n            data: None,\n            error: Some(error),\n            metadata: ResponseMetadata {\n                request_id,\n                timestamp: Utc::now(),\n                duration_ms: None,\n                version: env!(\"CARGO_PKG_VERSION\").to_string(),\n            },\n        }\n    }\n\n    /// Set the duration in milliseconds\n    pub fn with_duration(mut self, duration_ms: u64) -> Self {\n        self.metadata.duration_ms = Some(duration_ms);\n        self\n    }\n}\n\nimpl From<super::task::Task> for TaskResponse {\n    fn from(task: super::Task) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            status: task.status,\n            priority: task.priority,\n            microservice: task.microservice,\n            created_at: task.created_at,\n            updated_at: task.updated_at,\n            job_ids: Vec::new(), // To be populated by service layer\n        }\n    }\n}\n\nimpl From<super::job::Job> for JobResponse {\n    fn from(job: super::Job) -> Self {\n        Self {\n            id: job.id,\n            task_id: job.task_id,\n            job_type: job.job_type,\n            status: job.status,\n            k8s_job_name: job.k8s_job_name,\n            namespace: job.namespace,\n            created_at: job.created_at,\n            started_at: job.started_at,\n            completed_at: job.completed_at,\n            logs_url: None, // To be populated by service layer\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::models::task::{TaskPriority, TaskStatus};\n\n    #[test]\n    fn test_api_response_success() {\n        let response = ApiResponse::success(\n            TaskResponse {\n                id: \"task-123\".to_string(),\n                title: \"Test Task\".to_string(),\n                description: \"A test task\".to_string(),\n                status: TaskStatus::Pending,\n                priority: TaskPriority::Medium,\n                microservice: \"auth\".to_string(),\n                created_at: Utc::now(),\n                updated_at: Utc::now(),\n                job_ids: vec![],\n            },\n            \"req-123\".to_string(),\n        );\n\n        assert_eq!(response.status, ResponseStatus::Success);\n        assert!(response.data.is_some());\n        assert!(response.error.is_none());\n    }\n\n    #[test]\n    fn test_api_response_error() {\n        let response: ApiResponse<TaskResponse> = ApiResponse::error(\n            ErrorDetails {\n                code: \"TASK_NOT_FOUND\".to_string(),\n                message: \"Task not found\".to_string(),\n                details: None,\n            },\n            \"req-123\".to_string(),\n        );\n\n        assert_eq!(response.status, ResponseStatus::Error);\n        assert!(response.data.is_none());\n        assert!(response.error.is_some());\n    }\n}\n"
        },
        {
          "path": "common/src/models/request.rs",
          "file_type": "rust",
          "line_count": 201,
          "key_definitions": [
            "9:pub struct Request {",
            "20:pub enum RequestSource {",
            "31:pub enum RequestAction {",
            "44:pub struct RequestMetadata {",
            "56:pub struct ParsedRequest {",
            "69:pub struct CliRequest {",
            "77:pub struct CreateTaskRequest {",
            "89:pub struct UpdateTaskRequest {",
            "99:pub struct AssistanceRequest {",
            "110:pub enum AssistanceType {",
            "121:pub enum AssistancePriority {",
            "128:impl Request {",
            "131:pub fn new(source: RequestSource, action: RequestAction, payload: Value) -> Self {",
            "149:pub fn with_trace_id(mut self, trace_id: String) -> Self {",
            "156:pub fn with_user(mut self, user: String) -> Self {"
          ],
          "content": "//! Request models for unified orchestration\n\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Unified request interface\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Request {\n    pub id: String,\n    pub source: RequestSource,\n    pub action: RequestAction,\n    pub payload: Value,\n    pub metadata: RequestMetadata,\n}\n\n/// Source of incoming requests\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequestSource {\n    Cli,\n    PmAgent,\n    GitHub,\n    Grafana,\n    Discord,\n}\n\n/// Action to be performed\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequestAction {\n    CreateTask,\n    UpdateTask,\n    GetTaskStatus,\n    TriggerAssistance,\n    ListJobs,\n    GetJobLogs,\n    ReviewPR,\n    HandleAlert,\n}\n\n/// Additional request metadata\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\npub struct RequestMetadata {\n    pub user: Option<String>,\n    pub organization: Option<String>,\n    pub project: Option<String>,\n    pub channel: Option<String>,\n    pub timestamp: String,\n    pub trace_id: Option<String>,\n    pub labels: HashMap<String, String>,\n}\n\n/// Parsed request after normalization\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ParsedRequest {\n    pub action: RequestAction,\n    pub task_id: Option<String>,\n    pub microservice: Option<String>,\n    pub title: Option<String>,\n    pub description: Option<String>,\n    pub acceptance_criteria: Vec<String>,\n    pub priority: Option<String>,\n    pub metadata: Value,\n}\n\n/// CLI request format\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CliRequest {\n    pub command: String,\n    pub args: Vec<String>,\n    pub options: HashMap<String, String>,\n}\n\n/// Task submission request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CreateTaskRequest {\n    pub microservice: String,\n    pub title: String,\n    pub description: String,\n    pub acceptance_criteria: Vec<String>,\n    pub priority: Option<String>,\n    pub agent_type: Option<super::AgentType>,\n    pub metadata: Option<HashMap<String, Value>>,\n}\n\n/// Task update request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct UpdateTaskRequest {\n    pub status: Option<super::TaskStatus>,\n    pub priority: Option<super::task::TaskPriority>,\n    pub description: Option<String>,\n    pub acceptance_criteria: Option<Vec<String>>,\n    pub metadata: Option<HashMap<String, Value>>,\n}\n\n/// Assistance request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AssistanceRequest {\n    pub task_id: String,\n    pub reason: String,\n    pub assist_type: AssistanceType,\n    pub context: Option<Value>,\n    pub priority: AssistancePriority,\n}\n\n/// Type of assistance needed\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum AssistanceType {\n    ImplementationGuidance,\n    ArchitectureReview,\n    ErrorDiagnosis,\n    TestDebugging,\n    PerformanceOptimization,\n}\n\n/// Priority of assistance request\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum AssistancePriority {\n    Low,\n    Medium,\n    High,\n    Critical,\n}\n\nimpl Request {\n    /// Create a new request\n    #[must_use]\n    pub fn new(source: RequestSource, action: RequestAction, payload: Value) -> Self {\n        use chrono::Utc;\n        use uuid::Uuid;\n\n        Self {\n            id: Uuid::new_v4().to_string(),\n            source,\n            action,\n            payload,\n            metadata: RequestMetadata {\n                timestamp: Utc::now().to_rfc3339(),\n                ..Default::default()\n            },\n        }\n    }\n\n    /// Add trace ID for distributed tracing\n    #[must_use]\n    pub fn with_trace_id(mut self, trace_id: String) -> Self {\n        self.metadata.trace_id = Some(trace_id);\n        self\n    }\n\n    /// Add user information\n    #[must_use]\n    pub fn with_user(mut self, user: String) -> Self {\n        self.metadata.user = Some(user);\n        self\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_json::json;\n\n    #[test]\n    fn test_request_creation() {\n        let request = Request::new(\n            RequestSource::Cli,\n            RequestAction::CreateTask,\n            json!({\n                \"title\": \"Test Task\",\n                \"description\": \"A test task\"\n            }),\n        );\n\n        assert_eq!(request.source, RequestSource::Cli);\n        assert_eq!(request.action, RequestAction::CreateTask);\n        assert!(!request.id.is_empty());\n        assert!(!request.metadata.timestamp.is_empty());\n    }\n\n    #[test]\n    fn test_create_task_request_serialization() {\n        let req = CreateTaskRequest {\n            microservice: \"auth\".to_string(),\n            title: \"Implement JWT validation\".to_string(),\n            description: \"Add JWT token validation\".to_string(),\n            acceptance_criteria: vec![\"Validate tokens\".to_string()],\n            priority: Some(\"high\".to_string()),\n            agent_type: Some(super::super::AgentType::Claude),\n            metadata: None,\n        };\n\n        let json = serde_json::to_string(&req).unwrap();\n        let deserialized: CreateTaskRequest = serde_json::from_str(&json).unwrap();\n        assert_eq!(req.title, deserialized.title);\n        assert_eq!(req.microservice, deserialized.microservice);\n    }\n}\n"
        },
        {
          "path": "common/src/models/job.rs",
          "file_type": "rust",
          "line_count": 244,
          "key_definitions": [
            "10:pub struct Job {",
            "26:pub enum JobType {",
            "40:pub enum JobStatus {",
            "50:pub struct JobSpec {",
            "73:pub struct VolumeSpec {",
            "83:pub enum VolumeType {",
            "94:impl Job {",
            "97:pub fn new(",
            "120:pub fn update_from_k8s_job(&mut self, k8s_job: &K8sJob) {",
            "147:pub fn is_terminal(&self) -> bool {",
            "153:pub fn duration(&self) -> Option<chrono::Duration> {",
            "161:impl Default for JobSpec {",
            "177:impl std::fmt::Display for JobType {",
            "188:impl std::fmt::Display for JobStatus {"
          ],
          "content": "//! Job-related data models for Kubernetes job orchestration\n\nuse chrono::{DateTime, Utc};\nuse k8s_openapi::api::batch::v1::Job as K8sJob;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Represents a Kubernetes job for task execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Job {\n    pub id: String,\n    pub task_id: String,\n    pub job_type: JobType,\n    pub status: JobStatus,\n    pub k8s_job_name: String,\n    pub namespace: String,\n    pub spec: JobSpec,\n    pub started_at: Option<DateTime<Utc>>,\n    pub completed_at: Option<DateTime<Utc>>,\n    pub created_at: DateTime<Utc>,\n}\n\n/// Type of job in the orchestration pattern\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum JobType {\n    /// Prepare job that sets up workspace and context files\n    Prepare,\n    /// Execute job that runs the primary agent (Claude)\n    Execute,\n    /// Assist job that runs helper agent (Gemini)\n    Assist,\n    /// Review job for code review tasks\n    Review,\n}\n\n/// Job execution status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum JobStatus {\n    Pending,\n    Running,\n    Succeeded,\n    Failed,\n    Unknown,\n}\n\n/// Job specification details\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JobSpec {\n    /// Container image to use\n    pub image: String,\n    /// Agent type for execution jobs\n    pub agent: Option<super::AgentType>,\n    /// Environment variables\n    pub env_vars: HashMap<String, String>,\n    /// Resource limits and requests\n    pub resources: super::ResourceLimits,\n    /// Volume mounts\n    pub volumes: Vec<VolumeSpec>,\n    /// Command to execute\n    pub command: Option<Vec<String>>,\n    /// Working directory\n    pub working_dir: Option<String>,\n    /// Job timeout in seconds\n    pub timeout_seconds: Option<u32>,\n    /// Number of retries\n    pub retry_limit: Option<u32>,\n}\n\n/// Volume specification for job\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct VolumeSpec {\n    pub name: String,\n    pub mount_path: String,\n    pub volume_type: VolumeType,\n    pub read_only: bool,\n}\n\n/// Types of volumes that can be mounted\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum VolumeType {\n    /// `ConfigMap` volume\n    ConfigMap { name: String },\n    /// `PersistentVolumeClaim`\n    Pvc { claim_name: String },\n    /// `EmptyDir` volume\n    EmptyDir,\n    /// Secret volume\n    Secret { name: String },\n}\n\nimpl Job {\n    /// Create a new job\n    #[must_use]\n    pub fn new(\n        id: String,\n        task_id: String,\n        job_type: JobType,\n        k8s_job_name: String,\n        namespace: String,\n        spec: JobSpec,\n    ) -> Self {\n        Self {\n            id,\n            task_id,\n            job_type,\n            status: JobStatus::Pending,\n            k8s_job_name,\n            namespace,\n            spec,\n            started_at: None,\n            completed_at: None,\n            created_at: Utc::now(),\n        }\n    }\n\n    /// Update job status based on Kubernetes job status\n    pub fn update_from_k8s_job(&mut self, k8s_job: &K8sJob) {\n        if let Some(status) = &k8s_job.status {\n            if status.succeeded == Some(1) {\n                self.status = JobStatus::Succeeded;\n                self.completed_at = status.completion_time.as_ref().map(|t| {\n                    DateTime::parse_from_rfc3339(&t.0.to_rfc3339())\n                        .unwrap()\n                        .with_timezone(&Utc)\n                });\n            } else if status.failed.unwrap_or(0) > 0 {\n                self.status = JobStatus::Failed;\n                self.completed_at = Some(Utc::now());\n            } else if status.active == Some(1) {\n                self.status = JobStatus::Running;\n                if self.started_at.is_none() {\n                    self.started_at = status.start_time.as_ref().map(|t| {\n                        DateTime::parse_from_rfc3339(&t.0.to_rfc3339())\n                            .unwrap()\n                            .with_timezone(&Utc)\n                    });\n                }\n            }\n        }\n    }\n\n    /// Check if the job is in a terminal state\n    #[must_use]\n    pub fn is_terminal(&self) -> bool {\n        matches!(self.status, JobStatus::Succeeded | JobStatus::Failed)\n    }\n\n    /// Get job duration if available\n    #[must_use]\n    pub fn duration(&self) -> Option<chrono::Duration> {\n        match (self.started_at, self.completed_at) {\n            (Some(start), Some(end)) => Some(end - start),\n            _ => None,\n        }\n    }\n}\n\nimpl Default for JobSpec {\n    fn default() -> Self {\n        Self {\n            image: \"busybox:latest\".to_string(),\n            agent: None,\n            env_vars: HashMap::new(),\n            resources: super::ResourceLimits::default(),\n            volumes: Vec::new(),\n            command: None,\n            working_dir: None,\n            timeout_seconds: Some(1800), // 30 minutes default\n            retry_limit: Some(2),\n        }\n    }\n}\n\nimpl std::fmt::Display for JobType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            JobType::Prepare => write!(f, \"Prepare\"),\n            JobType::Execute => write!(f, \"Execute\"),\n            JobType::Assist => write!(f, \"Assist\"),\n            JobType::Review => write!(f, \"Review\"),\n        }\n    }\n}\n\nimpl std::fmt::Display for JobStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            JobStatus::Pending => write!(f, \"Pending\"),\n            JobStatus::Running => write!(f, \"Running\"),\n            JobStatus::Succeeded => write!(f, \"Succeeded\"),\n            JobStatus::Failed => write!(f, \"Failed\"),\n            JobStatus::Unknown => write!(f, \"Unknown\"),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_job_creation() {\n        let spec = JobSpec::default();\n        let job = Job::new(\n            \"job-123\".to_string(),\n            \"task-123\".to_string(),\n            JobType::Execute,\n            \"claude-task-123\".to_string(),\n            \"default\".to_string(),\n            spec,\n        );\n\n        assert_eq!(job.status, JobStatus::Pending);\n        assert!(job.started_at.is_none());\n        assert!(job.completed_at.is_none());\n        assert!(!job.is_terminal());\n    }\n\n    #[test]\n    fn test_job_serialization() {\n        let spec = JobSpec {\n            image: \"claude:latest\".to_string(),\n            agent: Some(super::super::AgentType::Claude),\n            ..Default::default()\n        };\n\n        let job = Job::new(\n            \"job-123\".to_string(),\n            \"task-123\".to_string(),\n            JobType::Execute,\n            \"claude-task-123\".to_string(),\n            \"default\".to_string(),\n            spec,\n        );\n\n        let json = serde_json::to_string(&job).unwrap();\n        let deserialized: Job = serde_json::from_str(&json).unwrap();\n        assert_eq!(job.id, deserialized.id);\n        assert_eq!(job.job_type, deserialized.job_type);\n    }\n}\n"
        },
        {
          "path": "common/src/models/config.rs",
          "file_type": "rust",
          "line_count": 147,
          "key_definitions": [
            "9:pub enum AgentType {",
            "17:pub struct AgentConfig {",
            "29:pub struct ResourceLimits {",
            "40:pub struct McpServerConfig {",
            "50:pub struct OrchestratorConfig {",
            "60:impl Default for ResourceLimits {",
            "73:impl AgentType {",
            "76:pub fn display_name(&self) -> &'static str {",
            "85:pub fn default_image(&self) -> &'static str {",
            "94:pub fn can_implement(&self) -> bool {",
            "103:pub fn can_assist(&self) -> bool {"
          ],
          "content": "//! Configuration-related models\n\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Agent types that can execute tasks\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Hash, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum AgentType {\n    #[default]\n    Claude,\n    Gemini,\n}\n\n/// Agent configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentConfig {\n    pub agent_type: AgentType,\n    pub image: String,\n    pub version: String,\n    pub env_vars: HashMap<String, String>,\n    pub resources: ResourceLimits,\n    pub capabilities: Vec<String>,\n    pub mcp_servers: Vec<String>,\n}\n\n/// Resource limits and requests\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResourceLimits {\n    pub cpu_request: String,\n    pub cpu_limit: String,\n    pub memory_request: String,\n    pub memory_limit: String,\n    pub ephemeral_storage_request: Option<String>,\n    pub ephemeral_storage_limit: Option<String>,\n}\n\n/// MCP server configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct McpServerConfig {\n    pub name: String,\n    pub command: String,\n    pub args: Vec<String>,\n    pub env: HashMap<String, String>,\n    pub capabilities: Vec<String>,\n}\n\n/// Orchestrator configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct OrchestratorConfig {\n    pub namespace: String,\n    pub agents: HashMap<AgentType, AgentConfig>,\n    pub default_timeout_seconds: u32,\n    pub max_retry_attempts: u32,\n    pub workspace_pvc_template: String,\n    pub prepare_job_image: String,\n    pub node_selector: HashMap<String, String>,\n}\n\nimpl Default for ResourceLimits {\n    fn default() -> Self {\n        Self {\n            cpu_request: \"100m\".to_string(),\n            cpu_limit: \"1000m\".to_string(),\n            memory_request: \"256Mi\".to_string(),\n            memory_limit: \"2Gi\".to_string(),\n            ephemeral_storage_request: None,\n            ephemeral_storage_limit: None,\n        }\n    }\n}\n\nimpl AgentType {\n    /// Get display name for the agent\n    #[must_use]\n    pub fn display_name(&self) -> &'static str {\n        match self {\n            AgentType::Claude => \"Claude Code\",\n            AgentType::Gemini => \"Gemini CLI\",\n        }\n    }\n\n    /// Get the default image for the agent\n    #[must_use]\n    pub fn default_image(&self) -> &'static str {\n        match self {\n            AgentType::Claude => \"anthropic/claude-code:latest\",\n            AgentType::Gemini => \"google/gemini-cli:latest\",\n        }\n    }\n\n    /// Check if this agent can be a primary implementer\n    #[must_use]\n    pub fn can_implement(&self) -> bool {\n        match self {\n            AgentType::Claude => true,\n            AgentType::Gemini => false, // Gemini is assistance-only in our pattern\n        }\n    }\n\n    /// Check if this agent can provide assistance\n    #[must_use]\n    pub fn can_assist(&self) -> bool {\n        match self {\n            AgentType::Claude => false, // Claude is implementation-only in our pattern\n            AgentType::Gemini => true,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_agent_type_capabilities() {\n        assert!(AgentType::Claude.can_implement());\n        assert!(!AgentType::Claude.can_assist());\n        assert!(!AgentType::Gemini.can_implement());\n        assert!(AgentType::Gemini.can_assist());\n    }\n\n    #[test]\n    fn test_resource_limits_default() {\n        let limits = ResourceLimits::default();\n        assert_eq!(limits.cpu_request, \"100m\");\n        assert_eq!(limits.memory_limit, \"2Gi\");\n    }\n\n    #[test]\n    fn test_agent_config_serialization() {\n        let config = AgentConfig {\n            agent_type: AgentType::Claude,\n            image: \"claude:v1\".to_string(),\n            version: \"1.0.0\".to_string(),\n            env_vars: HashMap::new(),\n            resources: ResourceLimits::default(),\n            capabilities: vec![\"code\".to_string(), \"test\".to_string()],\n            mcp_servers: vec![\"taskmaster\".to_string()],\n        };\n\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: AgentConfig = serde_json::from_str(&json).unwrap();\n        assert_eq!(config.agent_type, deserialized.agent_type);\n        assert_eq!(config.capabilities, deserialized.capabilities);\n    }\n}\n"
        },
        {
          "path": "common/src/models/webhook.rs",
          "file_type": "rust",
          "line_count": 232,
          "key_definitions": [
            "9:pub struct WebhookPayload {",
            "17:pub struct GitHubWebhookPayload {",
            "27:pub struct GitHubIssue {",
            "41:pub struct GitHubPullRequest {",
            "56:pub struct GitHubRepository {",
            "67:pub struct GitHubUser {",
            "76:pub struct GitHubLabel {",
            "83:pub struct GitHubRef {",
            "91:pub struct GrafanaAlert {",
            "106:pub struct GrafanaWebhookPayload {",
            "120:pub struct PmAgentPayload {",
            "128:pub struct PmTaskData {",
            "141:pub struct DiscordPayload {"
          ],
          "content": "//! Webhook payload models for various sources\n\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Generic webhook payload wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WebhookPayload {\n    pub source: super::RequestSource,\n    pub headers: HashMap<String, String>,\n    pub body: Value,\n}\n\n/// GitHub webhook payload for issue events\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubWebhookPayload {\n    pub action: String,\n    pub issue: Option<GitHubIssue>,\n    pub pull_request: Option<GitHubPullRequest>,\n    pub repository: GitHubRepository,\n    pub sender: GitHubUser,\n}\n\n/// GitHub issue structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubIssue {\n    pub id: u64,\n    pub number: u64,\n    pub title: String,\n    pub body: Option<String>,\n    pub state: String,\n    pub labels: Vec<GitHubLabel>,\n    pub created_at: String,\n    pub updated_at: String,\n    pub user: GitHubUser,\n}\n\n/// GitHub pull request structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubPullRequest {\n    pub id: u64,\n    pub number: u64,\n    pub title: String,\n    pub body: Option<String>,\n    pub state: String,\n    pub head: GitHubRef,\n    pub base: GitHubRef,\n    pub created_at: String,\n    pub updated_at: String,\n    pub user: GitHubUser,\n}\n\n/// GitHub repository information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubRepository {\n    pub id: u64,\n    pub name: String,\n    pub full_name: String,\n    pub owner: GitHubUser,\n    pub private: bool,\n    pub default_branch: String,\n}\n\n/// GitHub user information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubUser {\n    pub login: String,\n    pub id: u64,\n    #[serde(rename = \"type\")]\n    pub user_type: String,\n}\n\n/// GitHub label\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubLabel {\n    pub name: String,\n    pub color: String,\n}\n\n/// GitHub ref (branch/tag)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubRef {\n    pub label: String,\n    pub ref_field: String,\n    pub sha: String,\n}\n\n/// Grafana alert webhook payload\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GrafanaAlert {\n    pub status: String,\n    pub labels: HashMap<String, String>,\n    pub annotations: HashMap<String, String>,\n    pub values: HashMap<String, f64>,\n    #[serde(rename = \"startsAt\")]\n    pub starts_at: String,\n    #[serde(rename = \"endsAt\")]\n    pub ends_at: Option<String>,\n    #[serde(rename = \"generatorURL\")]\n    pub generator_url: String,\n}\n\n/// Grafana webhook payload wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GrafanaWebhookPayload {\n    pub receiver: String,\n    pub status: String,\n    pub alerts: Vec<GrafanaAlert>,\n    #[serde(rename = \"groupLabels\")]\n    pub group_labels: HashMap<String, String>,\n    #[serde(rename = \"commonLabels\")]\n    pub common_labels: HashMap<String, String>,\n    #[serde(rename = \"commonAnnotations\")]\n    pub common_annotations: HashMap<String, String>,\n}\n\n/// PM Agent webhook payload\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PmAgentPayload {\n    pub action: String,\n    pub project_id: String,\n    pub task: PmTaskData,\n}\n\n/// PM Agent task data\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PmTaskData {\n    pub id: String,\n    pub title: String,\n    pub description: String,\n    pub acceptance_criteria: Vec<String>,\n    pub priority: String,\n    pub status: String,\n    pub assigned_to: Option<String>,\n    pub metadata: HashMap<String, Value>,\n}\n\n/// Discord webhook payload (via relay)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DiscordPayload {\n    pub channel_id: String,\n    pub user_id: String,\n    pub username: String,\n    pub command: String,\n    pub args: Vec<String>,\n    pub message_id: String,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_github_webhook_deserialization() {\n        let json = r#\"{\n            \"action\": \"opened\",\n            \"issue\": {\n                \"id\": 123,\n                \"number\": 42,\n                \"title\": \"Test Issue\",\n                \"body\": \"Test body\",\n                \"state\": \"open\",\n                \"labels\": [],\n                \"created_at\": \"2024-01-01T00:00:00Z\",\n                \"updated_at\": \"2024-01-01T00:00:00Z\",\n                \"user\": {\n                    \"login\": \"testuser\",\n                    \"id\": 456,\n                    \"type\": \"User\"\n                }\n            },\n            \"repository\": {\n                \"id\": 789,\n                \"name\": \"test-repo\",\n                \"full_name\": \"org/test-repo\",\n                \"owner\": {\n                    \"login\": \"org\",\n                    \"id\": 999,\n                    \"type\": \"Organization\"\n                },\n                \"private\": false,\n                \"default_branch\": \"main\"\n            },\n            \"sender\": {\n                \"login\": \"testuser\",\n                \"id\": 456,\n                \"type\": \"User\"\n            }\n        }\"#;\n\n        let payload: GitHubWebhookPayload = serde_json::from_str(json).unwrap();\n        assert_eq!(payload.action, \"opened\");\n        assert!(payload.issue.is_some());\n        assert_eq!(payload.issue.unwrap().number, 42);\n    }\n\n    #[test]\n    fn test_grafana_alert_deserialization() {\n        let json = r#\"{\n            \"receiver\": \"webhook\",\n            \"status\": \"firing\",\n            \"alerts\": [{\n                \"status\": \"firing\",\n                \"labels\": {\n                    \"alertname\": \"HighErrorRate\",\n                    \"task_id\": \"123\"\n                },\n                \"annotations\": {\n                    \"summary\": \"High error rate detected\"\n                },\n                \"values\": {\n                    \"error_rate\": 0.45\n                },\n                \"startsAt\": \"2024-01-01T00:00:00Z\",\n                \"endsAt\": null,\n                \"generatorURL\": \"http://grafana/alert\"\n            }],\n            \"groupLabels\": {},\n            \"commonLabels\": {},\n            \"commonAnnotations\": {}\n        }\"#;\n\n        let payload: GrafanaWebhookPayload = serde_json::from_str(json).unwrap();\n        assert_eq!(payload.status, \"firing\");\n        assert_eq!(payload.alerts.len(), 1);\n        assert_eq!(\n            payload.alerts[0].labels.get(\"task_id\"),\n            Some(&\"123\".to_string())\n        );\n    }\n}\n"
        },
        {
          "path": "common/src/models/code_request.rs",
          "file_type": "rust",
          "line_count": 91,
          "key_definitions": [
            "9:pub struct SecretEnvVar {",
            "21:pub struct CodeRequest {"
          ],
          "content": "//! Clean code task submission request structure\n\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n// Re-export SecretEnvVar from orchestrator-core crate to avoid duplication\n// For now, we'll define it locally until we can reorganize the type sharing\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SecretEnvVar {\n    /// Name of the environment variable\n    pub name: String,\n    /// Name of the secret\n    #[serde(rename = \"secretName\")]\n    pub secret_name: String,\n    /// Key within the secret\n    #[serde(rename = \"secretKey\")]\n    pub secret_key: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CodeRequest {\n    /// Task ID to implement\n    pub task_id: u32,\n\n    /// Target service name\n    pub service: String,\n\n    /// Target project repository URL (where implementation work happens)\n    pub repository_url: String,\n\n    /// Documentation repository URL (where Task Master definitions come from)\n    pub docs_repository_url: String,\n\n    /// Project directory within docs repository (e.g. \"_projects/simple-api\")\n    pub docs_project_directory: Option<String>,\n\n    /// Working directory within target repository (defaults to service name)\n    pub working_directory: Option<String>,\n\n    /// Claude model to use (sonnet, opus) - optional, defaults handled by MCP tools\n    pub model: Option<String>,\n\n    /// GitHub username for authentication\n    pub github_user: String,\n\n    /// Local MCP tools/servers to enable (comma-separated)\n    #[serde(default)]\n    pub local_tools: Option<String>,\n\n    /// Remote MCP tools/servers to enable (comma-separated)\n    #[serde(default)]\n    pub remote_tools: Option<String>,\n\n    /// Context version for retry attempts (incremented on each retry)\n    #[serde(default = \"default_context_version\")]\n    pub context_version: u32,\n\n    /// Additional context for retry attempts\n    #[serde(default)]\n    pub prompt_modification: Option<String>,\n\n    /// Docs branch to use (e.g., \"main\", \"feature/branch\")\n    #[serde(default = \"default_docs_branch\")]\n    pub docs_branch: String,\n\n    /// Whether to continue a previous session (auto-continue on retries or user-requested)\n    #[serde(default)]\n    pub continue_session: bool,\n\n    /// Whether to overwrite memory before starting\n    #[serde(default)]\n    pub overwrite_memory: bool,\n\n    /// Environment variables to set in the container\n    #[serde(default)]\n    pub env: HashMap<String, String>,\n\n    /// Environment variables from secrets\n    #[serde(default)]\n    pub env_from_secrets: Vec<SecretEnvVar>,\n}\n\n/// Default context version\nfn default_context_version() -> u32 {\n    1\n}\n\n/// Default docs branch\nfn default_docs_branch() -> String {\n    \"main\".to_string()\n}\n"
        },
        {
          "path": "common/src/models/task.rs",
          "file_type": "rust",
          "line_count": 176,
          "key_definitions": [
            "9:pub struct Task {",
            "26:pub enum TaskStatus {",
            "38:pub enum TaskPriority {",
            "48:pub struct TaskMetadata {",
            "62:impl Task {",
            "65:pub fn new(id: String, title: String, description: String, microservice: String) -> Self {",
            "84:pub fn is_terminal(&self) -> bool {",
            "92:pub fn update_status(&mut self, status: TaskStatus) {",
            "98:impl std::fmt::Display for TaskStatus {",
            "111:impl std::fmt::Display for TaskPriority {"
          ],
          "content": "//! Task-related data models\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Represents a task to be executed by an agent\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct Task {\n    pub id: String,\n    pub title: String,\n    pub description: String,\n    pub acceptance_criteria: Vec<String>,\n    pub status: TaskStatus,\n    pub priority: TaskPriority,\n    pub microservice: String,\n    pub agent_type: Option<super::AgentType>,\n    pub metadata: TaskMetadata,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n}\n\n/// Task execution status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum TaskStatus {\n    Pending,\n    InProgress,\n    Completed,\n    Failed,\n    Cancelled,\n    Blocked,\n}\n\n/// Task priority levels\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum TaskPriority {\n    Low,\n    #[default]\n    Medium,\n    High,\n    Critical,\n}\n\n/// Additional metadata for tasks\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\npub struct TaskMetadata {\n    /// Source that created this task\n    pub source: Option<String>,\n    /// GitHub issue number if applicable\n    pub github_issue: Option<u64>,\n    /// Task Master task ID if applicable\n    pub task_master_id: Option<String>,\n    /// Custom labels\n    pub labels: HashMap<String, String>,\n    /// Additional arbitrary data\n    #[serde(flatten)]\n    pub extra: HashMap<String, serde_json::Value>,\n}\n\nimpl Task {\n    /// Create a new task with default values\n    #[must_use]\n    pub fn new(id: String, title: String, description: String, microservice: String) -> Self {\n        let now = Utc::now();\n        Self {\n            id,\n            title,\n            description,\n            acceptance_criteria: Vec::new(),\n            status: TaskStatus::Pending,\n            priority: TaskPriority::Medium,\n            microservice,\n            agent_type: None,\n            metadata: TaskMetadata::default(),\n            created_at: now,\n            updated_at: now,\n        }\n    }\n\n    /// Check if the task is in a terminal state\n    #[must_use]\n    pub fn is_terminal(&self) -> bool {\n        matches!(\n            self.status,\n            TaskStatus::Completed | TaskStatus::Failed | TaskStatus::Cancelled\n        )\n    }\n\n    /// Update the task status and timestamp\n    pub fn update_status(&mut self, status: TaskStatus) {\n        self.status = status;\n        self.updated_at = Utc::now();\n    }\n}\n\nimpl std::fmt::Display for TaskStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            TaskStatus::Pending => write!(f, \"Pending\"),\n            TaskStatus::InProgress => write!(f, \"In Progress\"),\n            TaskStatus::Completed => write!(f, \"Completed\"),\n            TaskStatus::Failed => write!(f, \"Failed\"),\n            TaskStatus::Cancelled => write!(f, \"Cancelled\"),\n            TaskStatus::Blocked => write!(f, \"Blocked\"),\n        }\n    }\n}\n\nimpl std::fmt::Display for TaskPriority {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            TaskPriority::Low => write!(f, \"Low\"),\n            TaskPriority::Medium => write!(f, \"Medium\"),\n            TaskPriority::High => write!(f, \"High\"),\n            TaskPriority::Critical => write!(f, \"Critical\"),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_task_creation() {\n        let task = Task::new(\n            \"test-123\".to_string(),\n            \"Test Task\".to_string(),\n            \"A test task\".to_string(),\n            \"auth\".to_string(),\n        );\n\n        assert_eq!(task.id, \"test-123\");\n        assert_eq!(task.status, TaskStatus::Pending);\n        assert_eq!(task.priority, TaskPriority::Medium);\n        assert!(!task.is_terminal());\n    }\n\n    #[test]\n    fn test_task_serialization() {\n        let task = Task::new(\n            \"test-123\".to_string(),\n            \"Test Task\".to_string(),\n            \"A test task\".to_string(),\n            \"auth\".to_string(),\n        );\n\n        let json = serde_json::to_string(&task).unwrap();\n        let deserialized: Task = serde_json::from_str(&json).unwrap();\n        assert_eq!(task.id, deserialized.id);\n        assert_eq!(task.status, deserialized.status);\n    }\n\n    #[test]\n    fn test_terminal_states() {\n        let mut task = Task::new(\n            \"test-123\".to_string(),\n            \"Test Task\".to_string(),\n            \"A test task\".to_string(),\n            \"auth\".to_string(),\n        );\n\n        assert!(!task.is_terminal());\n\n        task.update_status(TaskStatus::Completed);\n        assert!(task.is_terminal());\n\n        task.update_status(TaskStatus::Failed);\n        assert!(task.is_terminal());\n\n        task.update_status(TaskStatus::InProgress);\n        assert!(!task.is_terminal());\n    }\n}\n"
        },
        {
          "path": "common/src/models/docs_request.rs",
          "file_type": "rust",
          "line_count": 21,
          "key_definitions": [
            "6:pub struct DocsRequest {"
          ],
          "content": "//! Clean documentation generation request structure\n\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DocsRequest {\n    /// Git repository URL\n    pub repository_url: String,\n\n    /// Working directory within the repository\n    pub working_directory: String,\n\n    /// Claude model to use (sonnet, opus) - optional, defaults handled by MCP tools\n    pub model: Option<String>,\n\n    /// GitHub username for authentication\n    pub github_user: String,\n\n    /// Source branch (auto-detected)\n    pub source_branch: String,\n}\n"
        },
        {
          "path": "common/src/models/mod.rs",
          "file_type": "rust",
          "line_count": 25,
          "key_definitions": [],
          "content": "//! Core data models module\n\npub mod code_request;\npub mod config;\npub mod docs_request;\npub mod job;\npub mod pm_task;\npub mod request;\npub mod response;\npub mod task;\npub mod webhook;\n\n// Re-export commonly used types\npub use code_request::CodeRequest;\npub use config::{AgentConfig, AgentType, ResourceLimits};\npub use docs_request::DocsRequest;\npub use job::{Job, JobSpec, JobStatus, JobType};\npub use pm_task::{\n    DocsGenerationRequest, MarkdownPayload, PmTaskRequest, Subtask, Task as PmTask, TaskMaster,\n    TaskMasterFile,\n};\npub use request::{ParsedRequest, Request, RequestAction, RequestSource};\npub use response::{ApiResponse, JobResponse, TaskResponse};\npub use task::{Task, TaskMetadata, TaskStatus};\npub use webhook::{GitHubWebhookPayload, GrafanaAlert, WebhookPayload};\n"
        },
        {
          "path": "common/src/models/pm_task.rs",
          "file_type": "rust",
          "line_count": 447,
          "key_definitions": [
            "7:pub struct PmTaskRequest {",
            "70:pub struct Subtask {",
            "83:pub struct MarkdownPayload {",
            "91:pub struct AgentToolSpec {",
            "102:pub struct RepositorySpec {",
            "133:pub struct DocsGenerationRequest {",
            "173:pub struct TaskMasterFile {",
            "178:pub struct TaskMaster {",
            "183:pub struct Task {",
            "196:impl PmTaskRequest {",
            "199:pub fn new(",
            "218:pub fn new_with_tools(",
            "254:pub fn new_with_repository(",
            "291:pub fn new_with_full_spec(",
            "329:pub fn new_with_prompt_modification(",
            "369:pub fn new_with_tool_config("
          ],
          "content": "//! PM task submission models\n\nuse serde::{Deserialize, Serialize};\n\n/// PM task request structure according to design document\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PmTaskRequest {\n    // Task Master schema fields\n    pub id: u32,\n    pub title: String,\n    pub description: String,\n    pub details: String,\n    pub test_strategy: String,\n    pub priority: String,\n    pub dependencies: Vec<u32>,\n    pub status: String,\n    pub subtasks: Vec<Subtask>,\n\n    // PM-specific fields\n    pub service_name: String,\n    pub agent_name: String,\n\n    // Claude model selection (sonnet, opus)\n    pub model: String,\n\n    // Markdown files as structured payloads\n    pub markdown_files: Vec<MarkdownPayload>,\n\n    // Agent tools specification\n    #[serde(default)]\n    pub agent_tools: Vec<AgentToolSpec>,\n\n    // Repository specification for code access\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub repository: Option<RepositorySpec>,\n\n    // Working directory within target repository (defaults to service_name)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub working_directory: Option<String>,\n\n    // Additional prompt instructions for retry attempts\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_modification: Option<String>,\n\n    // How to apply prompt_modification: 'append' or 'replace'\n    #[serde(\n        default = \"default_prompt_mode\",\n        skip_serializing_if = \"is_default_prompt_mode\"\n    )]\n    pub prompt_mode: String,\n\n    // Local Claude Code tools to enable\n    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n    pub local_tools: Vec<String>,\n\n    // Remote MCP tools to enable\n    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n    pub remote_tools: Vec<String>,\n\n    // Tool configuration preset\n    #[serde(\n        default = \"default_tool_config\",\n        skip_serializing_if = \"is_default_tool_config\"\n    )]\n    pub tool_config: String,\n}\n\n/// Subtask structure from Task Master\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Subtask {\n    pub id: u32,\n    pub title: String,\n    pub description: String,\n    pub dependencies: Vec<u32>,\n    pub details: String,\n    pub status: String,\n    #[serde(default, alias = \"testStrategy\")]\n    pub test_strategy: String,\n}\n\n/// Markdown file payload for network transmission\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MarkdownPayload {\n    pub content: String,\n    pub filename: String,\n    pub file_type: String,\n}\n\n/// Agent tool specification for PM requests\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentToolSpec {\n    pub name: String,\n    pub enabled: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub config: Option<serde_json::Value>,\n    #[serde(default)]\n    pub restrictions: Vec<String>,\n}\n\n/// Repository specification for cloning source code\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RepositorySpec {\n    pub url: String,\n    #[serde(default = \"default_branch\")]\n    pub branch: String,\n    pub github_user: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub token: Option<String>, // Reserved for future use - TODO: Implement direct token submission\n}\n\nfn default_branch() -> String {\n    \"main\".to_string()\n}\n\nfn default_prompt_mode() -> String {\n    \"append\".to_string()\n}\n\nfn is_default_prompt_mode(mode: &str) -> bool {\n    mode == \"append\"\n}\n\nfn default_tool_config() -> String {\n    \"default\".to_string()\n}\n\nfn is_default_tool_config(config: &str) -> bool {\n    config == \"default\"\n}\n\n/// Documentation generation request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DocsGenerationRequest {\n    /// Repository URL to clone\n    pub repository_url: String,\n\n    /// Working directory within the repository (path to .taskmaster)\n    pub working_directory: String,\n\n    /// Source branch to checkout and base new branch from\n    pub source_branch: String,\n\n    /// Target branch for the PR\n    pub target_branch: String,\n\n    /// Service name for the job\n    pub service_name: String,\n\n    /// Agent name for the job\n    pub agent_name: String,\n\n    /// Claude model selection (sonnet, opus)\n    pub model: String,\n\n    /// GitHub user for authentication\n    pub github_user: String,\n\n    /// Optional specific task ID to generate docs for (if None, generates all)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub task_id: Option<u32>,\n\n    /// Force overwrite existing documentation\n    #[serde(default)]\n    pub force: bool,\n\n    /// Dry run mode (preview only)\n    #[serde(default)]\n    pub dry_run: bool,\n}\n\n/// Task Master JSON file structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskMasterFile {\n    pub master: TaskMaster,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskMaster {\n    pub tasks: Vec<Task>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Task {\n    pub id: u32,\n    pub title: String,\n    pub description: String,\n    pub details: String,\n    #[serde(default, alias = \"testStrategy\")]\n    pub test_strategy: String,\n    pub priority: String,\n    pub dependencies: Vec<u32>,\n    pub status: String,\n    pub subtasks: Vec<Subtask>,\n}\n\nimpl PmTaskRequest {\n    /// Create a new PM task request from Task Master task and markdown files\n    #[must_use]\n    pub fn new(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n    ) -> Self {\n        Self::new_with_tools(\n            task,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            Vec::new(),\n        )\n    }\n\n    /// Create a new PM task request with agent tools specification\n    #[must_use]\n    pub fn new_with_tools(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository: None,\n            working_directory: None,\n            prompt_modification: None,\n            prompt_mode: \"append\".to_string(),\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request from Task Master task with repository support\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_repository(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory: None,\n            prompt_modification: None,\n            prompt_mode: \"append\".to_string(),\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request with full specification including working directory\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_full_spec(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n        working_directory: Option<String>,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory,\n            prompt_modification: None,\n            prompt_mode: \"append\".to_string(),\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request with prompt modification support for retries\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_prompt_modification(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n        working_directory: Option<String>,\n        prompt_modification: Option<String>,\n        prompt_mode: String,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory,\n            prompt_modification,\n            prompt_mode,\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request with full tool configuration support\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_tool_config(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n        working_directory: Option<String>,\n        prompt_modification: Option<String>,\n        prompt_mode: String,\n        local_tools: Vec<String>,\n        remote_tools: Vec<String>,\n        tool_config: String,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory,\n            prompt_modification,\n            prompt_mode,\n            local_tools,\n            remote_tools,\n            tool_config,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_pm_task_request_creation() {\n        let task = Task {\n            id: 1001,\n            title: \"Test Task\".to_string(),\n            description: \"Test description\".to_string(),\n            details: \"Test details\".to_string(),\n            test_strategy: \"Test strategy\".to_string(),\n            priority: \"high\".to_string(),\n            dependencies: vec![],\n            status: \"pending\".to_string(),\n            subtasks: vec![],\n        };\n\n        let markdown_files = vec![MarkdownPayload {\n            content: \"# Task Content\".to_string(),\n            filename: \"task.md\".to_string(),\n            file_type: \"task\".to_string(),\n        }];\n\n        let request = PmTaskRequest::new(\n            task,\n            \"test-service\".to_string(),\n            \"claude-agent-1\".to_string(),\n            \"sonnet\".to_string(),\n            markdown_files,\n        );\n\n        assert_eq!(request.id, 1001);\n        assert_eq!(request.service_name, \"test-service\");\n        assert_eq!(request.model, \"sonnet\");\n        assert_eq!(request.markdown_files.len(), 1);\n    }\n}\n"
        }
      ],
      "dependencies": [],
      "description": "No description available",
      "line_count": 7687
    },
    {
      "name": "fivedlabs-tools",
      "path": "orchestrator/tools",
      "component_type": "RustLibrary",
      "source_files": [
        {
          "path": "src/mcp/tools.rs",
          "file_type": "rust",
          "line_count": 143,
          "key_definitions": [
            "4:pub fn get_all_tool_schemas() -> Value {"
          ],
          "content": "use serde_json::{json, Value};\n\n/// Get all tool schemas with descriptions and parameter definitions\npub fn get_all_tool_schemas() -> Value {\n    json!({\n        \"tools\": [\n            get_init_docs_schema(),\n            get_submit_implementation_task_schema()\n        ]\n    })\n}\n\nfn get_init_docs_schema() -> Value {\n    json!({\n        \"name\": \"docs\",\n        \"description\": \"Initialize documentation for Task Master tasks using Claude\",\n        \"inputSchema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"working_directory\": {\n                    \"type\": \"string\",\n                    \"description\": \"Working directory containing .taskmaster folder (required). Use relative paths like '_projects/simple-api'.\"\n                },\n                \"model\": {\n                    \"type\": \"string\",\n                    \"description\": \"Claude model to use (default: 'claude-opus-4-20250514')\",\n                    \"default\": \"claude-opus-4-20250514\"\n                },\n                \"github_user\": {\n                    \"type\": \"string\",\n                    \"description\": \"GitHub username for authentication (optional if FDL_DEFAULT_DOCS_USER environment variable is set, which takes precedence)\"\n                }\n            },\n            \"required\": [\"working_directory\"]\n        }\n    })\n}\n\nfn get_submit_implementation_task_schema() -> Value {\n    json!({\n        \"name\": \"task\",\n        \"description\": \"Submit a Task Master task for implementation using Claude with persistent workspace\",\n        \"inputSchema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"task_id\": {\n                    \"type\": \"integer\",\n                    \"description\": \"REQUIRED: Task ID to implement from tasks.json\",\n                    \"minimum\": 1\n                },\n                \"service\": {\n                    \"type\": \"string\",\n                    \"description\": \"REQUIRED: Target service name (creates workspace-{service} PVC)\",\n                    \"pattern\": \"^[a-z0-9-]+$\"\n                },\n                \"working_directory\": {\n                    \"type\": \"string\",\n                    \"description\": \"Working directory within target repository (required)\"\n                },\n                \"model\": {\n                    \"type\": \"string\",\n                    \"description\": \"Claude model to use (default: 'claude-sonnet-4-20250514')\",\n                    \"default\": \"claude-sonnet-4-20250514\"\n                },\n                \"docs_repository_url\": {\n                    \"type\": \"string\",\n                    \"description\": \"Documentation repository URL (where Task Master definitions come from)\"\n                },\n                \"docs_project_directory\": {\n                    \"type\": \"string\",\n                    \"description\": \"Project directory within docs repository (e.g. '_projects/simple-api')\"\n                },\n                \"github_user\": {\n                    \"type\": \"string\",\n                    \"description\": \"GitHub username for authentication (optional if FDL_DEFAULT_CODE_USER environment variable is set, which takes precedence)\"\n                },\n                \"local_tools\": {\n                    \"type\": \"string\",\n                    \"description\": \"Comma-separated list of local MCP tools/servers to enable (e.g., 'mcp-server-git,taskmaster')\"\n                },\n                \"remote_tools\": {\n                    \"type\": \"string\",\n                    \"description\": \"Comma-separated list of remote MCP tools/servers to enable (e.g., 'api-docs-tool')\"\n                },\n                \"context_version\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Context version for retry attempts (incremented on each retry, default: 1)\",\n                    \"minimum\": 1,\n                    \"default\": 1\n                },\n                \"prompt_modification\": {\n                    \"type\": \"string\",\n                    \"description\": \"Additional context for retry attempts\"\n                },\n                \"docs_branch\": {\n                    \"type\": \"string\",\n                    \"description\": \"Docs branch to use (e.g., 'main', 'feature/branch', default: 'main')\",\n                    \"default\": \"main\"\n                },\n                \"continue_session\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether to continue a previous session (auto-continue on retries or user-requested, default: false)\",\n                    \"default\": false\n                },\n                \"overwrite_memory\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether to overwrite memory before starting (default: false)\",\n                    \"default\": false\n                },\n                \"env\": {\n                    \"type\": \"object\",\n                    \"description\": \"Environment variables to set in the container (key-value pairs)\",\n                    \"additionalProperties\": {\n                        \"type\": \"string\"\n                    }\n                },\n                \"env_from_secrets\": {\n                    \"type\": \"array\",\n                    \"description\": \"Environment variables from secrets\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"name\": {\n                                \"type\": \"string\",\n                                \"description\": \"Name of the environment variable\"\n                            },\n                            \"secretName\": {\n                                \"type\": \"string\",\n                                \"description\": \"Name of the secret\"\n                            },\n                            \"secretKey\": {\n                                \"type\": \"string\",\n                                \"description\": \"Key within the secret\"\n                            }\n                        },\n                        \"required\": [\"name\", \"secretName\", \"secretKey\"]\n                    }\n                }\n            },\n            \"required\": [\"task_id\", \"service\", \"working_directory\"]\n        }\n    })\n}\n"
        },
        {
          "path": "src/mcp/main.rs",
          "file_type": "rust",
          "line_count": 548,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - MCP Tools for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\nuse anyhow::{anyhow, Context, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{json, Value};\nuse std::collections::HashMap;\nuse std::process::{Command, Stdio};\nuse tokio::io::{AsyncBufReadExt, AsyncWriteExt, BufReader};\nuse tokio::runtime::Runtime;\n\nmod tools;\n\n// Custom error type for production-ready error handling.\n#[derive(Debug, Serialize)]\nstruct RpcError {\n    code: i32,\n    message: String,\n    data: Option<Value>,\n}\n\n// JSON-RPC Success Response structure.\n#[derive(Serialize)]\nstruct RpcSuccessResponse {\n    jsonrpc: String,\n    result: Value,\n    id: Option<Value>,\n}\n\n// JSON-RPC Error Response structure.\n#[derive(Serialize)]\nstruct RpcErrorResponse {\n    jsonrpc: String,\n    error: RpcError,\n    id: Option<Value>,\n}\n\n// JSON-RPC Request structure.\n#[derive(Deserialize)]\nstruct RpcRequest {\n    #[allow(dead_code)]\n    jsonrpc: String,\n    method: String,\n    params: Option<Value>,\n    id: Option<Value>,\n}\n\n/// Run the orchestrator CLI command\nfn run_orchestrator_cli(args: &[&str]) -> Result<String> {\n    // Use the local build in the same directory as this MCP binary\n    let mut cmd = Command::new(\"fdl\");\n    cmd.args(args);\n    cmd.stderr(Stdio::piped());\n    let output = cmd.output().context(\"Failed to execute orchestrator-cli\")?;\n    if !output.status.success() {\n        let err = String::from_utf8_lossy(&output.stderr).to_string();\n        return Err(anyhow!(\"orchestrator-cli failed: {}\", err));\n    }\n    Ok(String::from_utf8_lossy(&output.stdout).to_string())\n}\n\n// Capabilities advertised by the server with full MCP tool schemas.\nfn get_capabilities() -> Value {\n    tools::get_all_tool_schemas()\n}\n\n// Extract parameters from JSON value into HashMap\nfn extract_params(params: Option<&Value>) -> HashMap<String, Value> {\n    params\n        .and_then(|p| {\n            p.as_object()\n                .map(|o| o.iter().map(|(k, v)| (k.clone(), v.clone())).collect())\n        })\n        .unwrap_or_default()\n}\n\n// Handle MCP protocol methods\nfn handle_mcp_protocol_methods(\n    method: &str,\n    params_map: &HashMap<String, Value>,\n) -> Option<Result<Value>> {\n    match method {\n        \"initialize\" => {\n            // MCP initialization - validate required fields and return proper server capabilities\n            let _protocol_version = params_map\n                .get(\"protocolVersion\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"2025-06-18\");\n\n            // Validate that required fields are present (as per MCP schema)\n            if params_map.get(\"capabilities\").is_none()\n                || params_map.get(\"clientInfo\").is_none()\n                || params_map.get(\"protocolVersion\").is_none()\n            {\n                return Some(Err(anyhow!(\"Missing required initialize parameters: capabilities, clientInfo, and protocolVersion are required\")));\n            }\n\n            Some(Ok(json!({\n                \"protocolVersion\": \"2025-06-18\",\n                \"capabilities\": {\n                    \"tools\": {\n                        \"listChanged\": true\n                    }\n                },\n                \"serverInfo\": {\n                    \"name\": \"orchestrator-mcp\",\n                    \"title\": \"Orchestrator MCP Server\",\n                    \"version\": \"1.0.0\"\n                }\n            })))\n        }\n        \"notifications/initialized\" => {\n            // MCP initialized notification - no response should be sent\n            None\n        }\n        method if method.starts_with(\"notifications/\") => {\n            // Debug: catch any notifications we might be missing\n            None\n        }\n\n        \"tools/list\" => {\n            // Return list of available tools with schemas\n            let capabilities = get_capabilities();\n            // Debug output removed to satisfy clippy\n            Some(Ok(capabilities))\n        }\n        _ => None,\n    }\n}\n\n// Handle orchestrator tool methods\nfn handle_orchestrator_tools(\n    method: &str,\n    params_map: &HashMap<String, Value>,\n) -> Option<Result<Value>> {\n    match method {\n        \"docs\" => {\n            // Initialize documentation for Task Master tasks\n            // Debug output removed to satisfy clippy\n\n            // Extract required working directory parameter\n            let working_directory =\n                match params_map.get(\"working_directory\").and_then(|v| v.as_str()) {\n                    Some(wd) => wd,\n                    None => return Some(Err(anyhow!(\"working_directory parameter is required\"))),\n                };\n\n            // Extract model with default\n            let model = params_map\n                .get(\"model\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"claude-opus-4-20250514\");\n\n            // Get GitHub user from environment variable (takes precedence) or parameter\n            let env_user = std::env::var(\"FDL_DEFAULT_DOCS_USER\").ok();\n            let github_user = match env_user\n                .as_deref()\n                .or_else(|| params_map.get(\"github_user\").and_then(|v| v.as_str()))\n            {\n                Some(user) => user,\n                None => return Some(Err(anyhow!(\"github_user parameter is required or FDL_DEFAULT_DOCS_USER environment variable must be set\"))),\n            };\n\n            // Validate model parameter - allow any model that starts with \"claude-\"\n            if !model.starts_with(\"claude-\") {\n                return Some(Err(anyhow!(\"Invalid model '{}'. Must be a valid Claude model name (e.g., 'claude-opus-4-20250514')\", model)));\n            }\n\n            // Build CLI arguments\n            let mut args = vec![\"task\", \"docs\"];\n\n            // Add required parameters\n            args.extend(&[\"--model\", model]);\n            args.extend(&[\"--working-directory\", working_directory]);\n            args.extend(&[\"--github-user\", github_user]);\n\n            // Debug output removed to satisfy clippy\n\n            // Execute the CLI command\n            match run_orchestrator_cli(&args) {\n                Ok(output) => Some(Ok(json!({\n                    \"success\": true,\n                    \"message\": \"Documentation generation initiated successfully\",\n                    \"output\": output,\n                    \"parameters_used\": {\n                        \"model\": model,\n                        \"working_directory\": working_directory,\n                        \"github_user\": github_user\n                    }\n                }))),\n                Err(e) => Some(Err(anyhow!(\"Failed to execute docs command: {}\", e))),\n            }\n        }\n        \"task\" => {\n            // Submit a Task Master task for implementation\n            // Debug output removed to satisfy clippy\n\n            // Extract required parameters\n            let task_id = match params_map\n                .get(\"task_id\")\n                .and_then(serde_json::Value::as_u64)\n            {\n                Some(id) => id,\n                None => return Some(Err(anyhow!(\"Missing required parameter: task_id\"))),\n            };\n\n            let service = match params_map.get(\"service\").and_then(|v| v.as_str()) {\n                Some(s) => s,\n                None => return Some(Err(anyhow!(\"Missing required parameter: service\"))),\n            };\n\n            // Extract optional parameters with defaults\n            let docs_repository_url = params_map\n                .get(\"docs_repository_url\")\n                .and_then(|v| v.as_str());\n\n            let docs_project_directory = params_map\n                .get(\"docs_project_directory\")\n                .and_then(|v| v.as_str());\n\n            let working_directory = params_map.get(\"working_directory\").and_then(|v| v.as_str());\n\n            // Extract parameters with task-specific default\n            let model = params_map\n                .get(\"model\")\n                .and_then(|v| v.as_str())\n                .filter(|s| !s.is_empty());\n\n            let model = match model {\n                Some(m) => m,\n                None => return Some(Err(anyhow!(\"Model parameter is required. Please specify a model like 'claude-opus-4-20250514' or 'claude-sonnet-4-20250514'\"))),\n            };\n\n            let github_user = params_map.get(\"github_user\").and_then(|v| v.as_str());\n\n            // Get GitHub user from environment variable (takes precedence) or parameter\n            let env_code_user = std::env::var(\"FDL_DEFAULT_CODE_USER\").ok();\n            let github_user = env_code_user.as_deref().or(github_user);\n\n            let local_tools = params_map.get(\"local_tools\").and_then(|v| v.as_str());\n\n            let remote_tools = params_map.get(\"remote_tools\").and_then(|v| v.as_str());\n\n            let context_version = params_map\n                .get(\"context_version\")\n                .and_then(serde_json::Value::as_u64)\n                .and_then(|v| u32::try_from(v).ok())\n                .unwrap_or(1);\n\n            let prompt_modification = params_map\n                .get(\"prompt_modification\")\n                .and_then(|v| v.as_str());\n\n            let docs_branch = params_map\n                .get(\"docs_branch\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"main\");\n\n            let continue_session = params_map\n                .get(\"continue_session\")\n                .and_then(serde_json::Value::as_bool)\n                .unwrap_or(false);\n\n            let overwrite_memory = params_map\n                .get(\"overwrite_memory\")\n                .and_then(serde_json::Value::as_bool)\n                .unwrap_or(false);\n\n            let env = params_map.get(\"env\").and_then(|v| v.as_object());\n\n            let env_from_secrets = params_map\n                .get(\"env_from_secrets\")\n                .and_then(|v| v.as_array());\n\n            // Validate model parameter - allow any model that starts with \"claude-\"\n            if !model.starts_with(\"claude-\") {\n                return Some(Err(anyhow!(\"Invalid model '{}'. Must be a valid Claude model name (e.g., 'claude-sonnet-4-20250514')\", model)));\n            }\n\n            // Validate service name (must be valid for PVC naming)\n            if !service\n                .chars()\n                .all(|c| c.is_ascii_lowercase() || c.is_ascii_digit() || c == '-')\n            {\n                return Some(Err(anyhow!(\"Invalid service name '{}'. Must contain only lowercase letters, numbers, and hyphens\", service)));\n            }\n\n            // Build CLI arguments using the new CLI interface\n            let mut args = vec![\"task\", \"code\"];\n\n            // Add required parameters (task_id is positional, not a flag)\n            let task_id_str = task_id.to_string();\n            args.push(&task_id_str);\n            args.extend(&[\"--service\", service]);\n\n            // Add model parameter\n            args.extend(&[\"--model\", model]);\n\n            // Add docs repository URL if specified\n            if let Some(docs_repo) = docs_repository_url {\n                args.extend(&[\"--docs-repository-url\", docs_repo]);\n            }\n\n            // Add docs project directory if specified\n            if let Some(docs_proj_dir) = docs_project_directory {\n                args.extend(&[\"--docs-project-directory\", docs_proj_dir]);\n            }\n\n            // Add working directory if specified\n            if let Some(wd) = working_directory {\n                args.extend(&[\"--working-directory\", wd]);\n            }\n\n            // Add GitHub user if specified\n            if let Some(user) = github_user {\n                args.extend(&[\"--github-user\", user]);\n            }\n\n            // Add tool configuration parameters\n            if let Some(local) = local_tools {\n                args.extend(&[\"--local-tools\", local]);\n            }\n\n            if let Some(remote) = remote_tools {\n                args.extend(&[\"--remote-tools\", remote]);\n            }\n\n            // Add context version\n            let context_version_str = context_version.to_string();\n            args.extend(&[\"--context-version\", &context_version_str]);\n\n            // Add prompt modification if specified\n            if let Some(prompt_mod) = prompt_modification {\n                args.extend(&[\"--prompt-modification\", prompt_mod]);\n            }\n\n            // Add docs branch\n            args.extend(&[\"--docs-branch\", docs_branch]);\n\n            // Add session flags\n            if continue_session {\n                args.push(\"--continue-session\");\n            }\n\n            if overwrite_memory {\n                args.push(\"--overwrite-memory\");\n            }\n\n            // Prepare environment variables string if specified\n            #[allow(unused_assignments)]\n            let mut env_string = String::new();\n            if let Some(env_obj) = env {\n                let mut env_pairs = Vec::new();\n                for (key, value) in env_obj {\n                    if let Some(val_str) = value.as_str() {\n                        env_pairs.push(format!(\"{key}={val_str}\"));\n                    }\n                }\n                if !env_pairs.is_empty() {\n                    env_string = env_pairs.join(\",\");\n                    args.extend(&[\"--env\", &env_string]);\n                }\n            }\n\n            // Prepare environment variables from secrets string if specified\n            #[allow(unused_assignments)]\n            let mut secrets_string = String::new();\n            if let Some(env_secrets_arr) = env_from_secrets {\n                let mut secret_specs = Vec::new();\n                for secret in env_secrets_arr {\n                    if let Some(secret_obj) = secret.as_object() {\n                        if let (Some(name), Some(secret_name), Some(secret_key)) = (\n                            secret_obj.get(\"name\").and_then(|v| v.as_str()),\n                            secret_obj.get(\"secretName\").and_then(|v| v.as_str()),\n                            secret_obj.get(\"secretKey\").and_then(|v| v.as_str()),\n                        ) {\n                            secret_specs.push(format!(\"{name}:{secret_name}:{secret_key}\"));\n                        }\n                    }\n                }\n                if !secret_specs.is_empty() {\n                    secrets_string = secret_specs.join(\",\");\n                    args.extend(&[\"--env-from-secrets\", &secrets_string]);\n                }\n            }\n\n            // Debug output removed to satisfy clippy\n\n            // Execute the CLI command\n            match run_orchestrator_cli(&args) {\n                Ok(output) => Some(Ok(json!({\n                    \"success\": true,\n                    \"message\": \"Implementation task submitted successfully\",\n                    \"output\": output,\n                    \"parameters_used\": {\n                        \"task_id\": task_id,\n                        \"service\": service,\n                        \"docs_repository_url\": docs_repository_url,\n                        \"docs_project_directory\": docs_project_directory,\n                        \"working_directory\": working_directory,\n                        \"model\": model,\n                        \"github_user\": github_user,\n                        \"local_tools\": local_tools,\n                        \"remote_tools\": remote_tools,\n                        \"context_version\": context_version,\n                        \"prompt_modification\": prompt_modification,\n                        \"docs_branch\": docs_branch,\n                        \"continue_session\": continue_session,\n                        \"overwrite_memory\": overwrite_memory,\n                        \"env\": env,\n                        \"env_from_secrets\": env_from_secrets\n                    }\n                }))),\n                Err(e) => Some(Err(anyhow!(\"Failed to execute submit task: {}\", e))),\n            }\n        }\n        _ => None,\n    }\n}\n\n// Handle tool invocation\nfn handle_tool_invocation(params_map: &HashMap<String, Value>) -> Result<Value> {\n    let name = params_map\n        .get(\"name\")\n        .and_then(|v| v.as_str())\n        .ok_or(anyhow!(\"Missing tool name\"))?;\n    let default_args = json!({});\n    let arguments = params_map.get(\"arguments\").unwrap_or(&default_args);\n\n    // Extract arguments as a map for the tool handlers\n    let args_map = extract_params(Some(arguments));\n\n    // Try orchestrator tools\n    if let Some(result) = handle_orchestrator_tools(name, &args_map) {\n        match result {\n            Ok(content) => Ok(json!({\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": serde_json::to_string_pretty(&content).unwrap_or_else(|_| content.to_string())\n                    }\n                ]\n            })),\n            Err(e) => Err(e),\n        }\n    } else {\n        Err(anyhow!(\"Unknown tool: {}\", name))\n    }\n}\n\n// Handle core MCP methods (including tool calls)\nfn handle_core_methods(method: &str, params_map: &HashMap<String, Value>) -> Option<Result<Value>> {\n    match method {\n        \"tools/call\" => Some(handle_tool_invocation(params_map)),\n        _ => None,\n    }\n}\n\n// Handler for each method (following MCP specification).\nfn handle_method(method: &str, params: Option<&Value>) -> Option<Result<Value>> {\n    let params_map = extract_params(params);\n\n    // Try MCP protocol methods FIRST (ping, initialize, tools/list, etc.)\n    if let Some(result) = handle_mcp_protocol_methods(method, &params_map) {\n        return Some(result); // Found a matching MCP method\n    }\n\n    // Special handling for notifications that should return None\n    if method.starts_with(\"notifications/\") {\n        return None; // Notifications should not have responses\n    }\n\n    // Try core methods (tools/call)\n    if let Some(result) = handle_core_methods(method, &params_map) {\n        return Some(result);\n    }\n\n    // Try orchestrator tools directly (for debugging)\n    if let Some(result) = handle_orchestrator_tools(method, &params_map) {\n        return Some(result);\n    }\n\n    Some(Err(anyhow!(\"Unknown method: {}\", method)))\n}\n\n// Main async RPC loop over stdio (from MCP specification).\nasync fn rpc_loop() -> Result<()> {\n    let stdin = tokio::io::stdin();\n    let reader = BufReader::new(stdin);\n    let mut lines = reader.lines();\n    let mut stdout = tokio::io::stdout();\n\n    while let Some(line) = lines.next_line().await? {\n        let request: RpcRequest = serde_json::from_str(&line).context(\"Invalid JSON request\")?;\n\n        let result = handle_method(&request.method, request.params.as_ref());\n        if let Some(method_result) = result {\n            let resp_json = match method_result {\n                Ok(res) => {\n                    let response = RpcSuccessResponse {\n                        jsonrpc: \"2.0\".to_string(),\n                        result: res,\n                        id: request.id,\n                    };\n                    serde_json::to_string(&response)?\n                }\n                Err(err) => {\n                    let response = RpcErrorResponse {\n                        jsonrpc: \"2.0\".to_string(),\n                        error: RpcError {\n                            code: -32600,\n                            message: err.to_string(),\n                            data: None,\n                        },\n                        id: request.id,\n                    };\n                    serde_json::to_string(&response)?\n                }\n            };\n            stdout.write_all((resp_json + \"\\n\").as_bytes()).await?;\n            stdout.flush().await?;\n        }\n        // If result is None, it's a notification - no response should be sent\n    }\n    Ok(())\n}\n\nfn main() -> Result<()> {\n    let rt = Runtime::new()?;\n    rt.block_on(rpc_loop())?;\n\n    Ok(())\n}\n"
        },
        {
          "path": "src/cli/analyzer.rs",
          "file_type": "rust",
          "line_count": 810,
          "key_definitions": [
            "8:pub struct CodebaseAnalysis {",
            "16:pub struct ProjectOverview {",
            "25:pub struct ProjectStatistics {",
            "34:pub struct Component {",
            "45:pub enum ComponentType {",
            "55:pub struct SourceFile {",
            "64:pub struct ApiDefinition {",
            "72:pub struct ApiEndpoint {",
            "80:pub struct DataModel {",
            "88:pub struct ConfigFile {",
            "95:pub struct CodebaseAnalyzer {",
            "100:impl CodebaseAnalyzer {",
            "101:pub fn new(workspace_root: PathBuf, include_source: bool) -> Self {",
            "108:pub fn analyze(&self) -> Result<CodebaseAnalysis> {",
            "614:pub fn generate_modular_markdown(&self, analysis: &CodebaseAnalysis, output_dir: &str) -> Result<()> {",
            "779:pub fn generate_single_markdown(&self, analysis: &CodebaseAnalysis) -> Result<String> {"
          ],
          "content": "use anyhow::Result;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::fs;\nuse std::path::{Path, PathBuf};\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct CodebaseAnalysis {\n    pub overview: ProjectOverview,\n    pub components: Vec<Component>,\n    pub apis: Vec<ApiDefinition>,\n    pub configurations: Vec<ConfigFile>,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ProjectOverview {\n    pub name: String,\n    pub description: String,\n    pub architecture: String,\n    pub technologies: Vec<String>,\n    pub statistics: ProjectStatistics,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ProjectStatistics {\n    pub rust_crates: usize,\n    pub total_rs_files: usize,\n    pub total_lines_of_code: usize,\n    pub config_files: usize,\n    pub components_analyzed: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct Component {\n    pub name: String,\n    pub path: String,\n    pub component_type: ComponentType,\n    pub source_files: Vec<SourceFile>,\n    pub dependencies: Vec<String>,\n    pub description: String,\n    pub line_count: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub enum ComponentType {\n    RustBinary,\n    RustLibrary,\n    HelmChart,\n    KubernetesConfig,\n    Documentation,\n    Scripts,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct SourceFile {\n    pub path: String,\n    pub file_type: String,\n    pub line_count: usize,\n    pub key_definitions: Vec<String>,\n    pub content: Option<String>, // Only included if include_source is true\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ApiDefinition {\n    pub name: String,\n    pub file_path: String,\n    pub endpoints: Vec<ApiEndpoint>,\n    pub data_models: Vec<DataModel>,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ApiEndpoint {\n    pub method: String,\n    pub path: String,\n    pub handler: String,\n    pub line_number: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct DataModel {\n    pub name: String,\n    pub model_type: String,\n    pub fields: Vec<String>,\n    pub file_path: String,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ConfigFile {\n    pub name: String,\n    pub path: String,\n    pub config_type: String,\n    pub content: Option<String>,\n}\n\npub struct CodebaseAnalyzer {\n    workspace_root: PathBuf,\n    include_source: bool,\n}\n\nimpl CodebaseAnalyzer {\n    pub fn new(workspace_root: PathBuf, include_source: bool) -> Self {\n        Self {\n            workspace_root,\n            include_source,\n        }\n    }\n\n        pub fn analyze(&self) -> Result<CodebaseAnalysis> {\n        println!(\"🔍 Analyzing codebase at: {}\", self.workspace_root.display());\n\n        let mut overview = self.analyze_project_overview()?;\n        let components = self.analyze_components()?;\n        let apis = self.analyze_apis()?;\n        let configurations = self.analyze_configurations()?;\n\n        // Update the components analyzed count\n        overview.statistics.components_analyzed = components.len();\n\n        Ok(CodebaseAnalysis {\n            overview,\n            components,\n            apis,\n            configurations,\n        })\n    }\n\n    fn analyze_project_overview(&self) -> Result<ProjectOverview> {\n        println!(\"📋 Analyzing project overview...\");\n\n        let readme_path = self.workspace_root.join(\"README.md\");\n        let mut description = String::new();\n        let mut name = \"Unknown Project\".to_string();\n\n        if readme_path.exists() {\n            let content = fs::read_to_string(&readme_path)?;\n            if let Some(first_line) = content.lines().find(|line| !line.starts_with('#') && !line.trim().is_empty()) {\n                description = first_line.to_string();\n            }\n            if let Some(header) = content.lines().find(|line| line.starts_with(\"# \")) {\n                name = header.trim_start_matches(\"# \").to_string();\n            }\n        }\n\n        // Calculate statistics\n        let rust_crates = self.count_cargo_files()?;\n        let (total_rs_files, total_lines_of_code) = self.count_rust_files()?;\n        let config_files = self.count_config_files()?;\n\n        Ok(ProjectOverview {\n            name,\n            description,\n            architecture: \"Kubernetes-based orchestrator with MCP integration\".to_string(),\n            technologies: vec![\n                \"Rust\".to_string(),\n                \"Kubernetes\".to_string(),\n                \"Helm\".to_string(),\n                \"MCP\".to_string(),\n                \"Docker\".to_string(),\n            ],\n            statistics: ProjectStatistics {\n                rust_crates,\n                total_rs_files,\n                total_lines_of_code,\n                config_files,\n                components_analyzed: 0, // Will be set correctly in analyze()\n            },\n        })\n    }\n\n    fn analyze_components(&self) -> Result<Vec<Component>> {\n        println!(\"🔧 Analyzing components...\");\n\n        let mut components = Vec::new();\n\n        // Analyze Rust components\n        self.analyze_rust_components(&mut components)?;\n\n        // Analyze infrastructure components\n        self.analyze_infra_components(&mut components)?;\n\n        println!(\"✅ Found {} components\", components.len());\n        Ok(components)\n    }\n\n    fn analyze_rust_components(&self, components: &mut Vec<Component>) -> Result<()> {\n        let cargo_files = self.find_files_by_name(\"Cargo.toml\")?;\n\n        for cargo_path in cargo_files {\n            if cargo_path.to_string_lossy().contains(\"target/\") {\n                continue;\n            }\n\n            let component_dir = cargo_path.parent().unwrap();\n            let rel_path = component_dir.strip_prefix(&self.workspace_root)\n                .unwrap_or(component_dir)\n                .to_string_lossy()\n                .to_string();\n\n            let cargo_content = fs::read_to_string(&cargo_path)?;\n            let component_name = self.extract_cargo_name(&cargo_content)\n                .unwrap_or_else(|| component_dir.file_name().unwrap().to_string_lossy().to_string());\n\n            let component_type = if component_dir.join(\"src/main.rs\").exists() {\n                ComponentType::RustBinary\n            } else {\n                ComponentType::RustLibrary\n            };\n\n            let source_files = self.analyze_rust_source_files(component_dir)?;\n            let dependencies = self.extract_dependencies(&cargo_content);\n            let line_count = source_files.iter().map(|f| f.line_count).sum();\n\n            components.push(Component {\n                name: component_name,\n                path: rel_path,\n                component_type,\n                source_files,\n                dependencies,\n                description: self.extract_description(&cargo_content),\n                line_count,\n            });\n        }\n\n        Ok(())\n    }\n\n    fn analyze_rust_source_files(&self, component_dir: &Path) -> Result<Vec<SourceFile>> {\n        let mut source_files = Vec::new();\n\n        self.walk_directory(component_dir, &mut |path| {\n            if path.extension().and_then(|s| s.to_str()) == Some(\"rs\") {\n                if let Ok(content) = fs::read_to_string(path) {\n                    let rel_path = path.strip_prefix(component_dir)\n                        .unwrap_or(path)\n                        .to_string_lossy()\n                        .to_string();\n\n                    let line_count = content.lines().count();\n                    let key_definitions = self.extract_key_definitions(&content);\n\n                    source_files.push(SourceFile {\n                        path: rel_path,\n                        file_type: \"rust\".to_string(),\n                        line_count,\n                        key_definitions,\n                        content: if self.include_source { Some(content) } else { None },\n                    });\n                }\n            }\n        })?;\n\n        Ok(source_files)\n    }\n\n    fn analyze_infra_components(&self, components: &mut Vec<Component>) -> Result<()> {\n        let infra_components = vec![\n            (\"helm-charts\", \"infra/charts\", ComponentType::HelmChart),\n            (\"kubernetes-config\", \"infra/cluster-config\", ComponentType::KubernetesConfig),\n            (\"scripts\", \"infra/scripts\", ComponentType::Scripts),\n            (\"documentation\", \"docs\", ComponentType::Documentation),\n        ];\n\n        for (name, path, comp_type) in infra_components {\n            let full_path = self.workspace_root.join(path);\n            if full_path.exists() {\n                let source_files = self.analyze_config_files(&full_path)?;\n                let line_count = source_files.iter().map(|f| f.line_count).sum();\n\n                components.push(Component {\n                    name: name.to_string(),\n                    path: path.to_string(),\n                    component_type: comp_type,\n                    source_files,\n                    dependencies: Vec::new(),\n                    description: format!(\"{} configuration and files\", name),\n                    line_count,\n                });\n            }\n        }\n\n        Ok(())\n    }\n\n    fn analyze_config_files(&self, dir: &Path) -> Result<Vec<SourceFile>> {\n        let mut source_files = Vec::new();\n\n        self.walk_directory(dir, &mut |path| {\n            if let Some(ext) = path.extension().and_then(|s| s.to_str()) {\n                if matches!(ext, \"yaml\" | \"yml\" | \"toml\" | \"json\" | \"md\" | \"sh\") {\n                    if let Ok(content) = fs::read_to_string(path) {\n                        let rel_path = path.strip_prefix(dir)\n                            .unwrap_or(path)\n                            .to_string_lossy()\n                            .to_string();\n\n                        let line_count = content.lines().count();\n\n                        source_files.push(SourceFile {\n                            path: rel_path,\n                            file_type: ext.to_string(),\n                            line_count,\n                            key_definitions: Vec::new(),\n                            content: if self.include_source { Some(content) } else { None },\n                        });\n                    }\n                }\n            }\n        })?;\n\n        Ok(source_files)\n    }\n\n        fn analyze_apis(&self) -> Result<Vec<ApiDefinition>> {\n        println!(\"🌐 Analyzing API surface...\");\n\n        let mut apis = Vec::new();\n\n        // Look for route definitions in main.rs files and handler files\n        let mut api_files = Vec::new();\n\n        // Find main.rs files that define routes\n        let main_files = self.find_files_by_name(\"main.rs\")?;\n        for file in main_files {\n            if file.to_string_lossy().contains(\"orchestrator\") && !file.to_string_lossy().contains(\"target\") {\n                api_files.push(file);\n            }\n        }\n\n        // Find handler files\n        let handler_files = self.find_files_in_path(\"handlers\")?;\n        for file in handler_files {\n            if file.extension().and_then(|s| s.to_str()) == Some(\"rs\") {\n                api_files.push(file);\n            }\n        }\n\n        for file in api_files {\n            let content = fs::read_to_string(&file)?;\n            let endpoints = self.extract_api_endpoints(&content);\n\n            if !endpoints.is_empty() {\n                let file_name = if file.file_name().unwrap().to_string_lossy() == \"main.rs\" {\n                    \"routes\".to_string()\n                } else {\n                    file.file_stem().unwrap().to_string_lossy().to_string()\n                };\n\n                apis.push(ApiDefinition {\n                    name: file_name,\n                    file_path: file.strip_prefix(&self.workspace_root)\n                        .unwrap_or(&file)\n                        .to_string_lossy()\n                        .to_string(),\n                    endpoints,\n                    data_models: Vec::new(), // Could be enhanced\n                });\n            }\n        }\n\n        Ok(apis)\n    }\n\n    fn analyze_configurations(&self) -> Result<Vec<ConfigFile>> {\n        println!(\"⚙️  Analyzing configurations...\");\n\n        let mut configs = Vec::new();\n\n        let extensions = vec![\"yaml\", \"yml\", \"toml\", \"json\"];\n        for ext in extensions {\n            let files = self.find_files_by_extension(ext)?;\n            for file in files {\n                let rel_path = file.strip_prefix(&self.workspace_root)\n                    .unwrap_or(&file)\n                    .to_string_lossy()\n                    .to_string();\n\n                if rel_path.contains(\"target/\") || rel_path.contains(\".git/\") {\n                    continue;\n                }\n\n                let content = if self.include_source {\n                    fs::read_to_string(&file).ok()\n                } else {\n                    None\n                };\n\n                configs.push(ConfigFile {\n                    name: file.file_name().unwrap().to_string_lossy().to_string(),\n                    path: rel_path,\n                    config_type: ext.to_string(),\n                    content,\n                });\n            }\n        }\n\n        Ok(configs)\n    }\n\n    // Helper methods\n    fn count_cargo_files(&self) -> Result<usize> {\n        Ok(self.find_files_by_name(\"Cargo.toml\")?\n            .into_iter()\n            .filter(|p| !p.to_string_lossy().contains(\"target/\"))\n            .count())\n    }\n\n    fn count_rust_files(&self) -> Result<(usize, usize)> {\n        let rust_files = self.find_files_by_extension(\"rs\")?;\n        let file_count = rust_files.len();\n        let mut total_lines = 0;\n\n        for file in rust_files {\n            if let Ok(content) = fs::read_to_string(&file) {\n                total_lines += content.lines().count();\n            }\n        }\n\n        Ok((file_count, total_lines))\n    }\n\n    fn count_config_files(&self) -> Result<usize> {\n        let mut count = 0;\n        for ext in &[\"yaml\", \"yml\", \"toml\", \"json\"] {\n            count += self.find_files_by_extension(ext)?.len();\n        }\n        Ok(count)\n    }\n\n    fn find_files_by_name(&self, name: &str) -> Result<Vec<PathBuf>> {\n        let mut files = Vec::new();\n        self.walk_directory(&self.workspace_root, &mut |path| {\n            if path.file_name().and_then(|s| s.to_str()) == Some(name) {\n                files.push(path.to_path_buf());\n            }\n        })?;\n        Ok(files)\n    }\n\n    fn find_files_by_extension(&self, ext: &str) -> Result<Vec<PathBuf>> {\n        let mut files = Vec::new();\n        self.walk_directory(&self.workspace_root, &mut |path| {\n            if path.extension().and_then(|s| s.to_str()) == Some(ext) {\n                files.push(path.to_path_buf());\n            }\n        })?;\n        Ok(files)\n    }\n\n    fn find_files_in_path(&self, subpath: &str) -> Result<Vec<PathBuf>> {\n        let mut files = Vec::new();\n        self.walk_directory(&self.workspace_root, &mut |path| {\n            if path.to_string_lossy().contains(subpath) && path.is_file() {\n                files.push(path.to_path_buf());\n            }\n        })?;\n        Ok(files)\n    }\n\n    fn walk_directory<F>(&self, dir: &Path, callback: &mut F) -> Result<()>\n    where\n        F: FnMut(&Path),\n    {\n        if dir.is_dir() {\n            for entry in fs::read_dir(dir)? {\n                let entry = entry?;\n                let path = entry.path();\n\n                if let Some(name) = path.file_name().and_then(|s| s.to_str()) {\n                    if name == \"target\" || name == \".git\" || name.starts_with('.') {\n                        continue;\n                    }\n                }\n\n                callback(&path);\n\n                if path.is_dir() {\n                    self.walk_directory(&path, callback)?;\n                }\n            }\n        }\n        Ok(())\n    }\n\n    fn extract_cargo_name(&self, content: &str) -> Option<String> {\n        for line in content.lines() {\n            if line.starts_with(\"name =\") {\n                return line.split('=').nth(1)\n                    .map(|s| s.trim().trim_matches('\"').to_string());\n            }\n        }\n        None\n    }\n\n    fn extract_dependencies(&self, content: &str) -> Vec<String> {\n        let mut deps = Vec::new();\n        let mut in_deps_section = false;\n\n        for line in content.lines() {\n            if line.starts_with(\"[dependencies]\") {\n                in_deps_section = true;\n                continue;\n            }\n            if line.starts_with('[') && in_deps_section {\n                break;\n            }\n            if in_deps_section && line.contains('=') && !line.starts_with('#') {\n                if let Some(dep_name) = line.split('=').next() {\n                    deps.push(dep_name.trim().to_string());\n                }\n            }\n        }\n\n        deps\n    }\n\n    fn extract_description(&self, content: &str) -> String {\n        for line in content.lines() {\n            if line.starts_with(\"description =\") {\n                return line.split('=').nth(1)\n                    .unwrap_or(\"\")\n                    .trim()\n                    .trim_matches('\"')\n                    .to_string();\n            }\n        }\n        \"No description available\".to_string()\n    }\n\n    fn extract_key_definitions(&self, content: &str) -> Vec<String> {\n        let mut definitions = Vec::new();\n\n        for (line_num, line) in content.lines().enumerate() {\n            if line.trim().starts_with(\"pub struct\")\n                || line.trim().starts_with(\"pub enum\")\n                || line.trim().starts_with(\"pub fn\")\n                || line.trim().starts_with(\"impl \")\n                || line.trim().starts_with(\"pub trait\") {\n                definitions.push(format!(\"{}:{}\", line_num + 1, line.trim()));\n            }\n        }\n\n        definitions\n    }\n\n        fn extract_api_endpoints(&self, content: &str) -> Vec<ApiEndpoint> {\n        let mut endpoints = Vec::new();\n\n        for (line_num, line) in content.lines().enumerate() {\n            let trimmed = line.trim();\n\n            // Look for axum route definitions\n            if trimmed.contains(\".route(\") {\n                // Handle .route(\"/path\", method(handler)) syntax\n                if let Some(path) = self.extract_route_path(trimmed) {\n                    let method = if trimmed.contains(\"post(\") { \"POST\" }\n                    else if trimmed.contains(\"get(\") { \"GET\" }\n                    else if trimmed.contains(\"put(\") { \"PUT\" }\n                    else if trimmed.contains(\"delete(\") { \"DELETE\" }\n                    else { \"ANY\" };\n\n                    endpoints.push(ApiEndpoint {\n                        method: method.to_string(),\n                        path,\n                        handler: trimmed.to_string(),\n                        line_number: line_num + 1,\n                    });\n                }\n            }\n            // Also look for direct method calls like .get(\"/path\", handler)\n            else if trimmed.contains(\".get(\") || trimmed.contains(\".post(\")\n                || trimmed.contains(\".put(\") || trimmed.contains(\".delete(\") {\n                if let Some(method) = self.extract_http_method(trimmed) {\n                    if let Some(path) = self.extract_route_path(trimmed) {\n                        endpoints.push(ApiEndpoint {\n                            method,\n                            path,\n                            handler: trimmed.to_string(),\n                            line_number: line_num + 1,\n                        });\n                    }\n                }\n            }\n        }\n\n        endpoints\n    }\n\n    fn extract_http_method(&self, line: &str) -> Option<String> {\n        if line.contains(\".get(\") { Some(\"GET\".to_string()) }\n        else if line.contains(\".post(\") { Some(\"POST\".to_string()) }\n        else if line.contains(\".put(\") { Some(\"PUT\".to_string()) }\n        else if line.contains(\".delete(\") { Some(\"DELETE\".to_string()) }\n        else { Some(\"ROUTE\".to_string()) }\n    }\n\n    fn extract_route_path(&self, line: &str) -> Option<String> {\n        // Look for quoted strings that look like routes (start with /)\n        let mut start_pos = 0;\n        while let Some(start) = line[start_pos..].find('\"') {\n            let actual_start = start_pos + start;\n            if let Some(end) = line[actual_start + 1..].find('\"') {\n                let path = &line[actual_start + 1..actual_start + 1 + end];\n                if path.starts_with('/') {\n                    return Some(path.to_string());\n                }\n                start_pos = actual_start + 1 + end + 1;\n            } else {\n                break;\n            }\n        }\n        None\n    }\n\n    pub fn generate_modular_markdown(&self, analysis: &CodebaseAnalysis, output_dir: &str) -> Result<()> {\n        println!(\"📝 Generating modular markdown documentation...\");\n\n        let output_path = Path::new(output_dir);\n        fs::create_dir_all(output_path)?;\n\n        // Generate master index\n        self.generate_index_file(analysis, output_path)?;\n\n        // Generate component files\n        for component in &analysis.components {\n            self.generate_component_file(component, output_path)?;\n        }\n\n        // Generate API documentation\n        if !analysis.apis.is_empty() {\n            self.generate_api_file(&analysis.apis, output_path)?;\n        }\n\n        // Generate configuration summary\n        self.generate_config_file(&analysis.configurations, output_path)?;\n\n        println!(\"✅ Modular documentation generated in: {}\", output_dir);\n        Ok(())\n    }\n\n    fn generate_index_file(&self, analysis: &CodebaseAnalysis, output_path: &Path) -> Result<()> {\n        let index_file = output_path.join(\"README.md\");\n        let mut content = String::new();\n\n        content.push_str(&format!(\"# {} - Codebase Analysis\\n\\n\", analysis.overview.name));\n        content.push_str(&format!(\"**Generated:** {}\\n\\n\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\")));\n\n        content.push_str(\"## Overview\\n\\n\");\n        content.push_str(&format!(\"**Description:** {}\\n\\n\", analysis.overview.description));\n        content.push_str(&format!(\"**Architecture:** {}\\n\\n\", analysis.overview.architecture));\n        content.push_str(&format!(\"**Technologies:** {}\\n\\n\", analysis.overview.technologies.join(\", \")));\n\n        content.push_str(\"## Statistics\\n\\n\");\n        let stats = &analysis.overview.statistics;\n        content.push_str(&format!(\"- **Rust Crates:** {}\\n\", stats.rust_crates));\n        content.push_str(&format!(\"- **Rust Files:** {}\\n\", stats.total_rs_files));\n        content.push_str(&format!(\"- **Lines of Code:** {}\\n\", stats.total_lines_of_code));\n        content.push_str(&format!(\"- **Config Files:** {}\\n\", stats.config_files));\n        content.push_str(&format!(\"- **Components:** {}\\n\\n\", analysis.components.len()));\n\n        content.push_str(\"## Components\\n\\n\");\n        for component in &analysis.components {\n            content.push_str(&format!(\"- [{}](./{}.md) - `{}` ({} lines)\\n\",\n                component.name,\n                component.name.replace(' ', \"-\").to_lowercase(),\n                component.path,\n                component.line_count\n            ));\n        }\n\n        if !analysis.apis.is_empty() {\n            content.push_str(\"\\n- [API Surface](./api-surface.md) - REST endpoints and data models\\n\");\n        }\n        content.push_str(\"- [Configurations](./configurations.md) - All configuration files\\n\");\n\n        fs::write(index_file, content)?;\n        Ok(())\n    }\n\n    fn generate_component_file(&self, component: &Component, output_path: &Path) -> Result<()> {\n        let filename = format!(\"{}.md\", component.name.replace(' ', \"-\").to_lowercase());\n        let file_path = output_path.join(filename);\n        let mut content = String::new();\n\n        content.push_str(&format!(\"# {} Analysis\\n\\n\", component.name));\n        content.push_str(&format!(\"**Path:** `{}`\\n\", component.path));\n        content.push_str(&format!(\"**Type:** {:?}\\n\", component.component_type));\n        content.push_str(&format!(\"**Lines of Code:** {}\\n\", component.line_count));\n        content.push_str(&format!(\"**Description:** {}\\n\\n\", component.description));\n\n        if !component.dependencies.is_empty() {\n            content.push_str(\"## Dependencies\\n\\n\");\n            for dep in &component.dependencies {\n                content.push_str(&format!(\"- {}\\n\", dep));\n            }\n            content.push_str(\"\\n\");\n        }\n\n        content.push_str(\"## Source Files\\n\\n\");\n        for source_file in &component.source_files {\n            content.push_str(&format!(\"### {} ({} lines)\\n\\n\", source_file.path, source_file.line_count));\n\n            if !source_file.key_definitions.is_empty() {\n                content.push_str(\"**Key Definitions:**\\n```rust\\n\");\n                for def in &source_file.key_definitions {\n                    content.push_str(&format!(\"{}\\n\", def));\n                }\n                content.push_str(\"```\\n\\n\");\n            }\n\n            if let Some(file_content) = &source_file.content {\n                content.push_str(\"**Full Content:**\\n```\");\n                content.push_str(&source_file.file_type);\n                content.push_str(\"\\n\");\n                content.push_str(file_content);\n                content.push_str(\"\\n```\\n\\n\");\n            }\n        }\n\n        fs::write(file_path, content)?;\n        Ok(())\n    }\n\n    fn generate_api_file(&self, apis: &[ApiDefinition], output_path: &Path) -> Result<()> {\n        let file_path = output_path.join(\"api-surface.md\");\n        let mut content = String::new();\n\n        content.push_str(\"# API Surface Analysis\\n\\n\");\n\n        for api in apis {\n            content.push_str(&format!(\"## {} ({})\\n\\n\", api.name, api.file_path));\n\n            if !api.endpoints.is_empty() {\n                content.push_str(\"### Endpoints\\n\\n\");\n                for endpoint in &api.endpoints {\n                    content.push_str(&format!(\"- **{}** `{}` - Line {}\\n\",\n                        endpoint.method, endpoint.path, endpoint.line_number));\n                    content.push_str(&format!(\"  ```rust\\n  {}\\n  ```\\n\\n\", endpoint.handler));\n                }\n            }\n        }\n\n        fs::write(file_path, content)?;\n        Ok(())\n    }\n\n    fn generate_config_file(&self, configs: &[ConfigFile], output_path: &Path) -> Result<()> {\n        let file_path = output_path.join(\"configurations.md\");\n        let mut content = String::new();\n\n        content.push_str(\"# Configuration Files\\n\\n\");\n\n        let mut configs_by_type: HashMap<String, Vec<&ConfigFile>> = HashMap::new();\n        for config in configs {\n            configs_by_type.entry(config.config_type.clone())\n                .or_insert_with(Vec::new)\n                .push(config);\n        }\n\n        for (config_type, type_configs) in configs_by_type {\n            content.push_str(&format!(\"## {} Files\\n\\n\", config_type.to_uppercase()));\n\n            for config in type_configs {\n                content.push_str(&format!(\"### {} ({})\\n\\n\", config.name, config.path));\n\n                if let Some(file_content) = &config.content {\n                    content.push_str(\"```\");\n                    content.push_str(&config.config_type);\n                    content.push_str(\"\\n\");\n                    content.push_str(file_content);\n                    content.push_str(\"\\n```\\n\\n\");\n                }\n            }\n        }\n\n        fs::write(file_path, content)?;\n        Ok(())\n    }\n\n    pub fn generate_single_markdown(&self, analysis: &CodebaseAnalysis) -> Result<String> {\n        let mut content = String::new();\n\n        content.push_str(&format!(\"# {} - Complete Codebase Analysis\\n\\n\", analysis.overview.name));\n        content.push_str(&format!(\"**Generated:** {}\\n\\n\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\")));\n\n        content.push_str(\"## Project Overview\\n\\n\");\n        content.push_str(&format!(\"**Description:** {}\\n\\n\", analysis.overview.description));\n        content.push_str(&format!(\"**Architecture:** {}\\n\\n\", analysis.overview.architecture));\n        content.push_str(&format!(\"**Technologies:** {}\\n\\n\", analysis.overview.technologies.join(\", \")));\n\n        content.push_str(\"## Components\\n\\n\");\n        for component in &analysis.components {\n            content.push_str(&format!(\"### {} ({})\\n\\n\", component.name, component.path));\n            content.push_str(&format!(\"**Type:** {:?} | **Lines:** {}\\n\\n\", component.component_type, component.line_count));\n            content.push_str(&format!(\"{}\\n\\n\", component.description));\n\n            for source_file in &component.source_files {\n                if let Some(file_content) = &source_file.content {\n                    content.push_str(&format!(\"#### {}\\n\\n\", source_file.path));\n                    content.push_str(\"```\");\n                    content.push_str(&source_file.file_type);\n                    content.push_str(\"\\n\");\n                    content.push_str(file_content);\n                    content.push_str(\"\\n```\\n\\n\");\n                }\n            }\n        }\n\n        Ok(content)\n    }\n}"
        },
        {
          "path": "src/cli/docs_generator.rs",
          "file_type": "rust",
          "line_count": 207,
          "key_definitions": [
            "11:pub struct DocsGenerator;",
            "13:impl DocsGenerator {",
            "15:pub fn prepare_for_submission("
          ],
          "content": "//! Minimal documentation generator for preparing local files before submission\n\nuse anyhow::{Context, Result};\nuse serde_json::Value;\nuse std::fs;\nuse std::path::Path;\nuse std::process::Command;\nuse tracing::info;\n\n/// Simple docs generator that handles local file preparation\npub struct DocsGenerator;\n\nimpl DocsGenerator {\n    /// Prepare documentation files and return git info for submission\n    pub fn prepare_for_submission(\n        working_directory: Option<&str>,\n    ) -> Result<(String, String, String, String)> {\n        info!(\"Preparing documentation files for submission...\");\n\n        // Auto-detect git repository URL\n        let repo_url = Self::get_git_remote_url()?;\n\n        // Auto-detect working directory (relative path from repo root to current dir)\n        let working_dir = Self::get_working_directory(working_directory)?;\n\n        // Auto-detect source branch\n        let source_branch = Self::get_current_branch()?;\n\n        // Generate unique target branch name with timestamp\n        let timestamp = chrono::Utc::now().format(\"%Y%m%d-%H%M%S\");\n        let target_branch = format!(\"docs-generation-{timestamp}\");\n\n        info!(\"Repository: {}\", repo_url);\n        info!(\"Working directory: {}\", working_dir);\n        info!(\"Source branch: {}\", source_branch);\n        info!(\"Target branch: {}\", target_branch);\n\n        // Check and commit .taskmaster changes if needed\n        Self::check_and_commit_taskmaster_changes(&working_dir, &source_branch)?;\n\n        // Create documentation directory structure and copy task files\n        Self::create_docs_structure(&working_dir)?;\n\n        Ok((repo_url, working_dir, source_branch, target_branch))\n    }\n\n    fn get_git_remote_url() -> Result<String> {\n        let output = Command::new(\"git\")\n            .args([\"remote\", \"get-url\", \"origin\"])\n            .output()\n            .context(\"Failed to get git remote URL\")?;\n\n        if !output.status.success() {\n            anyhow::bail!(\n                \"Failed to detect git repository URL. Please specify with --repository-url\"\n            );\n        }\n\n        Ok(String::from_utf8(output.stdout)?.trim().to_string())\n    }\n\n    fn get_working_directory(working_directory: Option<&str>) -> Result<String> {\n        if let Some(wd) = working_directory {\n            return Ok(wd.to_string());\n        }\n\n        let current_dir = std::env::current_dir()?;\n        let repo_root = Command::new(\"git\")\n            .args([\"rev-parse\", \"--show-toplevel\"])\n            .output()\n            .context(\"Failed to get git repo root\")?\n            .stdout;\n        let repo_root_string = String::from_utf8(repo_root)?;\n        let repo_root = repo_root_string.trim();\n\n        let rel_path = current_dir\n            .strip_prefix(repo_root)\n            .context(\"Current directory is not in repo\")?\n            .to_string_lossy()\n            .to_string();\n\n        Ok(if rel_path.is_empty() {\n            \".\".to_string()\n        } else {\n            rel_path\n        })\n    }\n\n    fn get_current_branch() -> Result<String> {\n        let output = Command::new(\"git\")\n            .args([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])\n            .output()\n            .context(\"Failed to get current git branch\")?;\n\n        if !output.status.success() {\n            return Ok(\"main\".to_string());\n        }\n\n        Ok(String::from_utf8(output.stdout)?.trim().to_string())\n    }\n\n    fn check_and_commit_taskmaster_changes(working_dir: &str, source_branch: &str) -> Result<()> {\n        let taskmaster_path = format!(\"{working_dir}/.taskmaster\");\n\n        if !Path::new(&taskmaster_path).exists() {\n            anyhow::bail!(\"No .taskmaster directory found in {}\", working_dir);\n        }\n\n        info!(\"Checking for uncommitted .taskmaster changes...\");\n\n        let status_output = Command::new(\"git\")\n            .args([\"status\", \"--porcelain\", &taskmaster_path])\n            .output()\n            .context(\"Failed to check git status\")?;\n\n        if status_output.stdout.is_empty() {\n            info!(\"No uncommitted changes in .taskmaster directory\");\n        } else {\n            info!(\"Found uncommitted changes in .taskmaster directory\");\n\n            Command::new(\"git\")\n                .args([\"add\", &taskmaster_path])\n                .status()\n                .context(\"Failed to add .taskmaster files\")?;\n\n            Command::new(\"git\")\n                .args([\n                    \"commit\",\n                    \"-m\",\n                    \"chore: auto-commit .taskmaster directory for documentation generation\",\n                ])\n                .status()\n                .context(\"Failed to commit .taskmaster files\")?;\n\n            info!(\"Pushing commit to remote...\");\n            let push_result = Command::new(\"git\")\n                .args([\"push\", \"origin\", source_branch])\n                .status()\n                .context(\"Failed to push commits\")?;\n\n            if !push_result.success() {\n                anyhow::bail!(\"Failed to push .taskmaster commit\");\n            }\n\n            info!(\"✓ Auto-committed and pushed .taskmaster directory\");\n        }\n\n        Ok(())\n    }\n\n    fn create_docs_structure(working_dir: &str) -> Result<()> {\n        info!(\"Creating documentation directory structure...\");\n\n        let taskmaster_path = format!(\"{working_dir}/.taskmaster\");\n        let tasks_json_path = format!(\"{taskmaster_path}/tasks/tasks.json\");\n\n        if !Path::new(&tasks_json_path).exists() {\n            anyhow::bail!(\"No tasks.json found at {}\", tasks_json_path);\n        }\n\n        let content = fs::read_to_string(&tasks_json_path).context(\"Failed to read tasks.json\")?;\n\n        let json: Value = serde_json::from_str(&content).context(\"Failed to parse tasks.json\")?;\n\n        let tasks = json\n            .get(\"master\")\n            .and_then(|m| m.get(\"tasks\"))\n            .and_then(|t| t.as_array())\n            .context(\"No tasks found in tasks.json\")?;\n\n        let docs_dir = format!(\"{taskmaster_path}/docs\");\n        fs::create_dir_all(&docs_dir).context(\"Failed to create docs directory\")?;\n\n        let mut created_count = 0;\n        for task in tasks {\n            if let Some(task_id) = task.get(\"id\").and_then(serde_json::Value::as_u64) {\n                if let Some(title) = task.get(\"title\").and_then(|t| t.as_str()) {\n                    let task_dir = format!(\"{docs_dir}/task-{task_id}\");\n                    fs::create_dir_all(&task_dir)\n                        .context(format!(\"Failed to create directory for task {task_id}\"))?;\n\n                    let source_file = format!(\"{taskmaster_path}/tasks/task_{task_id:03}.txt\");\n                    let dest_file = format!(\"{task_dir}/task.txt\");\n\n                    if Path::new(&source_file).exists() {\n                        fs::copy(&source_file, &dest_file)\n                            .context(format!(\"Failed to copy task file for task {task_id}\"))?;\n                        info!(\"✓ Copied task file for task {}: {}\", task_id, title);\n                    } else {\n                        info!(\n                            \"⚠ No task file found for task {} (expected: {})\",\n                            task_id, source_file\n                        );\n                    }\n\n                    created_count += 1;\n                }\n            }\n        }\n\n        info!(\n            \"✓ Created documentation structure for {} tasks\",\n            created_count\n        );\n        Ok(())\n    }\n}\n"
        },
        {
          "path": "src/cli/commands.rs",
          "file_type": "rust",
          "line_count": 388,
          "key_definitions": [
            "355:pub fn handle_analyze_command("
          ],
          "content": "use anyhow::Result;\nuse common::models::{CodeRequest, DocsRequest};\nuse std::path::PathBuf;\n\nuse crate::api::ApiClient;\nuse crate::docs_generator::DocsGenerator;\nuse crate::output::OutputManager;\n\n/// Handle task command routing\npub async fn handle_task_command(\n    command: crate::TaskCommands,\n    api_url: &str,\n    _output_format: &str,\n) -> Result<()> {\n    let api_client = ApiClient::new(api_url.to_string());\n    let output = OutputManager::new();\n\n    match command {\n        crate::TaskCommands::Docs {\n            working_directory,\n            model,\n            repository_url,\n            source_branch,\n            github_user,\n        } => {\n            handle_docs_command(\n                &api_client,\n                &output,\n                working_directory.as_deref(),\n                model.as_deref(),\n                repository_url.as_deref(),\n                source_branch.as_deref(),\n                &github_user,\n            )\n            .await\n        }\n        crate::TaskCommands::Code {\n            task_id,\n            service,\n            repository_url,\n            docs_repository_url,\n            docs_project_directory,\n            github_user,\n            working_directory,\n            model,\n            local_tools,\n            remote_tools,\n            context_version,\n            prompt_modification,\n            docs_branch,\n            continue_session,\n            overwrite_memory,\n            env,\n            env_from_secrets,\n        } => {\n            handle_code_command(\n                &api_client,\n                &output,\n                task_id,\n                &service,\n                repository_url.as_deref(),\n                docs_repository_url.as_deref(),\n                docs_project_directory.as_deref(),\n                &github_user,\n                working_directory.as_deref(),\n                model.as_deref(),\n                local_tools.as_deref(),\n                remote_tools.as_deref(),\n                context_version,\n                prompt_modification.as_deref(),\n                &docs_branch,\n                continue_session,\n                overwrite_memory,\n                env.as_deref(),\n                env_from_secrets.as_deref(),\n            )\n            .await\n        }\n    }\n}\n\n/// Handle docs command - does local file prep then submits docs generation job\nasync fn handle_docs_command(\n    api_client: &ApiClient,\n    output: &OutputManager,\n    working_directory: Option<&str>,\n    model: Option<&str>,\n    repository_url: Option<&str>,\n    source_branch: Option<&str>,\n    github_user: &str,\n) -> Result<()> {\n    output.info(\"Initializing documentation generator...\");\n\n    // Do local file preparation and get git info (used as fallbacks)\n    let (detected_repo_url, detected_working_dir, detected_source_branch, _generated_docs_branch) =\n        DocsGenerator::prepare_for_submission(working_directory)?;\n\n    // Use provided parameters or fall back to auto-detected values\n    let final_repo_url = repository_url.unwrap_or(&detected_repo_url);\n    let final_working_dir = working_directory.unwrap_or(&detected_working_dir);\n    let final_source_branch = source_branch.unwrap_or(&detected_source_branch);\n\n    // Create documentation generation request\n    let request = DocsRequest {\n        repository_url: final_repo_url.to_string(),\n        working_directory: final_working_dir.to_string(),\n        source_branch: final_source_branch.to_string(),\n        model: model.map(|s| s.to_string()),\n        github_user: github_user.to_string(),\n    };\n\n    output.info(\"Submitting documentation generation job...\");\n\n    match api_client.submit_docs_generation(&request).await {\n        Ok(response) => {\n            if response.success {\n                output.success(&response.message);\n\n                if let Some(data) = response.data {\n                    if let Some(taskrun_name) = data.get(\"taskrun_name\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"TaskRun name: {taskrun_name}\"));\n                    }\n                    if let Some(namespace) = data.get(\"namespace\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"Namespace: {namespace}\"));\n                        output.info(\"You can monitor the job with:\");\n                        output.info(&format!(\"  kubectl -n {namespace} get taskrun\"));\n                    }\n                }\n            } else {\n                output.error(&response.message);\n                anyhow::bail!(response.message);\n            }\n        }\n        Err(e) => {\n            output.error(&format!(\n                \"Failed to submit documentation generation job: {e}\"\n            ));\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Handle code command - submits code task directly\n#[allow(clippy::too_many_arguments)]\nasync fn handle_code_command(\n    api_client: &ApiClient,\n    output: &OutputManager,\n    task_id: u32,\n    service: &str,\n    repository_url: Option<&str>,\n    docs_repository_url: Option<&str>,\n    docs_project_directory: Option<&str>,\n    github_user: &str,\n    working_directory: Option<&str>,\n    model: Option<&str>,\n    local_tools: Option<&str>,\n    remote_tools: Option<&str>,\n    context_version: u32,\n    prompt_modification: Option<&str>,\n    docs_branch: &str,\n    continue_session: bool,\n    overwrite_memory: bool,\n    env: Option<&str>,\n    env_from_secrets: Option<&str>,\n) -> Result<()> {\n    output.info(&format!(\n        \"Submitting code task {task_id} for service '{service}'...\"\n    ));\n\n    // Auto-detect target repository URL if not provided\n    let repo_url = match repository_url {\n        Some(url) => url.to_string(),\n        None => get_git_remote_url()?,\n    };\n\n    // Auto-detect docs repository URL if not provided\n    let docs_repo_url = match docs_repository_url {\n        Some(url) => url.to_string(),\n        None => get_git_remote_url()?, // TODO: This should be configurable\n    };\n\n    // Use provided GitHub user (now required)\n    let github_user_name = github_user.to_string();\n\n    // Auto-detect working directory if not provided\n    let working_dir = match working_directory {\n        Some(wd) => wd.to_string(),\n        None => get_working_directory()?,\n    };\n\n    // Parse environment variables\n    let env_map = parse_env_vars(env)?;\n    let env_from_secrets_vec = parse_env_from_secrets(env_from_secrets)?;\n\n    // Create code task request\n    let request = CodeRequest {\n        task_id,\n        service: service.to_string(),\n        repository_url: repo_url.clone(),\n        docs_repository_url: docs_repo_url.clone(),\n        docs_project_directory: docs_project_directory.map(std::string::ToString::to_string),\n        working_directory: Some(working_dir.clone()),\n        model: model.map(|s| s.to_string()),\n        github_user: github_user_name.clone(),\n        local_tools: local_tools.map(std::string::ToString::to_string),\n        remote_tools: remote_tools.map(std::string::ToString::to_string),\n        context_version,\n        prompt_modification: prompt_modification.map(std::string::ToString::to_string),\n        docs_branch: docs_branch.to_string(),\n        continue_session,\n        overwrite_memory,\n        env: env_map,\n        env_from_secrets: env_from_secrets_vec,\n    };\n\n    output.info(&format!(\"Target repository: {repo_url}\"));\n    output.info(&format!(\"Docs repository: {docs_repo_url}\"));\n    output.info(&format!(\"Docs branch: {docs_branch}\"));\n    output.info(&format!(\"Working directory: {working_dir}\"));\n    output.info(&format!(\"Context version: {context_version}\"));\n    output.info(&format!(\"GitHub user: {github_user_name}\"));\n\n    match api_client.submit_code_task(&request).await {\n        Ok(response) => {\n            if response.success {\n                output.success(&response.message);\n\n                if let Some(data) = response.data {\n                    if let Some(coderun_name) = data.get(\"coderun_name\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"CodeRun name: {coderun_name}\"));\n                    }\n                    if let Some(namespace) = data.get(\"namespace\").and_then(|n| n.as_str()) {\n                        output.info(&format!(\"Namespace: {namespace}\"));\n                        output.info(\"You can monitor the job with:\");\n                        output.info(&format!(\"  kubectl -n {namespace} get coderun\"));\n                    }\n                }\n            } else {\n                output.error(&response.message);\n                anyhow::bail!(response.message);\n            }\n        }\n        Err(e) => {\n            output.error(&format!(\"Failed to submit code task: {e}\"));\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Helper functions for git operations\nfn get_git_remote_url() -> Result<String> {\n    use std::process::Command;\n\n    let output = Command::new(\"git\")\n        .args([\"remote\", \"get-url\", \"origin\"])\n        .output()?;\n\n    if !output.status.success() {\n        anyhow::bail!(\"Failed to get git remote URL\");\n    }\n\n    Ok(String::from_utf8(output.stdout)?.trim().to_string())\n}\n\nfn get_working_directory() -> Result<String> {\n    use std::process::Command;\n\n    let current_dir = std::env::current_dir()?;\n    let repo_root = Command::new(\"git\")\n        .args([\"rev-parse\", \"--show-toplevel\"])\n        .output()?\n        .stdout;\n    let repo_root_string = String::from_utf8(repo_root)?;\n    let repo_root = repo_root_string.trim();\n\n    let rel_path = current_dir\n        .strip_prefix(repo_root)?\n        .to_string_lossy()\n        .to_string();\n\n    Ok(if rel_path.is_empty() {\n        \".\".to_string()\n    } else {\n        rel_path\n    })\n}\n\n/// Parse environment variables from comma-separated key=value string\nfn parse_env_vars(env_str: Option<&str>) -> Result<std::collections::HashMap<String, String>> {\n    use std::collections::HashMap;\n\n    let mut env_map = HashMap::new();\n\n    if let Some(env_str) = env_str {\n        for pair in env_str.split(',') {\n            let pair = pair.trim();\n            if pair.is_empty() {\n                continue;\n            }\n\n            let mut parts = pair.splitn(2, '=');\n            let key = parts\n                .next()\n                .ok_or_else(|| anyhow::anyhow!(\"Invalid env format: {}\", pair))?;\n            let value = parts\n                .next()\n                .ok_or_else(|| anyhow::anyhow!(\"Invalid env format: {}\", pair))?;\n\n            env_map.insert(key.to_string(), value.to_string());\n        }\n    }\n\n    Ok(env_map)\n}\n\n/// Parse environment variables from secrets in format: name:secretName:secretKey,...\nfn parse_env_from_secrets(\n    env_secrets_str: Option<&str>,\n) -> Result<Vec<common::models::code_request::SecretEnvVar>> {\n    use common::models::code_request::SecretEnvVar;\n\n    let mut secrets = Vec::new();\n\n    if let Some(secrets_str) = env_secrets_str {\n        for secret_spec in secrets_str.split(',') {\n            let secret_spec = secret_spec.trim();\n            if secret_spec.is_empty() {\n                continue;\n            }\n\n            let parts: Vec<&str> = secret_spec.split(':').collect();\n            if parts.len() != 3 {\n                anyhow::bail!(\n                    \"Invalid secret env format: {}. Expected name:secretName:secretKey\",\n                    secret_spec\n                );\n            }\n\n            secrets.push(SecretEnvVar {\n                name: parts[0].to_string(),\n                secret_name: parts[1].to_string(),\n                secret_key: parts[2].to_string(),\n            });\n        }\n    }\n\n    Ok(secrets)\n}\n\n/// Handle analyze command\npub fn handle_analyze_command(\n    output: String,\n    format: String,\n    working_directory: Option<String>,\n    include_source: bool,\n) -> Result<()> {\n    use crate::analyzer::CodebaseAnalyzer;\n\n    let work_dir = working_directory\n        .map(PathBuf::from)\n        .unwrap_or_else(|| std::env::current_dir().expect(\"Failed to get current directory\"));\n\n    let analyzer = CodebaseAnalyzer::new(work_dir, include_source);\n    let analysis = analyzer.analyze()?;\n\n    match format.as_str() {\n        \"json\" => {\n            let json_output = serde_json::to_string_pretty(&analysis)?;\n            std::fs::write(&output, json_output)?;\n            println!(\"✅ Codebase analysis written to: {} (JSON format)\", output);\n        }\n        \"single\" => {\n            let markdown_output = analyzer.generate_single_markdown(&analysis)?;\n            std::fs::write(&output, markdown_output)?;\n            println!(\"✅ Codebase analysis written to: {} (Single Markdown)\", output);\n        }\n        \"modular\" | _ => {\n            analyzer.generate_modular_markdown(&analysis, &output)?;\n            println!(\"✅ Modular codebase analysis written to: {}/\", output);\n        }\n    }\n\n    Ok(())\n}\n"
        },
        {
          "path": "src/cli/output.rs",
          "file_type": "rust",
          "line_count": 26,
          "key_definitions": [
            "8:pub struct OutputManager;",
            "10:impl OutputManager {",
            "11:pub fn new() -> Self {",
            "15:pub fn info(&self, message: &str) {",
            "19:pub fn success(&self, message: &str) {",
            "23:pub fn error(&self, message: &str) {"
          ],
          "content": "//! Simple output formatting for the CLI\n\n#![allow(clippy::disallowed_macros)]\n\nuse colored::Colorize;\n\n/// Simple output manager for consistent formatting\npub struct OutputManager;\n\nimpl OutputManager {\n    pub fn new() -> Self {\n        Self\n    }\n\n    pub fn info(&self, message: &str) {\n        println!(\"{} {}\", \"INFO:\".blue().bold(), message);\n    }\n\n    pub fn success(&self, message: &str) {\n        println!(\"{} {}\", \"✓\".green().bold(), message);\n    }\n\n    pub fn error(&self, message: &str) {\n        eprintln!(\"{} {}\", \"✗\".red().bold(), message);\n    }\n}\n"
        },
        {
          "path": "src/cli/main.rs",
          "file_type": "rust",
          "line_count": 191,
          "key_definitions": [
            "79:pub enum TaskCommands {"
          ],
          "content": "/*\n * 5D Labs Agent Platform - CLI Tools for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Orchestrator CLI - Simplified with just docs and code task submission\n\nmod analyzer;\nmod api;\nmod commands;\nmod docs_generator;\nmod output;\nuse anyhow::Result;\nuse clap::{Parser, Subcommand};\n\n#[derive(Parser)]\n#[command(name = \"orchestrator\")]\n#[command(about = \"CLI for Orchestrator Service\", long_about = None)]\n#[command(version)]\nstruct Cli {\n    #[command(subcommand)]\n    command: Commands,\n\n    /// API endpoint URL\n    #[arg(\n        long,\n        env = \"ORCHESTRATOR_API_URL\",\n        default_value = \"http://orchestrator.orchestrator.svc.cluster.local/api/v1\"\n    )]\n    api_url: String,\n\n    /// Output format (table, json, yaml)\n    #[arg(long, short, default_value = \"table\")]\n    output: String,\n}\n\n#[derive(Subcommand)]\nenum Commands {\n    /// Task operations\n    Task {\n        #[command(subcommand)]\n        command: TaskCommands,\n    },\n    /// Analyze codebase and generate documentation for Task Master PRD\n    Analyze {\n        /// Output directory (default: docs/codebase-analysis)\n        #[arg(short, long, default_value = \"docs/codebase-analysis\")]\n        output: String,\n\n        /// Output format: modular, single, json (default: modular)\n        #[arg(short, long, default_value = \"modular\")]\n        format: String,\n\n        /// Working directory to analyze (default: current directory)\n        #[arg(short, long)]\n        working_directory: Option<String>,\n\n        /// Include full source code (default: true)\n        #[arg(long, default_value = \"true\")]\n        include_source: bool,\n    },\n}\n\n#[derive(Subcommand)]\n#[allow(clippy::large_enum_variant)]\npub enum TaskCommands {\n    /// Generate documentation for Task Master tasks\n    Docs {\n        /// Working directory containing .taskmaster folder\n        #[arg(long, short = 'w')]\n        working_directory: Option<String>,\n\n        /// Claude model to use (required) - e.g., 'claude-opus-4-20250514' or 'claude-sonnet-4-20250514'\n        #[arg(long)]\n        model: Option<String>,\n\n        /// Documentation repository URL\n        #[arg(long)]\n        repository_url: Option<String>,\n\n        /// Source branch to use\n        #[arg(long)]\n        source_branch: Option<String>,\n\n        /// GitHub username for authentication (required)\n        #[arg(long)]\n        github_user: String,\n    },\n\n    /// Submit implementation task to orchestrator\n    Code {\n        /// Task ID to implement\n        task_id: u32,\n\n        /// Target service name\n        #[arg(long, short = 's')]\n        service: String,\n\n        /// Target project repository URL (where implementation work happens)\n        #[arg(long)]\n        repository_url: Option<String>,\n\n        /// Documentation repository URL (where Task Master definitions come from)\n        #[arg(long)]\n        docs_repository_url: Option<String>,\n\n        /// Project directory within docs repository (e.g. \"_projects/simple-api\")\n        #[arg(long)]\n        docs_project_directory: Option<String>,\n\n        /// GitHub username for authentication (required)\n        #[arg(long)]\n        github_user: String,\n\n        /// Working directory within target repository\n        #[arg(long, short = 'w')]\n        working_directory: Option<String>,\n\n        /// Claude model to use (required) - e.g., 'claude-opus-4-20250514' or 'claude-sonnet-4-20250514'\n        #[arg(long)]\n        model: Option<String>,\n\n        /// Local MCP tools to enable (comma-separated)\n        #[arg(long)]\n        local_tools: Option<String>,\n\n        /// Remote MCP tools to enable (comma-separated)\n        #[arg(long)]\n        remote_tools: Option<String>,\n\n        /// Context version for retry attempts (incremented on each retry)\n        #[arg(long, default_value = \"1\")]\n        context_version: u32,\n\n        /// Additional context for retry attempts\n        #[arg(long)]\n        prompt_modification: Option<String>,\n\n        /// Docs branch to use (e.g., \"main\", \"feature/branch\")\n        #[arg(long, default_value = \"main\")]\n        docs_branch: String,\n\n        /// Whether to continue a previous session\n        #[arg(long)]\n        continue_session: bool,\n\n        /// Whether to overwrite memory before starting\n        #[arg(long)]\n        overwrite_memory: bool,\n\n        /// Environment variables (format: KEY=value,KEY2=value2)\n        #[arg(long)]\n        env: Option<String>,\n\n        /// Environment variables from secrets (format: name:secretName:secretKey,...)\n        #[arg(long)]\n        env_from_secrets: Option<String>,\n    },\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Initialize tracing\n    tracing_subscriber::fmt::init();\n\n    let cli = Cli::parse();\n\n    match cli.command {\n        Commands::Task { command } => {\n            commands::handle_task_command(command, &cli.api_url, &cli.output).await?;\n        }\n        Commands::Analyze { output, format, working_directory, include_source } => {\n            commands::handle_analyze_command(output, format, working_directory, include_source)?;\n        }\n    }\n\n    Ok(())\n}\n"
        },
        {
          "path": "src/cli/api.rs",
          "file_type": "rust",
          "line_count": 100,
          "key_definitions": [
            "12:pub struct ApiResponse {",
            "21:pub struct ApiClient {",
            "26:impl ApiClient {",
            "28:pub fn new(base_url: String) -> Self {"
          ],
          "content": "//! HTTP API client for orchestrator `TaskRun` submissions\n\nuse anyhow::{Context, Result};\nuse common::models::{CodeRequest, DocsRequest};\nuse reqwest::{Client, Response};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse tracing::{debug, info};\n\n/// API response structure used by PM endpoints\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApiResponse {\n    pub success: bool,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option<Value>,\n}\n\n/// API client for the orchestrator service\n#[derive(Clone)]\npub struct ApiClient {\n    client: Client,\n    base_url: String,\n}\n\nimpl ApiClient {\n    /// Create a new API client\n    pub fn new(base_url: String) -> Self {\n        Self {\n            client: Client::new(),\n            base_url,\n        }\n    }\n\n    /// Submit a code task\n    pub async fn submit_code_task(&self, request: &CodeRequest) -> Result<ApiResponse> {\n        info!(\n            \"Submitting code task: {} for service: {}\",\n            request.task_id, request.service\n        );\n        debug!(\"Code task request: {:?}\", request);\n\n        let response = self\n            .client\n            .post(format!(\"{}/pm/tasks\", self.base_url))\n            .json(request)\n            .send()\n            .await\n            .context(\"Failed to send code task submission request\")?;\n\n        self.handle_response(response).await\n    }\n\n    /// Submit a documentation generation job\n    pub async fn submit_docs_generation(&self, request: &DocsRequest) -> Result<ApiResponse> {\n        info!(\n            \"Submitting documentation generation job for repository: {}\",\n            request.repository_url\n        );\n        debug!(\"Docs generation request: {:?}\", request);\n\n        let response = self\n            .client\n            .post(format!(\"{}/pm/docs/generate\", self.base_url))\n            .json(request)\n            .send()\n            .await\n            .context(\"Failed to send documentation generation request\")?;\n\n        self.handle_response(response).await\n    }\n\n    /// Generic response handler for API responses\n    async fn handle_response(&self, response: Response) -> Result<ApiResponse> {\n        let status = response.status();\n        let response_text = response\n            .text()\n            .await\n            .context(\"Failed to read response body\")?;\n\n        debug!(\"API response status: {}\", status);\n        debug!(\"API response body: {}\", response_text);\n\n        if status.is_success() {\n            serde_json::from_str(&response_text)\n                .with_context(|| format!(\"Failed to parse successful response: {response_text}\"))\n        } else {\n            // Try to parse as error response first\n            if let Ok(error_response) = serde_json::from_str::<ApiResponse>(&response_text) {\n                Ok(error_response)\n            } else {\n                Err(anyhow::anyhow!(\n                    \"API request failed with status {}: {}\",\n                    status,\n                    response_text\n                ))\n            }\n        }\n    }\n}\n"
        }
      ],
      "dependencies": [
        "clap",
        "colored",
        "reqwest",
        "serde",
        "serde_json",
        "anyhow",
        "tracing",
        "tracing-subscriber",
        "tokio",
        "chrono",
        "common"
      ],
      "description": "5D Labs platform tools: CLI and MCP server for AI development workflows",
      "line_count": 2413
    },
    {
      "name": "core",
      "path": "orchestrator/core",
      "component_type": "RustBinary",
      "source_files": [
        {
          "path": "src/crds/mod.rs",
          "file_type": "rust",
          "line_count": 5,
          "key_definitions": [],
          "content": "pub mod coderun;\npub mod docsrun;\n\npub use coderun::*;\npub use docsrun::*;\n"
        },
        {
          "path": "src/crds/coderun.rs",
          "file_type": "rust",
          "line_count": 181,
          "key_definitions": [
            "10:pub struct SecretEnvVar {",
            "51:pub struct CodeRunSpec {",
            "121:pub struct CodeRunStatus {",
            "162:pub struct CodeRunCondition {"
          ],
          "content": "//! `CodeRun` Custom Resource Definition for code implementation tasks\n\nuse kube::CustomResource;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Reference to a secret for environment variable\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub struct SecretEnvVar {\n    /// Name of the environment variable\n    pub name: String,\n    /// Name of the secret\n    #[serde(rename = \"secretName\")]\n    pub secret_name: String,\n    /// Key within the secret\n    #[serde(rename = \"secretKey\")]\n    pub secret_key: String,\n}\n\n/// Default function for `context_version` field\nfn default_context_version() -> u32 {\n    1\n}\n\n/// Default function for `docs_branch` field\nfn default_docs_branch() -> String {\n    \"main\".to_string()\n}\n\n/// Default function for `continue_session` field\nfn default_continue_session() -> bool {\n    false\n}\n\n/// Default function for `overwrite_memory` field\nfn default_overwrite_memory() -> bool {\n    false\n}\n\n/// `CodeRun` CRD for code implementation tasks\n#[derive(CustomResource, Deserialize, Serialize, Clone, Debug, JsonSchema)]\n#[kube(group = \"orchestrator.platform\", version = \"v1\", kind = \"CodeRun\")]\n#[kube(namespaced)]\n#[kube(status = \"CodeRunStatus\")]\n#[kube(printcolumn = r#\"{\"name\":\"Task\",\"type\":\"integer\",\"jsonPath\":\".spec.taskId\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Service\",\"type\":\"string\",\"jsonPath\":\".spec.service\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Model\",\"type\":\"string\",\"jsonPath\":\".spec.model\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Phase\",\"type\":\"string\",\"jsonPath\":\".status.phase\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Age\",\"type\":\"date\",\"jsonPath\":\".metadata.creationTimestamp\"}\"#)]\npub struct CodeRunSpec {\n    /// Task ID to implement\n    #[serde(rename = \"taskId\")]\n    pub task_id: u32,\n\n    /// Target service name\n    pub service: String,\n\n    /// Target project repository URL (where implementation work happens)\n    #[serde(rename = \"repositoryUrl\")]\n    pub repository_url: String,\n\n    /// Documentation repository URL (where Task Master definitions come from)\n    #[serde(rename = \"docsRepositoryUrl\")]\n    pub docs_repository_url: String,\n\n    /// Project directory within docs repository (e.g. \"_projects/simple-api\")\n    #[serde(default, rename = \"docsProjectDirectory\")]\n    pub docs_project_directory: Option<String>,\n\n    /// Working directory within target repository (defaults to service name)\n    #[serde(default, rename = \"workingDirectory\")]\n    pub working_directory: Option<String>,\n\n    /// Claude model to use (sonnet, opus)\n    pub model: String,\n\n    /// GitHub username for authentication and commits\n    #[serde(rename = \"githubUser\")]\n    pub github_user: String,\n\n    /// Local MCP tools/servers to enable (comma-separated)\n    #[serde(default, rename = \"localTools\")]\n    pub local_tools: Option<String>,\n\n    /// Remote MCP tools/servers to enable (comma-separated)\n    #[serde(default, rename = \"remoteTools\")]\n    pub remote_tools: Option<String>,\n\n    /// Context version for retry attempts (incremented on each retry)\n    #[serde(default = \"default_context_version\", rename = \"contextVersion\")]\n    pub context_version: u32,\n\n    /// Additional context for retry attempts\n    #[serde(default, rename = \"promptModification\")]\n    pub prompt_modification: Option<String>,\n\n    /// Docs branch to use (e.g., \"main\", \"feature/branch\")\n    #[serde(default = \"default_docs_branch\", rename = \"docsBranch\")]\n    pub docs_branch: String,\n\n    /// Whether to continue a previous session (auto-continue on retries or user-requested)\n    #[serde(default = \"default_continue_session\", rename = \"continueSession\")]\n    pub continue_session: bool,\n\n    /// Whether to overwrite memory before starting\n    #[serde(default = \"default_overwrite_memory\", rename = \"overwriteMemory\")]\n    pub overwrite_memory: bool,\n\n    /// Environment variables to set in the container\n    #[serde(default)]\n    pub env: HashMap<String, String>,\n\n    /// Environment variables from secrets\n    #[serde(default, rename = \"envFromSecrets\")]\n    pub env_from_secrets: Vec<SecretEnvVar>,\n}\n\n/// Status of the `CodeRun`\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub struct CodeRunStatus {\n    /// Current phase of the code implementation\n    pub phase: String,\n\n    /// Human-readable message about the current state\n    pub message: Option<String>,\n\n    /// Timestamp when this phase was reached\n    pub last_update: Option<String>,\n\n    /// Associated Kubernetes Job name\n    pub job_name: Option<String>,\n\n    /// Pull request URL if created\n    pub pull_request_url: Option<String>,\n\n    /// Current retry attempt (if applicable)\n    pub retry_count: Option<u32>,\n\n    /// Conditions for the `CodeRun`\n    pub conditions: Option<Vec<CodeRunCondition>>,\n\n    /// Name of the `ConfigMap` containing the prompt and context\n    pub configmap_name: Option<String>,\n\n    /// Version of the context and prompt used\n    pub context_version: Option<u32>,\n\n    /// Modification to the prompt if any\n    pub prompt_modification: Option<String>,\n\n    /// Mode of prompt (e.g., \"direct\", \"indirect\")\n    pub prompt_mode: Option<String>,\n\n    /// Session ID for tracking\n    pub session_id: Option<String>,\n}\n\n/// Condition for the `CodeRun`\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct CodeRunCondition {\n    /// Type of condition\n    #[serde(rename = \"type\")]\n    pub condition_type: String,\n\n    /// Status of the condition (True, False, or Unknown)\n    pub status: String,\n\n    /// Last time the condition transitioned (RFC3339 format)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub last_transition_time: Option<String>,\n\n    /// Reason for the condition's last transition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub reason: Option<String>,\n\n    /// Human-readable message about the condition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub message: Option<String>,\n}\n"
        },
        {
          "path": "src/crds/docsrun.rs",
          "file_type": "rust",
          "line_count": 73,
          "key_definitions": [
            "13:pub struct DocsRunSpec {",
            "26:pub struct DocsRunStatus {",
            "39:pub struct DocsRunCondition {",
            "62:pub enum DocsRunPhase {"
          ],
          "content": "//! `DocsRun` Custom Resource Definition for documentation generation\n\nuse kube::CustomResource;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\n\n#[derive(CustomResource, Deserialize, Serialize, Clone, Debug, JsonSchema)]\n#[kube(group = \"orchestrator.platform\", version = \"v1\", kind = \"DocsRun\")]\n#[kube(namespaced)]\n#[kube(status = \"DocsRunStatus\")]\n#[kube(printcolumn = r#\"{\"name\":\"Phase\",\"type\":\"string\",\"jsonPath\":\".status.phase\"}\"#)]\n#[kube(printcolumn = r#\"{\"name\":\"Age\",\"type\":\"date\",\"jsonPath\":\".metadata.creationTimestamp\"}\"#)]\npub struct DocsRunSpec {\n    #[serde(rename = \"repositoryUrl\")]\n    pub repository_url: String,\n    #[serde(rename = \"workingDirectory\")]\n    pub working_directory: String,\n    #[serde(rename = \"sourceBranch\")]\n    pub source_branch: String,\n    pub model: String,\n    #[serde(rename = \"githubUser\")]\n    pub github_user: String,\n}\n\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub struct DocsRunStatus {\n    pub phase: String,\n    pub message: Option<String>,\n    pub last_update: Option<String>,\n    pub job_name: Option<String>,\n    pub pull_request_url: Option<String>,\n    pub conditions: Option<Vec<DocsRunCondition>>,\n    pub configmap_name: Option<String>,\n}\n\n/// Condition for the `DocsRun`\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct DocsRunCondition {\n    /// Type of condition\n    #[serde(rename = \"type\")]\n    pub condition_type: String,\n\n    /// Status of the condition (True, False, or Unknown)\n    pub status: String,\n\n    /// Last time the condition transitioned (RFC3339 format)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub last_transition_time: Option<String>,\n\n    /// Reason for the condition's last transition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub reason: Option<String>,\n\n    /// Human-readable message about the condition\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub message: Option<String>,\n}\n\n/// Phase of `DocsRun` execution\n#[derive(Deserialize, Serialize, Clone, Debug, JsonSchema)]\npub enum DocsRunPhase {\n    /// `DocsRun` has been created but not yet processed\n    Pending,\n    /// Documentation generation is in progress\n    Running,\n    /// Documentation generation completed successfully\n    Succeeded,\n    /// Documentation generation failed\n    Failed,\n    /// `DocsRun` was manually cancelled\n    Cancelled,\n}\n"
        },
        {
          "path": "src/bin/test_templates.rs",
          "file_type": "rust",
          "line_count": 148,
          "key_definitions": [],
          "content": "#!/usr/bin/env cargo\n//! Template testing utility for local handlebars template validation\n//!\n//! Usage: cargo run --bin `test_templates`\n\n#![allow(clippy::disallowed_macros)]\n\nuse handlebars::Handlebars;\nuse serde_json::json;\nuse std::path::Path;\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"🧪 Testing Handlebars Templates...\\n\");\n\n    // Initialize handlebars engine\n    let mut handlebars = Handlebars::new();\n\n    // Template directory\n    let template_dir = Path::new(\"orchestrator-core/templates\");\n\n    // Test docs templates\n    test_docs_templates(&mut handlebars, template_dir)?;\n\n    // Test code templates\n    test_code_templates(&mut handlebars, template_dir)?;\n\n    println!(\"✅ All templates rendered successfully!\");\n    Ok(())\n}\n\nfn test_docs_templates(\n    handlebars: &mut Handlebars,\n    template_dir: &Path,\n) -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"📄 Testing Docs Templates:\");\n\n    // Mock DocsRunSpec data\n    let docs_data = json!({\n        \"repository_url\": \"https://github.com/5dlabs/platform\",\n        \"working_directory\": \"_projects/simple-api\",\n        \"source_branch\": \"feature/example-project-and-cli\",\n        \"model\": \"claude-3-5-sonnet-20241022\",\n        \"github_user\": \"pm0-5dlabs\"\n    });\n\n    // Test docs templates\n    let docs_templates = [\n        \"docs/claude.md.hbs\",\n        \"docs/settings.json.hbs\",\n        \"docs/container.sh.hbs\",\n    ];\n\n    for template_name in &docs_templates {\n        let template_path = template_dir.join(template_name);\n\n        if template_path.exists() {\n            println!(\"  Testing {template_name}...\");\n\n            // Register template\n            let template_content = std::fs::read_to_string(&template_path)?;\n            handlebars.register_template_string(template_name, &template_content)?;\n\n            // Render template\n            let result = handlebars.render(template_name, &docs_data)?;\n\n            println!(\"    ✅ Rendered successfully ({} chars)\", result.len());\n\n            // Show first few lines of output for verification\n            let lines: Vec<&str> = result.lines().take(3).collect();\n            for line in lines {\n                println!(\"    │ {line}\");\n            }\n\n            if result.lines().count() > 3 {\n                println!(\"    │ ... ({} total lines)\", result.lines().count());\n            }\n            println!();\n        } else {\n            println!(\"  ⚠️  Template not found: {}\", template_path.display());\n        }\n    }\n\n    Ok(())\n}\n\nfn test_code_templates(\n    handlebars: &mut Handlebars,\n    template_dir: &Path,\n) -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"💻 Testing Code Templates:\");\n\n    // Mock CodeRunSpec data\n    let code_data = json!({\n        \"task_id\": 42,\n        \"service\": \"simple-api\",\n        \"repository_url\": \"https://github.com/5dlabs/platform\",\n        \"platform_repository_url\": \"https://github.com/5dlabs/platform\",\n        \"branch\": \"feature/example-project-and-cli\",\n        \"working_directory\": \"_projects/simple-api\",\n        \"model\": \"claude-3-5-sonnet-20241022\",\n        \"github_user\": \"pm0-5dlabs\",\n        \"local_tools\": \"bash,edit,read\",\n        \"remote_tools\": \"github_create_issue\",\n        \"tool_config\": \"default\",\n        \"context_version\": 1,\n        \"prompt_modification\": null,\n        \"prompt_mode\": \"append\"\n    });\n\n    // Test code templates\n    let code_templates = [\n        \"code/claude.md.hbs\",\n        \"code/settings.json.hbs\",\n        \"code/container.sh.hbs\",\n    ];\n\n    for template_name in &code_templates {\n        let template_path = template_dir.join(template_name);\n\n        if template_path.exists() {\n            println!(\"  Testing {template_name}...\");\n\n            // Register template\n            let template_content = std::fs::read_to_string(&template_path)?;\n            handlebars.register_template_string(template_name, &template_content)?;\n\n            // Render template\n            let result = handlebars.render(template_name, &code_data)?;\n\n            println!(\"    ✅ Rendered successfully ({} chars)\", result.len());\n\n            // Show first few lines of output for verification\n            let lines: Vec<&str> = result.lines().take(3).collect();\n            for line in lines {\n                println!(\"    │ {line}\");\n            }\n\n            if result.lines().count() > 3 {\n                println!(\"    │ ... ({} total lines)\", result.lines().count());\n            }\n            println!();\n        } else {\n            println!(\"  ⚠️  Template not found: {}\", template_path.display());\n        }\n    }\n\n    Ok(())\n}\n"
        },
        {
          "path": "src/lib.rs",
          "file_type": "rust",
          "line_count": 31,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - Kubernetes Orchestrator for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Orchestrator core library\n//!\n//! This crate provides the core functionality for the unified orchestration service,\n//! including Kubernetes client wrapper, job orchestration, and request handling.\n\npub mod controllers;\npub mod crds;\npub mod handlers;\n\n// Re-export commonly used types\npub use controllers::task_controller::ControllerConfig;\npub use crds::{CodeRun, CodeRunSpec, CodeRunStatus, DocsRun, DocsRunSpec, DocsRunStatus};\npub use handlers::*;\n"
        },
        {
          "path": "src/main.rs",
          "file_type": "rust",
          "line_count": 159,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - Kubernetes Orchestrator for AI Coding Agents\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Main entry point for the Orchestrator service\n\nuse anyhow::Result;\nuse axum::{\n    extract::State,\n    http::StatusCode,\n    response::Json,\n    routing::{get, post},\n    Router,\n};\nuse core::{\n    controllers::run_task_controller,\n    handlers::{code_handler::submit_code_task, common::AppState, docs_handler::generate_docs},\n};\nuse kube::Client;\nuse serde_json::{json, Value};\nuse tokio::signal;\nuse tower::ServiceBuilder;\nuse tower_http::{cors::CorsLayer, trace::TraceLayer};\nuse tracing::{error, info};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\nasync fn create_app_state() -> Result<AppState> {\n    // Initialize Kubernetes client\n    let k8s_client = Client::try_default()\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to create K8s client: {}\", e))?;\n\n    // Get namespace from environment or use default\n    let namespace =\n        std::env::var(\"KUBERNETES_NAMESPACE\").unwrap_or_else(|_| \"orchestrator\".to_string());\n\n    info!(\"Initialized orchestrator for namespace: {}\", namespace);\n\n    Ok(AppState {\n        k8s_client,\n        namespace,\n    })\n}\n\n/// Health check endpoint\nasync fn health_check(State(_state): State<AppState>) -> Result<Json<Value>, StatusCode> {\n    Ok(Json(json!({\n        \"status\": \"healthy\",\n        \"version\": env!(\"CARGO_PKG_VERSION\"),\n        \"timestamp\": chrono::Utc::now().to_rfc3339()\n    })))\n}\n\n/// Create API routes\nfn api_routes() -> Router<AppState> {\n    Router::new()\n        .route(\"/pm/tasks\", post(submit_code_task))\n        .route(\"/pm/docs/generate\", post(generate_docs))\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    // Initialize tracing with OpenTelemetry support\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| tracing_subscriber::EnvFilter::new(\"info\")),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    info!(\n        \"Starting Orchestrator service v{} with TaskRun CRD support\",\n        env!(\"CARGO_PKG_VERSION\")\n    );\n\n    // Initialize application state\n    let app_state = create_app_state().await?;\n\n    // Start task controller\n    let client = app_state.k8s_client.clone();\n    let namespace = app_state.namespace.clone();\n\n    info!(\"Starting task controller in namespace: {}\", namespace);\n\n    // Spawn the controller in the background\n    tokio::spawn(async move {\n        if let Err(e) = run_task_controller(client, namespace).await {\n            error!(\"Task controller error: {}\", e);\n        }\n    });\n\n    // Build the application with middleware layers\n    let app = Router::new()\n        .nest(\"/api/v1\", api_routes())\n        .route(\"/health\", get(health_check)) // Root health check for load balancers\n        .layer(\n            ServiceBuilder::new()\n                .layer(TraceLayer::new_for_http())\n                .layer(CorsLayer::permissive()), // Simplified for now\n        )\n        .with_state(app_state);\n\n    // Create TCP listener\n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:8080\")\n        .await\n        .expect(\"Failed to bind to address\");\n\n    info!(\"Server listening on {}\", listener.local_addr()?);\n\n    // Start server with graceful shutdown\n    axum::serve(listener, app)\n        .with_graceful_shutdown(shutdown_signal())\n        .await?;\n\n    info!(\"Server shutdown complete\");\n    Ok(())\n}\n\n/// Graceful shutdown signal handler\nasync fn shutdown_signal() {\n    let ctrl_c = async {\n        signal::ctrl_c()\n            .await\n            .expect(\"Failed to install Ctrl+C handler\");\n    };\n\n    #[cfg(unix)]\n    let terminate = async {\n        signal::unix::signal(signal::unix::SignalKind::terminate())\n            .expect(\"Failed to install signal handler\")\n            .recv()\n            .await;\n    };\n\n    #[cfg(not(unix))]\n    let terminate = std::future::pending::<()>();\n\n    tokio::select! {\n        () = ctrl_c => {},\n        () = terminate => {},\n    }\n\n    info!(\"Shutdown signal received, starting graceful shutdown\");\n}\n"
        },
        {
          "path": "src/controllers/mod.rs",
          "file_type": "rust",
          "line_count": 8,
          "key_definitions": [],
          "content": "// TODO: Remove this old controller once new one is complete\n// pub mod taskrun_old;\n// pub use taskrun_old::run_taskrun_controller;\n\npub mod task_controller;\n\n// Re-export the main controller function for easy access\npub use task_controller::run_task_controller;\n"
        },
        {
          "path": "src/controllers/task_controller/types.rs",
          "file_type": "rust",
          "line_count": 212,
          "key_definitions": [
            "9:pub enum Error {",
            "37:pub enum TaskType {",
            "42:impl TaskType {",
            "43:pub fn name(&self) -> String {",
            "50:pub fn is_docs(&self) -> bool {",
            "54:pub fn service_name(&self) -> &str {",
            "61:pub fn model(&self) -> &str {",
            "68:pub fn github_user(&self) -> &str {",
            "75:pub fn repository_url(&self) -> &str {",
            "82:pub fn source_branch(&self) -> Option<&str> {",
            "90:pub fn working_directory(&self) -> &str {",
            "103:pub fn task_id(&self) -> Option<u32> {",
            "111:pub fn context_version(&self) -> u32 {",
            "118:pub fn retry_count(&self) -> u32 {",
            "125:pub fn session_id(&self) -> Option<&str> {",
            "132:pub fn prompt_modification(&self) -> Option<&str> {",
            "140:pub fn local_tools(&self) -> Option<&str> {",
            "147:pub fn remote_tools(&self) -> Option<&str> {",
            "155:pub fn docs_repository_url(&self) -> Option<&str> {",
            "163:pub fn uses_ssh() -> bool {",
            "168:pub fn ssh_secret_name(&self) -> String {",
            "173:pub fn github_token_secret_name(&self) -> String {",
            "178:pub fn docs_branch(&self) -> &str {",
            "187:pub fn continue_session(&self) -> bool {",
            "198:pub fn overwrite_memory(&self) -> bool {",
            "206:pub fn docs_project_directory(&self) -> Option<&str> {"
          ],
          "content": "use super::config::ControllerConfig;\nuse crate::crds::{CodeRun, DocsRun};\nuse kube::{Client, ResourceExt};\nuse std::sync::Arc;\n\n// Error type for the controller\n#[derive(Debug, thiserror::Error)]\n#[allow(clippy::enum_variant_names)]\npub enum Error {\n    #[error(\"Kubernetes API error: {0}\")]\n    KubeError(#[from] kube::Error),\n\n    #[error(\"Missing object key\")]\n    MissingObjectKey,\n\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(#[from] serde_json::Error),\n\n    #[error(\"Task configuration error: {0}\")]\n    ConfigError(String),\n}\n\npub type Result<T, E = Error> = std::result::Result<T, E>;\n\n// Context shared across controller operations\npub(crate) struct Context {\n    pub client: Client,\n    pub namespace: String,\n    pub config: Arc<ControllerConfig>,\n}\n\n// Finalizer names for cleanup\npub(crate) const DOCS_FINALIZER_NAME: &str = \"docsruns.orchestrator.io/finalizer\";\npub(crate) const CODE_FINALIZER_NAME: &str = \"coderuns.orchestrator.io/finalizer\";\n\n// Enum to represent either task type for shared functionality\npub enum TaskType {\n    Docs(Arc<DocsRun>),\n    Code(Arc<CodeRun>),\n}\n\nimpl TaskType {\n    pub fn name(&self) -> String {\n        match self {\n            TaskType::Docs(dr) => dr.name_any(),\n            TaskType::Code(cr) => cr.name_any(),\n        }\n    }\n\n    pub fn is_docs(&self) -> bool {\n        matches!(self, TaskType::Docs(_))\n    }\n\n    pub fn service_name(&self) -> &str {\n        match self {\n            TaskType::Docs(_) => \"docs-generator\", // Fixed service name for docs\n            TaskType::Code(cr) => &cr.spec.service,\n        }\n    }\n\n    pub fn model(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.model,\n            TaskType::Code(cr) => &cr.spec.model,\n        }\n    }\n\n    pub fn github_user(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.github_user,\n            TaskType::Code(cr) => &cr.spec.github_user,\n        }\n    }\n\n    pub fn repository_url(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.repository_url,\n            TaskType::Code(cr) => &cr.spec.repository_url,\n        }\n    }\n\n    pub fn source_branch(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(dr) => Some(&dr.spec.source_branch),\n            TaskType::Code(_) => None, // CodeRun uses platform_branch instead\n        }\n    }\n\n    /// Get working directory (defaults to service name if not specified)\n    pub fn working_directory(&self) -> &str {\n        match self {\n            TaskType::Docs(dr) => &dr.spec.working_directory,\n            TaskType::Code(cr) => {\n                // Default to service name if working_directory is None or empty\n                match &cr.spec.working_directory {\n                    Some(wd) if !wd.is_empty() => wd,\n                    _ => &cr.spec.service,\n                }\n            }\n        }\n    }\n\n    pub fn task_id(&self) -> Option<u32> {\n        match self {\n            TaskType::Docs(_) => None, // Docs generation doesn't have a specific task ID\n            TaskType::Code(cr) => Some(cr.spec.task_id),\n        }\n    }\n\n    /// Get retry/versioning information for `CodeRun` (docs don't have retries)\n    pub fn context_version(&self) -> u32 {\n        match self {\n            TaskType::Docs(_) => 1, // Docs don't have context versions\n            TaskType::Code(cr) => cr.spec.context_version,\n        }\n    }\n\n    pub fn retry_count(&self) -> u32 {\n        match self {\n            TaskType::Docs(_) => 0, // Docs don't retry\n            TaskType::Code(cr) => cr.status.as_ref().map_or(0, |s| s.retry_count.unwrap_or(0)),\n        }\n    }\n\n    pub fn session_id(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => cr.status.as_ref().and_then(|s| s.session_id.as_deref()),\n        }\n    }\n\n    pub fn prompt_modification(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => cr.spec.prompt_modification.as_deref(),\n        }\n    }\n\n    /// Get tool configuration for the task\n    pub fn local_tools(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None, // Docs use fixed tool set\n            TaskType::Code(cr) => cr.spec.local_tools.as_deref(),\n        }\n    }\n\n    pub fn remote_tools(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None, // Docs use fixed tool set\n            TaskType::Code(cr) => cr.spec.remote_tools.as_deref(),\n        }\n    }\n\n    /// Get docs repository info (only for `CodeRun`)\n    pub fn docs_repository_url(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => Some(&cr.spec.docs_repository_url),\n        }\n    }\n\n    /// Always use SSH authentication (we're SSH-only now)\n    pub fn uses_ssh() -> bool {\n        true\n    }\n\n    /// Get SSH secret name for this GitHub user\n    pub fn ssh_secret_name(&self) -> String {\n        format!(\"github-ssh-{}\", self.github_user())\n    }\n\n    /// Get GitHub token secret name for this GitHub user\n    pub fn github_token_secret_name(&self) -> String {\n        format!(\"github-token-{}\", self.github_user())\n    }\n\n    /// Get docs branch (only for `CodeRun`)\n    pub fn docs_branch(&self) -> &str {\n        match self {\n            TaskType::Docs(_) => \"main\", // Docs use default branch\n            TaskType::Code(cr) => &cr.spec.docs_branch,\n        }\n    }\n\n    /// Get continue session flag - true for retries or user-requested continuation\n    #[allow(dead_code)]\n    pub fn continue_session(&self) -> bool {\n        match self {\n            TaskType::Docs(_) => false, // Docs don't continue sessions\n            TaskType::Code(cr) => {\n                // Continue if it's a retry attempt OR user explicitly requested it\n                self.retry_count() > 0 || cr.spec.continue_session\n            }\n        }\n    }\n\n    /// Get overwrite memory flag (only for `CodeRun`)\n    pub fn overwrite_memory(&self) -> bool {\n        match self {\n            TaskType::Docs(_) => true, // Docs always overwrite memory\n            TaskType::Code(cr) => cr.spec.overwrite_memory,\n        }\n    }\n\n    /// Get docs project directory (only for `CodeRun`)\n    pub fn docs_project_directory(&self) -> Option<&str> {\n        match self {\n            TaskType::Docs(_) => None,\n            TaskType::Code(cr) => cr.spec.docs_project_directory.as_deref(),\n        }\n    }\n}\n"
        },
        {
          "path": "src/controllers/task_controller/config.rs",
          "file_type": "rust",
          "line_count": 348,
          "key_definitions": [
            "12:pub struct ControllerConfig {",
            "38:pub struct JobConfig {",
            "46:pub struct AgentConfig {",
            "57:pub struct ImageConfig {",
            "67:pub struct SecretsConfig {",
            "79:pub struct PermissionsConfig {",
            "93:pub struct TelemetryConfig {",
            "116:pub struct StorageConfig {",
            "132:pub struct CleanupConfig {",
            "169:impl Default for CleanupConfig {",
            "180:impl ControllerConfig {",
            "182:pub fn validate(&self) -> Result<(), anyhow::Error> {",
            "195:pub fn from_mounted_file(config_path: &str) -> Result<Self, anyhow::Error> {",
            "226:impl Default for ControllerConfig {"
          ],
          "content": "//! Task Controller Configuration\n//!\n//! Simplified configuration structure for the new DocsRun/CodeRun controller.\n//! Contains only the essential configuration needed for our current implementation.\n\nuse k8s_openapi::api::core::v1::ConfigMap;\nuse kube::{api::Api, Client};\nuse serde::{Deserialize, Serialize};\n\n/// Main controller configuration structure\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ControllerConfig {\n    /// Job configuration\n    pub job: JobConfig,\n\n    /// Agent configuration\n    pub agent: AgentConfig,\n\n    /// Secrets configuration\n    pub secrets: SecretsConfig,\n\n    /// Tool permissions configuration\n    pub permissions: PermissionsConfig,\n\n    /// Telemetry configuration\n    pub telemetry: TelemetryConfig,\n\n    /// Storage configuration\n    pub storage: StorageConfig,\n\n    /// Cleanup configuration\n    #[serde(default)]\n    pub cleanup: CleanupConfig,\n}\n\n/// Job configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct JobConfig {\n    /// Job timeout in seconds\n    #[serde(rename = \"activeDeadlineSeconds\")]\n    pub active_deadline_seconds: i64,\n}\n\n/// Agent configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct AgentConfig {\n    /// Container image configuration\n    pub image: ImageConfig,\n\n    /// Image pull secrets for private registries\n    #[serde(default, rename = \"imagePullSecrets\")]\n    pub image_pull_secrets: Vec<String>,\n}\n\n/// Image configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct ImageConfig {\n    /// Image repository (e.g., \"ghcr.io/5dlabs/claude\")\n    pub repository: String,\n\n    /// Image tag (e.g., \"latest\", \"v2.1.0\")\n    pub tag: String,\n}\n\n/// Secrets configuration - only what we actually use\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct SecretsConfig {\n    /// Anthropic API key secret name (for rotation)\n    #[serde(rename = \"apiKeySecretName\")]\n    pub api_key_secret_name: String,\n\n    /// Anthropic API key secret key\n    #[serde(rename = \"apiKeySecretKey\")]\n    pub api_key_secret_key: String,\n}\n\n/// Tool permissions configuration (used in templates)\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct PermissionsConfig {\n    /// Whether to override default tool permissions\n    #[serde(rename = \"agentToolsOverride\")]\n    pub agent_tools_override: bool,\n\n    /// Allowed tool patterns\n    pub allow: Vec<String>,\n\n    /// Denied tool patterns\n    pub deny: Vec<String>,\n}\n\n/// Telemetry configuration (used in templates)\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct TelemetryConfig {\n    /// Whether telemetry is enabled\n    pub enabled: bool,\n\n    /// OTLP endpoint URL\n    #[serde(rename = \"otlpEndpoint\")]\n    pub otlp_endpoint: String,\n\n    /// OTLP protocol (grpc/http)\n    #[serde(rename = \"otlpProtocol\")]\n    pub otlp_protocol: String,\n\n    /// Logs endpoint (for code tasks)\n    #[serde(rename = \"logsEndpoint\")]\n    pub logs_endpoint: String,\n\n    /// Logs protocol (for code tasks)\n    #[serde(rename = \"logsProtocol\")]\n    pub logs_protocol: String,\n}\n\n/// Storage configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct StorageConfig {\n    /// Storage class name for PVCs (e.g., \"local-path\" for local development)\n    #[serde(rename = \"storageClassName\")]\n    pub storage_class_name: Option<String>,\n\n    /// Storage size for workspace PVCs\n    #[serde(rename = \"workspaceSize\", default = \"default_workspace_size\")]\n    pub workspace_size: String,\n}\n\nfn default_workspace_size() -> String {\n    \"10Gi\".to_string()\n}\n\n/// Cleanup configuration\n#[derive(Debug, Clone, Deserialize, Serialize)]\npub struct CleanupConfig {\n    /// Whether automatic cleanup is enabled\n    #[serde(default = \"default_cleanup_enabled\")]\n    pub enabled: bool,\n\n    /// Minutes to wait before cleaning up completed (successful) jobs\n    #[serde(\n        rename = \"completedJobDelayMinutes\",\n        default = \"default_completed_delay\"\n    )]\n    pub completed_job_delay_minutes: u64,\n\n    /// Minutes to wait before cleaning up failed jobs\n    #[serde(rename = \"failedJobDelayMinutes\", default = \"default_failed_delay\")]\n    pub failed_job_delay_minutes: u64,\n\n    /// Whether to delete the ConfigMap when cleaning up the job\n    #[serde(rename = \"deleteConfigMap\", default = \"default_delete_configmap\")]\n    pub delete_configmap: bool,\n}\n\nfn default_cleanup_enabled() -> bool {\n    true\n}\n\nfn default_completed_delay() -> u64 {\n    5 // 5 minutes\n}\n\nfn default_failed_delay() -> u64 {\n    60 // 60 minutes (1 hour)\n}\n\nfn default_delete_configmap() -> bool {\n    true\n}\n\nimpl Default for CleanupConfig {\n    fn default() -> Self {\n        CleanupConfig {\n            enabled: default_cleanup_enabled(),\n            completed_job_delay_minutes: default_completed_delay(),\n            failed_job_delay_minutes: default_failed_delay(),\n            delete_configmap: default_delete_configmap(),\n        }\n    }\n}\n\nimpl ControllerConfig {\n    /// Validate that configuration has required fields\n    pub fn validate(&self) -> Result<(), anyhow::Error> {\n        if self.agent.image.repository == \"MISSING_IMAGE_CONFIG\"\n            || self.agent.image.tag == \"MISSING_IMAGE_CONFIG\"\n        {\n            return Err(anyhow::anyhow!(\n                \"Agent image configuration is missing! This indicates the controller ConfigMap was not loaded properly. \\\n                Please ensure the 'agent.image.repository' and 'agent.image.tag' are set in the Helm values.\"\n            ));\n        }\n        Ok(())\n    }\n\n    /// Load configuration from mounted ConfigMap file\n    pub fn from_mounted_file(config_path: &str) -> Result<Self, anyhow::Error> {\n        let config_str = std::fs::read_to_string(config_path)\n            .map_err(|e| anyhow::anyhow!(\"Failed to read config file {}: {}\", config_path, e))?;\n\n        let config: ControllerConfig = serde_yaml::from_str(&config_str)\n            .map_err(|e| anyhow::anyhow!(\"Failed to parse config YAML: {}\", e))?;\n\n        Ok(config)\n    }\n\n    /// Load configuration from a `ConfigMap` (legacy API-based method)\n    pub async fn from_configmap(\n        client: &Client,\n        namespace: &str,\n        name: &str,\n    ) -> Result<Self, anyhow::Error> {\n        let api: Api<ConfigMap> = Api::namespaced(client.clone(), namespace);\n        let cm = api.get(name).await?;\n\n        let data = cm\n            .data\n            .ok_or_else(|| anyhow::anyhow!(\"ConfigMap has no data\"))?;\n        let config_str = data\n            .get(\"config.yaml\")\n            .ok_or_else(|| anyhow::anyhow!(\"ConfigMap missing config.yaml\"))?;\n\n        let config: ControllerConfig = serde_yaml::from_str(config_str)?;\n        Ok(config)\n    }\n}\n\nimpl Default for ControllerConfig {\n    fn default() -> Self {\n        Self {\n            job: JobConfig {\n                active_deadline_seconds: 7200, // 2 hours\n            },\n            agent: AgentConfig {\n                image: ImageConfig {\n                    repository: \"MISSING_IMAGE_CONFIG\".to_string(),\n                    tag: \"MISSING_IMAGE_CONFIG\".to_string(),\n                },\n                image_pull_secrets: vec![\"ghcr-secret\".to_string()],\n            },\n            secrets: SecretsConfig {\n                api_key_secret_name: \"anthropic-api-key\".to_string(),\n                api_key_secret_key: \"api-key\".to_string(),\n            },\n            permissions: PermissionsConfig {\n                agent_tools_override: false,\n                allow: vec![\n                    \"Bash(*)\".to_string(),\n                    \"Edit(*)\".to_string(),\n                    \"Read(*)\".to_string(),\n                    \"Write(*)\".to_string(),\n                    \"MultiEdit(*)\".to_string(),\n                    \"Glob(*)\".to_string(),\n                    \"Grep(*)\".to_string(),\n                    \"LS(*)\".to_string(),\n                ],\n                deny: vec![\n                    \"Bash(npm:install*, yarn:install*, cargo:install*, docker:*, kubectl:*, rm:-rf*, git:*)\".to_string(),\n                ],\n            },\n            // Telemetry configuration with environment variable overrides:\n            // - OTLP_ENDPOINT: OTLP traces endpoint (default: http://localhost:4317)\n            // - LOGS_ENDPOINT: Logs endpoint (default: http://localhost:4318)\n            // - LOGS_PROTOCOL: Logs protocol (default: http)\n            telemetry: TelemetryConfig {\n                enabled: false,\n                otlp_endpoint: std::env::var(\"OTLP_ENDPOINT\")\n                    .unwrap_or_else(|_| \"http://localhost:4317\".to_string()),\n                otlp_protocol: \"grpc\".to_string(),\n                logs_endpoint: std::env::var(\"LOGS_ENDPOINT\")\n                    .unwrap_or_else(|_| \"http://localhost:4318\".to_string()),\n                logs_protocol: std::env::var(\"LOGS_PROTOCOL\")\n                    .unwrap_or_else(|_| \"http\".to_string()),\n            },\n            storage: StorageConfig {\n                storage_class_name: None, // Let K8s use default storage class\n                workspace_size: \"10Gi\".to_string(),\n            },\n            cleanup: CleanupConfig {\n                enabled: true,\n                completed_job_delay_minutes: 5,\n                failed_job_delay_minutes: 60,\n                delete_configmap: true,\n            },\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_deserialization() {\n        let yaml = r#\"\njob:\n  activeDeadlineSeconds: 3600\n\nagent:\n  image:\n    repository: \"test/image\"\n    tag: \"latest\"\n\nsecrets:\n  apiKeySecretName: \"test-secret\"\n  apiKeySecretKey: \"key\"\n\npermissions:\n  agentToolsOverride: true\n  allow: [\"*\"]\n  deny: []\n\ntelemetry:\n  enabled: true\n  otlpEndpoint: \"localhost:4317\"\n  otlpProtocol: \"grpc\"\n  logsEndpoint: \"localhost:4318\"\n  logsProtocol: \"http\"\n\nstorage:\n  storageClassName: \"local-path\"\n  workspaceSize: \"5Gi\"\n\ncleanup:\n  enabled: true\n  completedJobDelayMinutes: 5\n  failedJobDelayMinutes: 60\n  deleteConfigMap: true\n\"#;\n\n        let config: ControllerConfig = serde_yaml::from_str(yaml).unwrap();\n        assert_eq!(config.job.active_deadline_seconds, 3600);\n        assert_eq!(config.agent.image.repository, \"test/image\");\n        assert!(config.telemetry.enabled);\n        assert_eq!(config.permissions.allow, vec![\"*\"]);\n        assert!(config.cleanup.enabled);\n        assert_eq!(config.cleanup.completed_job_delay_minutes, 5);\n        assert_eq!(config.cleanup.failed_job_delay_minutes, 60);\n    }\n\n    #[test]\n    fn test_default_config() {\n        let config = ControllerConfig::default();\n        assert_eq!(config.job.active_deadline_seconds, 7200);\n        assert_eq!(config.agent.image.repository, \"MISSING_IMAGE_CONFIG\");\n        assert_eq!(config.secrets.api_key_secret_name, \"anthropic-api-key\");\n        assert!(!config.telemetry.enabled);\n        assert!(!config.permissions.agent_tools_override);\n    }\n}\n"
        },
        {
          "path": "src/controllers/task_controller/auth.rs",
          "file_type": "rust",
          "line_count": 31,
          "key_definitions": [
            "5:pub fn generate_ssh_volumes(task: &TaskType) -> Vec<serde_json::Value> {"
          ],
          "content": "use super::types::TaskType;\nuse serde_json::json;\n\n/// Generate SSH key volume configuration if needed\npub fn generate_ssh_volumes(task: &TaskType) -> Vec<serde_json::Value> {\n    if !TaskType::uses_ssh() {\n        return vec![];\n    }\n\n    let ssh_secret_name = task.ssh_secret_name();\n\n    vec![json!({\n        \"name\": \"ssh-key\",\n        \"secret\": {\n            \"secretName\": ssh_secret_name,\n            \"defaultMode\": 0o600,\n            \"items\": [\n                {\n                    \"key\": \"ssh-privatekey\",\n                    \"path\": \"id_ed25519\",\n                    \"mode\": 0o600\n                },\n                {\n                    \"key\": \"ssh-publickey\",\n                    \"path\": \"id_ed25519.pub\",\n                    \"mode\": 0o644\n                }\n            ]\n        }\n    })]\n}\n"
        },
        {
          "path": "src/controllers/task_controller/mod.rs",
          "file_type": "rust",
          "line_count": 19,
          "key_definitions": [],
          "content": "//! Task Controller\n//!\n//! Unified controller for both `DocsRun` and `CodeRun` resources.\n//! Handles job orchestration, resource management, and status tracking.\n\n// Public API - re-export the main controller function\npub use reconcile::run_task_controller;\n\n// Public types - re-export config for external use\npub use config::ControllerConfig;\n\n// Internal modules\npub(crate) mod auth;\npub(crate) mod config;\npub(crate) mod reconcile;\npub(crate) mod resources;\npub(crate) mod status;\npub(crate) mod templates;\npub(crate) mod types;\n"
        },
        {
          "path": "src/controllers/task_controller/reconcile.rs",
          "file_type": "rust",
          "line_count": 266,
          "key_definitions": [],
          "content": "use super::config::ControllerConfig;\nuse crate::crds::{CodeRun, DocsRun};\nuse futures::StreamExt;\nuse k8s_openapi::api::{\n    batch::v1::Job,\n    core::v1::{ConfigMap, PersistentVolumeClaim},\n};\nuse kube::{\n    api::Api,\n    runtime::{\n        controller::{Action, Controller},\n        finalizer::{finalizer, Event as FinalizerEvent},\n        watcher::Config,\n    },\n    Client,\n};\nuse std::sync::Arc;\nuse tokio::time::Duration;\nuse tracing::error;\n\nuse super::resources::{cleanup_resources, reconcile_create_or_update};\nuse super::status::monitor_job_status;\nuse super::types::{Context, Error, Result, TaskType, CODE_FINALIZER_NAME, DOCS_FINALIZER_NAME};\n\n/// Run the task controller for both `DocsRun` and `CodeRun` resources\npub async fn run_task_controller(client: Client, namespace: String) -> Result<()> {\n    error!(\n        \"🚀 AGGRESSIVE DEBUG: Starting task controller in namespace: {}\",\n        namespace\n    );\n\n    error!(\"🔧 AGGRESSIVE DEBUG: About to load controller configuration from mounted file...\");\n\n    // Load controller configuration from mounted file\n    let config = match ControllerConfig::from_mounted_file(\"/config/config.yaml\") {\n        Ok(cfg) => {\n            error!(\"✅ AGGRESSIVE DEBUG: Successfully loaded controller configuration from mounted file\");\n            error!(\n                \"🔧 AGGRESSIVE DEBUG: Configuration cleanup enabled = {}\",\n                cfg.cleanup.enabled\n            );\n\n            // Validate configuration has required fields\n            if let Err(validation_error) = cfg.validate() {\n                error!(\n                    \"❌ AGGRESSIVE DEBUG: Configuration validation failed: {}\",\n                    validation_error\n                );\n                return Err(Error::ConfigError(validation_error.to_string()));\n            }\n            error!(\"✅ AGGRESSIVE DEBUG: Configuration validation passed\");\n            cfg\n        }\n        Err(e) => {\n            error!(\n                \"❌ AGGRESSIVE DEBUG: Failed to load configuration from mounted file, using defaults: {}\",\n                e\n            );\n            error!(\"🔧 AGGRESSIVE DEBUG: About to create default configuration...\");\n            let default_config = ControllerConfig::default();\n\n            // Validate default configuration - this should fail if image config is missing\n            if let Err(validation_error) = default_config.validate() {\n                error!(\n                    \"❌ AGGRESSIVE DEBUG: Default configuration is invalid: {}\",\n                    validation_error\n                );\n                return Err(Error::ConfigError(validation_error.to_string()));\n            }\n            error!(\"✅ AGGRESSIVE DEBUG: Default configuration validation passed\");\n            default_config\n        }\n    };\n\n    error!(\"🏗️ AGGRESSIVE DEBUG: Creating controller context...\");\n    let context = Arc::new(Context {\n        client: client.clone(),\n        namespace: namespace.clone(),\n        config: Arc::new(config),\n    });\n\n    error!(\"✅ AGGRESSIVE DEBUG: Controller context created successfully\");\n\n    // Start controllers for both DocsRun and CodeRun\n    error!(\"🔗 AGGRESSIVE DEBUG: Creating API clients for DocsRun and CodeRun...\");\n    let docs_runs = Api::<DocsRun>::namespaced(client.clone(), &namespace);\n    let code_runs = Api::<CodeRun>::namespaced(client.clone(), &namespace);\n\n    error!(\"✅ AGGRESSIVE DEBUG: API clients created, starting controllers...\");\n\n    let docs_controller = Controller::new(docs_runs, Config::default())\n        .shutdown_on_signal()\n        .run(reconcile_docs, error_policy_docs, context.clone())\n        .filter_map(|x| async move { std::result::Result::ok(x) })\n        .for_each(|_| futures::future::ready(()));\n\n    let code_controller = Controller::new(code_runs, Config::default())\n        .shutdown_on_signal()\n        .run(reconcile_code, error_policy_code, context.clone())\n        .filter_map(|x| async move { std::result::Result::ok(x) })\n        .for_each(|_| futures::future::ready(()));\n\n    error!(\"🚀 AGGRESSIVE DEBUG: Both controllers started, entering main loop...\");\n\n    // Run both controllers concurrently\n    tokio::select! {\n        () = docs_controller => error!(\"DocsRun controller finished\"),\n        () = code_controller => error!(\"CodeRun controller finished\"),\n    }\n\n    Ok(())\n}\n\n/// Reconciliation logic for `DocsRun` resources\nasync fn reconcile_docs(docs_run: Arc<DocsRun>, ctx: Arc<Context>) -> Result<Action> {\n    error!(\n        \"📝 AGGRESSIVE DEBUG: Starting reconcile_docs for: {}\",\n        docs_run\n            .metadata\n            .name\n            .as_ref()\n            .unwrap_or(&\"unnamed\".to_string())\n    );\n\n    let task = TaskType::Docs(docs_run.clone());\n    error!(\"🔍 AGGRESSIVE DEBUG: Created task type, calling reconcile_common...\");\n\n    let result = reconcile_common(task, ctx, DOCS_FINALIZER_NAME).await;\n    error!(\n        \"🏁 AGGRESSIVE DEBUG: reconcile_common completed with result: {:?}\",\n        result.is_ok()\n    );\n\n    result\n}\n\n/// Reconcile function for `CodeRun` resources\nasync fn reconcile_code(cr: Arc<CodeRun>, ctx: Arc<Context>) -> Result<Action> {\n    let task = TaskType::Code(cr.clone());\n    reconcile_common(task, ctx, CODE_FINALIZER_NAME).await\n}\n\n/// Common reconciliation logic for both `DocsRun` and `CodeRun`\nasync fn reconcile_common(\n    task: TaskType,\n    ctx: Arc<Context>,\n    finalizer_name: &str,\n) -> Result<Action> {\n    error!(\n        \"🎯 AGGRESSIVE DEBUG: Starting reconcile_common for: {}\",\n        task.name()\n    );\n\n    let namespace = &ctx.namespace;\n    let client = &ctx.client;\n    let name = task.name();\n\n    error!(\n        \"🔄 AGGRESSIVE DEBUG: Reconciling {}: {}\",\n        if task.is_docs() { \"DocsRun\" } else { \"CodeRun\" },\n        name\n    );\n\n    // Create APIs\n    error!(\"🔗 AGGRESSIVE DEBUG: Creating Kubernetes API clients...\");\n    let jobs: Api<Job> = Api::namespaced(client.clone(), namespace);\n    let configmaps: Api<ConfigMap> = Api::namespaced(client.clone(), namespace);\n    let pvcs: Api<PersistentVolumeClaim> = Api::namespaced(client.clone(), namespace);\n    error!(\"✅ AGGRESSIVE DEBUG: API clients created successfully\");\n\n    // Handle finalizers for cleanup based on task type\n    let _result = match &task {\n        TaskType::Docs(dr) => {\n            let docsruns: Api<DocsRun> = Api::namespaced(client.clone(), namespace);\n            finalizer(&docsruns, finalizer_name, dr.clone(), |event| async {\n                match event {\n                    FinalizerEvent::Apply(dr) => {\n                        let task = TaskType::Docs(dr);\n                        reconcile_create_or_update(\n                            task,\n                            &jobs,\n                            &configmaps,\n                            &pvcs,\n                            &ctx.config,\n                            &ctx,\n                        )\n                        .await\n                    }\n                    FinalizerEvent::Cleanup(dr) => {\n                        let task = TaskType::Docs(dr);\n                        cleanup_resources(task, &jobs, &configmaps).await\n                    }\n                }\n            })\n            .await\n        }\n        TaskType::Code(cr) => {\n            let coderuns: Api<CodeRun> = Api::namespaced(client.clone(), namespace);\n            finalizer(&coderuns, finalizer_name, cr.clone(), |event| async {\n                match event {\n                    FinalizerEvent::Apply(cr) => {\n                        let task = TaskType::Code(cr);\n                        reconcile_create_or_update(\n                            task,\n                            &jobs,\n                            &configmaps,\n                            &pvcs,\n                            &ctx.config,\n                            &ctx,\n                        )\n                        .await\n                    }\n                    FinalizerEvent::Cleanup(cr) => {\n                        let task = TaskType::Code(cr);\n                        cleanup_resources(task, &jobs, &configmaps).await\n                    }\n                }\n            })\n            .await\n        }\n    };\n\n    // Handle finalizer errors\n    let _result = _result.map_err(|e| match e {\n        kube::runtime::finalizer::Error::ApplyFailed(err) => err,\n        kube::runtime::finalizer::Error::CleanupFailed(err) => err,\n        kube::runtime::finalizer::Error::AddFinalizer(e) => Error::KubeError(e),\n        kube::runtime::finalizer::Error::RemoveFinalizer(e) => Error::KubeError(e),\n        kube::runtime::finalizer::Error::UnnamedObject => Error::MissingObjectKey,\n        kube::runtime::finalizer::Error::InvalidFinalizer => {\n            Error::ConfigError(\"Invalid finalizer name\".to_string())\n        }\n    })?;\n\n    // Monitor running jobs\n    monitor_running_job(&task, &jobs, &ctx).await?;\n\n    // Requeue after 30 seconds to check status\n    Ok(Action::requeue(Duration::from_secs(30)))\n}\n\n/// Monitor running job status for both task types\nasync fn monitor_running_job(task: &TaskType, jobs: &Api<Job>, ctx: &Arc<Context>) -> Result<()> {\n    let is_running = match task {\n        TaskType::Docs(dr) => dr.status.as_ref().is_some_and(|s| s.phase == \"Running\"),\n        TaskType::Code(cr) => cr.status.as_ref().is_some_and(|s| s.phase == \"Running\"),\n    };\n\n    if is_running {\n        monitor_job_status(task, jobs, ctx).await?;\n    }\n\n    Ok(())\n}\n\n/// Error policy for `DocsRun` controller\nfn error_policy_docs(_dr: Arc<DocsRun>, error: &Error, _ctx: Arc<Context>) -> Action {\n    error!(\"DocsRun reconciliation error: {:?}\", error);\n    Action::requeue(Duration::from_secs(30))\n}\n\n/// Error policy for `CodeRun` controller\nfn error_policy_code(_cr: Arc<CodeRun>, error: &Error, _ctx: Arc<Context>) -> Action {\n    error!(\"CodeRun reconciliation error: {:?}\", error);\n    Action::requeue(Duration::from_secs(30))\n}\n"
        },
        {
          "path": "src/controllers/task_controller/status.rs",
          "file_type": "rust",
          "line_count": 347,
          "key_definitions": [],
          "content": "use k8s_openapi::api::batch::v1::Job;\nuse kube::api::{Api, Patch, PatchParams};\nuse serde_json::json;\nuse std::sync::Arc;\nuse tracing::{error, info, warn};\n\nuse super::types::{Context, Result, TaskType};\nuse crate::crds::{CodeRun, CodeRunCondition, DocsRun, DocsRunCondition};\n\n/// Monitor Job status and update CRD accordingly\npub async fn monitor_job_status(\n    task: &TaskType,\n    jobs: &Api<Job>,\n    ctx: &Arc<Context>,\n) -> Result<()> {\n    let job_name = get_current_job_name(task);\n\n    if let Some(job_name) = job_name {\n        // Get the current job\n        match jobs.get(&job_name).await {\n            Ok(job) => {\n                let (phase, message, pull_request_url) = analyze_job_status(&job);\n                update_task_status(task, ctx, &phase, &message, pull_request_url).await?;\n\n                // Schedule cleanup if job is complete and cleanup is enabled\n                if ctx.config.cleanup.enabled && (phase == \"Succeeded\" || phase == \"Failed\") {\n                    schedule_job_cleanup(task, ctx, &job_name, &phase).await?;\n                }\n            }\n            Err(kube::Error::Api(ae)) if ae.code == 404 => {\n                // Job doesn't exist yet, which is fine for newly created tasks\n                info!(\"Job {} not found yet for task {}\", job_name, task.name());\n            }\n            Err(e) => {\n                warn!(\n                    \"Failed to get job {} for task {}: {}\",\n                    job_name,\n                    task.name(),\n                    e\n                );\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Get the current job name for a task\nfn get_current_job_name(task: &TaskType) -> Option<String> {\n    match task {\n        TaskType::Docs(dr) => dr.status.as_ref().and_then(|s| s.job_name.clone()),\n        TaskType::Code(cr) => cr.status.as_ref().and_then(|s| s.job_name.clone()),\n    }\n}\n\n/// Analyze job status and return (phase, message, `pull_request_url`)\nfn analyze_job_status(job: &Job) -> (String, String, Option<String>) {\n    if let Some(status) = &job.status {\n        // Check completion time first\n        if status.completion_time.is_some() {\n            if let Some(conditions) = &status.conditions {\n                for condition in conditions {\n                    if condition.type_ == \"Complete\" && condition.status == \"True\" {\n                        return (\n                            \"Succeeded\".to_string(),\n                            \"Job completed successfully\".to_string(),\n                            None,\n                        );\n                    } else if condition.type_ == \"Failed\" && condition.status == \"True\" {\n                        let message = condition.message.as_deref().unwrap_or(\"Job failed\");\n                        return (\"Failed\".to_string(), message.to_string(), None);\n                    }\n                }\n            }\n        }\n\n        // Check if job is running\n        if let Some(active) = status.active {\n            if active > 0 {\n                return (\"Running\".to_string(), \"Job is running\".to_string(), None);\n            }\n        }\n\n        // Check for failure conditions\n        if let Some(failed) = status.failed {\n            if failed > 0 {\n                return (\"Failed\".to_string(), \"Job failed\".to_string(), None);\n            }\n        }\n    }\n\n    // Default to pending if we can't determine status\n    (\n        \"Pending\".to_string(),\n        \"Job status unknown\".to_string(),\n        None,\n    )\n}\n\n/// Update the task CRD status\nasync fn update_task_status(\n    task: &TaskType,\n    ctx: &Arc<Context>,\n    phase: &str,\n    message: &str,\n    pull_request_url: Option<String>,\n) -> Result<()> {\n    let namespace = &ctx.namespace;\n    let client = &ctx.client;\n    let name = task.name();\n\n    let current_time = chrono::Utc::now().to_rfc3339();\n\n    match task {\n        TaskType::Docs(_dr) => {\n            let docs_api: Api<DocsRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": phase,\n                    \"message\": message,\n                    \"lastUpdate\": current_time,\n                    \"pullRequestUrl\": pull_request_url,\n                    \"conditions\": build_docs_conditions(phase, message, &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            let pp = PatchParams::default();\n\n            match docs_api.patch_status(&name, &pp, &patch).await {\n                Ok(_) => {\n                    info!(\"Updated DocsRun status: {} -> {}\", name, phase);\n                }\n                Err(e) => {\n                    error!(\"Failed to update DocsRun status for {}: {}\", name, e);\n                }\n            }\n        }\n        TaskType::Code(cr) => {\n            let code_api: Api<CodeRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": phase,\n                    \"message\": message,\n                    \"lastUpdate\": current_time,\n                    \"pullRequestUrl\": pull_request_url,\n                    \"retryCount\": cr.status.as_ref().map_or(0, |s| s.retry_count.unwrap_or(0)),\n                    \"conditions\": build_code_conditions(phase, message, &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            let pp = PatchParams::default();\n\n            match code_api.patch_status(&name, &pp, &patch).await {\n                Ok(_) => {\n                    info!(\"Updated CodeRun status: {} -> {}\", name, phase);\n                }\n                Err(e) => {\n                    error!(\"Failed to update CodeRun status for {}: {}\", name, e);\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Build conditions for `DocsRun` status\nfn build_docs_conditions(phase: &str, message: &str, timestamp: &str) -> Vec<DocsRunCondition> {\n    vec![DocsRunCondition {\n        condition_type: \"Ready\".to_string(),\n        status: if phase == \"Succeeded\" {\n            \"True\"\n        } else {\n            \"False\"\n        }\n        .to_string(),\n        last_transition_time: Some(timestamp.to_string()),\n        reason: Some(phase.to_string()),\n        message: Some(message.to_string()),\n    }]\n}\n\n/// Build conditions for `CodeRun` status\nfn build_code_conditions(phase: &str, message: &str, timestamp: &str) -> Vec<CodeRunCondition> {\n    vec![CodeRunCondition {\n        condition_type: \"Ready\".to_string(),\n        status: if phase == \"Succeeded\" {\n            \"True\"\n        } else {\n            \"False\"\n        }\n        .to_string(),\n        last_transition_time: Some(timestamp.to_string()),\n        reason: Some(phase.to_string()),\n        message: Some(message.to_string()),\n    }]\n}\n\n/// Update task status when job starts (called from reconcile logic)\npub async fn update_job_started(\n    task: &TaskType,\n    ctx: &Arc<Context>,\n    job_name: &str,\n    configmap_name: &str,\n) -> Result<()> {\n    let namespace = &ctx.namespace;\n    let client = &ctx.client;\n    let name = task.name();\n    let current_time = chrono::Utc::now().to_rfc3339();\n\n    match task {\n        TaskType::Docs(_) => {\n            let docs_api: Api<DocsRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": \"Running\",\n                    \"message\": \"Job started\",\n                    \"lastUpdate\": current_time,\n                    \"jobName\": job_name,\n                    \"configmapName\": configmap_name,\n                    \"conditions\": build_docs_conditions(\"Running\", \"Job started\", &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            docs_api\n                .patch_status(&name, &PatchParams::default(), &patch)\n                .await?;\n        }\n        TaskType::Code(_) => {\n            let code_api: Api<CodeRun> = Api::namespaced(client.clone(), namespace);\n\n            let status_patch = json!({\n                \"status\": {\n                    \"phase\": \"Running\",\n                    \"message\": \"Job started\",\n                    \"lastUpdate\": current_time,\n                    \"jobName\": job_name,\n                    \"configmapName\": configmap_name,\n                    \"conditions\": build_code_conditions(\"Running\", \"Job started\", &current_time)\n                }\n            });\n\n            let patch = Patch::Merge(&status_patch);\n            code_api\n                .patch_status(&name, &PatchParams::default(), &patch)\n                .await?;\n        }\n    }\n\n    info!(\"Updated {} status to Running with job: {}\", name, job_name);\n    Ok(())\n}\n\n/// Schedule cleanup of completed job after configured delay\nasync fn schedule_job_cleanup(\n    task: &TaskType,\n    ctx: &Arc<Context>,\n    job_name: &str,\n    phase: &str,\n) -> Result<()> {\n    let delay_minutes = if phase == \"Succeeded\" {\n        ctx.config.cleanup.completed_job_delay_minutes\n    } else {\n        ctx.config.cleanup.failed_job_delay_minutes\n    };\n\n    let job_name = job_name.to_string();\n    let task_name = task.name();\n    let namespace = ctx.namespace.clone();\n    let client = ctx.client.clone();\n    let delete_configmap = ctx.config.cleanup.delete_configmap;\n\n    info!(\n        \"Scheduling cleanup for job {} in {} minutes (phase: {})\",\n        job_name, delay_minutes, phase\n    );\n\n    // Spawn background task to handle cleanup after delay\n    tokio::spawn(async move {\n        // Wait for the configured delay\n        tokio::time::sleep(tokio::time::Duration::from_secs(delay_minutes * 60)).await;\n\n        info!(\"Starting scheduled cleanup for job: {}\", job_name);\n\n        // Delete the job\n        let jobs_api: Api<Job> = Api::namespaced(client.clone(), &namespace);\n        match jobs_api\n            .delete(&job_name, &kube::api::DeleteParams::background())\n            .await\n        {\n            Ok(_) => info!(\"Successfully deleted job: {}\", job_name),\n            Err(kube::Error::Api(ae)) if ae.code == 404 => {\n                info!(\"Job {} already deleted\", job_name);\n            }\n            Err(e) => {\n                error!(\"Failed to delete job {}: {}\", job_name, e);\n            }\n        }\n\n        // Delete associated ConfigMap if enabled\n        if delete_configmap {\n            let configmaps_api: Api<k8s_openapi::api::core::v1::ConfigMap> =\n                Api::namespaced(client.clone(), &namespace);\n\n            // Find ConfigMap associated with this job\n            let labels_selector = \"app=orchestrator\".to_string();\n            let list_params = kube::api::ListParams::default().labels(&labels_selector);\n\n            match configmaps_api.list(&list_params).await {\n                Ok(cms) => {\n                    for cm in cms.items {\n                        if let Some(cm_name) = &cm.metadata.name {\n                            // Check if ConfigMap is associated with this job\n                            if cm_name.starts_with(&task_name.replace('_', \"-\")) {\n                                match configmaps_api\n                                    .delete(cm_name, &kube::api::DeleteParams::default())\n                                    .await\n                                {\n                                    Ok(_) => info!(\"Successfully deleted ConfigMap: {}\", cm_name),\n                                    Err(kube::Error::Api(ae)) if ae.code == 404 => {\n                                        info!(\"ConfigMap {} already deleted\", cm_name);\n                                    }\n                                    Err(e) => {\n                                        error!(\"Failed to delete ConfigMap {}: {}\", cm_name, e);\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n                Err(e) => {\n                    error!(\"Failed to list ConfigMaps for cleanup: {}\", e);\n                }\n            }\n        }\n\n        info!(\"Completed cleanup for job: {}\", job_name);\n    });\n\n    Ok(())\n}\n"
        },
        {
          "path": "src/controllers/task_controller/resources.rs",
          "file_type": "rust",
          "line_count": 612,
          "key_definitions": [],
          "content": "use super::config::ControllerConfig;\nuse k8s_openapi::api::{\n    batch::v1::Job,\n    core::v1::{ConfigMap, PersistentVolumeClaim},\n};\nuse k8s_openapi::apimachinery::pkg::apis::meta::v1::{ObjectMeta, OwnerReference};\nuse kube::api::{Api, DeleteParams, ListParams, PostParams};\nuse kube::runtime::controller::Action;\nuse serde_json::json;\nuse std::collections::BTreeMap;\nuse std::sync::Arc;\nuse tracing::info;\n\nuse super::auth::generate_ssh_volumes;\nuse super::status::update_job_started;\nuse super::templates::generate_templates;\nuse super::types::{Result, TaskType};\n\n/// Reconciliation logic for create/update operations\npub async fn reconcile_create_or_update(\n    task: TaskType,\n    jobs: &Api<Job>,\n    configmaps: &Api<ConfigMap>,\n    pvcs: &Api<PersistentVolumeClaim>,\n    config: &Arc<ControllerConfig>,\n    ctx: &Arc<super::types::Context>,\n) -> Result<Action> {\n    let name = task.name();\n    info!(\"Creating/updating resources for task: {}\", name);\n\n    // Ensure PVC exists for code tasks (docs use emptyDir)\n    if !task.is_docs() {\n        let service_name = task.service_name();\n        let pvc_name = format!(\"workspace-{service_name}\");\n        ensure_pvc_exists(pvcs, &pvc_name, service_name, config).await?;\n    }\n\n    // Clean up older versions for retries\n    cleanup_old_jobs(&task, jobs).await?;\n    cleanup_old_configmaps(&task, configmaps).await?;\n\n    // Create ConfigMap FIRST (without owner reference) so Job can mount it\n    let cm_name = generate_configmap_name(&task);\n    let configmap = create_configmap(&task, &cm_name, config, None)?;\n\n    match configmaps.create(&PostParams::default(), &configmap).await {\n        Ok(_) => info!(\"Created ConfigMap: {}\", cm_name),\n        Err(kube::Error::Api(ae)) if ae.code == 409 => {\n            info!(\"ConfigMap already exists: {}\", cm_name);\n        }\n        Err(e) => return Err(e.into()),\n    }\n\n    // Create Job SECOND (now it can successfully mount the existing ConfigMap)\n    let job_ref = create_job(&task, jobs, &cm_name, config, ctx).await?;\n\n    // Update ConfigMap with Job as owner (for automatic cleanup on job deletion)\n    if let Some(owner_ref) = job_ref {\n        update_configmap_owner(&task, configmaps, &cm_name, owner_ref).await?;\n    }\n\n    Ok(Action::await_change())\n}\n\n/// Generate a unique `ConfigMap` name for the task\nfn generate_configmap_name(task: &TaskType) -> String {\n    let task_id = task.task_id().unwrap_or(0); // Fallback for docs\n    let service_name = task.service_name().replace('_', \"-\");\n    let context_version = task.context_version();\n\n    if task.is_docs() {\n        format!(\"{service_name}-docs-v{context_version}-files\")\n    } else {\n        format!(\"{service_name}-task{task_id}-v{context_version}-files\")\n    }\n}\n\n/// Create `ConfigMap` with all template files\nfn create_configmap(\n    task: &TaskType,\n    name: &str,\n    config: &ControllerConfig,\n    owner_ref: Option<OwnerReference>,\n) -> Result<ConfigMap> {\n    let mut data = BTreeMap::new();\n\n    // Generate all templates for this task\n    let templates = generate_templates(task, config)?;\n    for (filename, content) in templates {\n        data.insert(filename, content);\n    }\n\n    let labels = create_task_labels(task);\n    let mut metadata = ObjectMeta {\n        name: Some(name.to_string()),\n        labels: Some(labels),\n        ..Default::default()\n    };\n\n    // Set owner reference if provided (for automatic cleanup)\n    if let Some(owner) = owner_ref {\n        metadata.owner_references = Some(vec![owner]);\n    }\n\n    Ok(ConfigMap {\n        metadata,\n        data: Some(data),\n        ..Default::default()\n    })\n}\n\n/// Create the main job for the task\nasync fn create_job(\n    task: &TaskType,\n    jobs: &Api<Job>,\n    cm_name: &str,\n    config: &ControllerConfig,\n    ctx: &Arc<super::types::Context>,\n) -> Result<Option<OwnerReference>> {\n    let job_name = generate_job_name(task);\n    let job = build_job_spec(task, &job_name, cm_name, config)?;\n\n    match jobs.create(&PostParams::default(), &job).await {\n        Ok(created_job) => {\n            info!(\"Created job: {}\", job_name);\n            update_job_started(task, ctx, &job_name, cm_name).await?;\n\n            // Return owner reference for the created job\n            if let (Some(uid), Some(name)) = (created_job.metadata.uid, created_job.metadata.name) {\n                Ok(Some(OwnerReference {\n                    api_version: \"batch/v1\".to_string(),\n                    kind: \"Job\".to_string(),\n                    name,\n                    uid,\n                    controller: Some(true),\n                    block_owner_deletion: Some(true),\n                }))\n            } else {\n                Ok(None)\n            }\n        }\n        Err(kube::Error::Api(ae)) if ae.code == 409 => {\n            info!(\"Job already exists: {}\", job_name);\n            // Try to get existing job for owner reference\n            match jobs.get(&job_name).await {\n                Ok(existing_job) => {\n                    if let (Some(uid), Some(name)) =\n                        (existing_job.metadata.uid, existing_job.metadata.name)\n                    {\n                        Ok(Some(OwnerReference {\n                            api_version: \"batch/v1\".to_string(),\n                            kind: \"Job\".to_string(),\n                            name,\n                            uid,\n                            controller: Some(true),\n                            block_owner_deletion: Some(true),\n                        }))\n                    } else {\n                        Ok(None)\n                    }\n                }\n                Err(_) => Ok(None),\n            }\n        }\n        Err(e) => Err(e.into()),\n    }\n}\n\n/// Generate a deterministic job name for the task (based on resource name, not timestamp)\nfn generate_job_name(task: &TaskType) -> String {\n    let resource_name = task.name().replace(['_', '.'], \"-\");\n    match task {\n        TaskType::Docs(_) => {\n            format!(\"docs-gen-{resource_name}\")\n        }\n        TaskType::Code(_) => {\n            let task_id = task.task_id().unwrap_or(0);\n            let context_version = task.context_version();\n            format!(\"code-impl-{resource_name}-task{task_id}-v{context_version}\")\n        }\n    }\n}\n\n/// Build the complete Job specification\nfn build_job_spec(\n    task: &TaskType,\n    job_name: &str,\n    cm_name: &str,\n    config: &ControllerConfig,\n) -> Result<Job> {\n    let labels = create_task_labels(task);\n\n    // Build volumes based on task type\n    let mut volumes = vec![];\n    let mut volume_mounts = vec![];\n\n    // ConfigMap volume (always needed)\n    volumes.push(json!({\n        \"name\": \"task-files\",\n        \"configMap\": {\n            \"name\": cm_name\n        }\n    }));\n    volume_mounts.push(json!({\n        \"name\": \"task-files\",\n        \"mountPath\": \"/config\"\n    }));\n\n    // Workspace volume (only for code tasks)\n    if !task.is_docs() {\n        let service_name = task.service_name();\n        let pvc_name = format!(\"workspace-{service_name}\");\n\n        volumes.push(json!({\n            \"name\": \"workspace\",\n            \"persistentVolumeClaim\": {\n                \"claimName\": pvc_name\n            }\n        }));\n        volume_mounts.push(json!({\n            \"name\": \"workspace\",\n            \"mountPath\": \"/workspace\"\n        }));\n    }\n\n    // SSH volumes if needed\n    if TaskType::uses_ssh() {\n        let ssh_volumes = generate_ssh_volumes(task);\n        volumes.extend(ssh_volumes);\n\n        volume_mounts.push(json!({\n            \"name\": \"ssh-key\",\n            \"mountPath\": \"/workspace/.ssh\",\n            \"readOnly\": true\n        }));\n    }\n\n    // Mount settings.json directly to /etc/claude-code/managed-settings.json\n    volume_mounts.push(json!({\n        \"name\": \"task-files\",\n        \"mountPath\": \"/etc/claude-code/managed-settings.json\",\n        \"subPath\": \"settings.json\",\n        \"readOnly\": true\n    }));\n\n    // Guidelines files will be copied from ConfigMap to working directory by container.sh\n    // No need to mount them separately since they need to be in the working directory\n\n    // Environment variables\n    let mut env_vars = vec![\n        json!({\"name\": \"ANTHROPIC_API_KEY\", \"valueFrom\": {\"secretKeyRef\": {\"name\": config.secrets.api_key_secret_name, \"key\": config.secrets.api_key_secret_key}}}),\n        json!({\"name\": \"TASK_TYPE\", \"value\": if task.is_docs() { \"docs\" } else { \"code\" }}),\n        json!({\"name\": \"MODEL\", \"value\": task.model()}),\n        json!({\"name\": \"GITHUB_USER\", \"value\": task.github_user()}),\n        json!({\"name\": \"REPOSITORY_URL\", \"value\": task.repository_url()}),\n        json!({\"name\": \"WORKING_DIRECTORY\", \"value\": task.working_directory()}),\n    ];\n\n    // Add GitHub token from secret for API operations (PR creation, etc.)\n    env_vars.push(json!({\n        \"name\": \"GH_TOKEN\",\n        \"valueFrom\": {\n            \"secretKeyRef\": {\n                \"name\": task.github_token_secret_name(),\n                \"key\": \"token\"\n            }\n        }\n    }));\n\n    // Add task-specific environment variables\n    match task {\n        TaskType::Docs(dr) => {\n            env_vars.push(json!({\"name\": \"SOURCE_BRANCH\", \"value\": dr.spec.source_branch}));\n        }\n        TaskType::Code(cr) => {\n            env_vars.push(json!({\"name\": \"TASK_ID\", \"value\": cr.spec.task_id.to_string()}));\n            env_vars.push(json!({\"name\": \"SERVICE_NAME\", \"value\": cr.spec.service}));\n            env_vars\n                .push(json!({\"name\": \"DOCS_REPOSITORY_URL\", \"value\": cr.spec.docs_repository_url}));\n            env_vars\n                .push(json!({\"name\": \"MCP_CLIENT_CONFIG\", \"value\": \"/.claude/client-config.json\"}));\n\n            if let Some(local_tools) = &cr.spec.local_tools {\n                env_vars.push(json!({\"name\": \"LOCAL_TOOLS\", \"value\": local_tools}));\n            }\n            if let Some(remote_tools) = &cr.spec.remote_tools {\n                env_vars.push(json!({\"name\": \"REMOTE_TOOLS\", \"value\": remote_tools}));\n            }\n\n            // Add toolman server URL for MCP integration\n            // Environment variable: TOOLMAN_SERVER_URL (default: http://toolman.mcp.svc.cluster.local:3000/mcp)\n            let toolman_url = std::env::var(\"TOOLMAN_SERVER_URL\")\n                .unwrap_or_else(|_| \"http://toolman.mcp.svc.cluster.local:3000/mcp\".to_string());\n            env_vars.push(json!({\"name\": \"TOOLMAN_SERVER_URL\", \"value\": toolman_url}));\n\n            // Add custom environment variables\n            for (name, value) in &cr.spec.env {\n                env_vars.push(json!({\"name\": name, \"value\": value}));\n            }\n\n            // Add environment variables from secrets\n            for secret_env in &cr.spec.env_from_secrets {\n                env_vars.push(json!({\n                    \"name\": secret_env.name,\n                    \"valueFrom\": {\n                        \"secretKeyRef\": {\n                            \"name\": secret_env.secret_name,\n                            \"key\": secret_env.secret_key\n                        }\n                    }\n                }));\n            }\n        }\n    }\n\n    // Job deadline from config\n    let job_deadline = config.job.active_deadline_seconds;\n\n    // Agent image from config\n    let agent_image = format!(\n        \"{}:{}\",\n        config.agent.image.repository, config.agent.image.tag\n    );\n\n    let job_spec = json!({\n        \"apiVersion\": \"batch/v1\",\n        \"kind\": \"Job\",\n        \"metadata\": {\n            \"name\": job_name,\n            \"labels\": labels\n        },\n        \"spec\": {\n            \"activeDeadlineSeconds\": job_deadline,\n            \"backoffLimit\": 0,\n            \"template\": {\n                \"metadata\": {\n                    \"labels\": labels\n                },\n                \"spec\": {\n                    \"restartPolicy\": \"Never\",\n                    \"securityContext\": {\n                        \"fsGroup\": 1000,\n                        \"runAsUser\": 1000,\n                        \"runAsGroup\": 1000\n                    },\n                    \"imagePullSecrets\": config.agent.image_pull_secrets.iter().map(|name| {\n                        json!({\"name\": name})\n                    }).collect::<Vec<_>>(),\n                    \"containers\": [{\n                        \"name\": \"claude\",\n                        \"image\": agent_image,\n                        \"command\": [\"/bin/bash\", \"/config/container.sh\"],\n                        \"env\": env_vars,\n                        \"volumeMounts\": volume_mounts,\n                        \"resources\": {\n                            \"requests\": {\n                                \"cpu\": \"100m\",\n                                \"memory\": \"256Mi\"\n                            },\n                            \"limits\": {\n                                \"cpu\": \"2\",\n                                \"memory\": \"4Gi\"\n                            }\n                        }\n                    }],\n                    \"volumes\": volumes\n                }\n            }\n        }\n    });\n\n    Ok(serde_json::from_value(job_spec)?)\n}\n\n/// Create standard labels for task resources\nfn create_task_labels(task: &TaskType) -> BTreeMap<String, String> {\n    let mut labels = BTreeMap::new();\n\n    labels.insert(\"app\".to_string(), \"orchestrator\".to_string());\n    labels.insert(\n        \"component\".to_string(),\n        if task.is_docs() {\n            \"docs-generator\"\n        } else {\n            \"code-runner\"\n        }\n        .to_string(),\n    );\n    labels.insert(\n        \"github-user\".to_string(),\n        sanitize_label_value(task.github_user()),\n    );\n    labels.insert(\n        \"context-version\".to_string(),\n        task.context_version().to_string(),\n    );\n\n    match task {\n        TaskType::Docs(_) => {\n            labels.insert(\"task-type\".to_string(), \"docs\".to_string());\n        }\n        TaskType::Code(_) => {\n            labels.insert(\"task-type\".to_string(), \"code\".to_string());\n            if let Some(task_id) = task.task_id() {\n                labels.insert(\"task-id\".to_string(), task_id.to_string());\n            }\n            labels.insert(\"service-name\".to_string(), task.service_name().to_string());\n        }\n    }\n\n    labels\n}\n\n/// Sanitize a string value for use as a Kubernetes label value\n/// Kubernetes labels must be an empty string or consist of alphanumeric characters, '-', '_' or '.',\n/// and must start and end with an alphanumeric character\nfn sanitize_label_value(input: &str) -> String {\n    if input.is_empty() {\n        return String::new();\n    }\n\n    // Replace spaces with hyphens, convert to lowercase\n    let mut sanitized = input.to_lowercase().replace([' ', '_'], \"-\"); // Normalize spaces and underscores to hyphens\n\n    // Remove any characters that aren't alphanumeric, hyphens, underscores, or dots\n    sanitized.retain(|c| c.is_alphanumeric() || c == '-' || c == '_' || c == '.');\n\n    // Ensure it starts with an alphanumeric character\n    while !sanitized.is_empty() && !sanitized.chars().next().unwrap().is_alphanumeric() {\n        sanitized.remove(0);\n    }\n\n    // Ensure it ends with an alphanumeric character\n    while !sanitized.is_empty() && !sanitized.chars().last().unwrap().is_alphanumeric() {\n        sanitized.pop();\n    }\n\n    // If we ended up with an empty string, provide a fallback\n    if sanitized.is_empty() {\n        \"unknown\".to_string()\n    } else {\n        sanitized\n    }\n}\n\n/// Ensure PVC exists for the given service\nasync fn ensure_pvc_exists(\n    pvcs: &Api<PersistentVolumeClaim>,\n    pvc_name: &str,\n    service_name: &str,\n    config: &ControllerConfig,\n) -> Result<()> {\n    match pvcs.get(pvc_name).await {\n        Ok(_) => {\n            info!(\"PVC already exists: {}\", pvc_name);\n            return Ok(());\n        }\n        Err(kube::Error::Api(ae)) if ae.code == 404 => {\n            // PVC doesn't exist, create it\n        }\n        Err(e) => return Err(e.into()),\n    }\n\n    let mut pvc_spec = json!({\n        \"apiVersion\": \"v1\",\n        \"kind\": \"PersistentVolumeClaim\",\n        \"metadata\": {\n            \"name\": pvc_name,\n            \"labels\": {\n                \"app\": \"orchestrator\",\n                \"service\": service_name\n            }\n        },\n        \"spec\": {\n            \"accessModes\": [\"ReadWriteOnce\"],\n            \"resources\": {\n                \"requests\": {\n                    \"storage\": config.storage.workspace_size\n                }\n            }\n        }\n    });\n\n    // Add storage class if specified\n    if let Some(storage_class) = &config.storage.storage_class_name {\n        pvc_spec[\"spec\"][\"storageClassName\"] = json!(storage_class);\n    }\n\n    let pvc: PersistentVolumeClaim = serde_json::from_value(pvc_spec)?;\n    pvcs.create(&PostParams::default(), &pvc).await?;\n    info!(\"Created PVC: {}\", pvc_name);\n\n    Ok(())\n}\n\n/// Clean up older job versions for retry attempts\nasync fn cleanup_old_jobs(task: &TaskType, jobs: &Api<Job>) -> Result<()> {\n    if let Some(task_id) = task.task_id() {\n        let current_version = task.context_version();\n\n        let job_list = jobs\n            .list(&ListParams::default().labels(&format!(\"task-id={task_id}\")))\n            .await?;\n\n        for job in job_list.items {\n            if let Some(version) = job\n                .metadata\n                .labels\n                .as_ref()\n                .and_then(|l| l.get(\"context-version\"))\n                .and_then(|v| v.parse::<u32>().ok())\n            {\n                if version < current_version {\n                    if let Some(job_name) = &job.metadata.name {\n                        jobs.delete(job_name, &DeleteParams::background()).await?;\n                        info!(\"Deleted older job version: {}\", job_name);\n                    }\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Clean up older configmap versions for retry attempts\nasync fn cleanup_old_configmaps(task: &TaskType, configmaps: &Api<ConfigMap>) -> Result<()> {\n    if let Some(task_id) = task.task_id() {\n        let current_version = task.context_version();\n\n        let cm_list = configmaps\n            .list(&ListParams::default().labels(&format!(\"task-id={task_id}\")))\n            .await?;\n\n        for cm in cm_list.items {\n            if let Some(version) = cm\n                .metadata\n                .labels\n                .as_ref()\n                .and_then(|l| l.get(\"context-version\"))\n                .and_then(|v| v.parse::<u32>().ok())\n            {\n                if version < current_version {\n                    if let Some(cm_name) = &cm.metadata.name {\n                        configmaps.delete(cm_name, &DeleteParams::default()).await?;\n                        info!(\"Deleted older configmap version: {}\", cm_name);\n                    }\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Update the owner reference of an existing `ConfigMap`\nasync fn update_configmap_owner(\n    _task: &TaskType,\n    configmaps: &Api<ConfigMap>,\n    cm_name: &str,\n    owner_ref: OwnerReference,\n) -> Result<()> {\n    let mut configmap = configmaps.get(cm_name).await?;\n    configmap.metadata.owner_references = Some(vec![owner_ref]);\n    configmaps\n        .replace(cm_name, &PostParams::default(), &configmap)\n        .await?;\n    info!(\"Updated ConfigMap owner reference for: {}\", cm_name);\n    Ok(())\n}\n\n/// Cleanup resources when task is deleted\npub async fn cleanup_resources(\n    task: TaskType,\n    jobs: &Api<Job>,\n    configmaps: &Api<ConfigMap>,\n) -> Result<Action> {\n    let task_label = if let Some(task_id) = task.task_id() {\n        format!(\"task-id={task_id}\")\n    } else {\n        format!(\n            \"task-type=docs,github-user={}\",\n            sanitize_label_value(task.github_user())\n        )\n    };\n\n    info!(\"Cleaning up resources for task: {}\", task.name());\n\n    // Delete all jobs for this task\n    let job_list = jobs\n        .list(&ListParams::default().labels(&task_label))\n        .await?;\n    for job in job_list.items {\n        if let Some(name) = &job.metadata.name {\n            jobs.delete(name, &DeleteParams::background()).await?;\n            info!(\"Deleted job: {}\", name);\n        }\n    }\n\n    // Delete all configmaps for this task\n    let cm_list = configmaps\n        .list(&ListParams::default().labels(&task_label))\n        .await?;\n    for cm in cm_list.items {\n        if let Some(name) = &cm.metadata.name {\n            configmaps.delete(name, &DeleteParams::default()).await?;\n            info!(\"Deleted configmap: {}\", name);\n        }\n    }\n\n    Ok(Action::await_change())\n}\n"
        },
        {
          "path": "src/controllers/task_controller/templates.rs",
          "file_type": "rust",
          "line_count": 541,
          "key_definitions": [
            "32:pub fn generate_templates("
          ],
          "content": "use super::config::ControllerConfig;\nuse super::types::{Result, TaskType};\nuse handlebars::Handlebars;\nuse serde_json::json;\nuse std::collections::BTreeMap;\nuse std::fs;\nuse std::path::Path;\nuse tracing::debug;\n\n// Template base path (mounted from ConfigMap)\nconst CLAUDE_TEMPLATES_PATH: &str = \"/claude-templates\";\n\n/// Load a template file from the mounted `ConfigMap`\nfn load_template(relative_path: &str) -> Result<String> {\n    // Convert path separators to underscores for ConfigMap key lookup\n    let configmap_key = relative_path.replace('/', \"_\");\n    let full_path = Path::new(CLAUDE_TEMPLATES_PATH).join(&configmap_key);\n    debug!(\n        \"Loading template from: {} (key: {})\",\n        full_path.display(),\n        configmap_key\n    );\n\n    fs::read_to_string(&full_path).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to load template {relative_path} (key: {configmap_key}): {e}\"\n        ))\n    })\n}\n\n/// Generate all template files for a task\npub fn generate_templates(\n    task: &TaskType,\n    config: &ControllerConfig,\n) -> Result<BTreeMap<String, String>> {\n    let mut templates = BTreeMap::new();\n\n    // Generate container startup script\n    templates.insert(\"container.sh\".to_string(), generate_container_script(task)?);\n\n    // Generate Claude memory\n    templates.insert(\"CLAUDE.md\".to_string(), generate_claude_memory(task)?);\n\n    // Generate Claude settings\n    templates.insert(\n        \"settings.json\".to_string(),\n        generate_claude_settings(task, config)?,\n    );\n\n    // Generate task-specific templates\n    if task.is_docs() {\n        // Generate docs prompt\n        templates.insert(\"prompt.md\".to_string(), generate_docs_prompt(task)?);\n    } else {\n        // Generate code-specific templates\n        templates.insert(\"mcp.json\".to_string(), generate_mcp_config(task, config)?);\n        templates.insert(\n            \"client-config.json\".to_string(),\n            generate_client_config(task, config)?,\n        );\n        templates.insert(\n            \"coding-guidelines.md\".to_string(),\n            generate_coding_guidelines(task)?,\n        );\n        templates.insert(\n            \"github-guidelines.md\".to_string(),\n            generate_github_guidelines(task)?,\n        );\n        templates.insert(\"mcp-tools.md\".to_string(), generate_mcp_tools_doc(task)?);\n    }\n\n    // Generate hook scripts\n    let hook_scripts = generate_hook_scripts(task)?;\n    for (filename, content) in hook_scripts {\n        // Use hooks- prefix to comply with ConfigMap key constraints\n        templates.insert(format!(\"hooks-{filename}\"), content);\n    }\n\n    Ok(templates)\n}\n\n/// Generate CLAUDE.md content from memory template\nfn generate_claude_memory(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template_path = if task.is_docs() {\n        \"docs/claude.md.hbs\"\n    } else {\n        \"code/claude.md.hbs\"\n    };\n\n    let template = load_template(template_path)?;\n\n    handlebars\n        .register_template_string(\"claude_memory\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register CLAUDE.md template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"repository\": json!({\n            \"url\": task.repository_url(),\n            \"githubUser\": task.github_user()\n        }),\n        \"working_directory\": task.working_directory(),\n        \"task_id\": task.task_id(),\n        \"docs_repository_url\": task.docs_repository_url()\n    });\n\n    handlebars.render(\"claude_memory\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render CLAUDE.md template: {e}\"\n        ))\n    })\n}\n\n/// Generate Claude Code settings.json for tool permissions\nfn generate_claude_settings(task: &TaskType, config: &ControllerConfig) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template_path = if task.is_docs() {\n        \"docs/settings.json.hbs\"\n    } else {\n        \"code/settings.json.hbs\"\n    };\n\n    let template = load_template(template_path)?;\n\n    handlebars\n        .register_template_string(\"settings\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register settings template: {e}\"\n            ))\n        })?;\n\n    let data = build_settings_template_data(task, config);\n\n    handlebars.render(\"settings\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render settings template: {e}\"\n        ))\n    })\n}\n\n/// Generate container startup script from template\nfn generate_container_script(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template_path = if task.is_docs() {\n        \"docs/container.sh.hbs\"\n    } else {\n        \"code/container.sh.hbs\"\n    };\n\n    let template = load_template(template_path)?;\n\n    handlebars\n        .register_template_string(\"container_script\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register container script template: {e}\"\n            ))\n        })?;\n\n    // Prompt content is now embedded inline in container script - no template needed\n\n    let data = json!({\n        \"repository_url\": task.repository_url(),\n        \"github_user\": task.github_user(),\n        \"working_directory\": task.working_directory(),\n        \"model\": task.model(),\n        \"service_name\": task.service_name(),\n        \"task_id\": task.task_id(),\n        \"source_branch\": task.source_branch(),\n        \"docs_repository_url\": task.docs_repository_url(),\n        \"docs_branch\": task.docs_branch(),\n        \"docs_project_directory\": task.docs_project_directory(),\n        \"overwrite_memory\": task.overwrite_memory(),\n        \"continue_session\": task.continue_session(),\n        \"user_requested\": match task {\n            crate::controllers::task_controller::types::TaskType::Code(cr) => cr.spec.continue_session,\n            _ => false\n        }\n    });\n\n    handlebars.render(\"container_script\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render container script template: {e}\"\n        ))\n    })\n}\n\n/// Generate MCP configuration for implementation tasks\nfn generate_mcp_config(task: &TaskType, config: &ControllerConfig) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/mcp.json.hbs\")?;\n\n    handlebars\n        .register_template_string(\"mcp\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register MCP template: {e}\"\n            ))\n        })?;\n\n    let data = build_settings_template_data(task, config);\n\n    handlebars.render(\"mcp\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render MCP template: {e}\"\n        ))\n    })\n}\n\n/// Generate MCP tools documentation based on task configuration\nfn generate_mcp_tools_doc(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/mcp-tools.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"mcp_tools\", template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register MCP tools template: {e}\"\n            ))\n        })?;\n\n    // Parse comma-separated tool strings into arrays\n    let local_tools: Vec<String> = task\n        .local_tools()\n        .unwrap_or_default()\n        .split(',')\n        .filter(|s| !s.trim().is_empty())\n        .map(|s| s.trim().to_string())\n        .collect();\n\n    let remote_tools: Vec<String> = task\n        .remote_tools()\n        .unwrap_or_default()\n        .split(',')\n        .filter(|s| !s.trim().is_empty())\n        .map(|s| s.trim().to_string())\n        .collect();\n\n    let data = json!({\n        \"localTools\": local_tools,\n        \"remoteTools\": remote_tools,\n        \"service\": task.service_name(),\n        \"task_id\": task.task_id()\n    });\n\n    handlebars.render(\"mcp_tools\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render MCP tools template: {e}\"\n        ))\n    })\n}\n\n/// Generate client configuration for dynamic tool selection\nfn generate_client_config(task: &TaskType, config: &ControllerConfig) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/client-config.json.hbs\")?;\n\n    handlebars\n        .register_template_string(\"client_config\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register client config template: {e}\"\n            ))\n        })?;\n\n    let data = build_settings_template_data(task, config);\n\n    handlebars.render(\"client_config\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render client config template: {e}\"\n        ))\n    })\n}\n\n/// Generate coding guidelines for implementation tasks\nfn generate_coding_guidelines(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/coding-guidelines.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"coding_guidelines\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register coding guidelines template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name()\n    });\n\n    handlebars.render(\"coding_guidelines\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render coding guidelines template: {e}\"\n        ))\n    })\n}\n\n/// Generate GitHub guidelines for implementation tasks\nfn generate_github_guidelines(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"code/github-guidelines.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"github_guidelines\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register GitHub guidelines template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"github_user\": task.github_user()\n    });\n\n    handlebars.render(\"github_guidelines\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render GitHub guidelines template: {e}\"\n        ))\n    })\n}\n\n/// Generate docs prompt for documentation generation tasks\nfn generate_docs_prompt(task: &TaskType) -> Result<String> {\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    let template = load_template(\"docs/prompt.md.hbs\")?;\n\n    handlebars\n        .register_template_string(\"docs_prompt\", &template)\n        .map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to register docs prompt template: {e}\"\n            ))\n        })?;\n\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"github_user\": task.github_user(),\n        \"working_directory\": task.working_directory(),\n        \"repository_url\": task.repository_url()\n    });\n\n    handlebars.render(\"docs_prompt\", &data).map_err(|e| {\n        crate::controllers::task_controller::types::Error::ConfigError(format!(\n            \"Failed to render docs prompt template: {e}\"\n        ))\n    })\n}\n\n/// Build template data for settings/MCP/client config templates\nfn build_settings_template_data(task: &TaskType, config: &ControllerConfig) -> serde_json::Value {\n    let mut data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"model\": task.model(),\n        \"github_user\": task.github_user(),\n        \"repository\": {\n            \"url\": task.repository_url(),\n            \"githubUser\": task.github_user()\n        },\n        \"working_directory\": task.working_directory(),\n        \"agent_tools_override\": config.permissions.agent_tools_override,\n        \"permissions\": {\n            \"allow\": config.permissions.allow,\n            \"deny\": config.permissions.deny\n        },\n        \"telemetry\": {\n            \"enabled\": config.telemetry.enabled,\n            \"otlpEndpoint\": config.telemetry.otlp_endpoint,\n            \"otlpProtocol\": config.telemetry.otlp_protocol,\n            \"logs_endpoint\": config.telemetry.logs_endpoint,\n            \"logs_protocol\": config.telemetry.logs_protocol\n        }\n    });\n\n    // Add retry information for code tasks\n    if !task.is_docs() {\n        let retry_data = json!({\n            \"context_version\": task.context_version(),\n            \"prompt_modification\": task.prompt_modification(),\n            \"session_id\": task.session_id()\n        });\n        data[\"retry\"] = retry_data;\n\n        // Add tool configuration\n        let (local_tools, remote_tools) = parse_tool_configuration(task);\n        data[\"tools\"] = json!({\n            \"local\": local_tools,\n            \"remote\": remote_tools\n        });\n\n        // Add docs repository info\n        if let Some(docs_url) = task.docs_repository_url() {\n            data[\"docs_repository_url\"] = json!(docs_url);\n        }\n    }\n\n    data\n}\n\n/// Parse tool configuration into local and remote tool lists\nfn parse_tool_configuration(task: &TaskType) -> (Vec<String>, Vec<String>) {\n    let local_tools = task\n        .local_tools()\n        .map(|tools| tools.split(',').map(|s| s.trim().to_string()).collect())\n        .unwrap_or_default();\n\n    let remote_tools = task\n        .remote_tools()\n        .map(|tools| tools.split(',').map(|s| s.trim().to_string()).collect())\n        .unwrap_or_default();\n\n    (local_tools, remote_tools)\n}\n\n/// Generate hook scripts from the hooks directory\nfn generate_hook_scripts(task: &TaskType) -> Result<BTreeMap<String, String>> {\n    let mut hook_scripts = BTreeMap::new();\n    let mut handlebars = Handlebars::new();\n    handlebars.set_strict_mode(false);\n\n    // Get hook templates based on task type\n    let hook_templates = get_hook_templates(task)?;\n\n    // Prepare template data\n    let data = json!({\n        \"task_id\": task.task_id(),\n        \"service_name\": task.service_name(),\n        \"repository\": json!({\n            \"url\": task.repository_url(),\n            \"githubUser\": task.github_user()\n        }),\n        \"working_directory\": task.working_directory(),\n        \"attempts\": task.retry_count() + 1, // retry_count + 1 = attempt number\n        \"is_docs_generation\": task.is_docs(),\n        \"docs_repository_url\": task.docs_repository_url()\n    });\n\n    // Process each hook template\n    for (hook_name, template_content) in hook_templates {\n        handlebars\n            .register_template_string(&hook_name, &template_content)\n            .map_err(|e| {\n                crate::controllers::task_controller::types::Error::ConfigError(format!(\n                    \"Failed to register hook template {hook_name}: {e}\"\n                ))\n            })?;\n\n        let rendered = handlebars.render(&hook_name, &data).map_err(|e| {\n            crate::controllers::task_controller::types::Error::ConfigError(format!(\n                \"Failed to render hook template {hook_name}: {e}\"\n            ))\n        })?;\n\n        // Remove .hbs extension for the final filename\n        let filename = hook_name.strip_suffix(\".hbs\").unwrap_or(&hook_name);\n        hook_scripts.insert(filename.to_string(), rendered);\n    }\n\n    Ok(hook_scripts)\n}\n\n/// Get all hook templates for a specific task type by scanning the filesystem\nfn get_hook_templates(task: &TaskType) -> Result<Vec<(String, String)>> {\n    let hooks_prefix = match task {\n        TaskType::Docs(_) => \"docs_hooks_\",\n        TaskType::Code(_) => \"code_hooks_\",\n    };\n\n    debug!(\"Scanning for hook templates with prefix: {}\", hooks_prefix);\n\n    let mut templates = Vec::new();\n\n    // Read the ConfigMap directory and find files with the hook prefix\n    match std::fs::read_dir(CLAUDE_TEMPLATES_PATH) {\n        Ok(entries) => {\n            for entry in entries.flatten() {\n                let path = entry.path();\n                if path.is_file() {\n                    if let Some(filename) = path.file_name().and_then(|n| n.to_str()) {\n                        // Check if this is a hook template for our task type\n                        if filename.starts_with(hooks_prefix) && filename.ends_with(\".hbs\") {\n                            // Extract just the hook filename (remove prefix and convert back)\n                            let hook_name = filename.strip_prefix(hooks_prefix).unwrap_or(filename);\n\n                            match fs::read_to_string(&path) {\n                                Ok(content) => {\n                                    debug!(\n                                        \"Loaded hook template: {} (from {})\",\n                                        hook_name, filename\n                                    );\n                                    templates.push((hook_name.to_string(), content));\n                                }\n                                Err(e) => {\n                                    debug!(\"Failed to load hook template {}: {}\", filename, e);\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        Err(e) => {\n            debug!(\n                \"Templates directory {} not found or not accessible: {}\",\n                CLAUDE_TEMPLATES_PATH, e\n            );\n            // Don't fail - hooks are optional\n        }\n    }\n\n    Ok(templates)\n}\n"
        },
        {
          "path": "src/handlers/code_handler.rs",
          "file_type": "rust",
          "line_count": 126,
          "key_definitions": [],
          "content": "//! Code task submission handler\n\nuse axum::{extract::State, http::StatusCode, Json};\nuse chrono::Utc;\nuse kube::Api;\nuse std::collections::HashMap;\nuse tracing::{error, info};\n\nuse crate::crds::{CodeRun, CodeRunSpec, CodeRunStatus};\nuse crate::handlers::common::{ApiResponse, AppState};\nuse common::models::CodeRequest;\n\npub async fn submit_code_task(\n    State(state): State<AppState>,\n    Json(request): Json<CodeRequest>,\n) -> Result<Json<ApiResponse>, StatusCode> {\n    info!(\n        \"Received code task request: task_id={}, service={}\",\n        request.task_id, request.service\n    );\n\n    let spec = CodeRunSpec {\n        task_id: request.task_id,\n        service: request.service.clone(),\n        repository_url: request.repository_url,\n        docs_repository_url: request.docs_repository_url,\n        docs_project_directory: request.docs_project_directory,\n        working_directory: request.working_directory,\n        model: request.model.unwrap_or_else(|| {\n            std::env::var(\"DEFAULT_CODE_MODEL\")\n                .unwrap_or_else(|_| \"claude-sonnet-4-20250514\".to_string())\n        }),\n        github_user: request.github_user,\n        local_tools: request.local_tools,\n        remote_tools: request.remote_tools,\n        context_version: request.context_version,\n        prompt_modification: request.prompt_modification,\n        docs_branch: request.docs_branch,\n        continue_session: request.continue_session,\n        overwrite_memory: request.overwrite_memory,\n        env: request.env,\n        env_from_secrets: request\n            .env_from_secrets\n            .into_iter()\n            .map(|s| crate::crds::coderun::SecretEnvVar {\n                name: s.name,\n                secret_name: s.secret_name,\n                secret_key: s.secret_key,\n            })\n            .collect(),\n    };\n\n    let coderun = CodeRun {\n        metadata: kube::api::ObjectMeta {\n            name: Some(format!(\n                \"code-{}-{}\",\n                request.task_id,\n                Utc::now().timestamp()\n            )),\n            namespace: Some(state.namespace.clone()),\n            ..Default::default()\n        },\n        spec,\n        status: Some(CodeRunStatus {\n            phase: \"Pending\".to_string(),\n            message: Some(\"CodeRun created successfully\".to_string()),\n            last_update: Some(Utc::now().to_rfc3339()),\n            job_name: None,\n            pull_request_url: None,\n            retry_count: Some(0),\n            conditions: None,\n            configmap_name: None,\n            context_version: Some(1),\n            prompt_modification: None,\n            prompt_mode: Some(\"direct\".to_string()),\n            session_id: None,\n        }),\n    };\n\n    let api: Api<CodeRun> = Api::namespaced(state.k8s_client.clone(), &state.namespace);\n\n    // Check if a CodeRun already exists for this task\n    let existing_name = format!(\"code-{}\", request.task_id);\n    if let Ok(_existing) = api.get(&existing_name).await {\n        error!(\"CodeRun already exists for task {}\", request.task_id);\n        return Ok(Json(ApiResponse {\n            success: false,\n            message: format!(\"CodeRun already exists for task {}\", request.task_id),\n            data: None,\n        }));\n    }\n\n    match api.create(&Default::default(), &coderun).await {\n        Ok(created) => {\n            info!(\"CodeRun created successfully: {:?}\", created.metadata.name);\n\n            let mut response_data = HashMap::new();\n            if let Some(name) = &created.metadata.name {\n                response_data.insert(\n                    \"coderun_name\".to_string(),\n                    serde_json::Value::String(name.clone()),\n                );\n            }\n            response_data.insert(\n                \"namespace\".to_string(),\n                serde_json::Value::String(state.namespace.clone()),\n            );\n\n            Ok(Json(ApiResponse {\n                success: true,\n                message: \"Code task submitted successfully\".to_string(),\n                data: Some(serde_json::Value::Object(\n                    response_data.into_iter().collect(),\n                )),\n            }))\n        }\n        Err(e) => {\n            error!(\"Failed to create CodeRun: {}\", e);\n            Ok(Json(ApiResponse {\n                success: false,\n                message: format!(\"Failed to create CodeRun: {e}\"),\n                data: None,\n            }))\n        }\n    }\n}\n"
        },
        {
          "path": "src/handlers/mod.rs",
          "file_type": "rust",
          "line_count": 9,
          "key_definitions": [],
          "content": "//! Request handlers for the orchestrator service\n\npub mod code_handler;\npub mod common;\npub mod docs_handler;\n\npub use code_handler::submit_code_task;\npub use common::{ApiResponse, AppError, AppState};\npub use docs_handler::generate_docs;\n"
        },
        {
          "path": "src/handlers/docs_handler.rs",
          "file_type": "rust",
          "line_count": 102,
          "key_definitions": [],
          "content": "//! Documentation generation handler\n\nuse axum::extract::State;\nuse axum::http::StatusCode;\nuse axum::Json;\nuse k8s_openapi::apimachinery::pkg::apis::meta::v1::ObjectMeta;\nuse kube::api::{Api, PostParams};\nuse serde_json::json;\nuse std::collections::BTreeMap;\nuse tracing::{error, info};\n\nuse crate::crds::{DocsRun, DocsRunSpec, DocsRunStatus};\nuse crate::handlers::common::{ApiResponse, AppError, AppState};\nuse common::models::DocsRequest;\n\n/// Generate documentation for Task Master tasks\npub async fn generate_docs(\n    State(state): State<AppState>,\n    Json(request): Json<DocsRequest>,\n) -> Result<(StatusCode, Json<ApiResponse>), (StatusCode, Json<ApiResponse>)> {\n    info!(\n        \"Generate documentation request received for repository: {}\",\n        request.repository_url\n    );\n\n    // Generate a unique DocsRun name using timestamp\n    let timestamp = std::time::SystemTime::now()\n        .duration_since(std::time::UNIX_EPOCH)\n        .unwrap()\n        .as_secs();\n    let docsrun_name = format!(\"docs-gen-{timestamp}\");\n\n    // Create DocsRun spec for documentation generation\n    let spec = DocsRunSpec {\n        repository_url: request.repository_url.clone(),\n        working_directory: request.working_directory.clone(),\n        source_branch: request.source_branch.clone(),\n        model: request.model.unwrap_or_else(|| {\n            std::env::var(\"DEFAULT_DOCS_MODEL\")\n                .unwrap_or_else(|_| \"claude-opus-4-20250514\".to_string())\n        }),\n        github_user: request.github_user.clone(),\n    };\n\n    // Create DocsRun\n    let docsrun = DocsRun {\n        metadata: ObjectMeta {\n            name: Some(docsrun_name.clone()),\n            namespace: Some(state.namespace.clone()),\n            labels: Some({\n                let mut labels = BTreeMap::new();\n                labels.insert(\"app\".to_string(), \"orchestrator\".to_string());\n                labels.insert(\"type\".to_string(), \"docs\".to_string());\n                labels\n            }),\n            ..Default::default()\n        },\n        spec,\n        status: Some(DocsRunStatus {\n            phase: \"Pending\".to_string(),\n            message: Some(\"DocsRun created successfully\".to_string()),\n            last_update: Some(chrono::Utc::now().to_rfc3339()),\n            job_name: None,\n            pull_request_url: None,\n            conditions: None,\n            configmap_name: None,\n        }),\n    };\n\n    // Create DocsRun in Kubernetes\n    let api: Api<DocsRun> = Api::namespaced(state.k8s_client.clone(), &state.namespace);\n\n    match api.create(&PostParams::default(), &docsrun).await {\n        Ok(created) => {\n            info!(\"Created documentation generation DocsRun: {}\", docsrun_name);\n            Ok((\n                StatusCode::CREATED,\n                Json(ApiResponse {\n                    success: true,\n                    message: \"Documentation generation job submitted successfully\".to_string(),\n                    data: Some(json!({\n                        \"docsrun_name\": docsrun_name,\n                        \"namespace\": state.namespace,\n                        \"repository_url\": created.spec.repository_url,\n                        \"model\": created.spec.model,\n                    })),\n                }),\n            ))\n        }\n        Err(e) => {\n            error!(\"Failed to create documentation generation DocsRun: {}\", e);\n            let status_code = StatusCode::from(AppError::from(e));\n            Err((\n                status_code,\n                Json(ApiResponse::error(&format!(\n                    \"Failed to submit documentation generation job: {}\",\n                    status_code.canonical_reason().unwrap_or(\"Unknown error\")\n                ))),\n            ))\n        }\n    }\n}\n"
        },
        {
          "path": "src/handlers/common.rs",
          "file_type": "rust",
          "line_count": 77,
          "key_definitions": [
            "9:pub struct AppState {",
            "16:pub enum AppError {",
            "22:impl std::fmt::Display for AppError {",
            "32:impl std::error::Error for AppError {}",
            "34:impl From<kube::Error> for AppError {",
            "40:impl From<AppError> for StatusCode {",
            "52:pub struct ApiResponse {",
            "59:impl ApiResponse {",
            "61:pub fn success(message: &str) -> Self {",
            "70:pub fn error(message: &str) -> Self {"
          ],
          "content": "//! Shared types and utilities for API handlers\n\nuse axum::http::StatusCode;\nuse kube::Client;\nuse serde_json::Value;\n\n/// Application state shared across handlers\n#[derive(Clone)]\npub struct AppState {\n    pub k8s_client: Client,\n    pub namespace: String,\n}\n\n/// Error type for API handlers\n#[derive(Debug)]\npub enum AppError {\n    BadRequest(String),\n    Conflict(String),\n    Internal(String),\n}\n\nimpl std::fmt::Display for AppError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            AppError::BadRequest(msg) => write!(f, \"Bad Request: {msg}\"),\n            AppError::Conflict(msg) => write!(f, \"Conflict: {msg}\"),\n            AppError::Internal(msg) => write!(f, \"Internal Error: {msg}\"),\n        }\n    }\n}\n\nimpl std::error::Error for AppError {}\n\nimpl From<kube::Error> for AppError {\n    fn from(e: kube::Error) -> Self {\n        AppError::Internal(e.to_string())\n    }\n}\n\nimpl From<AppError> for StatusCode {\n    fn from(err: AppError) -> Self {\n        match err {\n            AppError::BadRequest(_) => StatusCode::BAD_REQUEST,\n            AppError::Conflict(_) => StatusCode::CONFLICT,\n            AppError::Internal(_) => StatusCode::INTERNAL_SERVER_ERROR,\n        }\n    }\n}\n\n/// API response structure\n#[derive(serde::Serialize)]\npub struct ApiResponse {\n    pub success: bool,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option<Value>,\n}\n\nimpl ApiResponse {\n    #[must_use]\n    pub fn success(message: &str) -> Self {\n        Self {\n            success: true,\n            message: message.to_string(),\n            data: None,\n        }\n    }\n\n    #[must_use]\n    pub fn error(message: &str) -> Self {\n        Self {\n            success: false,\n            message: message.to_string(),\n            data: None,\n        }\n    }\n}\n"
        }
      ],
      "dependencies": [
        "axum",
        "tokio",
        "tower",
        "tower-http",
        "kube",
        "kube-derive",
        "k8s-openapi",
        "schemars",
        "serde",
        "serde_json",
        "serde_yaml",
        "anyhow",
        "thiserror",
        "tracing",
        "tracing-subscriber",
        "opentelemetry",
        "opentelemetry-otlp",
        "opentelemetry_sdk",
        "tracing-opentelemetry",
        "reqwest",
        "futures",
        "async-trait",
        "chrono",
        "regex",
        "handlebars",
        "tempfile",
        "common"
      ],
      "description": "5D Labs platform orchestrator core API server (for Kubernetes deployment)",
      "line_count": 3295
    },
    {
      "name": "common",
      "path": "orchestrator/common",
      "component_type": "RustLibrary",
      "source_files": [
        {
          "path": "src/error.rs",
          "file_type": "rust",
          "line_count": 37,
          "key_definitions": [
            "6:pub enum Error {",
            "33:impl From<anyhow::Error> for Error {"
          ],
          "content": "//! Common error types for the orchestrator\n\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum Error {\n    #[error(\"Kubernetes operation failed: {0}\")]\n    Kubernetes(String),\n\n    #[error(\"Invalid request: {0}\")]\n    InvalidRequest(String),\n\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n\n    #[error(\"HTTP request failed: {0}\")]\n    Http(String),\n\n    #[error(\"Configuration error: {0}\")]\n    Config(String),\n\n    #[error(\"Task not found: {0}\")]\n    TaskNotFound(String),\n\n    #[error(\"Job failed: {0}\")]\n    JobFailed(String),\n\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\n// Implement conversion from anyhow::Error for easier error handling\nimpl From<anyhow::Error> for Error {\n    fn from(err: anyhow::Error) -> Self {\n        Error::Internal(err.to_string())\n    }\n}\n"
        },
        {
          "path": "src/lib.rs",
          "file_type": "rust",
          "line_count": 28,
          "key_definitions": [],
          "content": "/*\n * 5D Labs Agent Platform - Common Types and Utilities\n * Copyright (C) 2025 5D Labs\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU Affero General Public License as published\n * by the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU Affero General Public License for more details.\n *\n * You should have received a copy of the GNU Affero General Public License\n * along with this program. If not, see <https://www.gnu.org/licenses/>.\n */\n\n//! Shared types and utilities for the Orchestrator project\n\npub mod error;\npub mod models;\n\npub use error::Error;\npub type Result<T> = std::result::Result<T, Error>;\n\n// Re-export commonly used types for convenience\npub use models::{AgentType, Job, JobStatus, JobType, Request, RequestSource, Task, TaskStatus};\n"
        },
        {
          "path": "src/models/response.rs",
          "file_type": "rust",
          "line_count": 239,
          "key_definitions": [
            "10:pub struct ApiResponse<T> {",
            "20:pub enum ResponseStatus {",
            "28:pub struct ErrorDetails {",
            "36:pub struct ResponseMetadata {",
            "45:pub struct TaskResponse {",
            "59:pub struct JobResponse {",
            "74:pub struct JobListResponse {",
            "83:pub struct TaskListResponse {",
            "92:pub struct HealthResponse {",
            "102:pub enum HealthStatus {",
            "110:pub struct ComponentHealth {",
            "118:pub struct WebhookResponse {",
            "127:pub fn success(data: T, request_id: String) -> Self {",
            "143:pub fn error(error: ErrorDetails, request_id: String) -> Self {",
            "158:pub fn with_duration(mut self, duration_ms: u64) -> Self {",
            "164:impl From<super::task::Task> for TaskResponse {",
            "180:impl From<super::job::Job> for JobResponse {"
          ],
          "content": "//! Response models for API endpoints\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Generic API response wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApiResponse<T> {\n    pub status: ResponseStatus,\n    pub data: Option<T>,\n    pub error: Option<ErrorDetails>,\n    pub metadata: ResponseMetadata,\n}\n\n/// Response status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ResponseStatus {\n    Success,\n    Error,\n    Partial,\n}\n\n/// Error details in response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ErrorDetails {\n    pub code: String,\n    pub message: String,\n    pub details: Option<Value>,\n}\n\n/// Response metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResponseMetadata {\n    pub request_id: String,\n    pub timestamp: DateTime<Utc>,\n    pub duration_ms: Option<u64>,\n    pub version: String,\n}\n\n/// Task response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskResponse {\n    pub id: String,\n    pub title: String,\n    pub description: String,\n    pub status: super::task::TaskStatus,\n    pub priority: super::task::TaskPriority,\n    pub microservice: String,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n    pub job_ids: Vec<String>,\n}\n\n/// Job response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JobResponse {\n    pub id: String,\n    pub task_id: String,\n    pub job_type: super::job::JobType,\n    pub status: super::job::JobStatus,\n    pub k8s_job_name: String,\n    pub namespace: String,\n    pub created_at: DateTime<Utc>,\n    pub started_at: Option<DateTime<Utc>>,\n    pub completed_at: Option<DateTime<Utc>>,\n    pub logs_url: Option<String>,\n}\n\n/// Job list response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JobListResponse {\n    pub jobs: Vec<JobResponse>,\n    pub total: usize,\n    pub page: usize,\n    pub page_size: usize,\n}\n\n/// Task list response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskListResponse {\n    pub tasks: Vec<TaskResponse>,\n    pub total: usize,\n    pub page: usize,\n    pub page_size: usize,\n}\n\n/// Health check response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HealthResponse {\n    pub status: HealthStatus,\n    pub version: String,\n    pub uptime_seconds: u64,\n    pub components: HashMap<String, ComponentHealth>,\n}\n\n/// Health status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum HealthStatus {\n    Healthy,\n    Degraded,\n    Unhealthy,\n}\n\n/// Component health status\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ComponentHealth {\n    pub status: HealthStatus,\n    pub message: Option<String>,\n    pub last_check: DateTime<Utc>,\n}\n\n/// Webhook processing response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WebhookResponse {\n    pub accepted: bool,\n    pub task_id: Option<String>,\n    pub job_ids: Vec<String>,\n    pub message: String,\n}\n\nimpl<T> ApiResponse<T> {\n    /// Create a success response\n    pub fn success(data: T, request_id: String) -> Self {\n        Self {\n            status: ResponseStatus::Success,\n            data: Some(data),\n            error: None,\n            metadata: ResponseMetadata {\n                request_id,\n                timestamp: Utc::now(),\n                duration_ms: None,\n                version: env!(\"CARGO_PKG_VERSION\").to_string(),\n            },\n        }\n    }\n\n    /// Create an error response\n    #[must_use]\n    pub fn error(error: ErrorDetails, request_id: String) -> Self {\n        Self {\n            status: ResponseStatus::Error,\n            data: None,\n            error: Some(error),\n            metadata: ResponseMetadata {\n                request_id,\n                timestamp: Utc::now(),\n                duration_ms: None,\n                version: env!(\"CARGO_PKG_VERSION\").to_string(),\n            },\n        }\n    }\n\n    /// Set the duration in milliseconds\n    pub fn with_duration(mut self, duration_ms: u64) -> Self {\n        self.metadata.duration_ms = Some(duration_ms);\n        self\n    }\n}\n\nimpl From<super::task::Task> for TaskResponse {\n    fn from(task: super::Task) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            status: task.status,\n            priority: task.priority,\n            microservice: task.microservice,\n            created_at: task.created_at,\n            updated_at: task.updated_at,\n            job_ids: Vec::new(), // To be populated by service layer\n        }\n    }\n}\n\nimpl From<super::job::Job> for JobResponse {\n    fn from(job: super::Job) -> Self {\n        Self {\n            id: job.id,\n            task_id: job.task_id,\n            job_type: job.job_type,\n            status: job.status,\n            k8s_job_name: job.k8s_job_name,\n            namespace: job.namespace,\n            created_at: job.created_at,\n            started_at: job.started_at,\n            completed_at: job.completed_at,\n            logs_url: None, // To be populated by service layer\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::models::task::{TaskPriority, TaskStatus};\n\n    #[test]\n    fn test_api_response_success() {\n        let response = ApiResponse::success(\n            TaskResponse {\n                id: \"task-123\".to_string(),\n                title: \"Test Task\".to_string(),\n                description: \"A test task\".to_string(),\n                status: TaskStatus::Pending,\n                priority: TaskPriority::Medium,\n                microservice: \"auth\".to_string(),\n                created_at: Utc::now(),\n                updated_at: Utc::now(),\n                job_ids: vec![],\n            },\n            \"req-123\".to_string(),\n        );\n\n        assert_eq!(response.status, ResponseStatus::Success);\n        assert!(response.data.is_some());\n        assert!(response.error.is_none());\n    }\n\n    #[test]\n    fn test_api_response_error() {\n        let response: ApiResponse<TaskResponse> = ApiResponse::error(\n            ErrorDetails {\n                code: \"TASK_NOT_FOUND\".to_string(),\n                message: \"Task not found\".to_string(),\n                details: None,\n            },\n            \"req-123\".to_string(),\n        );\n\n        assert_eq!(response.status, ResponseStatus::Error);\n        assert!(response.data.is_none());\n        assert!(response.error.is_some());\n    }\n}\n"
        },
        {
          "path": "src/models/request.rs",
          "file_type": "rust",
          "line_count": 201,
          "key_definitions": [
            "9:pub struct Request {",
            "20:pub enum RequestSource {",
            "31:pub enum RequestAction {",
            "44:pub struct RequestMetadata {",
            "56:pub struct ParsedRequest {",
            "69:pub struct CliRequest {",
            "77:pub struct CreateTaskRequest {",
            "89:pub struct UpdateTaskRequest {",
            "99:pub struct AssistanceRequest {",
            "110:pub enum AssistanceType {",
            "121:pub enum AssistancePriority {",
            "128:impl Request {",
            "131:pub fn new(source: RequestSource, action: RequestAction, payload: Value) -> Self {",
            "149:pub fn with_trace_id(mut self, trace_id: String) -> Self {",
            "156:pub fn with_user(mut self, user: String) -> Self {"
          ],
          "content": "//! Request models for unified orchestration\n\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Unified request interface\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Request {\n    pub id: String,\n    pub source: RequestSource,\n    pub action: RequestAction,\n    pub payload: Value,\n    pub metadata: RequestMetadata,\n}\n\n/// Source of incoming requests\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequestSource {\n    Cli,\n    PmAgent,\n    GitHub,\n    Grafana,\n    Discord,\n}\n\n/// Action to be performed\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequestAction {\n    CreateTask,\n    UpdateTask,\n    GetTaskStatus,\n    TriggerAssistance,\n    ListJobs,\n    GetJobLogs,\n    ReviewPR,\n    HandleAlert,\n}\n\n/// Additional request metadata\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\npub struct RequestMetadata {\n    pub user: Option<String>,\n    pub organization: Option<String>,\n    pub project: Option<String>,\n    pub channel: Option<String>,\n    pub timestamp: String,\n    pub trace_id: Option<String>,\n    pub labels: HashMap<String, String>,\n}\n\n/// Parsed request after normalization\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ParsedRequest {\n    pub action: RequestAction,\n    pub task_id: Option<String>,\n    pub microservice: Option<String>,\n    pub title: Option<String>,\n    pub description: Option<String>,\n    pub acceptance_criteria: Vec<String>,\n    pub priority: Option<String>,\n    pub metadata: Value,\n}\n\n/// CLI request format\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CliRequest {\n    pub command: String,\n    pub args: Vec<String>,\n    pub options: HashMap<String, String>,\n}\n\n/// Task submission request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CreateTaskRequest {\n    pub microservice: String,\n    pub title: String,\n    pub description: String,\n    pub acceptance_criteria: Vec<String>,\n    pub priority: Option<String>,\n    pub agent_type: Option<super::AgentType>,\n    pub metadata: Option<HashMap<String, Value>>,\n}\n\n/// Task update request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct UpdateTaskRequest {\n    pub status: Option<super::TaskStatus>,\n    pub priority: Option<super::task::TaskPriority>,\n    pub description: Option<String>,\n    pub acceptance_criteria: Option<Vec<String>>,\n    pub metadata: Option<HashMap<String, Value>>,\n}\n\n/// Assistance request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AssistanceRequest {\n    pub task_id: String,\n    pub reason: String,\n    pub assist_type: AssistanceType,\n    pub context: Option<Value>,\n    pub priority: AssistancePriority,\n}\n\n/// Type of assistance needed\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum AssistanceType {\n    ImplementationGuidance,\n    ArchitectureReview,\n    ErrorDiagnosis,\n    TestDebugging,\n    PerformanceOptimization,\n}\n\n/// Priority of assistance request\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum AssistancePriority {\n    Low,\n    Medium,\n    High,\n    Critical,\n}\n\nimpl Request {\n    /// Create a new request\n    #[must_use]\n    pub fn new(source: RequestSource, action: RequestAction, payload: Value) -> Self {\n        use chrono::Utc;\n        use uuid::Uuid;\n\n        Self {\n            id: Uuid::new_v4().to_string(),\n            source,\n            action,\n            payload,\n            metadata: RequestMetadata {\n                timestamp: Utc::now().to_rfc3339(),\n                ..Default::default()\n            },\n        }\n    }\n\n    /// Add trace ID for distributed tracing\n    #[must_use]\n    pub fn with_trace_id(mut self, trace_id: String) -> Self {\n        self.metadata.trace_id = Some(trace_id);\n        self\n    }\n\n    /// Add user information\n    #[must_use]\n    pub fn with_user(mut self, user: String) -> Self {\n        self.metadata.user = Some(user);\n        self\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_json::json;\n\n    #[test]\n    fn test_request_creation() {\n        let request = Request::new(\n            RequestSource::Cli,\n            RequestAction::CreateTask,\n            json!({\n                \"title\": \"Test Task\",\n                \"description\": \"A test task\"\n            }),\n        );\n\n        assert_eq!(request.source, RequestSource::Cli);\n        assert_eq!(request.action, RequestAction::CreateTask);\n        assert!(!request.id.is_empty());\n        assert!(!request.metadata.timestamp.is_empty());\n    }\n\n    #[test]\n    fn test_create_task_request_serialization() {\n        let req = CreateTaskRequest {\n            microservice: \"auth\".to_string(),\n            title: \"Implement JWT validation\".to_string(),\n            description: \"Add JWT token validation\".to_string(),\n            acceptance_criteria: vec![\"Validate tokens\".to_string()],\n            priority: Some(\"high\".to_string()),\n            agent_type: Some(super::super::AgentType::Claude),\n            metadata: None,\n        };\n\n        let json = serde_json::to_string(&req).unwrap();\n        let deserialized: CreateTaskRequest = serde_json::from_str(&json).unwrap();\n        assert_eq!(req.title, deserialized.title);\n        assert_eq!(req.microservice, deserialized.microservice);\n    }\n}\n"
        },
        {
          "path": "src/models/job.rs",
          "file_type": "rust",
          "line_count": 244,
          "key_definitions": [
            "10:pub struct Job {",
            "26:pub enum JobType {",
            "40:pub enum JobStatus {",
            "50:pub struct JobSpec {",
            "73:pub struct VolumeSpec {",
            "83:pub enum VolumeType {",
            "94:impl Job {",
            "97:pub fn new(",
            "120:pub fn update_from_k8s_job(&mut self, k8s_job: &K8sJob) {",
            "147:pub fn is_terminal(&self) -> bool {",
            "153:pub fn duration(&self) -> Option<chrono::Duration> {",
            "161:impl Default for JobSpec {",
            "177:impl std::fmt::Display for JobType {",
            "188:impl std::fmt::Display for JobStatus {"
          ],
          "content": "//! Job-related data models for Kubernetes job orchestration\n\nuse chrono::{DateTime, Utc};\nuse k8s_openapi::api::batch::v1::Job as K8sJob;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Represents a Kubernetes job for task execution\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Job {\n    pub id: String,\n    pub task_id: String,\n    pub job_type: JobType,\n    pub status: JobStatus,\n    pub k8s_job_name: String,\n    pub namespace: String,\n    pub spec: JobSpec,\n    pub started_at: Option<DateTime<Utc>>,\n    pub completed_at: Option<DateTime<Utc>>,\n    pub created_at: DateTime<Utc>,\n}\n\n/// Type of job in the orchestration pattern\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum JobType {\n    /// Prepare job that sets up workspace and context files\n    Prepare,\n    /// Execute job that runs the primary agent (Claude)\n    Execute,\n    /// Assist job that runs helper agent (Gemini)\n    Assist,\n    /// Review job for code review tasks\n    Review,\n}\n\n/// Job execution status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum JobStatus {\n    Pending,\n    Running,\n    Succeeded,\n    Failed,\n    Unknown,\n}\n\n/// Job specification details\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JobSpec {\n    /// Container image to use\n    pub image: String,\n    /// Agent type for execution jobs\n    pub agent: Option<super::AgentType>,\n    /// Environment variables\n    pub env_vars: HashMap<String, String>,\n    /// Resource limits and requests\n    pub resources: super::ResourceLimits,\n    /// Volume mounts\n    pub volumes: Vec<VolumeSpec>,\n    /// Command to execute\n    pub command: Option<Vec<String>>,\n    /// Working directory\n    pub working_dir: Option<String>,\n    /// Job timeout in seconds\n    pub timeout_seconds: Option<u32>,\n    /// Number of retries\n    pub retry_limit: Option<u32>,\n}\n\n/// Volume specification for job\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct VolumeSpec {\n    pub name: String,\n    pub mount_path: String,\n    pub volume_type: VolumeType,\n    pub read_only: bool,\n}\n\n/// Types of volumes that can be mounted\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum VolumeType {\n    /// `ConfigMap` volume\n    ConfigMap { name: String },\n    /// `PersistentVolumeClaim`\n    Pvc { claim_name: String },\n    /// `EmptyDir` volume\n    EmptyDir,\n    /// Secret volume\n    Secret { name: String },\n}\n\nimpl Job {\n    /// Create a new job\n    #[must_use]\n    pub fn new(\n        id: String,\n        task_id: String,\n        job_type: JobType,\n        k8s_job_name: String,\n        namespace: String,\n        spec: JobSpec,\n    ) -> Self {\n        Self {\n            id,\n            task_id,\n            job_type,\n            status: JobStatus::Pending,\n            k8s_job_name,\n            namespace,\n            spec,\n            started_at: None,\n            completed_at: None,\n            created_at: Utc::now(),\n        }\n    }\n\n    /// Update job status based on Kubernetes job status\n    pub fn update_from_k8s_job(&mut self, k8s_job: &K8sJob) {\n        if let Some(status) = &k8s_job.status {\n            if status.succeeded == Some(1) {\n                self.status = JobStatus::Succeeded;\n                self.completed_at = status.completion_time.as_ref().map(|t| {\n                    DateTime::parse_from_rfc3339(&t.0.to_rfc3339())\n                        .unwrap()\n                        .with_timezone(&Utc)\n                });\n            } else if status.failed.unwrap_or(0) > 0 {\n                self.status = JobStatus::Failed;\n                self.completed_at = Some(Utc::now());\n            } else if status.active == Some(1) {\n                self.status = JobStatus::Running;\n                if self.started_at.is_none() {\n                    self.started_at = status.start_time.as_ref().map(|t| {\n                        DateTime::parse_from_rfc3339(&t.0.to_rfc3339())\n                            .unwrap()\n                            .with_timezone(&Utc)\n                    });\n                }\n            }\n        }\n    }\n\n    /// Check if the job is in a terminal state\n    #[must_use]\n    pub fn is_terminal(&self) -> bool {\n        matches!(self.status, JobStatus::Succeeded | JobStatus::Failed)\n    }\n\n    /// Get job duration if available\n    #[must_use]\n    pub fn duration(&self) -> Option<chrono::Duration> {\n        match (self.started_at, self.completed_at) {\n            (Some(start), Some(end)) => Some(end - start),\n            _ => None,\n        }\n    }\n}\n\nimpl Default for JobSpec {\n    fn default() -> Self {\n        Self {\n            image: \"busybox:latest\".to_string(),\n            agent: None,\n            env_vars: HashMap::new(),\n            resources: super::ResourceLimits::default(),\n            volumes: Vec::new(),\n            command: None,\n            working_dir: None,\n            timeout_seconds: Some(1800), // 30 minutes default\n            retry_limit: Some(2),\n        }\n    }\n}\n\nimpl std::fmt::Display for JobType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            JobType::Prepare => write!(f, \"Prepare\"),\n            JobType::Execute => write!(f, \"Execute\"),\n            JobType::Assist => write!(f, \"Assist\"),\n            JobType::Review => write!(f, \"Review\"),\n        }\n    }\n}\n\nimpl std::fmt::Display for JobStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            JobStatus::Pending => write!(f, \"Pending\"),\n            JobStatus::Running => write!(f, \"Running\"),\n            JobStatus::Succeeded => write!(f, \"Succeeded\"),\n            JobStatus::Failed => write!(f, \"Failed\"),\n            JobStatus::Unknown => write!(f, \"Unknown\"),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_job_creation() {\n        let spec = JobSpec::default();\n        let job = Job::new(\n            \"job-123\".to_string(),\n            \"task-123\".to_string(),\n            JobType::Execute,\n            \"claude-task-123\".to_string(),\n            \"default\".to_string(),\n            spec,\n        );\n\n        assert_eq!(job.status, JobStatus::Pending);\n        assert!(job.started_at.is_none());\n        assert!(job.completed_at.is_none());\n        assert!(!job.is_terminal());\n    }\n\n    #[test]\n    fn test_job_serialization() {\n        let spec = JobSpec {\n            image: \"claude:latest\".to_string(),\n            agent: Some(super::super::AgentType::Claude),\n            ..Default::default()\n        };\n\n        let job = Job::new(\n            \"job-123\".to_string(),\n            \"task-123\".to_string(),\n            JobType::Execute,\n            \"claude-task-123\".to_string(),\n            \"default\".to_string(),\n            spec,\n        );\n\n        let json = serde_json::to_string(&job).unwrap();\n        let deserialized: Job = serde_json::from_str(&json).unwrap();\n        assert_eq!(job.id, deserialized.id);\n        assert_eq!(job.job_type, deserialized.job_type);\n    }\n}\n"
        },
        {
          "path": "src/models/config.rs",
          "file_type": "rust",
          "line_count": 147,
          "key_definitions": [
            "9:pub enum AgentType {",
            "17:pub struct AgentConfig {",
            "29:pub struct ResourceLimits {",
            "40:pub struct McpServerConfig {",
            "50:pub struct OrchestratorConfig {",
            "60:impl Default for ResourceLimits {",
            "73:impl AgentType {",
            "76:pub fn display_name(&self) -> &'static str {",
            "85:pub fn default_image(&self) -> &'static str {",
            "94:pub fn can_implement(&self) -> bool {",
            "103:pub fn can_assist(&self) -> bool {"
          ],
          "content": "//! Configuration-related models\n\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Agent types that can execute tasks\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Hash, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum AgentType {\n    #[default]\n    Claude,\n    Gemini,\n}\n\n/// Agent configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentConfig {\n    pub agent_type: AgentType,\n    pub image: String,\n    pub version: String,\n    pub env_vars: HashMap<String, String>,\n    pub resources: ResourceLimits,\n    pub capabilities: Vec<String>,\n    pub mcp_servers: Vec<String>,\n}\n\n/// Resource limits and requests\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResourceLimits {\n    pub cpu_request: String,\n    pub cpu_limit: String,\n    pub memory_request: String,\n    pub memory_limit: String,\n    pub ephemeral_storage_request: Option<String>,\n    pub ephemeral_storage_limit: Option<String>,\n}\n\n/// MCP server configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct McpServerConfig {\n    pub name: String,\n    pub command: String,\n    pub args: Vec<String>,\n    pub env: HashMap<String, String>,\n    pub capabilities: Vec<String>,\n}\n\n/// Orchestrator configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct OrchestratorConfig {\n    pub namespace: String,\n    pub agents: HashMap<AgentType, AgentConfig>,\n    pub default_timeout_seconds: u32,\n    pub max_retry_attempts: u32,\n    pub workspace_pvc_template: String,\n    pub prepare_job_image: String,\n    pub node_selector: HashMap<String, String>,\n}\n\nimpl Default for ResourceLimits {\n    fn default() -> Self {\n        Self {\n            cpu_request: \"100m\".to_string(),\n            cpu_limit: \"1000m\".to_string(),\n            memory_request: \"256Mi\".to_string(),\n            memory_limit: \"2Gi\".to_string(),\n            ephemeral_storage_request: None,\n            ephemeral_storage_limit: None,\n        }\n    }\n}\n\nimpl AgentType {\n    /// Get display name for the agent\n    #[must_use]\n    pub fn display_name(&self) -> &'static str {\n        match self {\n            AgentType::Claude => \"Claude Code\",\n            AgentType::Gemini => \"Gemini CLI\",\n        }\n    }\n\n    /// Get the default image for the agent\n    #[must_use]\n    pub fn default_image(&self) -> &'static str {\n        match self {\n            AgentType::Claude => \"anthropic/claude-code:latest\",\n            AgentType::Gemini => \"google/gemini-cli:latest\",\n        }\n    }\n\n    /// Check if this agent can be a primary implementer\n    #[must_use]\n    pub fn can_implement(&self) -> bool {\n        match self {\n            AgentType::Claude => true,\n            AgentType::Gemini => false, // Gemini is assistance-only in our pattern\n        }\n    }\n\n    /// Check if this agent can provide assistance\n    #[must_use]\n    pub fn can_assist(&self) -> bool {\n        match self {\n            AgentType::Claude => false, // Claude is implementation-only in our pattern\n            AgentType::Gemini => true,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_agent_type_capabilities() {\n        assert!(AgentType::Claude.can_implement());\n        assert!(!AgentType::Claude.can_assist());\n        assert!(!AgentType::Gemini.can_implement());\n        assert!(AgentType::Gemini.can_assist());\n    }\n\n    #[test]\n    fn test_resource_limits_default() {\n        let limits = ResourceLimits::default();\n        assert_eq!(limits.cpu_request, \"100m\");\n        assert_eq!(limits.memory_limit, \"2Gi\");\n    }\n\n    #[test]\n    fn test_agent_config_serialization() {\n        let config = AgentConfig {\n            agent_type: AgentType::Claude,\n            image: \"claude:v1\".to_string(),\n            version: \"1.0.0\".to_string(),\n            env_vars: HashMap::new(),\n            resources: ResourceLimits::default(),\n            capabilities: vec![\"code\".to_string(), \"test\".to_string()],\n            mcp_servers: vec![\"taskmaster\".to_string()],\n        };\n\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: AgentConfig = serde_json::from_str(&json).unwrap();\n        assert_eq!(config.agent_type, deserialized.agent_type);\n        assert_eq!(config.capabilities, deserialized.capabilities);\n    }\n}\n"
        },
        {
          "path": "src/models/webhook.rs",
          "file_type": "rust",
          "line_count": 232,
          "key_definitions": [
            "9:pub struct WebhookPayload {",
            "17:pub struct GitHubWebhookPayload {",
            "27:pub struct GitHubIssue {",
            "41:pub struct GitHubPullRequest {",
            "56:pub struct GitHubRepository {",
            "67:pub struct GitHubUser {",
            "76:pub struct GitHubLabel {",
            "83:pub struct GitHubRef {",
            "91:pub struct GrafanaAlert {",
            "106:pub struct GrafanaWebhookPayload {",
            "120:pub struct PmAgentPayload {",
            "128:pub struct PmTaskData {",
            "141:pub struct DiscordPayload {"
          ],
          "content": "//! Webhook payload models for various sources\n\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Generic webhook payload wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct WebhookPayload {\n    pub source: super::RequestSource,\n    pub headers: HashMap<String, String>,\n    pub body: Value,\n}\n\n/// GitHub webhook payload for issue events\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubWebhookPayload {\n    pub action: String,\n    pub issue: Option<GitHubIssue>,\n    pub pull_request: Option<GitHubPullRequest>,\n    pub repository: GitHubRepository,\n    pub sender: GitHubUser,\n}\n\n/// GitHub issue structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubIssue {\n    pub id: u64,\n    pub number: u64,\n    pub title: String,\n    pub body: Option<String>,\n    pub state: String,\n    pub labels: Vec<GitHubLabel>,\n    pub created_at: String,\n    pub updated_at: String,\n    pub user: GitHubUser,\n}\n\n/// GitHub pull request structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubPullRequest {\n    pub id: u64,\n    pub number: u64,\n    pub title: String,\n    pub body: Option<String>,\n    pub state: String,\n    pub head: GitHubRef,\n    pub base: GitHubRef,\n    pub created_at: String,\n    pub updated_at: String,\n    pub user: GitHubUser,\n}\n\n/// GitHub repository information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubRepository {\n    pub id: u64,\n    pub name: String,\n    pub full_name: String,\n    pub owner: GitHubUser,\n    pub private: bool,\n    pub default_branch: String,\n}\n\n/// GitHub user information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubUser {\n    pub login: String,\n    pub id: u64,\n    #[serde(rename = \"type\")]\n    pub user_type: String,\n}\n\n/// GitHub label\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubLabel {\n    pub name: String,\n    pub color: String,\n}\n\n/// GitHub ref (branch/tag)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GitHubRef {\n    pub label: String,\n    pub ref_field: String,\n    pub sha: String,\n}\n\n/// Grafana alert webhook payload\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GrafanaAlert {\n    pub status: String,\n    pub labels: HashMap<String, String>,\n    pub annotations: HashMap<String, String>,\n    pub values: HashMap<String, f64>,\n    #[serde(rename = \"startsAt\")]\n    pub starts_at: String,\n    #[serde(rename = \"endsAt\")]\n    pub ends_at: Option<String>,\n    #[serde(rename = \"generatorURL\")]\n    pub generator_url: String,\n}\n\n/// Grafana webhook payload wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GrafanaWebhookPayload {\n    pub receiver: String,\n    pub status: String,\n    pub alerts: Vec<GrafanaAlert>,\n    #[serde(rename = \"groupLabels\")]\n    pub group_labels: HashMap<String, String>,\n    #[serde(rename = \"commonLabels\")]\n    pub common_labels: HashMap<String, String>,\n    #[serde(rename = \"commonAnnotations\")]\n    pub common_annotations: HashMap<String, String>,\n}\n\n/// PM Agent webhook payload\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PmAgentPayload {\n    pub action: String,\n    pub project_id: String,\n    pub task: PmTaskData,\n}\n\n/// PM Agent task data\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PmTaskData {\n    pub id: String,\n    pub title: String,\n    pub description: String,\n    pub acceptance_criteria: Vec<String>,\n    pub priority: String,\n    pub status: String,\n    pub assigned_to: Option<String>,\n    pub metadata: HashMap<String, Value>,\n}\n\n/// Discord webhook payload (via relay)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DiscordPayload {\n    pub channel_id: String,\n    pub user_id: String,\n    pub username: String,\n    pub command: String,\n    pub args: Vec<String>,\n    pub message_id: String,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_github_webhook_deserialization() {\n        let json = r#\"{\n            \"action\": \"opened\",\n            \"issue\": {\n                \"id\": 123,\n                \"number\": 42,\n                \"title\": \"Test Issue\",\n                \"body\": \"Test body\",\n                \"state\": \"open\",\n                \"labels\": [],\n                \"created_at\": \"2024-01-01T00:00:00Z\",\n                \"updated_at\": \"2024-01-01T00:00:00Z\",\n                \"user\": {\n                    \"login\": \"testuser\",\n                    \"id\": 456,\n                    \"type\": \"User\"\n                }\n            },\n            \"repository\": {\n                \"id\": 789,\n                \"name\": \"test-repo\",\n                \"full_name\": \"org/test-repo\",\n                \"owner\": {\n                    \"login\": \"org\",\n                    \"id\": 999,\n                    \"type\": \"Organization\"\n                },\n                \"private\": false,\n                \"default_branch\": \"main\"\n            },\n            \"sender\": {\n                \"login\": \"testuser\",\n                \"id\": 456,\n                \"type\": \"User\"\n            }\n        }\"#;\n\n        let payload: GitHubWebhookPayload = serde_json::from_str(json).unwrap();\n        assert_eq!(payload.action, \"opened\");\n        assert!(payload.issue.is_some());\n        assert_eq!(payload.issue.unwrap().number, 42);\n    }\n\n    #[test]\n    fn test_grafana_alert_deserialization() {\n        let json = r#\"{\n            \"receiver\": \"webhook\",\n            \"status\": \"firing\",\n            \"alerts\": [{\n                \"status\": \"firing\",\n                \"labels\": {\n                    \"alertname\": \"HighErrorRate\",\n                    \"task_id\": \"123\"\n                },\n                \"annotations\": {\n                    \"summary\": \"High error rate detected\"\n                },\n                \"values\": {\n                    \"error_rate\": 0.45\n                },\n                \"startsAt\": \"2024-01-01T00:00:00Z\",\n                \"endsAt\": null,\n                \"generatorURL\": \"http://grafana/alert\"\n            }],\n            \"groupLabels\": {},\n            \"commonLabels\": {},\n            \"commonAnnotations\": {}\n        }\"#;\n\n        let payload: GrafanaWebhookPayload = serde_json::from_str(json).unwrap();\n        assert_eq!(payload.status, \"firing\");\n        assert_eq!(payload.alerts.len(), 1);\n        assert_eq!(\n            payload.alerts[0].labels.get(\"task_id\"),\n            Some(&\"123\".to_string())\n        );\n    }\n}\n"
        },
        {
          "path": "src/models/code_request.rs",
          "file_type": "rust",
          "line_count": 91,
          "key_definitions": [
            "9:pub struct SecretEnvVar {",
            "21:pub struct CodeRequest {"
          ],
          "content": "//! Clean code task submission request structure\n\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n// Re-export SecretEnvVar from orchestrator-core crate to avoid duplication\n// For now, we'll define it locally until we can reorganize the type sharing\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SecretEnvVar {\n    /// Name of the environment variable\n    pub name: String,\n    /// Name of the secret\n    #[serde(rename = \"secretName\")]\n    pub secret_name: String,\n    /// Key within the secret\n    #[serde(rename = \"secretKey\")]\n    pub secret_key: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CodeRequest {\n    /// Task ID to implement\n    pub task_id: u32,\n\n    /// Target service name\n    pub service: String,\n\n    /// Target project repository URL (where implementation work happens)\n    pub repository_url: String,\n\n    /// Documentation repository URL (where Task Master definitions come from)\n    pub docs_repository_url: String,\n\n    /// Project directory within docs repository (e.g. \"_projects/simple-api\")\n    pub docs_project_directory: Option<String>,\n\n    /// Working directory within target repository (defaults to service name)\n    pub working_directory: Option<String>,\n\n    /// Claude model to use (sonnet, opus) - optional, defaults handled by MCP tools\n    pub model: Option<String>,\n\n    /// GitHub username for authentication\n    pub github_user: String,\n\n    /// Local MCP tools/servers to enable (comma-separated)\n    #[serde(default)]\n    pub local_tools: Option<String>,\n\n    /// Remote MCP tools/servers to enable (comma-separated)\n    #[serde(default)]\n    pub remote_tools: Option<String>,\n\n    /// Context version for retry attempts (incremented on each retry)\n    #[serde(default = \"default_context_version\")]\n    pub context_version: u32,\n\n    /// Additional context for retry attempts\n    #[serde(default)]\n    pub prompt_modification: Option<String>,\n\n    /// Docs branch to use (e.g., \"main\", \"feature/branch\")\n    #[serde(default = \"default_docs_branch\")]\n    pub docs_branch: String,\n\n    /// Whether to continue a previous session (auto-continue on retries or user-requested)\n    #[serde(default)]\n    pub continue_session: bool,\n\n    /// Whether to overwrite memory before starting\n    #[serde(default)]\n    pub overwrite_memory: bool,\n\n    /// Environment variables to set in the container\n    #[serde(default)]\n    pub env: HashMap<String, String>,\n\n    /// Environment variables from secrets\n    #[serde(default)]\n    pub env_from_secrets: Vec<SecretEnvVar>,\n}\n\n/// Default context version\nfn default_context_version() -> u32 {\n    1\n}\n\n/// Default docs branch\nfn default_docs_branch() -> String {\n    \"main\".to_string()\n}\n"
        },
        {
          "path": "src/models/task.rs",
          "file_type": "rust",
          "line_count": 176,
          "key_definitions": [
            "9:pub struct Task {",
            "26:pub enum TaskStatus {",
            "38:pub enum TaskPriority {",
            "48:pub struct TaskMetadata {",
            "62:impl Task {",
            "65:pub fn new(id: String, title: String, description: String, microservice: String) -> Self {",
            "84:pub fn is_terminal(&self) -> bool {",
            "92:pub fn update_status(&mut self, status: TaskStatus) {",
            "98:impl std::fmt::Display for TaskStatus {",
            "111:impl std::fmt::Display for TaskPriority {"
          ],
          "content": "//! Task-related data models\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// Represents a task to be executed by an agent\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct Task {\n    pub id: String,\n    pub title: String,\n    pub description: String,\n    pub acceptance_criteria: Vec<String>,\n    pub status: TaskStatus,\n    pub priority: TaskPriority,\n    pub microservice: String,\n    pub agent_type: Option<super::AgentType>,\n    pub metadata: TaskMetadata,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n}\n\n/// Task execution status\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"snake_case\")]\npub enum TaskStatus {\n    Pending,\n    InProgress,\n    Completed,\n    Failed,\n    Cancelled,\n    Blocked,\n}\n\n/// Task priority levels\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum TaskPriority {\n    Low,\n    #[default]\n    Medium,\n    High,\n    Critical,\n}\n\n/// Additional metadata for tasks\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\npub struct TaskMetadata {\n    /// Source that created this task\n    pub source: Option<String>,\n    /// GitHub issue number if applicable\n    pub github_issue: Option<u64>,\n    /// Task Master task ID if applicable\n    pub task_master_id: Option<String>,\n    /// Custom labels\n    pub labels: HashMap<String, String>,\n    /// Additional arbitrary data\n    #[serde(flatten)]\n    pub extra: HashMap<String, serde_json::Value>,\n}\n\nimpl Task {\n    /// Create a new task with default values\n    #[must_use]\n    pub fn new(id: String, title: String, description: String, microservice: String) -> Self {\n        let now = Utc::now();\n        Self {\n            id,\n            title,\n            description,\n            acceptance_criteria: Vec::new(),\n            status: TaskStatus::Pending,\n            priority: TaskPriority::Medium,\n            microservice,\n            agent_type: None,\n            metadata: TaskMetadata::default(),\n            created_at: now,\n            updated_at: now,\n        }\n    }\n\n    /// Check if the task is in a terminal state\n    #[must_use]\n    pub fn is_terminal(&self) -> bool {\n        matches!(\n            self.status,\n            TaskStatus::Completed | TaskStatus::Failed | TaskStatus::Cancelled\n        )\n    }\n\n    /// Update the task status and timestamp\n    pub fn update_status(&mut self, status: TaskStatus) {\n        self.status = status;\n        self.updated_at = Utc::now();\n    }\n}\n\nimpl std::fmt::Display for TaskStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            TaskStatus::Pending => write!(f, \"Pending\"),\n            TaskStatus::InProgress => write!(f, \"In Progress\"),\n            TaskStatus::Completed => write!(f, \"Completed\"),\n            TaskStatus::Failed => write!(f, \"Failed\"),\n            TaskStatus::Cancelled => write!(f, \"Cancelled\"),\n            TaskStatus::Blocked => write!(f, \"Blocked\"),\n        }\n    }\n}\n\nimpl std::fmt::Display for TaskPriority {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            TaskPriority::Low => write!(f, \"Low\"),\n            TaskPriority::Medium => write!(f, \"Medium\"),\n            TaskPriority::High => write!(f, \"High\"),\n            TaskPriority::Critical => write!(f, \"Critical\"),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_task_creation() {\n        let task = Task::new(\n            \"test-123\".to_string(),\n            \"Test Task\".to_string(),\n            \"A test task\".to_string(),\n            \"auth\".to_string(),\n        );\n\n        assert_eq!(task.id, \"test-123\");\n        assert_eq!(task.status, TaskStatus::Pending);\n        assert_eq!(task.priority, TaskPriority::Medium);\n        assert!(!task.is_terminal());\n    }\n\n    #[test]\n    fn test_task_serialization() {\n        let task = Task::new(\n            \"test-123\".to_string(),\n            \"Test Task\".to_string(),\n            \"A test task\".to_string(),\n            \"auth\".to_string(),\n        );\n\n        let json = serde_json::to_string(&task).unwrap();\n        let deserialized: Task = serde_json::from_str(&json).unwrap();\n        assert_eq!(task.id, deserialized.id);\n        assert_eq!(task.status, deserialized.status);\n    }\n\n    #[test]\n    fn test_terminal_states() {\n        let mut task = Task::new(\n            \"test-123\".to_string(),\n            \"Test Task\".to_string(),\n            \"A test task\".to_string(),\n            \"auth\".to_string(),\n        );\n\n        assert!(!task.is_terminal());\n\n        task.update_status(TaskStatus::Completed);\n        assert!(task.is_terminal());\n\n        task.update_status(TaskStatus::Failed);\n        assert!(task.is_terminal());\n\n        task.update_status(TaskStatus::InProgress);\n        assert!(!task.is_terminal());\n    }\n}\n"
        },
        {
          "path": "src/models/docs_request.rs",
          "file_type": "rust",
          "line_count": 21,
          "key_definitions": [
            "6:pub struct DocsRequest {"
          ],
          "content": "//! Clean documentation generation request structure\n\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DocsRequest {\n    /// Git repository URL\n    pub repository_url: String,\n\n    /// Working directory within the repository\n    pub working_directory: String,\n\n    /// Claude model to use (sonnet, opus) - optional, defaults handled by MCP tools\n    pub model: Option<String>,\n\n    /// GitHub username for authentication\n    pub github_user: String,\n\n    /// Source branch (auto-detected)\n    pub source_branch: String,\n}\n"
        },
        {
          "path": "src/models/mod.rs",
          "file_type": "rust",
          "line_count": 25,
          "key_definitions": [],
          "content": "//! Core data models module\n\npub mod code_request;\npub mod config;\npub mod docs_request;\npub mod job;\npub mod pm_task;\npub mod request;\npub mod response;\npub mod task;\npub mod webhook;\n\n// Re-export commonly used types\npub use code_request::CodeRequest;\npub use config::{AgentConfig, AgentType, ResourceLimits};\npub use docs_request::DocsRequest;\npub use job::{Job, JobSpec, JobStatus, JobType};\npub use pm_task::{\n    DocsGenerationRequest, MarkdownPayload, PmTaskRequest, Subtask, Task as PmTask, TaskMaster,\n    TaskMasterFile,\n};\npub use request::{ParsedRequest, Request, RequestAction, RequestSource};\npub use response::{ApiResponse, JobResponse, TaskResponse};\npub use task::{Task, TaskMetadata, TaskStatus};\npub use webhook::{GitHubWebhookPayload, GrafanaAlert, WebhookPayload};\n"
        },
        {
          "path": "src/models/pm_task.rs",
          "file_type": "rust",
          "line_count": 447,
          "key_definitions": [
            "7:pub struct PmTaskRequest {",
            "70:pub struct Subtask {",
            "83:pub struct MarkdownPayload {",
            "91:pub struct AgentToolSpec {",
            "102:pub struct RepositorySpec {",
            "133:pub struct DocsGenerationRequest {",
            "173:pub struct TaskMasterFile {",
            "178:pub struct TaskMaster {",
            "183:pub struct Task {",
            "196:impl PmTaskRequest {",
            "199:pub fn new(",
            "218:pub fn new_with_tools(",
            "254:pub fn new_with_repository(",
            "291:pub fn new_with_full_spec(",
            "329:pub fn new_with_prompt_modification(",
            "369:pub fn new_with_tool_config("
          ],
          "content": "//! PM task submission models\n\nuse serde::{Deserialize, Serialize};\n\n/// PM task request structure according to design document\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PmTaskRequest {\n    // Task Master schema fields\n    pub id: u32,\n    pub title: String,\n    pub description: String,\n    pub details: String,\n    pub test_strategy: String,\n    pub priority: String,\n    pub dependencies: Vec<u32>,\n    pub status: String,\n    pub subtasks: Vec<Subtask>,\n\n    // PM-specific fields\n    pub service_name: String,\n    pub agent_name: String,\n\n    // Claude model selection (sonnet, opus)\n    pub model: String,\n\n    // Markdown files as structured payloads\n    pub markdown_files: Vec<MarkdownPayload>,\n\n    // Agent tools specification\n    #[serde(default)]\n    pub agent_tools: Vec<AgentToolSpec>,\n\n    // Repository specification for code access\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub repository: Option<RepositorySpec>,\n\n    // Working directory within target repository (defaults to service_name)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub working_directory: Option<String>,\n\n    // Additional prompt instructions for retry attempts\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_modification: Option<String>,\n\n    // How to apply prompt_modification: 'append' or 'replace'\n    #[serde(\n        default = \"default_prompt_mode\",\n        skip_serializing_if = \"is_default_prompt_mode\"\n    )]\n    pub prompt_mode: String,\n\n    // Local Claude Code tools to enable\n    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n    pub local_tools: Vec<String>,\n\n    // Remote MCP tools to enable\n    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n    pub remote_tools: Vec<String>,\n\n    // Tool configuration preset\n    #[serde(\n        default = \"default_tool_config\",\n        skip_serializing_if = \"is_default_tool_config\"\n    )]\n    pub tool_config: String,\n}\n\n/// Subtask structure from Task Master\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Subtask {\n    pub id: u32,\n    pub title: String,\n    pub description: String,\n    pub dependencies: Vec<u32>,\n    pub details: String,\n    pub status: String,\n    #[serde(default, alias = \"testStrategy\")]\n    pub test_strategy: String,\n}\n\n/// Markdown file payload for network transmission\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MarkdownPayload {\n    pub content: String,\n    pub filename: String,\n    pub file_type: String,\n}\n\n/// Agent tool specification for PM requests\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentToolSpec {\n    pub name: String,\n    pub enabled: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub config: Option<serde_json::Value>,\n    #[serde(default)]\n    pub restrictions: Vec<String>,\n}\n\n/// Repository specification for cloning source code\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RepositorySpec {\n    pub url: String,\n    #[serde(default = \"default_branch\")]\n    pub branch: String,\n    pub github_user: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub token: Option<String>, // Reserved for future use - TODO: Implement direct token submission\n}\n\nfn default_branch() -> String {\n    \"main\".to_string()\n}\n\nfn default_prompt_mode() -> String {\n    \"append\".to_string()\n}\n\nfn is_default_prompt_mode(mode: &str) -> bool {\n    mode == \"append\"\n}\n\nfn default_tool_config() -> String {\n    \"default\".to_string()\n}\n\nfn is_default_tool_config(config: &str) -> bool {\n    config == \"default\"\n}\n\n/// Documentation generation request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DocsGenerationRequest {\n    /// Repository URL to clone\n    pub repository_url: String,\n\n    /// Working directory within the repository (path to .taskmaster)\n    pub working_directory: String,\n\n    /// Source branch to checkout and base new branch from\n    pub source_branch: String,\n\n    /// Target branch for the PR\n    pub target_branch: String,\n\n    /// Service name for the job\n    pub service_name: String,\n\n    /// Agent name for the job\n    pub agent_name: String,\n\n    /// Claude model selection (sonnet, opus)\n    pub model: String,\n\n    /// GitHub user for authentication\n    pub github_user: String,\n\n    /// Optional specific task ID to generate docs for (if None, generates all)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub task_id: Option<u32>,\n\n    /// Force overwrite existing documentation\n    #[serde(default)]\n    pub force: bool,\n\n    /// Dry run mode (preview only)\n    #[serde(default)]\n    pub dry_run: bool,\n}\n\n/// Task Master JSON file structure\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskMasterFile {\n    pub master: TaskMaster,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskMaster {\n    pub tasks: Vec<Task>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Task {\n    pub id: u32,\n    pub title: String,\n    pub description: String,\n    pub details: String,\n    #[serde(default, alias = \"testStrategy\")]\n    pub test_strategy: String,\n    pub priority: String,\n    pub dependencies: Vec<u32>,\n    pub status: String,\n    pub subtasks: Vec<Subtask>,\n}\n\nimpl PmTaskRequest {\n    /// Create a new PM task request from Task Master task and markdown files\n    #[must_use]\n    pub fn new(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n    ) -> Self {\n        Self::new_with_tools(\n            task,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            Vec::new(),\n        )\n    }\n\n    /// Create a new PM task request with agent tools specification\n    #[must_use]\n    pub fn new_with_tools(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository: None,\n            working_directory: None,\n            prompt_modification: None,\n            prompt_mode: \"append\".to_string(),\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request from Task Master task with repository support\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_repository(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory: None,\n            prompt_modification: None,\n            prompt_mode: \"append\".to_string(),\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request with full specification including working directory\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_full_spec(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n        working_directory: Option<String>,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory,\n            prompt_modification: None,\n            prompt_mode: \"append\".to_string(),\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request with prompt modification support for retries\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_prompt_modification(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n        working_directory: Option<String>,\n        prompt_modification: Option<String>,\n        prompt_mode: String,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory,\n            prompt_modification,\n            prompt_mode,\n            local_tools: Vec::new(),\n            remote_tools: Vec::new(),\n            tool_config: \"default\".to_string(),\n        }\n    }\n\n    /// Create a new PM task request with full tool configuration support\n    #[allow(clippy::too_many_arguments)]\n    #[must_use]\n    pub fn new_with_tool_config(\n        task: Task,\n        service_name: String,\n        agent_name: String,\n        model: String,\n        markdown_files: Vec<MarkdownPayload>,\n        agent_tools: Vec<AgentToolSpec>,\n        repository: Option<RepositorySpec>,\n        working_directory: Option<String>,\n        prompt_modification: Option<String>,\n        prompt_mode: String,\n        local_tools: Vec<String>,\n        remote_tools: Vec<String>,\n        tool_config: String,\n    ) -> Self {\n        Self {\n            id: task.id,\n            title: task.title,\n            description: task.description,\n            details: task.details,\n            test_strategy: task.test_strategy,\n            priority: task.priority,\n            dependencies: task.dependencies,\n            status: task.status,\n            subtasks: task.subtasks,\n            service_name,\n            agent_name,\n            model,\n            markdown_files,\n            agent_tools,\n            repository,\n            working_directory,\n            prompt_modification,\n            prompt_mode,\n            local_tools,\n            remote_tools,\n            tool_config,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_pm_task_request_creation() {\n        let task = Task {\n            id: 1001,\n            title: \"Test Task\".to_string(),\n            description: \"Test description\".to_string(),\n            details: \"Test details\".to_string(),\n            test_strategy: \"Test strategy\".to_string(),\n            priority: \"high\".to_string(),\n            dependencies: vec![],\n            status: \"pending\".to_string(),\n            subtasks: vec![],\n        };\n\n        let markdown_files = vec![MarkdownPayload {\n            content: \"# Task Content\".to_string(),\n            filename: \"task.md\".to_string(),\n            file_type: \"task\".to_string(),\n        }];\n\n        let request = PmTaskRequest::new(\n            task,\n            \"test-service\".to_string(),\n            \"claude-agent-1\".to_string(),\n            \"sonnet\".to_string(),\n            markdown_files,\n        );\n\n        assert_eq!(request.id, 1001);\n        assert_eq!(request.service_name, \"test-service\");\n        assert_eq!(request.model, \"sonnet\");\n        assert_eq!(request.markdown_files.len(), 1);\n    }\n}\n"
        }
      ],
      "dependencies": [
        "serde",
        "serde_json",
        "anyhow",
        "thiserror",
        "chrono",
        "k8s-openapi",
        "async-trait",
        "uuid"
      ],
      "description": "No description available",
      "line_count": 1888
    },
    {
      "name": "helm-charts",
      "path": "infra/charts",
      "component_type": "HelmChart",
      "source_files": [
        {
          "path": "orchestrator/crds/platform-crds.yaml",
          "file_type": "yaml",
          "line_count": 269,
          "key_definitions": [],
          "content": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: coderuns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: coderuns\n    singular: coderun\n    kind: CodeRun\n    shortNames:\n    - cr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Task\n      type: integer\n      jsonPath: .spec.taskId\n    - name: Service\n      type: string\n      jsonPath: .spec.service\n    - name: Model\n      type: string\n      jsonPath: .spec.model\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"taskId\", \"service\", \"repositoryUrl\", \"docsRepositoryUrl\", \"workingDirectory\", \"model\", \"githubUser\"]\n            properties:\n              taskId:\n                type: integer\n                description: \"Task ID to implement\"\n              service:\n                type: string\n                description: \"Target service name\"\n              repositoryUrl:\n                type: string\n                description: \"Target project repository URL (where implementation work happens)\"\n              docsRepositoryUrl:\n                type: string\n                description: \"Documentation repository URL (where Task Master definitions come from)\"\n              docsProjectDirectory:\n                type: string\n                description: \"Project directory within docs repository (e.g. '_projects/simple-api')\"\n              docsBranch:\n                type: string\n                default: \"main\"\n                description: \"Docs branch to use (e.g., 'main', 'feature/branch')\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within target repository (defaults to service name if not specified)\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n              localTools:\n                type: string\n                description: \"Local MCP tools/servers to enable (comma-separated)\"\n              remoteTools:\n                type: string\n                description: \"Remote MCP tools/servers to enable (comma-separated)\"\n              contextVersion:\n                type: integer\n                default: 1\n                description: \"Context version for retry attempts (incremented on each retry)\"\n              promptModification:\n                type: string\n                description: \"Additional context for retry attempts\"\n              continueSession:\n                type: boolean\n                default: false\n                description: \"Whether to continue a previous session\"\n              overwriteMemory:\n                type: boolean\n                default: false\n                description: \"Whether to overwrite memory before starting\"\n              env:\n                type: object\n                additionalProperties:\n                  type: string\n                description: \"Environment variables to set in the container\"\n              envFromSecrets:\n                type: array\n                items:\n                  type: object\n                  properties:\n                    name:\n                      type: string\n                      description: \"Name of the environment variable\"\n                    secretName:\n                      type: string\n                      description: \"Name of the secret\"\n                    secretKey:\n                      type: string\n                      description: \"Key within the secret\"\n                  required:\n                    - name\n                    - secretName\n                    - secretKey\n                description: \"Environment variables from secrets\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the code implementation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              retryCount:\n                type: integer\n                description: \"Current retry attempt (if applicable)\"\n              conditions:\n                type: array\n                description: \"Conditions for the CodeRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\"\n              contextVersion:\n                type: integer\n                description: \"Version of the context and prompt used\"\n              promptModification:\n                type: string\n                description: \"Modification to the prompt if any\"\n              promptMode:\n                type: string\n                description: \"Mode of prompt (e.g., direct, indirect)\"\n              sessionId:\n                type: string\n                description: \"Session ID for tracking\"\n---\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: docsruns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: docsruns\n    singular: docsrun\n    kind: DocsRun\n    shortNames:\n    - dr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"repositoryUrl\", \"workingDirectory\", \"sourceBranch\", \"model\", \"githubUser\"]\n            properties:\n              repositoryUrl:\n                type: string\n                description: \"Repository URL for documentation generation\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within repository\"\n              sourceBranch:\n                type: string\n                description: \"Source branch to analyze\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the documentation generation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              conditions:\n                type: array\n                description: \"Conditions for the DocsRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\""
        },
        {
          "path": "orchestrator/crds/coderun-crd.yaml",
          "file_type": "yaml",
          "line_count": 175,
          "key_definitions": [],
          "content": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: coderuns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: coderuns\n    singular: coderun\n    kind: CodeRun\n    shortNames:\n    - cr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Task\n      type: integer\n      jsonPath: .spec.taskId\n    - name: Service\n      type: string\n      jsonPath: .spec.service\n    - name: Model\n      type: string\n      jsonPath: .spec.model\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"taskId\", \"service\", \"repositoryUrl\", \"docsRepositoryUrl\", \"workingDirectory\", \"model\", \"githubUser\"]\n            properties:\n              taskId:\n                type: integer\n                description: \"Task ID to implement\"\n              service:\n                type: string\n                description: \"Target service name\"\n              repositoryUrl:\n                type: string\n                description: \"Target project repository URL (where implementation work happens)\"\n              docsRepositoryUrl:\n                type: string\n                description: \"Documentation repository URL (where Task Master definitions come from)\"\n              docsProjectDirectory:\n                type: string\n                description: \"Project directory within docs repository (e.g. '_projects/simple-api')\"\n              docsBranch:\n                type: string\n                default: \"main\"\n                description: \"Docs branch to use (e.g., 'main', 'feature/branch')\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within target repository (defaults to service name if not specified)\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n              localTools:\n                type: string\n                description: \"Local MCP tools/servers to enable (comma-separated)\"\n              remoteTools:\n                type: string\n                description: \"Remote MCP tools/servers to enable (comma-separated)\"\n              contextVersion:\n                type: integer\n                default: 1\n                description: \"Context version for retry attempts (incremented on each retry)\"\n              promptModification:\n                type: string\n                description: \"Additional context for retry attempts\"\n              continueSession:\n                type: boolean\n                default: false\n                description: \"Whether to continue a previous session\"\n              overwriteMemory:\n                type: boolean\n                default: false\n                description: \"Whether to overwrite memory before starting\"\n              env:\n                type: object\n                additionalProperties:\n                  type: string\n                description: \"Environment variables to set in the container\"\n              envFromSecrets:\n                type: array\n                items:\n                  type: object\n                  properties:\n                    name:\n                      type: string\n                      description: \"Name of the environment variable\"\n                    secretName:\n                      type: string\n                      description: \"Name of the secret\"\n                    secretKey:\n                      type: string\n                      description: \"Key within the secret\"\n                  required:\n                    - name\n                    - secretName\n                    - secretKey\n                description: \"Environment variables from secrets\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the code implementation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              retryCount:\n                type: integer\n                description: \"Current retry attempt (if applicable)\"\n              conditions:\n                type: array\n                description: \"Conditions for the CodeRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\"\n              contextVersion:\n                type: integer\n                description: \"Version of the context and prompt used\"\n              promptModification:\n                type: string\n                description: \"Modification to the prompt if any\"\n              promptMode:\n                type: string\n                description: \"Mode of prompt (e.g., direct, indirect)\"\n              sessionId:\n                type: string\n                description: \"Session ID for tracking\""
        },
        {
          "path": "orchestrator/crds/docsrun-crd.yaml",
          "file_type": "yaml",
          "line_count": 93,
          "key_definitions": [],
          "content": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: docsruns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: docsruns\n    singular: docsrun\n    kind: DocsRun\n    shortNames:\n    - dr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"repositoryUrl\", \"workingDirectory\", \"sourceBranch\", \"model\", \"githubUser\"]\n            properties:\n              repositoryUrl:\n                type: string\n                description: \"Repository URL for documentation generation\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within repository\"\n              sourceBranch:\n                type: string\n                description: \"Source branch to analyze\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the documentation generation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              conditions:\n                type: array\n                description: \"Conditions for the DocsRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\""
        },
        {
          "path": "orchestrator/Chart.yaml",
          "file_type": "yaml",
          "line_count": 23,
          "key_definitions": [],
          "content": "apiVersion: v2\nname: orchestrator\ndescription: A Helm chart for the Platform Orchestrator - manages Claude Code agents via TaskRun CRDs\ntype: application\nversion: 0.1.1\nappVersion: \"latest\"\n\nkeywords:\n  - orchestrator\n  - claude-code\n  - task-management\n  - kubernetes\n  - automation\n\nhome: https://github.com/5dlabs/platform\nmaintainers:\n  - name: Platform Team\n    email: platform@5dlabs.com\n\nsources:\n  - https://github.com/5dlabs/platform\n\ndependencies: []"
        },
        {
          "path": "orchestrator/README.md",
          "file_type": "md",
          "line_count": 310,
          "key_definitions": [],
          "content": "# Orchestrator Helm Chart\n\nA Helm chart for deploying the Platform Orchestrator that manages Claude Code agents and task execution across Kubernetes clusters.\n\n## Overview\n\nThe Orchestrator is a Rust-based service that:\n- Processes PM task submissions via REST API\n- Deploys Claude Code jobs to Kubernetes clusters\n- Manages per-service workspaces and agent coordination\n- Handles webhook events from GitHub\n- Orchestrates multi-agent collaboration\n\n## Prerequisites\n\n- Kubernetes 1.19+\n- Helm 3.2.0+\n- Persistent Volume provisioner (for per-service workspaces)\n- Container registry access for pulling images\n\n## Installation\n\n### Using the Helm Repository (Recommended)\n\nAdd the 5dlabs Helm repository to install the orchestrator chart:\n\n```bash\n# Add the Helm repository\nhelm repo add 5dlabs https://5dlabs.github.io/platform\nhelm repo update\n\n# Install the orchestrator chart\nhelm install orchestrator 5dlabs/orchestrator --namespace orchestrator --create-namespace\n```\n\n**Note**: CRDs are not included in the Helm chart and must be installed separately (see Step 1 below).\n\n### Manual Installation from Source\n\nIf you prefer to install from the source repository:\n\n### Step 1: Install Custom Resource Definitions (CRDs)\n\n**⚠️ Important**: CRDs must be installed before the Helm chart.\n\n```bash\n# Install CRDs from GitHub (recommended)\nkubectl apply -f https://raw.githubusercontent.com/5dlabs/platform/main/infra/charts/orchestrator/crds/platform-crds.yaml\n\n# Or install from local files\nkubectl apply -f crds/\n```\n\n### Step 2: Setup GitHub Agent Secrets\n\n**⚠️ Important**: Each agent needs SSH keys and GitHub tokens configured externally.\n\n```bash\n# Setup secrets for your GitHub user\n./infra/scripts/setup-agent-secrets.sh \\\n  --user your-github-username \\\n  --ssh-key ~/.ssh/your_github_key \\\n  --token ghp_your_personal_access_token\n\n# Setup additional agents (repeat as needed)\n./infra/scripts/setup-agent-secrets.sh \\\n  --user another-user \\\n  --ssh-key ~/.ssh/another_key \\\n  --token ghp_another_token\n```\n\n**Requirements:**\n- SSH key pair for each GitHub user (private key + `.pub` file)\n- GitHub Personal Access Token with `repo` permissions\n- SSH key must be added to the GitHub account\n\n### Step 3: Install the Helm Chart\n\n#### Quick Start\n\n```bash\n# Add the chart repository (if using a helm repo)\n# helm repo add platform https://charts.5dlabs.com\n# helm repo update\n\n# Install with default values\nhelm install orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --create-namespace \\\n  --set secrets.anthropicApiKey=\"your-anthropic-api-key\"\n```\n\n#### Production Installation\n\n```bash\n# 1. First install CRDs and setup agent secrets (if not already done)\nkubectl apply -f https://raw.githubusercontent.com/5dlabs/platform/main/infra/charts/orchestrator/crds/platform-crds.yaml\n./infra/scripts/setup-agent-secrets.sh --user your-user --ssh-key ~/.ssh/key --token ghp_xxx\n\n# 2. Create a values file for production\ncat > orchestrator-prod-values.yaml << EOF\nimage:\n  tag: \"v1.0.0\"  # Use specific version tag\n\nsecrets:\n  anthropicApiKey: \"your-anthropic-api-key\"\n\ningress:\n  enabled: true\n  hosts:\n    - host: orchestrator.yourdomain.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: orchestrator-tls\n      hosts:\n        - orchestrator.yourdomain.com\n\nresources:\n  limits:\n    cpu: 1000m\n    memory: 1Gi\n  requests:\n    cpu: 200m\n    memory: 256Mi\n\n# Per-service workspace configuration\nstorage:\n  storageClassName: \"fast-ssd\"\n  workspaceSize: \"100Gi\"\nEOF\n\n# Install with production values\nhelm install orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --create-namespace \\\n  --values orchestrator-prod-values.yaml\n```\n\n## Configuration\n\n### Required Configuration\n\n| Parameter | Description | Required |\n|-----------|-------------|----------|\n| `secrets.anthropicApiKey` | Anthropic API key for Claude agents | Yes |\n| `secrets.githubToken` | GitHub token for repository access | Yes |\n\n### Common Configuration Options\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `replicaCount` | Number of orchestrator replicas | `1` |\n| `image.repository` | Container image repository | `ghcr.io/5dlabs/platform/orchestrator` |\n| `image.tag` | Container image tag | `\"latest\"` |\n| `image.pullPolicy` | Image pull policy | `Always` |\n\n### Service Configuration\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `service.type` | Kubernetes service type | `ClusterIP` |\n| `service.port` | Service port | `80` |\n| `service.targetPort` | Container port | `8080` |\n\n### Ingress Configuration\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `ingress.enabled` | Enable ingress | `true` |\n| `ingress.className` | Ingress class name | `\"nginx\"` |\n| `ingress.hosts[0].host` | Hostname | `orchestrator.local` |\n\n### RBAC Configuration\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `rbac.create` | Create RBAC resources | `true` |\n| `rbac.namespaced` | Use Role/RoleBinding instead of ClusterRole | `true` |\n\n### Claude Code Chart Configuration\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `storage.storageClassName` | Storage class for workspace PVCs | `\"local-path\"` |\n| `storage.workspaceSize` | Size for workspace PVCs | `\"10Gi\"` |\n\n### Workspace Management\n\nWorkspaces are automatically created per-service as PVCs named `workspace-{service}`. Each CodeRun gets its own isolated workspace, while DocsRuns use ephemeral storage.\n\n## Upgrading\n\n```bash\n# Upgrade to a new version\nhelm upgrade orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --values your-values.yaml\n\n# Upgrade with new configuration\nhelm upgrade orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --set image.tag=\"v1.1.0\" \\\n  --reuse-values\n```\n\n## Uninstalling\n\n```bash\n# Uninstall the release\nhelm uninstall orchestrator --namespace orchestrator\n\n# Optionally delete the namespace\nkubectl delete namespace orchestrator\n```\n\n## Monitoring and Troubleshooting\n\n### Health Checks\n\nThe orchestrator exposes a health check endpoint at `/health`:\n\n```bash\n# Check health via port-forward\nkubectl port-forward -n orchestrator svc/orchestrator 8080:80\ncurl http://localhost:8080/health\n\n# Check health via ingress (if enabled)\ncurl http://orchestrator.local/health\n```\n\n### Logs\n\n```bash\n# View orchestrator logs\nkubectl logs -n orchestrator -l app.kubernetes.io/name=orchestrator -f\n\n# View logs from specific pod\nkubectl logs -n orchestrator deployment/orchestrator -f\n```\n\n### Common Issues\n\n1. **Orchestrator pod not starting**\n   - Check if API keys are properly set\n   - Verify image pull secrets are configured\n   - Check resource limits and node capacity\n\n2. **Claude Code deployments failing**\n   - Verify RBAC permissions\n   - Check if service workspace PVCs exist (`kubectl get pvc | grep workspace-`)\n   - Ensure Claude Code Helm chart is properly mounted\n\n3. **Ingress not working**\n   - Verify ingress controller is installed\n   - Check DNS resolution for ingress host\n   - Verify TLS certificates (if using HTTPS)\n\n## Development\n\n### Local Development\n\n```bash\n# Install with development values\nhelm install orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --create-namespace \\\n  --set image.pullPolicy=IfNotPresent \\\n  --set secrets.anthropicApiKey=\"test-key\" \\\n  --set secrets.githubToken=\"test-token\"\n```\n\n### Testing\n\n```bash\n# Lint the chart\nhelm lint ./infra/orchestrator-chart\n\n# Render templates locally\nhelm template orchestrator ./infra/orchestrator-chart \\\n  --values test-values.yaml\n\n# Test installation\nhelm install --dry-run --debug orchestrator ./infra/orchestrator-chart\n```\n\n## Architecture\n\nThe orchestrator consists of:\n\n1. **Deployment**: Main orchestrator service\n2. **Service**: ClusterIP service for internal communication\n3. **Ingress**: External access (optional)\n4. **ConfigMap**: Configuration settings\n5. **Secret**: API keys and sensitive data\n6. **ServiceAccount**: Kubernetes service account\n7. **RBAC**: Role and RoleBinding for permissions\n8. **Claude Code Chart ConfigMap**: Embedded Helm chart for agents\n\n## Contributing\n\n1. Make changes to the chart templates\n2. Update the Chart.yaml version\n3. Test the changes locally\n4. Submit a pull request\n\n## License\n\nThis chart is part of the Platform project and follows the same license terms."
        },
        {
          "path": "orchestrator/DEPLOYMENT.md",
          "file_type": "md",
          "line_count": 299,
          "key_definitions": [],
          "content": "# Orchestrator Deployment Guide\n\nThis guide walks you through deploying the orchestrator using the Helm chart and migrating from the existing manifest-based deployment.\n\n## Current State Analysis\n\nBased on the current deployment in the `orchestrator` namespace, the following resources are currently deployed via manifests:\n\n- **Deployment**: `orchestrator` (1 replica)\n- **Service**: `orchestrator` (ClusterIP)\n- **ConfigMap**: `orchestrator-config`\n- **Secret**: `orchestrator-secrets`\n- **ConfigMap**: `claude-code-helm-chart` (contains Claude Code chart files)\n- **ServiceAccount**: `orchestrator`\n- **RBAC**: Role and RoleBinding for orchestrator permissions\n\n## Migration Strategy\n\n### Option 1: In-Place Migration (Recommended)\n\nThis approach updates the existing deployment with minimal downtime.\n\n#### Step 1: Backup Current Configuration\n\n```bash\n# Export current configuration\nkubectl get configmap orchestrator-config -n orchestrator -o yaml > backup-config.yaml\nkubectl get secret orchestrator-secrets -n orchestrator -o yaml > backup-secrets.yaml\n\n# Extract current API keys (base64 decode them)\nkubectl get secret orchestrator-secrets -n orchestrator -o jsonpath='{.data.ANTHROPIC_API_KEY}' | base64 -d\nkubectl get secret orchestrator-secrets -n orchestrator -o jsonpath='{.data.GITHUB_TOKEN}' | base64 -d\n```\n\n#### Step 2: Create Values File\n\n```bash\n# Create values file with current configuration\ncat > orchestrator-values.yaml << EOF\nsecrets:\n  anthropicApiKey: \"$(kubectl get secret orchestrator-secrets -n orchestrator -o jsonpath='{.data.ANTHROPIC_API_KEY}' | base64 -d)\"\n  githubToken: \"$(kubectl get secret orchestrator-secrets -n orchestrator -o jsonpath='{.data.GITHUB_TOKEN}' | base64 -d)\"\n\nconfig:\n  kubernetesNamespace: \"orchestrator\"\n  helmChartPath: \"/infra/claude-code\"\n  helmNamespace: \"orchestrator\"\n  helmTimeout: \"600s\"\n  serverHost: \"0.0.0.0\"\n  serverPort: \"8080\"\n  rustLog: \"orchestrator=debug,tower_http=debug,axum=debug\"\n\ningress:\n  enabled: true\n  hosts:\n    - host: orchestrator.local\n      paths:\n        - path: /\n          pathType: Prefix\n\ntolerations:\n  - key: node-role.kubernetes.io/control-plane\n    operator: Exists\n    effect: NoSchedule\nEOF\n```\n\n#### Step 3: Deploy with Helm\n\n```bash\n# Install the Helm chart (this will take over management of existing resources)\nhelm install orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --values orchestrator-values.yaml\n\n# Verify deployment\nkubectl get pods -n orchestrator\nkubectl logs -n orchestrator deployment/orchestrator\n```\n\n#### Step 4: Cleanup Old Resources (if needed)\n\n```bash\n# Check for any orphaned resources\nkubectl get all -n orchestrator\n\n# Remove any old manually created resources that aren't managed by Helm\n# (The Helm chart should adopt most existing resources)\n```\n\n### Option 2: Fresh Deployment\n\nThis approach creates a new deployment alongside the old one, then switches traffic.\n\n#### Step 1: Deploy to New Namespace\n\n```bash\n# Create a custom values file with your configuration\ncat > orchestrator-prod-values.yaml << EOF\nsecrets:\n  anthropicApiKey: \"your-anthropic-api-key\"\n  githubToken: \"your-github-token\"\ningress:\n  enabled: true\n  hosts:\n    - host: orchestrator.yourdomain.com\nEOF\n# Edit the file with additional configuration as needed\n\n# Deploy to new namespace\nhelm install orchestrator-new ./infra/orchestrator-chart \\\n  --namespace orchestrator-new \\\n  --create-namespace \\\n  --values orchestrator-prod-values.yaml\n```\n\n#### Step 2: Test New Deployment\n\n```bash\n# Test the new deployment\nkubectl port-forward -n orchestrator-new svc/orchestrator 8080:80\ncurl http://localhost:8080/health\n\n# Test Claude Code deployment functionality\n# (Submit a test task to verify the orchestrator can deploy agents)\n```\n\n#### Step 3: Switch Traffic\n\n```bash\n# Update ingress or load balancer to point to new service\n# Or scale down old deployment and rename new one\n\n# Scale down old deployment\nkubectl scale deployment orchestrator --replicas=0 -n orchestrator\n\n# Verify new deployment is working\nkubectl get pods -n orchestrator-new\n```\n\n#### Step 4: Cleanup Old Deployment\n\n```bash\n# Remove old resources\nkubectl delete namespace orchestrator\n\n# Rename new namespace (optional)\n# This requires recreating resources, so consider keeping the new namespace name\n```\n\n## Deployment Verification\n\n### Health Checks\n\n```bash\n# Check pod status\nkubectl get pods -n orchestrator -l app.kubernetes.io/name=orchestrator\n\n# Check health endpoint\nkubectl port-forward -n orchestrator svc/orchestrator 8080:80\ncurl http://localhost:8080/health\n\n# Check via ingress (if configured)\ncurl http://orchestrator.local/health\n```\n\n### Configuration Verification\n\n```bash\n# Verify ConfigMap\nkubectl get configmap -n orchestrator -l app.kubernetes.io/name=orchestrator\n\n# Verify Secret (without exposing values)\nkubectl get secret -n orchestrator -l app.kubernetes.io/name=orchestrator\n\n# Verify RBAC\nkubectl auth can-i create jobs --as=system:serviceaccount:orchestrator:orchestrator -n orchestrator\nkubectl auth can-i create configmaps --as=system:serviceaccount:orchestrator:orchestrator -n orchestrator\n```\n\n### Claude Code Chart Verification\n\n```bash\n# Verify the Claude Code chart is mounted\nkubectl exec -n orchestrator deployment/orchestrator -- ls -la /infra/claude-code/\n\n# Check chart files\nkubectl exec -n orchestrator deployment/orchestrator -- cat /infra/claude-code/Chart.yaml\n```\n\n## Monitoring and Logging\n\n### Logs\n\n```bash\n# View orchestrator logs\nkubectl logs -n orchestrator -l app.kubernetes.io/name=orchestrator -f\n\n# View previous logs (if pod restarted)\nkubectl logs -n orchestrator -l app.kubernetes.io/name=orchestrator --previous\n```\n\n### Metrics\n\n```bash\n# If metrics are enabled, check metrics endpoint\nkubectl port-forward -n orchestrator svc/orchestrator 8080:80\ncurl http://localhost:8080/metrics\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Pod not starting**\n   ```bash\n   kubectl describe pod -n orchestrator -l app.kubernetes.io/name=orchestrator\n   kubectl logs -n orchestrator -l app.kubernetes.io/name=orchestrator\n   ```\n\n2. **RBAC permissions**\n   ```bash\n   kubectl auth can-i create jobs --as=system:serviceaccount:orchestrator:orchestrator -n orchestrator\n   ```\n\n3. **ConfigMap/Secret issues**\n   ```bash\n   kubectl get configmap,secret -n orchestrator\n   kubectl describe configmap orchestrator-config -n orchestrator\n   ```\n\n4. **Ingress not working**\n   ```bash\n   kubectl get ingress -n orchestrator\n   kubectl describe ingress orchestrator -n orchestrator\n   ```\n\n### Recovery Procedures\n\nIf something goes wrong during migration:\n\n```bash\n# Rollback Helm release\nhelm rollback orchestrator -n orchestrator\n\n# Or restore from backup\nkubectl apply -f backup-config.yaml\nkubectl apply -f backup-secrets.yaml\n\n# Scale up original deployment if it was scaled down\nkubectl scale deployment orchestrator --replicas=1 -n orchestrator\n```\n\n## Maintenance\n\n### Updating the Orchestrator\n\n```bash\n# Update image tag\nhelm upgrade orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --set image.tag=\"v1.1.0\" \\\n  --reuse-values\n\n# Update configuration\nhelm upgrade orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --values updated-values.yaml\n```\n\n### Backup and Restore\n\n```bash\n# Backup Helm values\nhelm get values orchestrator -n orchestrator > orchestrator-backup-values.yaml\n\n# Backup all resources\nkubectl get all,configmap,secret,ingress -n orchestrator -o yaml > orchestrator-backup.yaml\n\n# Restore if needed\nhelm install orchestrator ./infra/orchestrator-chart \\\n  --namespace orchestrator \\\n  --values orchestrator-backup-values.yaml\n```\n\n## Security Considerations\n\n1. **API Keys**: Store in Kubernetes secrets, never in values files\n2. **RBAC**: Use namespaced roles when possible\n3. **Network Policies**: Consider implementing network policies for pod-to-pod communication\n4. **Image Security**: Use specific image tags, not `latest` in production\n5. **TLS**: Enable TLS for ingress in production environments\n\n## Performance Tuning\n\n1. **Resources**: Adjust CPU/memory limits based on workload\n2. **Replicas**: Consider running multiple replicas for high availability\n3. **Storage**: Use fast storage classes for per-service workspace PVCs\n4. **Node Affinity**: Pin orchestrator to specific nodes if needed"
        },
        {
          "path": "orchestrator/templates/deployment.yaml",
          "file_type": "yaml",
          "line_count": 120,
          "key_definitions": [],
          "content": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nspec:\n  {{- if not .Values.autoscaling.enabled }}\n  replicas: {{ .Values.replicaCount }}\n  {{- end }}\n  selector:\n    matchLabels:\n      {{- include \"orchestrator.selectorLabels\" . | nindent 6 }}\n  template:\n    metadata:\n      annotations:\n        # Force pod restart when claude-templates ConfigMap changes\n        claude-templates/checksum: {{ include (print $.Template.BasePath \"/claude-templates-configmap.yaml\") . | sha256sum }}\n        # Force pod restart when controller config changes\n        controller-config/checksum: {{ include (print $.Template.BasePath \"/task-controller-config.yaml\") . | sha256sum }}\n        {{- with .Values.podAnnotations }}\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      labels:\n        {{- include \"orchestrator.selectorLabels\" . | nindent 8 }}\n    spec:\n      {{- with .Values.imagePullSecrets }}\n      imagePullSecrets:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      serviceAccountName: {{ include \"orchestrator.serviceAccountName\" . }}\n      securityContext:\n        {{- toYaml .Values.podSecurityContext | nindent 8 }}\n      containers:\n        - name: {{ .Chart.Name }}\n          securityContext:\n            {{- toYaml .Values.securityContext | nindent 12 }}\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n          imagePullPolicy: {{ .Values.image.pullPolicy }}\n          command: [\"/app/orchestrator\"]\n          ports:\n            - name: {{ .Values.service.name }}\n              containerPort: {{ .Values.service.targetPort }}\n              protocol: TCP\n          env:\n            # Kubernetes configuration\n            - name: KUBERNETES_NAMESPACE\n              valueFrom:\n                configMapKeyRef:\n                  name: {{ include \"orchestrator.fullname\" . }}-config\n                  key: KUBERNETES_NAMESPACE\n            - name: RUST_LOG\n              valueFrom:\n                configMapKeyRef:\n                  name: {{ include \"orchestrator.fullname\" . }}-config\n                  key: RUST_LOG\n            # Secrets for agents\n            {{- if .Values.secrets.anthropicApiKey }}\n            - name: ANTHROPIC_API_KEY\n              valueFrom:\n                secretKeyRef:\n                  {{- if eq .Values.secrets.anthropicApiKey \"use-existing\" }}\n                  name: orchestrator-secrets\n                  {{- else }}\n                  name: {{ include \"orchestrator.fullname\" . }}-secrets\n                  {{- end }}\n                  key: ANTHROPIC_API_KEY\n            {{- end }}\n          volumeMounts:\n            # Mount claude templates ConfigMap\n            - name: claude-templates\n              mountPath: /claude-templates\n              readOnly: true\n            # Mount controller configuration ConfigMap\n            - name: controller-config\n              mountPath: /config\n              readOnly: true\n          {{- if .Values.healthCheck.enabled }}\n          livenessProbe:\n            httpGet:\n              path: {{ .Values.healthCheck.path }}\n              port: {{ .Values.service.name }}\n            initialDelaySeconds: {{ .Values.healthCheck.livenessProbe.initialDelaySeconds }}\n            periodSeconds: {{ .Values.healthCheck.livenessProbe.periodSeconds }}\n            timeoutSeconds: {{ .Values.healthCheck.livenessProbe.timeoutSeconds }}\n            successThreshold: {{ .Values.healthCheck.livenessProbe.successThreshold }}\n            failureThreshold: {{ .Values.healthCheck.livenessProbe.failureThreshold }}\n          readinessProbe:\n            httpGet:\n              path: {{ .Values.healthCheck.path }}\n              port: {{ .Values.service.name }}\n            initialDelaySeconds: {{ .Values.healthCheck.readinessProbe.initialDelaySeconds }}\n            periodSeconds: {{ .Values.healthCheck.readinessProbe.periodSeconds }}\n            timeoutSeconds: {{ .Values.healthCheck.readinessProbe.timeoutSeconds }}\n            successThreshold: {{ .Values.healthCheck.readinessProbe.successThreshold }}\n            failureThreshold: {{ .Values.healthCheck.readinessProbe.failureThreshold }}\n          {{- end }}\n          resources:\n            {{- toYaml .Values.resources | nindent 12 }}\n      volumes:\n        # Mount claude templates ConfigMap\n        - name: claude-templates\n          configMap:\n            name: {{ include \"orchestrator.fullname\" . }}-claude-templates\n        # Mount controller configuration ConfigMap\n        - name: controller-config\n          configMap:\n            name: {{ include \"orchestrator.fullname\" . }}-task-controller-config\n      {{- with .Values.nodeSelector }}\n      nodeSelector:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.affinity }}\n      affinity:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.tolerations }}\n      tolerations:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}"
        },
        {
          "path": "orchestrator/templates/ingress.yaml",
          "file_type": "yaml",
          "line_count": 59,
          "key_definitions": [],
          "content": "{{- if .Values.ingress.enabled -}}\n{{- $fullName := include \"orchestrator.fullname\" . -}}\n{{- $svcPort := .Values.service.port -}}\n{{- if and .Values.ingress.className (not (hasKey .Values.ingress.annotations \"kubernetes.io/ingress.class\")) }}\n  {{- $_ := set .Values.ingress.annotations \"kubernetes.io/ingress.class\" .Values.ingress.className}}\n{{- end }}\n{{- if semverCompare \">=1.19-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1\n{{- else if semverCompare \">=1.14-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1beta1\n{{- else -}}\napiVersion: extensions/v1beta1\n{{- end }}\nkind: Ingress\nmetadata:\n  name: {{ $fullName }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\n  {{- with .Values.ingress.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  {{- if and .Values.ingress.className (semverCompare \">=1.18-0\" .Capabilities.KubeVersion.GitVersion) }}\n  ingressClassName: {{ .Values.ingress.className }}\n  {{- end }}\n  {{- if .Values.ingress.tls }}\n  tls:\n    {{- range .Values.ingress.tls }}\n    - hosts:\n        {{- range .hosts }}\n        - {{ . | quote }}\n        {{- end }}\n      secretName: {{ .secretName }}\n    {{- end }}\n  {{- end }}\n  rules:\n    {{- range .Values.ingress.hosts }}\n    - host: {{ .host | quote }}\n      http:\n        paths:\n          {{- range .paths }}\n          - path: {{ .path }}\n            {{- if and .pathType (semverCompare \">=1.18-0\" $.Capabilities.KubeVersion.GitVersion) }}\n            pathType: {{ .pathType }}\n            {{- end }}\n            backend:\n              {{- if semverCompare \">=1.19-0\" $.Capabilities.KubeVersion.GitVersion }}\n              service:\n                name: {{ $fullName }}\n                port:\n                  number: {{ $svcPort }}\n              {{- else }}\n              serviceName: {{ $fullName }}\n              servicePort: {{ $svcPort }}\n              {{- end }}\n          {{- end }}\n    {{- end }}\n{{- end }}"
        },
        {
          "path": "orchestrator/templates/service.yaml",
          "file_type": "yaml",
          "line_count": 15,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nspec:\n  type: {{ .Values.service.type }}\n  ports:\n    - port: {{ .Values.service.port }}\n      targetPort: {{ .Values.service.name }}\n      protocol: TCP\n      name: {{ .Values.service.name }}\n  selector:\n    {{- include \"orchestrator.selectorLabels\" . | nindent 4 }}"
        },
        {
          "path": "orchestrator/templates/task-controller-config.yaml",
          "file_type": "yaml",
          "line_count": 76,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-task-controller-config\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ndata:\n  config.yaml: |\n    # Task Controller Configuration\n    # Simplified configuration for CodeRun and DocsRun controllers\n\n    # Job configuration\n    job:\n      activeDeadlineSeconds: 3600  # 1 hour timeout\n\n    # Claude agent configuration\n    agent:\n      image:\n        repository: {{ .Values.agent.image.repository | quote }}\n        tag: {{ .Values.agent.image.tag | quote }}\n      imagePullSecrets:\n        {{- range .Values.imagePullSecrets }}\n        - {{ .name | quote }}\n        {{- end }}\n\n    # Secrets configuration (references Kubernetes secrets)\n    secrets:\n      apiKeySecretName: \"{{ include \"orchestrator.fullname\" . }}-secrets\"\n      apiKeySecretKey: \"ANTHROPIC_API_KEY\"\n\n    # Tool permissions configuration (only used when agentToolsOverride=true)\n    # When false: uses hardcoded list in settings.json.hbs template\n    # When true: uses this configuration\n    permissions:\n      agentToolsOverride: false\n      allow:\n        - \"Bash\"\n        - \"Edit\"\n        - \"Read\"\n        - \"Write\"\n        - \"MultiEdit\"\n        - \"Glob\"\n        - \"Grep\"\n        - \"LS\"\n        - \"Task\"\n        - \"ExitPlanMode\"\n        - \"NotebookRead\"\n        - \"NotebookEdit\"\n        - \"WebFetch\"\n        - \"WebSearch\"\n        - \"TodoRead\"\n        - \"TodoWrite\"\n      deny: []\n\n    # Telemetry configuration (used in templates)\n    telemetry:\n      enabled: true\n      otlpEndpoint: \"otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317\"\n      otlpProtocol: \"grpc\"\n      logsEndpoint: \"otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317\"\n      logsProtocol: \"grpc\"\n\n    # Storage configuration\n    storage:\n      {{- if .Values.storage.storageClassName }}\n      storageClassName: {{ .Values.storage.storageClassName | quote }}\n      {{- end }}\n      workspaceSize: {{ .Values.storage.workspaceSize | default \"10Gi\" | quote }}\n\n    # Cleanup configuration (event-driven cleanup by controller)\n    cleanup:\n      enabled: {{ .Values.cleanup.enabled | default true }}\n      completedJobDelayMinutes: {{ .Values.cleanup.completedJobDelayMinutes | default 5 }}\n      failedJobDelayMinutes: {{ .Values.cleanup.failedJobDelayMinutes | default 60 }}\n      deleteConfigMap: {{ .Values.cleanup.deleteConfigMap | default true }}"
        },
        {
          "path": "orchestrator/templates/rbac.yaml",
          "file_type": "yaml",
          "line_count": 51,
          "key_definitions": [],
          "content": "{{- if .Values.rbac.create -}}\n{{- if .Values.rbac.namespaced }}\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nrules:\n{{- toYaml .Values.rbac.rules | nindent 2 }}\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: {{ include \"orchestrator.roleName\" . }}\nsubjects:\n- kind: ServiceAccount\n  name: {{ include \"orchestrator.serviceAccountName\" . }}\n  namespace: {{ .Release.Namespace }}\n{{- else }}\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nrules:\n{{- toYaml .Values.rbac.rules | nindent 2 }}\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: {{ include \"orchestrator.roleName\" . }}\nsubjects:\n- kind: ServiceAccount\n  name: {{ include \"orchestrator.serviceAccountName\" . }}\n  namespace: {{ .Release.Namespace }}\n{{- end }}\n{{- end }}"
        },
        {
          "path": "orchestrator/templates/claude-templates-configmap.yaml",
          "file_type": "yaml",
          "line_count": 12,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-claude-templates\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ndata:\n{{- range $path, $content := .Files.Glob \"claude-templates/**/*.hbs\" }}\n  {{ $path | trimPrefix \"claude-templates/\" | replace \"/\" \"_\" }}: |\n{{ $.Files.Get $path | nindent 4 }}\n{{- end }}"
        },
        {
          "path": "orchestrator/templates/serviceaccount.yaml",
          "file_type": "yaml",
          "line_count": 12,
          "key_definitions": [],
          "content": "{{- if .Values.serviceAccount.create -}}\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: {{ include \"orchestrator.serviceAccountName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\n  {{- with .Values.serviceAccount.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\n{{- end }}"
        },
        {
          "path": "orchestrator/templates/configmap.yaml",
          "file_type": "yaml",
          "line_count": 13,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-config\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ndata:\n  KUBERNETES_NAMESPACE: {{ .Values.config.kubernetesNamespace | quote }}\n  SERVER_HOST: {{ .Values.config.serverHost | quote }}\n  SERVER_PORT: {{ .Values.config.serverPort | quote }}\n  RUST_LOG: {{ .Values.config.rustLog | quote }}\n  DEFAULT_DOCS_MODEL: {{ .Values.models.defaultDocsModel | quote }}\n  DEFAULT_CODE_MODEL: {{ .Values.models.defaultCodeModel | quote }}"
        },
        {
          "path": "orchestrator/templates/secret.yaml",
          "file_type": "yaml",
          "line_count": 13,
          "key_definitions": [],
          "content": "{{- if and .Values.secrets.anthropicApiKey (ne .Values.secrets.anthropicApiKey \"use-existing\") }}\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-secrets\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ntype: Opaque\nstringData:\n  {{- if .Values.secrets.anthropicApiKey }}\n  ANTHROPIC_API_KEY: {{ .Values.secrets.anthropicApiKey | quote }}\n  {{- end }}\n{{- end }}"
        },
        {
          "path": "orchestrator/values.yaml",
          "file_type": "yaml",
          "line_count": 199,
          "key_definitions": [],
          "content": "# Default values for orchestrator.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nreplicaCount: 1\n\nimage:\n  repository: ghcr.io/5dlabs/platform/orchestrator\n  pullPolicy: Always\n  # Overrides the image tag whose default is the chart appVersion.\n  tag: \"latest\"\n\n# Agent/Task Runner image configuration (used by controller to create Jobs)\nagent:\n  image:\n    repository: ghcr.io/5dlabs/platform/claude-code\n    tag: \"1.0.56\"\n    pullPolicy: Always\n\n# Storage configuration for workspace PVCs\nstorage:\n  # Storage class name (e.g., \"local-path\" for local development, leave empty for default)\n  storageClassName: \"local-path\"\n  # Size of workspace PVCs\n  workspaceSize: \"10Gi\"\n\n# Cleanup configuration (controller-based event-driven cleanup)\ncleanup:\n  # Whether to enable automatic cleanup of completed jobs\n  enabled: true\n  # Minutes to wait before cleaning up successful jobs (default: 5 minutes)\n  completedJobDelayMinutes: 5\n  # Minutes to wait before cleaning up failed jobs (default: 60 minutes)\n  failedJobDelayMinutes: 60\n  # Whether to delete associated ConfigMaps when cleaning up jobs\n  deleteConfigMap: true\n\nimagePullSecrets:\n  - name: ghcr-secret\n\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: \"orchestrator\"\n\npodAnnotations:\n  kubectl.kubernetes.io/restartedAt: \"\"\n\npodSecurityContext:\n  fsGroup: 2000\n  runAsNonRoot: true\n  runAsUser: 1000\n\nsecurityContext:\n  allowPrivilegeEscalation: false\n  readOnlyRootFilesystem: false\n  runAsNonRoot: true\n  runAsUser: 1000\n  capabilities:\n    drop:\n    - ALL\n  seccompProfile:\n    type: RuntimeDefault\n\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 8080\n  name: http\n\ningress:\n  enabled: false\n  className: \"nginx\"\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n  hosts:\n    - host: orchestrator.local\n      paths:\n        - path: /\n          pathType: Prefix\n  tls: []\n\nresources:\n  limits:\n    cpu: 500m\n    memory: 512Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 100\n  targetCPUUtilizationPercentage: 80\n  # targetMemoryUtilizationPercentage: 80\n\nnodeSelector: {}\n\ntolerations:\n  - key: node-role.kubernetes.io/control-plane\n    operator: Exists\n    effect: NoSchedule\n\naffinity: {}\n\n# Configuration for the orchestrator service\nconfig:\n  # Kubernetes namespace (auto-populated in most cases)\n  kubernetesNamespace: \"orchestrator\"\n\n  # Server configuration\n  serverHost: \"0.0.0.0\"\n  serverPort: \"8080\"\n\n  # Logging\n  rustLog: \"orchestrator=debug,tower_http=debug,axum=debug,kube=info\"\n\n# Default model configurations\nmodels:\n  # Default model for documentation generation\n  defaultDocsModel: \"claude-opus-4-20250514\"\n  # Default model for code tasks\n  defaultCodeModel: \"claude-sonnet-4-20250514\"\n\n# Secret configuration for API keys\nsecrets:\n  # REQUIRED: Set your Anthropic API key\n  anthropicApiKey: \"\"\n  # Note: GitHub secrets (SSH keys + tokens) are managed externally per agent\n  # See infra/scripts/setup-agent-secrets.sh for setup instructions\n\n# RBAC configuration\nrbac:\n  # Create RBAC resources\n  create: true\n  # Use Role/RoleBinding (true) or ClusterRole/ClusterRoleBinding (false)\n  namespaced: true\n  rules:\n    # CodeRun and DocsRun CRD management\n    - apiGroups: [\"orchestrator.platform\"]\n      resources: [\"coderuns\", \"docsruns\"]\n      verbs: [\"create\", \"get\", \"list\", \"watch\", \"update\", \"patch\", \"delete\"]\n    - apiGroups: [\"orchestrator.platform\"]\n      resources: [\"coderuns/status\", \"docsruns/status\"]\n      verbs: [\"get\", \"update\", \"patch\"]\n    # Job management in orchestrator namespace\n    - apiGroups: [\"batch\"]\n      resources: [\"jobs\"]\n      verbs: [\"create\", \"get\", \"list\", \"watch\", \"delete\", \"patch\", \"update\"]\n    # ConfigMap and Secret access (for agent configuration and task files)\n    - apiGroups: [\"\"]\n      resources: [\"configmaps\", \"secrets\"]\n      verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\", \"watch\", \"patch\"]\n    # ServiceAccount management (required for Helm operations)\n    - apiGroups: [\"\"]\n      resources: [\"serviceaccounts\"]\n      verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\", \"patch\"]\n    # Service management (required for Helm operations)\n    - apiGroups: [\"\"]\n      resources: [\"services\"]\n      verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\", \"patch\"]\n    # Pod monitoring\n    - apiGroups: [\"\"]\n      resources: [\"pods\", \"pods/log\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n    # PVC management for agent workspaces\n    - apiGroups: [\"\"]\n      resources: [\"persistentvolumeclaims\"]\n      verbs: [\"create\", \"get\", \"list\", \"delete\"]\n    # Events for debugging\n    - apiGroups: [\"\"]\n      resources: [\"events\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n\n# Health checks\nhealthCheck:\n  enabled: true\n  path: \"/health\"\n  port: 8080\n  livenessProbe:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n  readinessProbe:\n    initialDelaySeconds: 10\n    periodSeconds: 30\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n"
        }
      ],
      "dependencies": [],
      "description": "helm-charts configuration and files",
      "line_count": 1739
    },
    {
      "name": "kubernetes-config",
      "path": "infra/cluster-config",
      "component_type": "KubernetesConfig",
      "source_files": [
        {
          "path": "otel-collector-metrics-service.yaml",
          "file_type": "yaml",
          "line_count": 18,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: otel-collector-metrics\n  namespace: telemetry\n  labels:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector\nspec:\n  type: ClusterIP\n  ports:\n  - name: metrics\n    port: 8890\n    targetPort: 8890\n    protocol: TCP\n  selector:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector"
        },
        {
          "path": "otel-prometheus-service.yaml",
          "file_type": "yaml",
          "line_count": 22,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: otel-collector-metrics\n  namespace: telemetry\n  labels:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector\nspec:\n  type: ClusterIP\n  ports:\n    - name: prometheus\n      port: 8889\n      targetPort: 8889\n      protocol: TCP\n    - name: internal-metrics\n      port: 8890\n      targetPort: 8890\n      protocol: TCP\n  selector:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector"
        },
        {
          "path": "local-path-config-patch.yaml",
          "file_type": "yaml",
          "line_count": 44,
          "key_definitions": [],
          "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: local-path-config\n  namespace: local-path-storage\ndata:\n  config.json: |-\n    {\n            \"nodePathMap\":[\n            {\n                    \"node\":\"DEFAULT_PATH_FOR_NON_LISTED_NODES\",\n                    \"paths\":[\"/var/mnt/local-path-provisioner\"]\n            }\n            ]\n    }\n  helperPod.yaml: |-\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: helper-pod\n    spec:\n      priorityClassName: system-node-critical\n      tolerations:\n        - key: node.kubernetes.io/disk-pressure\n          operator: Exists\n          effect: NoSchedule\n      securityContext:\n        fsGroup: 0\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: helper-pod\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n  setup: |-\n    #!/bin/sh\n    set -eu\n    mkdir -m 0777 -p \"$VOL_DIR\"\n  teardown: |-\n    #!/bin/sh\n    set -eu\n    rm -rf \"$VOL_DIR\""
        },
        {
          "path": "talos-local-path-volume.yaml",
          "file_type": "yaml",
          "line_count": 8,
          "key_definitions": [],
          "content": "apiVersion: v1alpha1\nkind: UserVolumeConfig\nname: local-path-provisioner\nprovisioning:\n  diskSelector:\n    match: \"!system_disk\"\n  minSize: 100GB\n  maxSize: 100GB"
        }
      ],
      "dependencies": [],
      "description": "kubernetes-config configuration and files",
      "line_count": 92
    },
    {
      "name": "scripts",
      "path": "infra/scripts",
      "component_type": "Scripts",
      "source_files": [
        {
          "path": "configure-grafana-alerts.sh",
          "file_type": "sh",
          "line_count": 238,
          "key_definitions": [],
          "content": "#!/bin/bash\nset -e\n\n# Grafana API configuration\nGRAFANA_URL=\"http://localhost:3000\"\nGRAFANA_USER=\"admin\"\nGRAFANA_PASS=\"admin123!\"\n\n# Wait for Grafana to be ready\necho \"Waiting for Grafana to be ready...\"\nuntil curl -s \"${GRAFANA_URL}/api/health\" > /dev/null; do\n    echo \"Grafana not ready yet, waiting...\"\n    sleep 5\ndone\n\necho \"Grafana is ready. Configuring alerts...\"\n\n# Create folder for Claude Code alerts if it doesn't exist\nFOLDER_RESPONSE=$(curl -s -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -u \"${GRAFANA_USER}:${GRAFANA_PASS}\" \\\n  -d '{\"title\":\"Claude Code Alerts\",\"uid\":\"claude-code-alerts\"}' \\\n  \"${GRAFANA_URL}/api/folders\" 2>/dev/null || true)\n\n# Get folder UID\nFOLDER_UID=$(echo \"$FOLDER_RESPONSE\" | jq -r '.uid // \"claude-code-alerts\"')\n\n# Convert Prometheus alerting rules to Grafana unified alerting format\n# This is a simplified example - in production you'd want a more robust converter\n\n# Alert 1: High API Error Rate\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -u \"${GRAFANA_USER}:${GRAFANA_PASS}\" \\\n  -d '{\n    \"uid\": \"claude-code-high-error-rate\",\n    \"title\": \"Claude Code High Error Rate\",\n    \"condition\": \"A\",\n    \"data\": [\n      {\n        \"refId\": \"A\",\n        \"queryType\": \"\",\n        \"relativeTimeRange\": {\n          \"from\": 300,\n          \"to\": 0\n        },\n        \"datasourceUid\": \"VictoriaMetrics\",\n        \"model\": {\n          \"expr\": \"(sum(rate(claude_code_api_error[5m])) by (github_user, working_service) / sum(rate(claude_code_api_request[5m])) by (github_user, working_service)) * 100\",\n          \"refId\": \"A\",\n          \"interval\": \"\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"VictoriaMetrics\"\n          }\n        }\n      }\n    ],\n    \"noDataState\": \"NoData\",\n    \"execErrState\": \"Alerting\",\n    \"for\": \"5m\",\n    \"annotations\": {\n      \"summary\": \"High API error rate for Claude Code\",\n      \"description\": \"Error rate is above 5% threshold\"\n    },\n    \"labels\": {\n      \"severity\": \"warning\",\n      \"component\": \"claude-code\"\n    },\n    \"folderUID\": \"'\"${FOLDER_UID}\"'\"\n  }' \\\n  \"${GRAFANA_URL}/api/v1/provisioning/alert-rules\" || echo \"Alert rule already exists or error creating\"\n\n# Alert 2: High User Spend\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -u \"${GRAFANA_USER}:${GRAFANA_PASS}\" \\\n  -d '{\n    \"uid\": \"claude-code-high-user-spend\",\n    \"title\": \"Claude Code High User Spend\",\n    \"condition\": \"A\",\n    \"data\": [\n      {\n        \"refId\": \"A\",\n        \"queryType\": \"\",\n        \"relativeTimeRange\": {\n          \"from\": 3600,\n          \"to\": 0\n        },\n        \"datasourceUid\": \"VictoriaMetrics\",\n        \"model\": {\n          \"expr\": \"sum(increase(claude_code_cost_usage[1h])) by (github_user, working_service)\",\n          \"refId\": \"A\",\n          \"interval\": \"\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"VictoriaMetrics\"\n          }\n        }\n      }\n    ],\n    \"noDataState\": \"NoData\",\n    \"execErrState\": \"Alerting\",\n    \"for\": \"5m\",\n    \"annotations\": {\n      \"summary\": \"High spending detected\",\n      \"description\": \"User spending over $100/hour\"\n    },\n    \"labels\": {\n      \"severity\": \"warning\",\n      \"component\": \"claude-code\",\n      \"cost_alert\": \"true\"\n    },\n    \"folderUID\": \"'\"${FOLDER_UID}\"'\"\n  }' \\\n  \"${GRAFANA_URL}/api/v1/provisioning/alert-rules\" || echo \"Alert rule already exists or error creating\"\n\n# Alert 3: Component Down\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -u \"${GRAFANA_USER}:${GRAFANA_PASS}\" \\\n  -d '{\n    \"uid\": \"telemetry-component-down\",\n    \"title\": \"Telemetry Component Down\",\n    \"condition\": \"A\",\n    \"data\": [\n      {\n        \"refId\": \"A\",\n        \"queryType\": \"\",\n        \"relativeTimeRange\": {\n          \"from\": 300,\n          \"to\": 0\n        },\n        \"datasourceUid\": \"VictoriaMetrics\",\n        \"model\": {\n          \"expr\": \"up{namespace=\\\"telemetry\\\"}\",\n          \"refId\": \"A\",\n          \"interval\": \"\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"VictoriaMetrics\"\n          }\n        }\n      }\n    ],\n    \"noDataState\": \"Alerting\",\n    \"execErrState\": \"Alerting\",\n    \"for\": \"2m\",\n    \"annotations\": {\n      \"summary\": \"Telemetry component is down\",\n      \"description\": \"One or more telemetry components are not responding\"\n    },\n    \"labels\": {\n      \"severity\": \"critical\",\n      \"component\": \"infrastructure\"\n    },\n    \"folderUID\": \"'\"${FOLDER_UID}\"'\"\n  }' \\\n  \"${GRAFANA_URL}/api/v1/provisioning/alert-rules\" || echo \"Alert rule already exists or error creating\"\n\n# Alert 4: High Memory Usage\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -u \"${GRAFANA_USER}:${GRAFANA_PASS}\" \\\n  -d '{\n    \"uid\": \"high-memory-usage\",\n    \"title\": \"High Memory Usage\",\n    \"condition\": \"A\",\n    \"data\": [\n      {\n        \"refId\": \"A\",\n        \"queryType\": \"\",\n        \"relativeTimeRange\": {\n          \"from\": 300,\n          \"to\": 0\n        },\n        \"datasourceUid\": \"VictoriaMetrics\",\n        \"model\": {\n          \"expr\": \"(container_memory_working_set_bytes{namespace=\\\"telemetry\\\",container!=\\\"\\\"} / container_spec_memory_limit_bytes{namespace=\\\"telemetry\\\",container!=\\\"\\\"}) * 100\",\n          \"refId\": \"A\",\n          \"interval\": \"\",\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"VictoriaMetrics\"\n          }\n        }\n      }\n    ],\n    \"noDataState\": \"NoData\",\n    \"execErrState\": \"Alerting\",\n    \"for\": \"5m\",\n    \"annotations\": {\n      \"summary\": \"High memory usage detected\",\n      \"description\": \"Container memory usage is above 80%\"\n    },\n    \"labels\": {\n      \"severity\": \"warning\",\n      \"component\": \"infrastructure\"\n    },\n    \"folderUID\": \"'\"${FOLDER_UID}\"'\"\n  }' \\\n  \"${GRAFANA_URL}/api/v1/provisioning/alert-rules\" || echo \"Alert rule already exists or error creating\"\n\n# Create notification policy (route alerts to default contact point)\ncurl -X PUT \\\n  -H \"Content-Type: application/json\" \\\n  -u \"${GRAFANA_USER}:${GRAFANA_PASS}\" \\\n  -d '{\n    \"receiver\": \"grafana-default-email\",\n    \"group_by\": [\"alertname\", \"cluster\", \"service\"],\n    \"group_wait\": \"30s\",\n    \"group_interval\": \"5m\",\n    \"repeat_interval\": \"12h\",\n    \"routes\": [\n      {\n        \"receiver\": \"grafana-default-email\",\n        \"matchers\": [\n          \"severity=critical\"\n        ],\n        \"continue\": true,\n        \"group_wait\": \"10s\",\n        \"group_interval\": \"2m\",\n        \"repeat_interval\": \"1h\"\n      },\n      {\n        \"receiver\": \"grafana-default-email\",\n        \"matchers\": [\n          \"cost_alert=true\"\n        ],\n        \"continue\": true,\n        \"group_interval\": \"5m\",\n        \"repeat_interval\": \"4h\"\n      }\n    ]\n  }' \\\n  \"${GRAFANA_URL}/api/v1/provisioning/policies\" || echo \"Notification policy already exists or error creating\"\n\necho \"Alert configuration complete!\""
        },
        {
          "path": "test-telemetry-pipeline.sh",
          "file_type": "sh",
          "line_count": 84,
          "key_definitions": [],
          "content": "#\\!/bin/bash\n\necho \"Testing telemetry pipeline...\"\n\n# Test metrics via OTLP HTTP\necho \"Sending test metrics...\"\ncurl -X POST http://otel-http.local:31251/v1/metrics \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceMetrics\": [{\n      \"resource\": {\n        \"attributes\": [{\n          \"key\": \"service.name\",\n          \"value\": {\"stringValue\": \"claude-code-test\"}\n        }]\n      },\n      \"scopeMetrics\": [{\n        \"scope\": {\n          \"name\": \"test.metrics\"\n        },\n        \"metrics\": [{\n          \"name\": \"claude_code_sessions_total\",\n          \"description\": \"Test session counter\",\n          \"sum\": {\n            \"dataPoints\": [{\n              \"attributes\": [{\n                \"key\": \"user_id\",\n                \"value\": {\"stringValue\": \"test-user-1\"}\n              }],\n              \"startTimeUnixNano\": \"'\"$(date -u +%s)000000000\"'\",\n              \"timeUnixNano\": \"'\"$(date -u +%s)000000000\"'\",\n              \"asInt\": \"1\"\n            }],\n            \"aggregationTemporality\": 2,\n            \"isMonotonic\": true\n          }\n        }]\n      }]\n    }]\n  }'\n\necho \"\"\necho \"Sending test logs...\"\ncurl -X POST http://otel-http.local:31251/v1/logs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceLogs\": [{\n      \"resource\": {\n        \"attributes\": [{\n          \"key\": \"service.name\",\n          \"value\": {\"stringValue\": \"claude-code\"}\n        },{\n          \"key\": \"app\",\n          \"value\": {\"stringValue\": \"claude-code\"}\n        }]\n      },\n      \"scopeLogs\": [{\n        \"scope\": {\n          \"name\": \"test.logs\"\n        },\n        \"logRecords\": [{\n          \"timeUnixNano\": \"'\"$(date -u +%s)000000000\"'\",\n          \"severityNumber\": 9,\n          \"severityText\": \"INFO\",\n          \"body\": {\n            \"stringValue\": \"{\\\"timestamp\\\":\\\"'\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"'\\\",\\\"level\\\":\\\"info\\\",\\\"message\\\":\\\"Test log from telemetry pipeline\\\",\\\"user_id\\\":\\\"test-user-1\\\",\\\"action\\\":\\\"test\\\"}\"\n          },\n          \"attributes\": [{\n            \"key\": \"app\",\n            \"value\": {\"stringValue\": \"claude-code\"}\n          }]\n        }]\n      }]\n    }]\n  }'\n\necho \"\"\necho \"Test data sent successfully\\!\"\necho \"\"\necho \"You can now check:\"\necho \"1. Grafana dashboards at http://grafana.local:31251\"\necho \"2. VictoriaMetrics metrics at: http://grafana.local:31251/explore (select VictoriaMetrics datasource)\"\necho \"3. VictoriaLogs logs at: http://grafana.local:31251/explore (select VictoriaLogs datasource)\"\nEOF < /dev/null"
        },
        {
          "path": "test-all-dashboard-metrics.sh",
          "file_type": "sh",
          "line_count": 80,
          "key_definitions": [],
          "content": "#!/bin/bash\n\necho \"Testing all Claude Code dashboard metrics...\"\necho \"==========================================\"\n\n# Port forward to VictoriaMetrics\necho \"Setting up port-forward to VictoriaMetrics...\"\nkubectl port-forward -n telemetry statefulset/victoria-metrics-victoria-metrics-single-server 8428:8428 &\nPF_PID=$!\nsleep 3\n\n# Function to query metrics\nquery_metric() {\n    local metric=$1\n    local description=$2\n    echo \"\"\n    echo \"Checking: $description\"\n    echo \"Query: $metric\"\n    result=$(curl -s \"http://localhost:8428/api/v1/query?query=$metric\" | jq -r '.data.result | length')\n    if [ \"$result\" -gt 0 ]; then\n        echo \"✅ Found $result results\"\n        curl -s \"http://localhost:8428/api/v1/query?query=$metric\" | jq -r '.data.result[0]' | head -20\n    else\n        echo \"❌ No data found\"\n    fi\n}\n\necho \"\"\necho \"=== EXECUTIVE OVERVIEW DASHBOARD METRICS ===\"\nquery_metric \"sum(increase(claude_code_sessions_total[24h]))\" \"Total Sessions (24h)\"\nquery_metric \"count(count%20by%20(user_id)%20(claude_code_sessions_total))\" \"Daily Active Users\"\nquery_metric \"sum%20by%20(model)%20(increase(claude_code_token_cost_dollars_total[24h]))\" \"Cost Breakdown by Model\"\nquery_metric \"sum(increase(claude_code_token_cost_dollars_total[30d]))\" \"Monthly Cost\"\nquery_metric \"count(count%20by%20(user_id)%20(increase(claude_code_sessions_total[7d])))\" \"User Adoption Trend\"\nquery_metric \"topk(10,%20sum%20by%20(user_id)%20(increase(claude_code_token_cost_dollars_total[24h])))\" \"Top Users by Cost\"\n\necho \"\"\necho \"=== ENGINEERING METRICS DASHBOARD METRICS ===\"\nquery_metric \"sum%20by%20(language)%20(increase(claude_code_lines_modified_total[1h]))\" \"Lines of Code Modified by Language\"\nquery_metric \"sum(increase(claude_code_pull_requests_created_total[24h]))\" \"Pull Requests Created (24h)\"\nquery_metric \"sum(increase(claude_code_commits_total[24h]))\" \"Commits (24h)\"\nquery_metric \"sum%20by%20(tool_name)%20(increase(claude_code_tool_usage_total[24h]))\" \"Tool Usage Distribution\"\n\necho \"\"\necho \"=== OPERATIONS MONITORING DASHBOARD METRICS ===\"\nquery_metric \"up{job=\\\"otel-collector\\\"}\" \"OTLP Collector Health\"\nquery_metric \"up{job=\\\"victoria-metrics\\\"}\" \"VictoriaMetrics Health\"\nquery_metric \"rate(claude_code_api_errors_total[5m])%20/%20rate(claude_code_api_requests_total[5m])\" \"API Error Rate\"\nquery_metric \"histogram_quantile(0.95,%20sum(rate(claude_code_api_duration_bucket[5m]))%20by%20(le))\" \"API Response Time p95\"\n\necho \"\"\necho \"=== COST MANAGEMENT DASHBOARD METRICS ===\"\nquery_metric \"sum(increase(claude_code_token_cost_dollars_total[1h]))\" \"Current Hour Spend\"\nquery_metric \"sum(increase(claude_code_token_cost_dollars_total[1d]))\" \"Daily Cost Trend\"\nquery_metric \"sum%20by%20(model)%20(increase(claude_code_token_cost_dollars_total[24h]))\" \"Cost by Model (24h)\"\nquery_metric \"topk(10,%20sum%20by%20(user_id)%20(increase(claude_code_token_cost_dollars_total[7d])))\" \"User Cost Ranking (7d)\"\n\necho \"\"\necho \"=== CHECKING RAW METRICS ===\"\necho \"Looking for any metrics with 'claude' in the name...\"\ncurl -s \"http://localhost:8428/api/v1/label/__name__/values\" | jq -r '.data[]' | grep -i claude || echo \"No claude metrics found\"\n\necho \"\"\necho \"Looking for metrics with service_name='claude-code'...\"\ncurl -s \"http://localhost:8428/api/v1/query?query={service_name=\\\"claude-code\\\"}\" | jq -r '.data.result[].metric.__name__' 2>/dev/null | sort -u || echo \"No metrics with service_name=claude-code\"\n\necho \"\"\necho \"=== CHECKING OTLP COLLECTOR METRICS ===\"\nquery_metric \"otelcol_receiver_accepted_metric_points{receiver=\\\"otlp\\\"}\" \"OTLP Metrics Received\"\nquery_metric \"otelcol_receiver_accepted_log_records{receiver=\\\"otlp\\\"}\" \"OTLP Logs Received\"\nquery_metric \"otelcol_exporter_sent_metric_points{exporter=\\\"prometheusremotewrite\\\"}\" \"Metrics Sent to VictoriaMetrics\"\nquery_metric \"otelcol_exporter_sent_log_records{exporter=\\\"otlphttp/victorialogs\\\"}\" \"Logs Sent to VictoriaLogs\"\n\n# Clean up port-forward\necho \"\"\necho \"Cleaning up port-forward...\"\nkill $PF_PID 2>/dev/null\n\necho \"\"\necho \"Test complete!\""
        },
        {
          "path": "validate-telemetry-metrics.sh",
          "file_type": "sh",
          "line_count": 159,
          "key_definitions": [],
          "content": "#!/bin/bash\n# Telemetry Metrics Validation Script\n# Verifies that all expected Claude Code metrics are flowing to VictoriaMetrics\n\nset -e\n\n# Colors for output\nGREEN='\\033[0;32m'\nRED='\\033[0;31m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\nVICTORIA_METRICS_URL=\"http://localhost:8428\"\nFAILED_CHECKS=0\nTOTAL_CHECKS=0\n\necho -e \"${BLUE}=== Claude Code Telemetry Validation ===${NC}\"\necho \"Checking VictoriaMetrics at: $VICTORIA_METRICS_URL\"\necho \"\"\n\n# Function to check if a metric exists\ncheck_metric() {\n    local metric_name=\"$1\"\n    local description=\"$2\"\n    \n    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))\n    \n    echo -n \"Checking $description: \"\n    \n    # Query VictoriaMetrics for the metric\n    result=$(curl -s \"$VICTORIA_METRICS_URL/api/v1/query?query=${metric_name}\" | jq -r '.data.result | length')\n    \n    if [ \"$result\" != \"null\" ] && [ \"$result\" -gt 0 ]; then\n        echo -e \"${GREEN}✓ Found ($result series)${NC}\"\n        return 0\n    else\n        echo -e \"${RED}✗ Missing${NC}\"\n        FAILED_CHECKS=$((FAILED_CHECKS + 1))\n        return 1\n    fi\n}\n\n# Function to check log events in VictoriaLogs\ncheck_log_event() {\n    local event_pattern=\"$1\"\n    local description=\"$2\"\n    \n    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))\n    \n    echo -n \"Checking $description: \"\n    \n    # Query VictoriaLogs for the event\n    result=$(curl -s \"http://localhost:9428/select/logsql/query?query=${event_pattern}&limit=1\" | jq -r '. | length' 2>/dev/null || echo \"0\")\n    \n    if [ \"$result\" -gt 0 ]; then\n        echo -e \"${GREEN}✓ Found${NC}\"\n        return 0\n    else\n        echo -e \"${RED}✗ Missing${NC}\"\n        FAILED_CHECKS=$((FAILED_CHECKS + 1))\n        return 1\n    fi\n}\n\necho -e \"${YELLOW}=== Core Metrics (Required for all dashboards) ===${NC}\"\n\n# Essential metrics that should exist\ncheck_metric \"claude_code_session_count\" \"Session tracking\"\ncheck_metric \"claude_code_cost_usage\" \"Cost tracking\"\ncheck_metric \"claude_code_token_usage\" \"Token usage\"\n\necho \"\"\necho -e \"${YELLOW}=== Engineering Metrics Dashboard ===${NC}\"\n\n# Engineering productivity metrics\ncheck_metric \"claude_code_lines_of_code_count\" \"Lines of code modified\"\ncheck_metric \"claude_code_commit_count\" \"Git commits\"\ncheck_metric \"claude_code_pull_request_count\" \"Pull requests created\"\ncheck_metric \"claude_code_code_edit_tool_decision\" \"Code edit tool usage\"\n\necho \"\"\necho -e \"${YELLOW}=== Operations Monitoring Dashboard ===${NC}\"\n\n# Operations and reliability metrics\ncheck_metric \"claude_code_api_request\" \"API request tracking\"\ncheck_metric \"claude_code_api_error\" \"API error tracking\"\n\necho \"\"\necho -e \"${YELLOW}=== Cost Management Dashboard ===${NC}\"\n\n# Cost-specific metrics (these might be the same as core cost metrics)\ncheck_metric \"claude_code_cost_usage\" \"Detailed cost tracking\"\n\necho \"\"\necho -e \"${YELLOW}=== Log Events (VictoriaLogs) ===${NC}\"\n\n# Check for key log events\ncheck_log_event \"_msg:claude_code.api_request\" \"API request events\"\ncheck_log_event \"_msg:claude_code.tool_result\" \"Tool result events\"\ncheck_log_event \"_msg:claude_code.user_prompt\" \"User prompt events\"\n\necho \"\"\necho -e \"${YELLOW}=== Component Health ===${NC}\"\n\n# Check that telemetry components are running\necho -n \"OTLP Collector health: \"\nif kubectl get pods -n telemetry -l app.kubernetes.io/name=opentelemetry-collector --no-headers | grep -q \"1/1.*Running\"; then\n    echo -e \"${GREEN}✓ Running${NC}\"\nelse\n    echo -e \"${RED}✗ Not running${NC}\"\n    FAILED_CHECKS=$((FAILED_CHECKS + 1))\nfi\nTOTAL_CHECKS=$((TOTAL_CHECKS + 1))\n\necho -n \"VictoriaMetrics health: \"\nif kubectl get pods -n telemetry victoria-metrics-victoria-metrics-single-server-0 --no-headers | grep -q \"1/1.*Running\"; then\n    echo -e \"${GREEN}✓ Running${NC}\"\nelse\n    echo -e \"${RED}✗ Not running${NC}\"\n    FAILED_CHECKS=$((FAILED_CHECKS + 1))\nfi\nTOTAL_CHECKS=$((TOTAL_CHECKS + 1))\n\necho -n \"VictoriaLogs health: \"\nif kubectl get pods -n telemetry victoria-logs-victoria-logs-single-server-0 --no-headers | grep -q \"1/1.*Running\"; then\n    echo -e \"${GREEN}✓ Running${NC}\"\nelse\n    echo -e \"${RED}✗ Not running${NC}\"\n    FAILED_CHECKS=$((FAILED_CHECKS + 1))\nfi\nTOTAL_CHECKS=$((TOTAL_CHECKS + 1))\n\necho -n \"Claude Code pod status: \"\nif kubectl get pods -n claude-code-dev -l app.kubernetes.io/name=claude-code --no-headers | grep -q \"Running\\|Completed\"; then\n    echo -e \"${GREEN}✓ Running/Completed${NC}\"\nelse\n    echo -e \"${YELLOW}⚠ Not running (needs valid API key)${NC}\"\nfi\nTOTAL_CHECKS=$((TOTAL_CHECKS + 1))\n\necho \"\"\necho -e \"${BLUE}=== Summary ===${NC}\"\n\nif [ $FAILED_CHECKS -eq 0 ]; then\n    echo -e \"${GREEN}✅ All $TOTAL_CHECKS checks passed! Telemetry is working correctly.${NC}\"\n    exit 0\nelse\n    echo -e \"${RED}❌ $FAILED_CHECKS out of $TOTAL_CHECKS checks failed.${NC}\"\n    echo \"\"\n    echo -e \"${YELLOW}Common issues:${NC}\"\n    echo \"1. Claude Code pod needs a valid API key to generate telemetry\"\n    echo \"2. Metrics may take time to appear after first run\"\n    echo \"3. Check Claude Code configuration: kubectl get configmap -n claude-code-dev claude-code-dev-config\"\n    echo \"4. Verify endpoints are accessible:\"\n    echo \"   - VictoriaMetrics: curl http://localhost:8428/api/v1/query?query=up\"\n    echo \"   - VictoriaLogs: curl 'http://localhost:9428/select/logsql/query?query=*&limit=1'\"\n    exit 1\nfi"
        },
        {
          "path": "comprehensive-test.sh",
          "file_type": "sh",
          "line_count": 214,
          "key_definitions": [],
          "content": "#!/bin/bash\n# Comprehensive Testing and Verification Script for Claude Code Telemetry Stack\nset -e\n\n# Colors for output\nGREEN='\\033[0;32m'\nRED='\\033[0;31m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n# Test results tracking\nTESTS_PASSED=0\nTESTS_FAILED=0\nFAILED_TESTS=()\n\n# Function to run a test\nrun_test() {\n    local test_name=\"$1\"\n    local test_command=\"$2\"\n    \n    echo -e \"\\n${YELLOW}Running test: ${test_name}${NC}\"\n    if eval \"$test_command\"; then\n        echo -e \"${GREEN}✓ PASSED: ${test_name}${NC}\"\n        ((TESTS_PASSED++))\n    else\n        echo -e \"${RED}✗ FAILED: ${test_name}${NC}\"\n        ((TESTS_FAILED++))\n        FAILED_TESTS+=(\"$test_name\")\n    fi\n}\n\n# Function to check if a pod is running\ncheck_pod_running() {\n    local namespace=\"$1\"\n    local pod_pattern=\"$2\"\n    kubectl get pods -n \"$namespace\" | grep -E \"$pod_pattern\" | grep -q \"Running\"\n}\n\n# Function to check service endpoint\ncheck_endpoint() {\n    local url=\"$1\"\n    local expected_code=\"${2:-200}\"\n    local actual_code=$(curl -s -o /dev/null -w \"%{http_code}\" \"$url\" 2>/dev/null || echo \"000\")\n    [ \"$actual_code\" = \"$expected_code\" ]\n}\n\necho \"=========================================\"\necho \"Claude Code Telemetry Stack - Comprehensive Test Suite\"\necho \"=========================================\"\n\n# 1. Infrastructure Tests\necho -e \"\\n${YELLOW}=== 1. Infrastructure Tests ===${NC}\"\n\nrun_test \"Kind cluster is running\" \\\n    \"kubectl cluster-info &>/dev/null\"\n\nrun_test \"Telemetry namespace exists\" \\\n    \"kubectl get namespace telemetry &>/dev/null\"\n\nrun_test \"NGINX Ingress Controller is running\" \\\n    \"check_pod_running ingress-nginx 'ingress-nginx-controller.*Running'\"\n\n# 2. Component Health Tests\necho -e \"\\n${YELLOW}=== 2. Component Health Tests ===${NC}\"\n\nrun_test \"OpenTelemetry Collector is running\" \\\n    \"check_pod_running telemetry 'otel-collector.*Running'\"\n\nrun_test \"VictoriaMetrics is running\" \\\n    \"check_pod_running telemetry 'victoria-metrics.*Running'\"\n\nrun_test \"VictoriaLogs is running\" \\\n    \"check_pod_running telemetry 'victoria-logs.*Running'\"\n\nrun_test \"Grafana is running\" \\\n    \"check_pod_running telemetry 'grafana.*Running'\"\n\n# 3. Service Connectivity Tests\necho -e \"\\n${YELLOW}=== 3. Service Connectivity Tests ===${NC}\"\n\n# Start port forwards in background\necho \"Setting up port forwards...\"\nkubectl port-forward -n telemetry svc/grafana 3000:80 &>/dev/null &\nGRAFANA_PF_PID=$!\nkubectl port-forward -n telemetry svc/victoria-metrics-victoria-metrics-single-server 8428:8428 &>/dev/null &\nVM_PF_PID=$!\nkubectl port-forward -n telemetry svc/victoria-logs-victoria-logs-single-server 9428:9428 &>/dev/null &\nVL_PF_PID=$!\nkubectl port-forward -n telemetry svc/otel-collector 4318:4318 &>/dev/null &\nOTEL_PF_PID=$!\n\nsleep 5  # Wait for port forwards to establish\n\nrun_test \"Grafana UI is accessible\" \\\n    \"check_endpoint http://localhost:3000/api/health\"\n\nrun_test \"VictoriaMetrics API is accessible\" \\\n    \"check_endpoint http://localhost:8428/api/v1/query?query=up\"\n\nrun_test \"VictoriaLogs API is accessible\" \\\n    \"check_endpoint http://localhost:9428/select/logsql/query?query=*\"\n\nrun_test \"OTLP HTTP endpoint is accessible\" \\\n    \"check_endpoint http://localhost:4318/v1/metrics 405\"  # 405 because GET not allowed\n\n# 4. Data Ingestion Tests\necho -e \"\\n${YELLOW}=== 4. Data Ingestion Tests ===${NC}\"\n\n# Test metric ingestion\nrun_test \"OTLP metrics ingestion works\" \\\n    'curl -s -X POST http://localhost:4318/v1/metrics \\\n        -H \"Content-Type: application/json\" \\\n        -d \"{\\\"resourceMetrics\\\":[{\\\"resource\\\":{\\\"attributes\\\":[{\\\"key\\\":\\\"service.name\\\",\\\"value\\\":{\\\"stringValue\\\":\\\"test-service\\\"}},{\\\"key\\\":\\\"test.run\\\",\\\"value\\\":{\\\"stringValue\\\":\\\"comprehensive-test\\\"}}]},\\\"scopeMetrics\\\":[{\\\"metrics\\\":[{\\\"name\\\":\\\"test.metric\\\",\\\"sum\\\":{\\\"dataPoints\\\":[{\\\"asInt\\\":\\\"42\\\",\\\"timeUnixNano\\\":\\\"'$(date +%s)'000000000\\\"}]}}]}]}]}\" \\\n        | grep -q \"Partial success\" || [ $? -eq 1 ]'\n\n# Test log ingestion\nrun_test \"OTLP logs ingestion works\" \\\n    'curl -s -X POST http://localhost:4318/v1/logs \\\n        -H \"Content-Type: application/json\" \\\n        -d \"{\\\"resourceLogs\\\":[{\\\"resource\\\":{\\\"attributes\\\":[{\\\"key\\\":\\\"service.name\\\",\\\"value\\\":{\\\"stringValue\\\":\\\"test-service\\\"}}]},\\\"scopeLogs\\\":[{\\\"logRecords\\\":[{\\\"timeUnixNano\\\":\\\"'$(date +%s)'000000000\\\",\\\"severityText\\\":\\\"INFO\\\",\\\"body\\\":{\\\"stringValue\\\":\\\"Test log from comprehensive test\\\"}}]}]}]}\" \\\n        | grep -q \"Partial success\" || [ $? -eq 1 ]'\n\nsleep 5  # Wait for data to be processed\n\n# 5. Data Query Tests\necho -e \"\\n${YELLOW}=== 5. Data Query Tests ===${NC}\"\n\nrun_test \"Can query test metrics from VictoriaMetrics\" \\\n    'curl -s \"http://localhost:8428/api/v1/query?query=test.metric\" | jq -e \".data.result | length > 0\" &>/dev/null'\n\nrun_test \"Can query logs from VictoriaLogs\" \\\n    'curl -s \"http://localhost:9428/select/logsql/query?query=service.name:test-service\" | grep -q \"Test log from comprehensive test\"'\n\n# 6. Grafana Configuration Tests\necho -e \"\\n${YELLOW}=== 6. Grafana Configuration Tests ===${NC}\"\n\nGRAFANA_AUTH=\"admin:admin123!\"\n\nrun_test \"VictoriaMetrics datasource is configured\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/datasources/name/VictoriaMetrics | jq -e \".id > 0\" &>/dev/null'\n\nrun_test \"VictoriaLogs datasource is configured\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/datasources/name/VictoriaLogs | jq -e \".id > 0\" &>/dev/null'\n\n# 7. Dashboard Tests\necho -e \"\\n${YELLOW}=== 7. Dashboard Tests ===${NC}\"\n\nrun_test \"Executive Overview dashboard exists\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/dashboards/uid/executive-overview | jq -e \".dashboard.id > 0\" &>/dev/null'\n\nrun_test \"Engineering Metrics dashboard exists\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/dashboards/uid/engineering-metrics | jq -e \".dashboard.id > 0\" &>/dev/null'\n\nrun_test \"Operations Monitoring dashboard exists\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/dashboards/uid/operations-monitoring | jq -e \".dashboard.id > 0\" &>/dev/null'\n\nrun_test \"Cost Management dashboard exists\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/dashboards/uid/cost-management | jq -e \".dashboard.id > 0\" &>/dev/null'\n\n# 8. Alerting Tests\necho -e \"\\n${YELLOW}=== 8. Alerting Tests ===${NC}\"\n\nrun_test \"Alert rules are configured\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/v1/provisioning/alert-rules | jq -e \"length > 0\" &>/dev/null'\n\nrun_test \"Notification policy is configured\" \\\n    'curl -s -u $GRAFANA_AUTH http://localhost:3000/api/v1/provisioning/policies | jq -e \".receiver != null\" &>/dev/null'\n\n# 9. Claude Code Integration Tests\necho -e \"\\n${YELLOW}=== 9. Claude Code Integration Tests ===${NC}\"\n\nrun_test \"Claude Code deployment exists\" \\\n    \"kubectl get deployment -n telemetry claude-code &>/dev/null || kubectl get deployment -n claude-code-conversation claude-code-conversation &>/dev/null\"\n\nrun_test \"Claude Code ConfigMap with telemetry settings exists\" \\\n    \"kubectl get configmap -n telemetry claude-code-config &>/dev/null || true\"\n\n# 10. Resource Usage Tests\necho -e \"\\n${YELLOW}=== 10. Resource Usage Tests ===${NC}\"\n\nrun_test \"All pods have resource limits defined\" \\\n    'kubectl get pods -n telemetry -o json | jq -e \".items[].spec.containers[].resources.limits.memory != null\" &>/dev/null'\n\nrun_test \"Persistent volumes are bound\" \\\n    'kubectl get pvc -n telemetry -o json | jq -e \".items[] | select(.status.phase != \\\"Bound\\\") | length == 0\" &>/dev/null || [ $(kubectl get pvc -n telemetry -o json | jq \".items | length\") -eq 0 ]'\n\n# Cleanup port forwards\necho -e \"\\nCleaning up port forwards...\"\nkill $GRAFANA_PF_PID $VM_PF_PID $VL_PF_PID $OTEL_PF_PID 2>/dev/null || true\n\n# Test Summary\necho -e \"\\n=========================================\"\necho -e \"${YELLOW}Test Summary${NC}\"\necho \"=========================================\"\necho -e \"Tests Passed: ${GREEN}${TESTS_PASSED}${NC}\"\necho -e \"Tests Failed: ${RED}${TESTS_FAILED}${NC}\"\n\nif [ ${#FAILED_TESTS[@]} -gt 0 ]; then\n    echo -e \"\\n${RED}Failed Tests:${NC}\"\n    for test in \"${FAILED_TESTS[@]}\"; do\n        echo -e \"  - $test\"\n    done\nfi\n\necho -e \"\\n=========================================\"\n\n# Exit with appropriate code\nif [ $TESTS_FAILED -eq 0 ]; then\n    echo -e \"${GREEN}All tests passed!${NC}\"\n    exit 0\nelse\n    echo -e \"${RED}Some tests failed!${NC}\"\n    exit 1\nfi"
        },
        {
          "path": "package-crds.sh",
          "file_type": "sh",
          "line_count": 68,
          "key_definitions": [],
          "content": "#!/bin/bash\n# Package 5D Labs Platform CRDs for release\n\nset -euo pipefail\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nCHART_DIR=\"${SCRIPT_DIR}/../charts/orchestrator\"\nCRDS_DIR=\"${CHART_DIR}/crds\"\nOUTPUT_DIR=\"${1:-${SCRIPT_DIR}/../dist}\"\n\n# Ensure output directory exists\nmkdir -p \"${OUTPUT_DIR}\"\n\necho \"🔧 Packaging 5D Labs Platform CRDs...\"\necho \"📁 Chart directory: ${CHART_DIR}\"\necho \"📁 CRDs directory: ${CRDS_DIR}\"\necho \"📁 Output directory: ${OUTPUT_DIR}\"\n\n# Check if CRDs directory exists\nif [[ ! -d \"${CRDS_DIR}\" ]]; then\n    echo \"❌ Error: CRDs directory not found at ${CRDS_DIR}\"\n    exit 1\nfi\n\n# Check if platform-crds.yaml exists\nif [[ ! -f \"${CRDS_DIR}/platform-crds.yaml\" ]]; then\n    echo \"❌ Error: platform-crds.yaml not found at ${CRDS_DIR}/platform-crds.yaml\"\n    echo \"   Please ensure the combined CRDs file exists.\"\n    exit 1\nfi\n\n# Copy the combined CRDs file\ncp \"${CRDS_DIR}/platform-crds.yaml\" \"${OUTPUT_DIR}/\"\n\n# Validate the CRDs\necho \"🔍 Validating CRDs...\"\nif kubectl apply --dry-run=client -f \"${OUTPUT_DIR}/platform-crds.yaml\" > /dev/null 2>&1; then\n    echo \"✅ CRDs validation passed\"\nelse\n    echo \"❌ CRDs validation failed\"\n    exit 1\nfi\n\n# Generate individual CRD files as well (for flexibility)\necho \"📦 Copying individual CRD files...\"\ncp \"${CRDS_DIR}/coderun-crd.yaml\" \"${OUTPUT_DIR}/\"\ncp \"${CRDS_DIR}/docsrun-crd.yaml\" \"${OUTPUT_DIR}/\"\n\n# Generate checksums\necho \"🔐 Generating checksums...\"\ncd \"${OUTPUT_DIR}\"\nsha256sum platform-crds.yaml > platform-crds.yaml.sha256\nsha256sum coderun-crd.yaml > coderun-crd.yaml.sha256\nsha256sum docsrun-crd.yaml > docsrun-crd.yaml.sha256\n\necho \"✅ CRDs packaged successfully!\"\necho \"\"\necho \"📦 Generated files:\"\nls -la \"${OUTPUT_DIR}\"/*.yaml \"${OUTPUT_DIR}\"/*.sha256\necho \"\"\necho \"🚀 Upload these files to GitHub releases:\"\necho \"   - platform-crds.yaml (combined CRDs)\"\necho \"   - coderun-crd.yaml (individual CRD)\"\necho \"   - docsrun-crd.yaml (individual CRD)\"\necho \"   - *.sha256 (checksums)\"\necho \"\"\necho \"📋 Installation command for users:\"\necho \"   kubectl apply -f https://github.com/5dlabs/platform/releases/download/TAG/platform-crds.yaml\""
        },
        {
          "path": "scrape-otlp-metrics.sh",
          "file_type": "sh",
          "line_count": 25,
          "key_definitions": [],
          "content": "#!/bin/bash\n\necho \"Quick workaround: Scraping Claude Code metrics from OTLP Collector\"\n\n# Port forward to OTLP collector\nkubectl port-forward -n telemetry deploy/otel-collector-opentelemetry-collector 8889:8889 &\nPF_PID=$!\nsleep 3\n\n# Get all Claude Code metrics\necho \"Fetching Claude Code metrics...\"\ncurl -s http://localhost:8889/metrics | grep \"^claude_code\" > /tmp/claude_metrics.txt\n\necho \"Found metrics:\"\ncat /tmp/claude_metrics.txt | cut -d'{' -f1 | sort -u\n\n# Clean up\nkill $PF_PID 2>/dev/null\n\necho \"\"\necho \"Metrics saved to /tmp/claude_metrics.txt\"\necho \"\"\necho \"To query these metrics in Grafana:\"\necho \"1. Configure Grafana to scrape the OTLP collector's Prometheus endpoint\"\necho \"2. Or configure VictoriaMetrics to scrape it\""
        },
        {
          "path": "test-telemetry-pipeline-v2.sh",
          "file_type": "sh",
          "line_count": 53,
          "key_definitions": [],
          "content": "#!/bin/bash\n\necho \"=== Testing Claude Code Telemetry Pipeline ===\"\necho \"\"\n\n# 1. Check Claude Code pod status\necho \"1. Claude Code Pod Status:\"\nkubectl get pods -n claude-code -o wide\necho \"\"\n\n# 2. Check Claude Code telemetry configuration\necho \"2. Claude Code Telemetry Configuration:\"\nkubectl exec -n claude-code deploy/claude-code -- env | grep -E \"(OTEL_|CLAUDE_CODE_ENABLE)\" | sort\necho \"\"\n\n# 3. Check OTLP Collector status\necho \"3. OTLP Collector Status:\"\nkubectl get pods -n telemetry -l app.kubernetes.io/name=opentelemetry-collector\necho \"\"\n\n# 4. Test OTLP collector metrics endpoint\necho \"4. Testing OTLP Collector Prometheus Endpoint:\"\nkubectl port-forward -n telemetry svc/otel-collector-metrics 8889:8889 > /dev/null 2>&1 &\nPF_PID=$!\nsleep 3\necho \"Checking for any metrics...\"\ncurl -s http://localhost:8889/metrics | grep -E \"^(claude_code|# TYPE)\" | head -20\nkill $PF_PID 2>/dev/null\necho \"\"\n\n# 5. Check VictoriaMetrics native OTLP ingestion\necho \"5. Checking VictoriaMetrics OTLP Endpoint:\"\nkubectl logs -n telemetry victoria-metrics-victoria-metrics-single-server-0 --tail=20 | grep -i \"opentelemetry\"\necho \"\"\n\n# 6. Query VictoriaMetrics for metrics\necho \"6. Querying VictoriaMetrics for Claude Code metrics:\"\nkubectl port-forward -n telemetry victoria-metrics-victoria-metrics-single-server-0 8428:8428 > /dev/null 2>&1 &\nPF_PID=$!\nsleep 3\ncurl -s \"http://localhost:8428/api/v1/label/__name__/values\" | jq -r '.data[]' | grep -E \"claude_code\" || echo \"No claude_code metrics found\"\nkill $PF_PID 2>/dev/null\necho \"\"\n\n# 7. Check OTLP collector logs for errors\necho \"7. OTLP Collector Recent Logs:\"\nkubectl logs -n telemetry deploy/otel-collector-opentelemetry-collector --tail=10\necho \"\"\n\necho \"=== Summary ===\"\necho \"The telemetry pipeline should flow as:\"\necho \"Claude Code -> OTLP Collector (HTTP) -> VictoriaMetrics (Native OTLP)\"\necho \"Additionally, VictoriaMetrics scrapes OTLP Collector's Prometheus endpoint\""
        },
        {
          "path": "setup-all-agents.sh",
          "file_type": "sh",
          "line_count": 422,
          "key_definitions": [],
          "content": "#!/bin/bash\n# Fully automated batch setup script for multiple GitHub agents\n# Only requires GitHub PAT tokens - SSH keys are auto-generated and added to GitHub\n\nset -euo pipefail\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPLATFORM_ROOT=\"$(cd \"$SCRIPT_DIR/../..\" && pwd)\"\nAGENTS_DIR=\"$PLATFORM_ROOT/agents\"\nNAMESPACE=\"orchestrator\"\nDRY_RUN=\"\"\nVERBOSE=\"\"\nAUTO_GENERATE=\"\"\n\n# Color codes for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\nusage() {\n    cat << EOF\nFully automated GitHub agent setup for 5D Labs Platform\n\nUSAGE:\n    $0 [OPTIONS]\n\nOPTIONS:\n    --auto-generate         Generate SSH keys AND auto-add to GitHub via API (RECOMMENDED)\n    --namespace <name>      Kubernetes namespace (default: orchestrator)\n    --dry-run              Show commands without executing\n    --verbose              Show detailed output\n    --help                 Show this help message\n\nDIRECTORY STRUCTURE:\n    agents/\n    ├── agent-name-1/\n    │   └── .env            # TOKEN=ghp_xxxxx (only this required!)\n    └── agent-name-2/\n        └── .env            # TOKEN=ghp_xxxxx (only this required!)\n\nAUTOMATED WORKFLOW:\n    1. Create agent directories with .env files containing GitHub PAT tokens\n    2. Run: $0 --auto-generate\n    3. Script automatically:\n       ✓ Generates SSH key pairs for each agent\n       ✓ Adds public keys to GitHub accounts via API\n       ✓ Creates Kubernetes secrets\n    4. You're done! No manual steps needed.\n\nGITHUB PAT REQUIREMENTS:\n    For Classic PATs: 'write:gpg_key' scope\n    For Fine-grained PATs: 'Git SSH keys' user permissions (write)\n\nEXAMPLES:\n    # Fully automated setup (recommended)\n    $0 --auto-generate\n\n    # Dry run to see what would happen\n    $0 --auto-generate --dry-run\n\n    # Setup in different namespace with verbose output\n    $0 --auto-generate --namespace my-orchestrator --verbose\n\n    # Create agent structure quickly\n    for agent in pm0-5dlabs qa0-5dlabs swe-1-5dlabs swe-2-5dlabs SWE-2-5dlabs; do\n        mkdir -p agents/\\$agent\n        echo \"TOKEN=ghp_YOUR_TOKEN_HERE\" > agents/\\$agent/.env\n    done\n\nEOF\n}\n\nlog() {\n    if [[ -n \"$VERBOSE\" ]]; then\n        echo -e \"${BLUE}[DEBUG]${NC} $*\" >&2\n    fi\n}\n\ninfo() {\n    echo -e \"${GREEN}[INFO]${NC} $*\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[WARN]${NC} $*\" >&2\n}\n\nerror() {\n    echo -e \"${RED}[ERROR]${NC} $*\" >&2\n}\n\n# Function to add SSH key to GitHub via API\nadd_ssh_key_to_github() {\n    local agent_name=\"$1\"\n    local token=\"$2\"\n    local public_key_file=\"$3\"\n\n    local title=\"5D Labs Platform Agent: $agent_name\"\n\n    log \"Adding SSH key to GitHub for agent: $agent_name\"\n\n    if [[ -n \"$DRY_RUN\" ]]; then\n        echo \"DRY RUN: Would add SSH key to GitHub via API\"\n        echo \"  Title: $title\"\n        echo \"  Key: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAASIMULATED... ${agent_name}@5dlabs.platform\"\n        return 0\n    fi\n\n    if [[ ! -f \"$public_key_file\" ]]; then\n        error \"Public key file not found: $public_key_file\"\n        return 1\n    fi\n\n    local public_key_content\n    public_key_content=$(cat \"$public_key_file\")\n\n    # GitHub API call to add SSH key\n    local response\n    local http_code\n\n    response=$(curl -s -w \"\\n%{http_code}\" \\\n        -X POST \\\n        -H \"Accept: application/vnd.github+json\" \\\n        -H \"Authorization: Bearer $token\" \\\n        -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n        https://api.github.com/user/keys \\\n        -d \"{\\\"title\\\":\\\"$title\\\",\\\"key\\\":\\\"$public_key_content\\\"}\")\n\n    http_code=$(echo \"$response\" | tail -n1)\n    response_body=$(echo \"$response\" | head -n -1)\n\n    log \"GitHub API response code: $http_code\"\n    log \"GitHub API response: $response_body\"\n\n    case $http_code in\n        201)\n            info \"✅ Successfully added SSH key to GitHub for: $agent_name\"\n            return 0\n            ;;\n        422)\n            if echo \"$response_body\" | grep -q \"key is already in use\"; then\n                warn \"SSH key already exists in GitHub for: $agent_name (skipping)\"\n                return 0\n            else\n                error \"GitHub API validation error for $agent_name: $response_body\"\n                return 1\n            fi\n            ;;\n        401)\n            error \"GitHub API authentication failed for $agent_name. Check your PAT token and scopes.\"\n            error \"Required scopes: Classic PAT needs 'write:gpg_key', Fine-grained PAT needs 'Git SSH keys' write permission\"\n            return 1\n            ;;\n        403)\n            error \"GitHub API forbidden for $agent_name. Check your PAT token permissions.\"\n            return 1\n            ;;\n        *)\n            error \"GitHub API error for $agent_name (HTTP $http_code): $response_body\"\n            return 1\n            ;;\n    esac\n}\n\n# Parse command line arguments\nwhile [[ $# -gt 0 ]]; do\n    case $1 in\n        --namespace)\n            NAMESPACE=\"$2\"\n            shift 2\n            ;;\n        --auto-generate)\n            AUTO_GENERATE=\"true\"\n            shift\n            ;;\n        --dry-run)\n            DRY_RUN=\"true\"\n            shift\n            ;;\n        --verbose)\n            VERBOSE=\"true\"\n            shift\n            ;;\n        --help)\n            usage\n            exit 0\n            ;;\n        *)\n            error \"Unknown option: $1\"\n            echo \"Use --help for usage information\" >&2\n            exit 1\n            ;;\n    esac\ndone\n\n# Check if --auto-generate was provided\nif [[ -z \"$AUTO_GENERATE\" ]]; then\n    error \"Please use --auto-generate for the new fully automated workflow\"\n    echo \"\"\n    usage\n    exit 1\nfi\n\n# Check if agents directory exists\nif [[ ! -d \"$AGENTS_DIR\" ]]; then\n    error \"Agents directory not found: $AGENTS_DIR\"\n    echo \"Please create the agents/ directory structure:\" >&2\n    echo \"  mkdir -p agents/{pm0-5dlabs,qa0-5dlabs,swe-1-5dlabs,swe-2-5dlabs,SWE-2-5dlabs}\" >&2\n    echo \"  echo 'TOKEN=ghp_YOUR_TOKEN_HERE' > agents/pm0-5dlabs/.env\" >&2\n    echo \"  # ... repeat for each agent\" >&2\n    exit 1\nfi\n\n# Check required tools\nfor tool in kubectl ssh-keygen curl; do\n    if ! command -v \"$tool\" >/dev/null 2>&1; then\n        error \"$tool is not installed or not in PATH\"\n        exit 1\n    fi\ndone\n\n# Check if namespace exists (unless dry run)\nif [[ -z \"$DRY_RUN\" ]]; then\n    if ! kubectl get namespace \"$NAMESPACE\" >/dev/null 2>&1; then\n        warn \"Namespace '$NAMESPACE' does not exist\"\n        info \"Creating namespace: $NAMESPACE\"\n        kubectl create namespace \"$NAMESPACE\"\n    fi\nfi\n\ninfo \"🚀 Starting fully automated agent setup\"\ninfo \"   Agents directory: $AGENTS_DIR\"\ninfo \"   Namespace: $NAMESPACE\"\ninfo \"   Mode: Auto-generate SSH keys + Auto-add to GitHub\"\nif [[ -n \"$DRY_RUN\" ]]; then\n    info \"   Mode: DRY RUN (no changes will be made)\"\nfi\necho \"\"\n\n# Find all agent directories\nAGENT_COUNT=0\nPROCESSED_COUNT=0\nFAILED_COUNT=0\nAPI_ADDED_KEYS=()\n\n# Count agents first\nfor agent_dir in \"$AGENTS_DIR\"/*; do\n    if [[ -d \"$agent_dir\" ]]; then\n        AGENT_COUNT=$((AGENT_COUNT + 1))\n    fi\ndone\n\nif [[ $AGENT_COUNT -eq 0 ]]; then\n    warn \"No agent directories found in $AGENTS_DIR\"\n    echo \"Please create agent directories with .env files containing GitHub PAT tokens\"\n    exit 1\nfi\n\ninfo \"📋 Found $AGENT_COUNT agent(s) to process\"\necho \"\"\n\n# Process each agent directory\nfor agent_dir in \"$AGENTS_DIR\"/*; do\n    if [[ ! -d \"$agent_dir\" ]]; then\n        continue\n    fi\n\n    agent_name=$(basename \"$agent_dir\")\n    log \"Processing agent directory: $agent_dir\"\n\n    # Check for .env file (required)\n    env_file=\"$agent_dir/.env\"\n    if [[ ! -f \"$env_file\" ]]; then\n        error \"Agent '$agent_name': Missing .env file with GitHub PAT token\"\n        FAILED_COUNT=$((FAILED_COUNT + 1))\n        continue\n    fi\n\n    # Load token from .env file\n    if ! source \"$env_file\"; then\n        error \"Agent '$agent_name': Failed to load .env file\"\n        FAILED_COUNT=$((FAILED_COUNT + 1))\n        continue\n    fi\n\n    if [[ -z \"${TOKEN:-}\" ]]; then\n        error \"Agent '$agent_name': TOKEN not found in .env file\"\n        FAILED_COUNT=$((FAILED_COUNT + 1))\n        continue\n    fi\n\n    # Validate token format\n    if [[ ! \"$TOKEN\" =~ ^ghp_[a-zA-Z0-9_]{36}$ ]]; then\n        warn \"Agent '$agent_name': Token doesn't match expected format (ghp_xxxxx)\"\n    fi\n\n    # SSH key paths\n    ssh_private=\"$agent_dir/id_ed25519\"\n    ssh_public=\"$agent_dir/id_ed25519.pub\"\n\n    # Generate SSH keys\n    info \"🔑 Generating SSH key pair for agent: $agent_name\"\n\n    if [[ -z \"$DRY_RUN\" ]]; then\n        # Generate SSH key pair\n        ssh-keygen -t ed25519 -f \"$ssh_private\" -N \"\" -C \"${agent_name}@5dlabs.platform\" -q\n\n        if [[ -f \"$ssh_private\" && -f \"$ssh_public\" ]]; then\n            # Set proper permissions\n            chmod 600 \"$ssh_private\"\n            chmod 644 \"$ssh_public\"\n            info \"✅ Generated SSH key pair for: $agent_name\"\n        else\n            error \"Failed to generate SSH key pair for: $agent_name\"\n            FAILED_COUNT=$((FAILED_COUNT + 1))\n            continue\n        fi\n    else\n        echo \"DRY RUN: ssh-keygen -t ed25519 -f $ssh_private -N \\\"\\\" -C \\\"${agent_name}@5dlabs.platform\\\" -q\"\n    fi\n\n    # Add SSH key to GitHub via API\n    info \"🌐 Adding SSH key to GitHub for agent: $agent_name\"\n\n    if add_ssh_key_to_github \"$agent_name\" \"$TOKEN\" \"$ssh_public\"; then\n        API_ADDED_KEYS+=(\"$agent_name\")\n        info \"✅ SSH key added to GitHub for: $agent_name\"\n    else\n        error \"❌ Failed to add SSH key to GitHub for: $agent_name\"\n        FAILED_COUNT=$((FAILED_COUNT + 1))\n        continue\n    fi\n\n    # Create Kubernetes secrets\n    info \"🔧 Setting up Kubernetes secrets for agent: $agent_name\"\n\n    # Call the setup-agent-secrets.sh script\n    setup_cmd=(\n        \"$SCRIPT_DIR/setup-agent-secrets.sh\"\n        \"--user\" \"$agent_name\"\n        \"--ssh-key\" \"$ssh_private\"\n        \"--token\" \"$TOKEN\"\n        \"--namespace\" \"$NAMESPACE\"\n    )\n\n    if [[ -n \"$DRY_RUN\" ]]; then\n        setup_cmd+=(\"--dry-run\")\n    fi\n\n    if [[ -n \"$VERBOSE\" ]]; then\n        setup_cmd+=(\"--verbose\")\n    fi\n\n    log \"Executing: ${setup_cmd[*]}\"\n\n    if \"${setup_cmd[@]}\"; then\n        info \"✅ Successfully processed agent: $agent_name\"\n        PROCESSED_COUNT=$((PROCESSED_COUNT + 1))\n    else\n        error \"❌ Failed to process agent: $agent_name\"\n        FAILED_COUNT=$((FAILED_COUNT + 1))\n    fi\n\n    echo \"\"\ndone\n\n# Display summary of API actions\nif [[ ${#API_ADDED_KEYS[@]} -gt 0 ]]; then\n    echo \"════════════════════════════════════════════════════════════════\"\n    info \"🌐 SSH Keys Successfully Added to GitHub:\"\n    echo \"\"\n\n    for agent_name in \"${API_ADDED_KEYS[@]}\"; do\n        echo -e \"${GREEN}   ✅ ${agent_name}${NC} - SSH key active in GitHub account\"\n    done\n    echo \"\"\n\n    info \"🎯 All SSH keys are now configured and ready to use!\"\n    echo \"\"\nfi\n\n# Summary\necho \"════════════════════════════════════════════════════════════════\"\ninfo \"🎉 Fully automated agent setup completed!\"\necho \"\"\ninfo \"📊 Summary:\"\ninfo \"   Total agents found: $AGENT_COUNT\"\ninfo \"   Successfully processed: $PROCESSED_COUNT\"\nif [[ $FAILED_COUNT -gt 0 ]]; then\n    warn \"   Failed: $FAILED_COUNT\"\nelse\n    info \"   Failed: $FAILED_COUNT\"\nfi\ninfo \"   SSH keys added to GitHub: ${#API_ADDED_KEYS[@]}\"\necho \"\"\n\nif [[ $FAILED_COUNT -eq 0 ]]; then\n    info \"✅ All agents processed successfully!\"\n    if [[ -z \"$DRY_RUN\" ]]; then\n        echo \"\"\n        info \"🔍 Verify secrets:\"\n        echo \"   kubectl get secrets -n $NAMESPACE | grep github\"\n        echo \"\"\n        info \"🚀 Next steps:\"\n        echo \"   1. Install Helm chart: helm install orchestrator ./infra/charts/orchestrator\"\n        echo \"   2. Create your first task with any of these agents:\"\n        for agent_dir in \"$AGENTS_DIR\"/*; do\n            if [[ -d \"$agent_dir\" ]]; then\n                agent_name=$(basename \"$agent_dir\")\n                echo \"      - githubUser: \\\"$agent_name\\\"\"\n            fi\n        done\n        echo \"\"\n        info \"🎯 No manual steps required - everything is automated!\"\n    else\n        info \"🏃 Remove --dry-run to execute these commands\"\n    fi\nelse\n    error \"❌ Some agents failed to process. Check the errors above.\"\n    exit 1\nfi"
        },
        {
          "path": "create-all-dashboards.sh",
          "file_type": "sh",
          "line_count": 1279,
          "key_definitions": [],
          "content": "#!/bin/bash\n\n# Create dashboards directory if it doesn't exist\nmkdir -p /Users/jonathonfritz/platform/manifests/dashboards\n\n# Engineering Metrics Dashboard\ncat > /Users/jonathonfritz/platform/manifests/dashboards/engineering-metrics-configmap.yaml << 'EOF'\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: engineering-metrics-dashboard\n  namespace: telemetry\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  engineering-metrics.json: |\n    {\n      \"annotations\": {\n        \"list\": [\n          {\n            \"builtIn\": 1,\n            \"datasource\": {\n              \"type\": \"grafana\",\n              \"uid\": \"-- Grafana --\"\n            },\n            \"enable\": true,\n            \"hide\": true,\n            \"iconColor\": \"rgba(0, 211, 255, 1)\",\n            \"name\": \"Annotations & Alerts\",\n            \"type\": \"dashboard\"\n          }\n        ]\n      },\n      \"editable\": true,\n      \"fiscalYearStartMonth\": 0,\n      \"graphTooltip\": 0,\n      \"id\": null,\n      \"links\": [],\n      \"liveNow\": false,\n      \"panels\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"\",\n                \"axisPlacement\": \"auto\",\n                \"fillOpacity\": 20,\n                \"lineWidth\": 1,\n                \"drawStyle\": \"line\",\n                \"stacking\": {\n                  \"mode\": \"normal\",\n                  \"group\": \"A\"\n                }\n              },\n              \"mappings\": [],\n              \"unit\": \"short\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 0\n          },\n          \"id\": 1,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum by (language) (increase(claude_code_lines_modified_total[1h]))\",\n              \"refId\": \"A\",\n              \"legendFormat\": \"{{language}}\"\n            }\n          ],\n          \"title\": \"Lines of Code Modified by Language\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"short\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 12,\n            \"y\": 0\n          },\n          \"id\": 2,\n          \"options\": {\n            \"colorMode\": \"value\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum(increase(claude_code_pull_requests_created_total[24h]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Pull Requests Created (24h)\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"short\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 18,\n            \"y\": 0\n          },\n          \"id\": 3,\n          \"options\": {\n            \"colorMode\": \"value\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum(increase(claude_code_commits_total[24h]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Commits (24h)\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                }\n              },\n              \"mappings\": []\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 4\n          },\n          \"id\": 4,\n          \"options\": {\n            \"legend\": {\n              \"displayMode\": \"list\",\n              \"placement\": \"right\",\n              \"showLegend\": true\n            },\n            \"pieType\": \"donut\",\n            \"reduceOptions\": {\n              \"values\": false,\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\"\n            },\n            \"tooltip\": {\n              \"mode\": \"single\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum by (tool_name) (increase(claude_code_tool_usage_total[24h]))\",\n              \"refId\": \"A\",\n              \"legendFormat\": \"{{tool_name}}\"\n            }\n          ],\n          \"title\": \"Tool Usage Distribution (24h)\",\n          \"type\": \"piechart\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"victoriametrics-logs-datasource\",\n            \"uid\": \"${logs_datasource}\"\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 24,\n            \"x\": 0,\n            \"y\": 8\n          },\n          \"id\": 5,\n          \"options\": {\n            \"showTime\": true,\n            \"showLabels\": false,\n            \"showCommonLabels\": false,\n            \"wrapLogMessage\": true,\n            \"prettifyLogMessage\": false,\n            \"enableLogDetails\": true,\n            \"dedupStrategy\": \"none\",\n            \"sortOrder\": \"Descending\"\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"victoriametrics-logs-datasource\",\n                \"uid\": \"${logs_datasource}\"\n              },\n              \"expr\": \"_stream:{app=\\\"claude-code\\\"} | json | line_format \\\"{{.timestamp}} [{{.level}}] {{.message}}\\\"\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Developer Activity Timeline\",\n          \"type\": \"logs\"\n        }\n      ],\n      \"refresh\": \"30s\",\n      \"schemaVersion\": 39,\n      \"style\": \"dark\",\n      \"tags\": [\"claude-code\", \"engineering\"],\n      \"templating\": {\n        \"list\": [\n          {\n            \"current\": {\n              \"selected\": false,\n              \"text\": \"VictoriaMetrics\",\n              \"value\": \"P4169E866C3094E38\"\n            },\n            \"hide\": 0,\n            \"includeAll\": false,\n            \"label\": \"Metrics Data Source\",\n            \"multi\": false,\n            \"name\": \"datasource\",\n            \"options\": [],\n            \"query\": \"prometheus\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"skipUrlSync\": false,\n            \"type\": \"datasource\"\n          },\n          {\n            \"current\": {\n              \"selected\": false,\n              \"text\": \"VictoriaLogs\",\n              \"value\": \"PD775F2863313E6C7\"\n            },\n            \"hide\": 0,\n            \"includeAll\": false,\n            \"label\": \"Logs Data Source\",\n            \"multi\": false,\n            \"name\": \"logs_datasource\",\n            \"options\": [],\n            \"query\": \"victoriametrics-logs-datasource\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"skipUrlSync\": false,\n            \"type\": \"datasource\"\n          }\n        ]\n      },\n      \"time\": {\n        \"from\": \"now-6h\",\n        \"to\": \"now\"\n      },\n      \"timepicker\": {},\n      \"timezone\": \"\",\n      \"title\": \"Claude Code - Engineering Metrics\",\n      \"uid\": \"claude-code-engineering\",\n      \"version\": 1,\n      \"weekStart\": \"\"\n    }\nEOF\n\n# Operations Monitoring Dashboard\ncat > /Users/jonathonfritz/platform/manifests/dashboards/operations-monitoring-configmap.yaml << 'EOF'\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: operations-monitoring-dashboard\n  namespace: telemetry\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  operations-monitoring.json: |\n    {\n      \"annotations\": {\n        \"list\": [\n          {\n            \"builtIn\": 1,\n            \"datasource\": {\n              \"type\": \"grafana\",\n              \"uid\": \"-- Grafana --\"\n            },\n            \"enable\": true,\n            \"hide\": true,\n            \"iconColor\": \"rgba(0, 211, 255, 1)\",\n            \"name\": \"Annotations & Alerts\",\n            \"type\": \"dashboard\"\n          }\n        ]\n      },\n      \"editable\": true,\n      \"fiscalYearStartMonth\": 0,\n      \"graphTooltip\": 0,\n      \"id\": null,\n      \"links\": [],\n      \"liveNow\": false,\n      \"panels\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [\n                {\n                  \"options\": {\n                    \"0\": {\n                      \"color\": \"red\",\n                      \"index\": 0,\n                      \"text\": \"DOWN\"\n                    },\n                    \"1\": {\n                      \"color\": \"green\",\n                      \"index\": 1,\n                      \"text\": \"UP\"\n                    }\n                  },\n                  \"type\": \"value\"\n                }\n              ],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"red\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"green\",\n                    \"value\": 1\n                  }\n                ]\n              }\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 0,\n            \"y\": 0\n          },\n          \"id\": 1,\n          \"options\": {\n            \"colorMode\": \"background\",\n            \"graphMode\": \"none\",\n            \"justifyMode\": \"center\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"value\"\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"up{job=\\\"otel-collector\\\"}\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"OTLP Collector Health\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [\n                {\n                  \"options\": {\n                    \"0\": {\n                      \"color\": \"red\",\n                      \"index\": 0,\n                      \"text\": \"DOWN\"\n                    },\n                    \"1\": {\n                      \"color\": \"green\",\n                      \"index\": 1,\n                      \"text\": \"UP\"\n                    }\n                  },\n                  \"type\": \"value\"\n                }\n              ],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"red\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"green\",\n                    \"value\": 1\n                  }\n                ]\n              }\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 6,\n            \"y\": 0\n          },\n          \"id\": 2,\n          \"options\": {\n            \"colorMode\": \"background\",\n            \"graphMode\": \"none\",\n            \"justifyMode\": \"center\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"value\"\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"up{job=\\\"victoria-metrics\\\"}\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"VictoriaMetrics Health\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"linear\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"never\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"area\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"yellow\",\n                    \"value\": 0.01\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 0.05\n                  }\n                ]\n              },\n              \"unit\": \"percentunit\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 0\n          },\n          \"id\": 3,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"mode\": \"single\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"rate(claude_code_api_errors_total[5m]) / rate(claude_code_api_requests_total[5m])\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"API Error Rate\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"linear\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"never\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"unit\": \"ms\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 4\n          },\n          \"id\": 4,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"mode\": \"multi\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"histogram_quantile(0.95, sum(rate(claude_code_api_duration_bucket[5m])) by (le))\",\n              \"refId\": \"A\",\n              \"legendFormat\": \"p95\"\n            },\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"histogram_quantile(0.99, sum(rate(claude_code_api_duration_bucket[5m])) by (le))\",\n              \"refId\": \"B\",\n              \"legendFormat\": \"p99\"\n            }\n          ],\n          \"title\": \"API Response Times\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"victoriametrics-logs-datasource\",\n            \"uid\": \"${logs_datasource}\"\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 24,\n            \"x\": 0,\n            \"y\": 12\n          },\n          \"id\": 5,\n          \"options\": {\n            \"showTime\": true,\n            \"showLabels\": true,\n            \"showCommonLabels\": false,\n            \"wrapLogMessage\": true,\n            \"prettifyLogMessage\": false,\n            \"enableLogDetails\": true,\n            \"dedupStrategy\": \"none\",\n            \"sortOrder\": \"Descending\"\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"victoriametrics-logs-datasource\",\n                \"uid\": \"${logs_datasource}\"\n              },\n              \"expr\": \"_stream:{app=\\\"claude-code\\\"} | json | level:error\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Recent Errors\",\n          \"type\": \"logs\"\n        }\n      ],\n      \"refresh\": \"10s\",\n      \"schemaVersion\": 39,\n      \"style\": \"dark\",\n      \"tags\": [\"claude-code\", \"operations\"],\n      \"templating\": {\n        \"list\": [\n          {\n            \"current\": {\n              \"selected\": false,\n              \"text\": \"VictoriaMetrics\",\n              \"value\": \"P4169E866C3094E38\"\n            },\n            \"hide\": 0,\n            \"includeAll\": false,\n            \"label\": \"Metrics Data Source\",\n            \"multi\": false,\n            \"name\": \"datasource\",\n            \"options\": [],\n            \"query\": \"prometheus\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"skipUrlSync\": false,\n            \"type\": \"datasource\"\n          },\n          {\n            \"current\": {\n              \"selected\": false,\n              \"text\": \"VictoriaLogs\",\n              \"value\": \"PD775F2863313E6C7\"\n            },\n            \"hide\": 0,\n            \"includeAll\": false,\n            \"label\": \"Logs Data Source\",\n            \"multi\": false,\n            \"name\": \"logs_datasource\",\n            \"options\": [],\n            \"query\": \"victoriametrics-logs-datasource\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"skipUrlSync\": false,\n            \"type\": \"datasource\"\n          }\n        ]\n      },\n      \"time\": {\n        \"from\": \"now-1h\",\n        \"to\": \"now\"\n      },\n      \"timepicker\": {},\n      \"timezone\": \"\",\n      \"title\": \"Claude Code - Operations Monitoring\",\n      \"uid\": \"claude-code-operations\",\n      \"version\": 1,\n      \"weekStart\": \"\"\n    }\nEOF\n\n# Cost Management Dashboard\ncat > /Users/jonathonfritz/platform/manifests/dashboards/cost-management-configmap.yaml << 'EOF'\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: cost-management-dashboard\n  namespace: telemetry\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  cost-management.json: |\n    {\n      \"annotations\": {\n        \"list\": [\n          {\n            \"builtIn\": 1,\n            \"datasource\": {\n              \"type\": \"grafana\",\n              \"uid\": \"-- Grafana --\"\n            },\n            \"enable\": true,\n            \"hide\": true,\n            \"iconColor\": \"rgba(0, 211, 255, 1)\",\n            \"name\": \"Annotations & Alerts\",\n            \"type\": \"dashboard\"\n          }\n        ]\n      },\n      \"editable\": true,\n      \"fiscalYearStartMonth\": 0,\n      \"graphTooltip\": 0,\n      \"id\": null,\n      \"links\": [],\n      \"liveNow\": false,\n      \"panels\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"decimals\": 2,\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"yellow\",\n                    \"value\": 5\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 10\n                  }\n                ]\n              },\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 6,\n            \"w\": 6,\n            \"x\": 0,\n            \"y\": 0\n          },\n          \"id\": 1,\n          \"options\": {\n            \"colorMode\": \"background\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"center\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum(increase(claude_code_token_cost_dollars_total[1h]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Current Hour Spend\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 20,\n                \"gradientMode\": \"opacity\",\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                },\n                \"insertNulls\": false,\n                \"lineInterpolation\": \"linear\",\n                \"lineWidth\": 2,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"never\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 18,\n            \"x\": 6,\n            \"y\": 0\n          },\n          \"id\": 2,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [\"sum\"],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"mode\": \"single\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum(increase(claude_code_token_cost_dollars_total[1d]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Daily Cost Trend\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"\",\n                \"axisPlacement\": \"auto\",\n                \"fillOpacity\": 80,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                },\n                \"lineWidth\": 1,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 8\n          },\n          \"id\": 3,\n          \"options\": {\n            \"barRadius\": 0,\n            \"barWidth\": 0.97,\n            \"fullHighlight\": false,\n            \"groupWidth\": 0.7,\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"orientation\": \"auto\",\n            \"showValue\": \"auto\",\n            \"stacking\": \"normal\",\n            \"tooltip\": {\n              \"mode\": \"single\",\n              \"sort\": \"none\"\n            },\n            \"xTickLabelRotation\": 0,\n            \"xTickLabelSpacing\": 0\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum by (model) (increase(claude_code_token_cost_dollars_total[24h]))\",\n              \"refId\": \"A\",\n              \"legendFormat\": \"{{model}}\"\n            }\n          ],\n          \"title\": \"Cost by Model (24h)\",\n          \"type\": \"barchart\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"continuous-GrYlRd\"\n              },\n              \"mappings\": [],\n              \"max\": 100,\n              \"min\": 0,\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 8\n          },\n          \"id\": 4,\n          \"options\": {\n            \"displayMode\": \"lcd\",\n            \"minVizHeight\": 10,\n            \"minVizWidth\": 0,\n            \"orientation\": \"horizontal\",\n            \"reduceOptions\": {\n              \"values\": false,\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\"\n            },\n            \"showUnfilled\": false,\n            \"valueMode\": \"color\"\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"topk(10, sum by (user_id) (increase(claude_code_token_cost_dollars_total[7d])))\",\n              \"format\": \"table\",\n              \"instant\": true,\n              \"refId\": \"A\"\n            }\n          ],\n          \"transformations\": [\n            {\n              \"id\": \"organize\",\n              \"options\": {\n                \"excludeByName\": {\n                  \"Time\": true\n                },\n                \"indexByName\": {},\n                \"renameByName\": {\n                  \"user_id\": \"User\",\n                  \"Value\": \"Cost\"\n                }\n              }\n            }\n          ],\n          \"title\": \"User Cost Ranking (7d)\",\n          \"type\": \"bargauge\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"max\": 1000,\n              \"min\": 0,\n              \"thresholds\": {\n                \"mode\": \"percentage\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"yellow\",\n                    \"value\": 70\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 90\n                  }\n                ]\n              },\n              \"unit\": \"percentunit\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 6,\n            \"w\": 6,\n            \"x\": 0,\n            \"y\": 6\n          },\n          \"id\": 5,\n          \"options\": {\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"values\": false,\n              \"calcs\": [\"lastNotNull\"],\n              \"fields\": \"\"\n            },\n            \"showThresholdLabels\": false,\n            \"showThresholdMarkers\": true\n          },\n          \"pluginVersion\": \"11.1.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"expr\": \"sum(increase(claude_code_token_cost_dollars_total[30d])) / 1000\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Monthly Budget Burn ($1000)\",\n          \"type\": \"gauge\"\n        }\n      ],\n      \"refresh\": \"30s\",\n      \"schemaVersion\": 39,\n      \"style\": \"dark\",\n      \"tags\": [\"claude-code\", \"cost\"],\n      \"templating\": {\n        \"list\": [\n          {\n            \"current\": {\n              \"selected\": false,\n              \"text\": \"VictoriaMetrics\",\n              \"value\": \"P4169E866C3094E38\"\n            },\n            \"hide\": 0,\n            \"includeAll\": false,\n            \"label\": \"Data Source\",\n            \"multi\": false,\n            \"name\": \"datasource\",\n            \"options\": [],\n            \"query\": \"prometheus\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"skipUrlSync\": false,\n            \"type\": \"datasource\"\n          }\n        ]\n      },\n      \"time\": {\n        \"from\": \"now-24h\",\n        \"to\": \"now\"\n      },\n      \"timepicker\": {},\n      \"timezone\": \"\",\n      \"title\": \"Claude Code - Cost Management\",\n      \"uid\": \"claude-code-cost\",\n      \"version\": 1,\n      \"weekStart\": \"\"\n    }\nEOF\n\necho \"Applying all dashboards...\"\nkubectl apply -f /Users/jonathonfritz/platform/manifests/dashboards/engineering-metrics-configmap.yaml\nkubectl apply -f /Users/jonathonfritz/platform/manifests/dashboards/operations-monitoring-configmap.yaml\nkubectl apply -f /Users/jonathonfritz/platform/manifests/dashboards/cost-management-configmap.yaml\n\necho \"Dashboards created and applied successfully!\""
        },
        {
          "path": "setup-agent-secrets.sh",
          "file_type": "sh",
          "line_count": 213,
          "key_definitions": [],
          "content": "#!/bin/bash\n# Setup GitHub agent secrets for 5D Labs Platform\n# This script creates the SSH and GitHub token secrets that the orchestrator expects\n\nset -euo pipefail\n\n# Default values\nNAMESPACE=\"orchestrator\"\nDRY_RUN=\"\"\nVERBOSE=\"\"\n\n# Function to show usage\nusage() {\n    cat << EOF\nSetup GitHub agent secrets for 5D Labs Platform\n\nUSAGE:\n    $0 --user <github-user> --ssh-key <path> --token <token> [OPTIONS]\n\nREQUIRED:\n    --user <username>       GitHub username (e.g., 'johnsmith')\n    --ssh-key <path>        Path to SSH private key (e.g., '~/.ssh/github_key')\n    --token <token>         GitHub personal access token (ghp_xxxx)\n\nOPTIONS:\n    --namespace <name>      Kubernetes namespace (default: orchestrator)\n    --dry-run              Show commands without executing\n    --verbose              Show detailed output\n    --help                 Show this help message\n\nEXAMPLES:\n    # Setup secrets for user 'johnsmith'\n    $0 --user johnsmith --ssh-key ~/.ssh/github_johnsmith --token ghp_abc123\n\n    # Dry run to see what would be created\n    $0 --user alice --ssh-key ~/.ssh/alice_github --token ghp_xyz789 --dry-run\n\n    # Setup in different namespace\n    $0 --user bob --ssh-key ~/.ssh/bob --token ghp_def456 --namespace my-orchestrator\n\nNOTES:\n    - SSH key path should point to the PRIVATE key (public key will be derived)\n    - GitHub token needs 'repo' permissions for PR creation\n    - Secrets will be named: github-ssh-<user> and github-token-<user>\n    - Existing secrets will be replaced without warning\n\nEOF\n}\n\n# Function for verbose logging\nlog() {\n    if [[ -n \"$VERBOSE\" ]]; then\n        echo \"🔧 $*\" >&2\n    fi\n}\n\n# Function to execute or show commands\nexecute() {\n    if [[ -n \"$DRY_RUN\" ]]; then\n        echo \"DRY RUN: $*\"\n    else\n        log \"Executing: $*\"\n        eval \"$@\"\n    fi\n}\n\n# Parse command line arguments\nGITHUB_USER=\"\"\nSSH_KEY_PATH=\"\"\nGITHUB_TOKEN=\"\"\n\nwhile [[ $# -gt 0 ]]; do\n    case $1 in\n        --user)\n            GITHUB_USER=\"$2\"\n            shift 2\n            ;;\n        --ssh-key)\n            SSH_KEY_PATH=\"$2\"\n            shift 2\n            ;;\n        --token)\n            GITHUB_TOKEN=\"$2\"\n            shift 2\n            ;;\n        --namespace)\n            NAMESPACE=\"$2\"\n            shift 2\n            ;;\n        --dry-run)\n            DRY_RUN=\"true\"\n            shift\n            ;;\n        --verbose)\n            VERBOSE=\"true\"\n            shift\n            ;;\n        --help)\n            usage\n            exit 0\n            ;;\n        *)\n            echo \"❌ Unknown option: $1\" >&2\n            echo \"Use --help for usage information\" >&2\n            exit 1\n            ;;\n    esac\ndone\n\n# Validate required arguments\nif [[ -z \"$GITHUB_USER\" ]]; then\n    echo \"❌ Error: --user is required\" >&2\n    echo \"Use --help for usage information\" >&2\n    exit 1\nfi\n\nif [[ -z \"$SSH_KEY_PATH\" ]]; then\n    echo \"❌ Error: --ssh-key is required\" >&2\n    echo \"Use --help for usage information\" >&2\n    exit 1\nfi\n\nif [[ -z \"$GITHUB_TOKEN\" ]]; then\n    echo \"❌ Error: --token is required\" >&2\n    echo \"Use --help for usage information\" >&2\n    exit 1\nfi\n\n# Validate SSH key path\nSSH_KEY_PATH=$(eval echo \"$SSH_KEY_PATH\")  # Expand ~ if present\nif [[ ! -f \"$SSH_KEY_PATH\" ]]; then\n    echo \"❌ Error: SSH private key not found at: $SSH_KEY_PATH\" >&2\n    exit 1\nfi\n\n# Derive public key path\nSSH_PUB_PATH=\"${SSH_KEY_PATH}.pub\"\nif [[ ! -f \"$SSH_PUB_PATH\" ]]; then\n    echo \"❌ Error: SSH public key not found at: $SSH_PUB_PATH\" >&2\n    echo \"Expected to find public key alongside private key\" >&2\n    exit 1\nfi\n\n# Validate GitHub token format\nif [[ ! \"$GITHUB_TOKEN\" =~ ^ghp_[a-zA-Z0-9_]{36}$ ]]; then\n    echo \"⚠️  Warning: GitHub token doesn't match expected format (ghp_xxxxx)\" >&2\n    echo \"Continuing anyway...\" >&2\nfi\n\n# Generate secret names\nSSH_SECRET_NAME=\"github-ssh-${GITHUB_USER}\"\nTOKEN_SECRET_NAME=\"github-token-${GITHUB_USER}\"\n\n# Show summary\necho \"🚀 Setting up GitHub agent secrets\"\necho \"   User: $GITHUB_USER\"\necho \"   SSH Key: $SSH_KEY_PATH\"\necho \"   Namespace: $NAMESPACE\"\necho \"   SSH Secret: $SSH_SECRET_NAME\"\necho \"   Token Secret: $TOKEN_SECRET_NAME\"\necho \"\"\n\nif [[ -n \"$DRY_RUN\" ]]; then\n    echo \"🔍 DRY RUN MODE - No changes will be made\"\n    echo \"\"\nfi\n\n# Check if kubectl is available\nif ! command -v kubectl >/dev/null 2>&1; then\n    echo \"❌ Error: kubectl is not installed or not in PATH\" >&2\n    exit 1\nfi\n\n# Check if namespace exists\nif [[ -z \"$DRY_RUN\" ]]; then\n    if ! kubectl get namespace \"$NAMESPACE\" >/dev/null 2>&1; then\n        echo \"❌ Error: Namespace '$NAMESPACE' does not exist\" >&2\n        echo \"Create it first: kubectl create namespace $NAMESPACE\" >&2\n        exit 1\n    fi\nfi\n\n# Create SSH secret\nlog \"Creating SSH secret: $SSH_SECRET_NAME\"\nexecute kubectl create secret generic \"$SSH_SECRET_NAME\" \\\n    --namespace=\"$NAMESPACE\" \\\n    --from-file=ssh-privatekey=\"$SSH_KEY_PATH\" \\\n    --from-file=ssh-publickey=\"$SSH_PUB_PATH\" \\\n    --dry-run=client -o yaml \\| kubectl apply -f -\n\n# Create GitHub token secret\nlog \"Creating GitHub token secret: $TOKEN_SECRET_NAME\"\nexecute kubectl create secret generic \"$TOKEN_SECRET_NAME\" \\\n    --namespace=\"$NAMESPACE\" \\\n    --from-literal=token=\"$GITHUB_TOKEN\" \\\n    --dry-run=client -o yaml \\| kubectl apply -f -\n\nif [[ -z \"$DRY_RUN\" ]]; then\n    echo \"\"\n    echo \"✅ Successfully created agent secrets for user: $GITHUB_USER\"\n    echo \"\"\n    echo \"🔍 Verify secrets:\"\n    echo \"   kubectl get secrets -n $NAMESPACE | grep github-$GITHUB_USER\"\n    echo \"\"\n    echo \"📋 To use this agent in a CodeRun:\"\n    echo \"   spec:\"\n    echo \"     githubUser: \\\"$GITHUB_USER\\\"\"\n    echo \"     # ... other fields\"\nelse\n    echo \"\"\n    echo \"✅ Dry run completed successfully\"\n    echo \"Remove --dry-run to execute these commands\"\nfi"
        }
      ],
      "dependencies": [],
      "description": "scripts configuration and files",
      "line_count": 2835
    },
    {
      "name": "documentation",
      "path": "docs",
      "component_type": "Documentation",
      "source_files": [
        {
          "path": "qa-agent-design.md",
          "file_type": "md",
          "line_count": 267,
          "key_definitions": [],
          "content": "# QA Agent Design Document\n\n## 🎯 **Overview**\n\nThe QA Agent is an autonomous quality assurance system that monitors pull requests, deploys applications to test environments, validates functionality and code quality, and provides automated feedback to development teams. It operates as a feedback loop until both functionality and quality standards are met.\n\n## 🏗️ **Architecture**\n\n### **Core Principles**\n- **Pull/Polling Model**: 30-second intervals per repository\n- **Service-Based Isolation**: Dedicated namespaces per service (`qa-{service-name}`)\n- **Functionality-First**: Deploy and test functionality before code quality\n- **Self-Healing**: Automatically fixes deployment issues\n- **Human-Gated Merging**: Can approve PRs but never merge (CTO-only)\n- **Feedback Loop**: Continuous iteration until both functionality + quality pass\n\n### **Integration Points**\n- **Tasks System**: References acceptance criteria via task IDs\n- **MCP Quality Server**: Pluggable code quality analysis\n- **GitHub API**: PR management, comments, approvals\n- **Kubernetes**: Deployment orchestration and namespace management\n- **Code Agent**: Triggers remediation work via PR comments\n\n## 📋 **QAAgentRun CRD Specification**\n\n```yaml\napiVersion: orchestrator.platform/v1\nkind: QAAgentRun\nmetadata:\n  name: qa-simple-api\n  namespace: orchestrator\nspec:\n  # Repository Configuration\n  repository: \"5dlabs/simple-api\"\n  service: \"simple-api\"           # Creates qa-simple-api namespace\n  githubUser: \"pm0-5dlabs\"\n  branches: [\"main\", \"feature/*\"]\n  pollInterval: \"30s\"\n\n  # Testing Configuration\n  tasksAcceptanceCriteria: \"task-123\"  # Reference to Tasks system\n  deploymentChart: \"./helm\"            # Path to Helm chart in repo\n\n  # Image Strategy\n  imageRegistry: \"ghcr.io/5dlabs\"\n  buildAndPush: true                   # Build fresh image per PR\n\n  # Testing Phases (executed in order)\n  phases:\n    - \"functionality\"                  # Deploy + functional tests first\n    - \"quality\"                        # Code quality via MCP server\n    - \"approval\"                       # Auto-approve if both pass\n\n  # Self-Healing & Alerting\n  autoFixDeployments: true\n  alertCTOOnFailure: true             # Stretch goal: Alert on critical issues\n  maxRetryAttempts: 3\n\n  # Actions\n  autoApprove: true                   # Approve PRs that pass all phases\n  autoMerge: false                    # NEVER merge (human-only gate)\n\n  # State Tracking\n  lastCheckedCommit: \"\"\n  lastQArun: \"\"\n  currentPhase: \"\"\n```\n\n## 🔄 **Workflow Sequence**\n\n### **1. Detection Phase**\n- Poll GitHub every 30 seconds for:\n  - New pull requests on monitored branches\n  - New commits on existing pull requests\n  - Merge conflicts requiring resolution\n- Track state using `lastCheckedCommit` to avoid duplicate processing\n\n### **2. Build & Push Phase**\n```bash\n# Build application image\ndocker build -t ${imageRegistry}/${service}:pr-${PR_NUMBER} .\ndocker push ${imageRegistry}/${service}:pr-${PR_NUMBER}\n```\n\n### **3. Deployment Phase**\n- Deploy to service-specific namespace: `qa-${service}`\n- Use Helm chart from repository: `helm upgrade qa-${service} ./helm`\n- Override image tag to use PR-specific build\n- **Self-Healing**: If deployment fails, analyze and fix issues automatically\n\n### **4. Functionality Testing Phase**\n- Execute acceptance criteria from Tasks system\n- Validate endpoints, core functionality, integration points\n- **Priority**: Must pass before proceeding to quality phase\n\n### **5. Quality Analysis Phase**\n- Call quality MCP server for code review\n- Check coding standards, architecture patterns, security issues\n- Generate detailed quality report\n\n### **6. Results & Actions Phase**\n- **Both Pass**: Auto-approve PR, comment with success details\n- **Functionality Fails**: Comment with issues, trigger Code agent to fix\n- **Quality Fails**: Comment with quality issues, trigger Code agent to improve\n- **Deployment Fails**: Attempt auto-fix, alert CTO if unable to resolve\n\n### **7. Merge Conflict Detection**\n- Detect merge conflicts during polling\n- Comment: \"⚠️ Merge conflict detected. @Code-Agent please resolve conflicts with main branch\"\n- Trigger Code agent to resolve conflicts and continue\n\n## 🛠️ **Implementation Components**\n\n### **QA Agent Container**\n```dockerfile\n# Base image with GitHub CLI, Docker, Helm, kubectl\nFROM ghcr.io/5dlabs/qa-agent:latest\n\n# QA-specific tools and MCP client\nCOPY qa-agent.py /app/\nCOPY quality-checkers/ /app/checkers/\n```\n\n### **QA Templates Structure**\n```\nclaude-templates/qa/\n├── claude.md.hbs           # QA agent personality and instructions\n├── container.sh.hbs        # QA execution script\n├── settings.json.hbs       # QA-specific Claude settings\n└── hooks/\n    ├── pre-deployment.sh.hbs\n    ├── post-deployment.sh.hbs\n    └── quality-check.sh.hbs\n```\n\n### **Controller Logic**\n- **QA Controller**: Manages QAAgentRun lifecycle\n- **Namespace Management**: Creates/manages `qa-{service}` namespaces\n- **State Tracking**: Maintains polling state and retry counts\n- **Integration**: Interfaces with GitHub API and Tasks system\n\n## 🔧 **Configuration Management**\n\n### **Quality Standards**\n```yaml\nqualityStandards:\n  level: \"strict\"                    # strict|standard|minimal\n  mcpServer: \"rust-quality-server\"\n  checkers:\n    - \"security-scan\"\n    - \"code-complexity\"\n    - \"test-coverage\"\n    - \"documentation\"\n```\n\n### **Deployment Configuration**\n```yaml\ndeployment:\n  namespace: \"qa-{service}\"\n  helmChart: \"./helm\"\n  valueOverrides:\n    image:\n      tag: \"pr-{PR_NUMBER}\"\n    resources:\n      limits:\n        cpu: \"500m\"\n        memory: \"512Mi\"\n```\n\n## 🚨 **Error Handling & Alerting**\n\n### **Self-Healing Scenarios**\n- **Helm deployment failures**: Analyze and fix chart issues\n- **Resource constraints**: Adjust resource requests/limits\n- **Dependency issues**: Install missing dependencies\n- **Configuration errors**: Fix common misconfigurations\n\n### **CTO Alerting (Stretch Goal)**\n- **Critical deployment failures** after max retries\n- **Security vulnerabilities** found during quality checks\n- **System-wide issues** affecting multiple services\n- **Code agent unresponsive** to QA feedback\n\n## 📊 **Success Metrics**\n\n### **Functionality Metrics**\n- Deployment success rate\n- Functional test pass rate\n- Time to detect issues\n\n### **Quality Metrics**\n- Code quality score trends\n- Security vulnerability detection\n- Technical debt accumulation\n\n### **Process Metrics**\n- Average time from PR to approval\n- Merge conflict detection/resolution time\n- Human intervention frequency\n\n## 🚀 **Implementation Phases**\n\n### **Phase 1: Core QA Agent**\n- [ ] Create QAAgentRun CRD\n- [ ] Implement basic polling and PR detection\n- [ ] Build deployment automation\n- [ ] Basic functionality testing\n\n### **Phase 2: Quality Integration**\n- [ ] Integrate MCP quality server\n- [ ] Implement quality scoring\n- [ ] Add quality-based approval logic\n\n### **Phase 3: Advanced Features**\n- [ ] Self-healing deployment fixes\n- [ ] CTO alerting system\n- [ ] Advanced merge conflict detection\n- [ ] Performance and security testing\n\n### **Phase 4: Optimization**\n- [ ] Multi-service orchestration\n- [ ] Advanced quality metrics\n- [ ] Predictive failure detection\n- [ ] Integration with CI/CD pipelines\n\n## 🎛️ **Configuration Examples**\n\n### **Simple API Service**\n```yaml\napiVersion: orchestrator.platform/v1\nkind: QAAgentRun\nmetadata:\n  name: qa-simple-api\nspec:\n  repository: \"5dlabs/simple-api\"\n  service: \"simple-api\"\n  tasksAcceptanceCriteria: \"task-456\"\n  deploymentChart: \"./helm\"\n  autoApprove: true\n```\n\n### **Complex Microservice**\n```yaml\napiVersion: orchestrator.platform/v1\nkind: QAAgentRun\nmetadata:\n  name: qa-trader-service\nspec:\n  repository: \"5dlabs/trader\"\n  service: \"trader\"\n  tasksAcceptanceCriteria: \"task-789\"\n  deploymentChart: \"./k8s/helm\"\n  qualityStandards:\n    level: \"strict\"\n    mcpServer: \"financial-quality-server\"\n  maxRetryAttempts: 5\n  alertCTOOnFailure: true\n```\n\n## 🔮 **Future Enhancements**\n\n- **Multi-Environment Testing**: Test across dev, staging, prod-like environments\n- **Performance Testing**: Automated load and performance testing\n- **Security Scanning**: Integrated vulnerability scanning\n- **Compliance Checking**: Automated compliance validation\n- **Cross-Service Integration Testing**: Test service interactions\n- **Rollback Automation**: Automatic rollback on failure detection"
        },
        {
          "path": "mcp-tools-template-design.md",
          "file_type": "md",
          "line_count": 461,
          "key_definitions": [],
          "content": "# MCP Tools Template Design\n\n## Problem Statement\n\nClaude Code CRD tasks need to understand what MCP tools are available to them, but currently this information is not dynamically provided. This leads to:\n\n- Claude not knowing what capabilities it has\n- Suboptimal tool usage\n- Manual documentation that gets out of sync\n- Inability to adapt behavior based on available tools\n\n## REFINED APPROACH: Template-Driven Tool Documentation\n\n### Enhanced Concept\n\nInstead of a static catalog, use the tool configuration as a **source template** to dynamically generate an `mcp-tools.md` file that gets included in Claude's memory. This provides:\n\n- **Dynamic Documentation**: Only shows tools that are actually enabled\n- **Conditional Usage Guidelines**: Different recommendations based on tool availability\n- **Single Source of Truth**: Tool config drives both deployment AND documentation\n- **Context-Aware**: Can vary by task type, environment, or service\n\n### Implementation Architecture\n\n#### 1. Enhanced Tool Configuration\n```yaml\n# values.yaml\ncodeRunConfig:\n  toolConfigurations:\n    minimal:\n      localTools:\n        - name: \"read_file\"\n          enabled: true\n          description: \"Read file contents with line-range support\"\n          category: \"file-ops\"\n          riskLevel: \"low\"\n          usageGuidelines:\n            - \"Always read before editing to understand context\"\n            - \"Use line ranges for large files\"\n            - \"Prefer for understanding code structure\"\n          examples:\n            - \"Reading package.json to understand dependencies\"\n            - \"Checking existing code before modifications\"\n\n        - name: \"edit_file\"\n          enabled: true\n          description: \"Edit files with precise diff-based changes\"\n          category: \"file-ops\"\n          riskLevel: \"medium\"\n          usageGuidelines:\n            - \"Always include sufficient context around changes\"\n            - \"Use for targeted modifications, not wholesale rewrites\"\n            - \"Verify changes with read_file afterward\"\n          examples:\n            - \"Adding new functions to existing modules\"\n            - \"Updating configuration files\"\n\n        - name: \"run_terminal_cmd\"\n          enabled: true\n          description: \"Execute shell commands in the workspace\"\n          category: \"system\"\n          riskLevel: \"high\"\n          usageGuidelines:\n            - \"Use sparingly and with caution\"\n            - \"Prefer specific tools over generic shell commands\"\n            - \"Always explain what command does before running\"\n            - \"Never run commands that could damage the system\"\n          conditionalUsage:\n            - condition: \"Installing dependencies\"\n              recommendation: \"Use npm install, pip install, etc.\"\n            - condition: \"Running tests\"\n              recommendation: \"Use npm test, pytest, cargo test, etc.\"\n\n      remoteTools:\n        - name: \"web_search\"\n          enabled: false  # Not available in minimal config\n          description: \"Search the web for current information\"\n          category: \"research\"\n\n    advanced:\n      localTools:\n        # ... includes all minimal tools plus:\n        - name: \"codebase_search\"\n          enabled: true\n          description: \"Semantic search across the codebase\"\n          category: \"code-analysis\"\n          riskLevel: \"low\"\n          usageGuidelines:\n            - \"Use for understanding unfamiliar codebases\"\n            - \"Great for finding patterns and implementations\"\n            - \"Prefer over grep for conceptual searches\"\n\n      remoteTools:\n        - name: \"web_search\"\n          enabled: true\n          description: \"Search the web for current information\"\n          category: \"research\"\n          riskLevel: \"low\"\n          usageGuidelines:\n            - \"Use for latest documentation and best practices\"\n            - \"Helpful for debugging error messages\"\n            - \"Good for checking library compatibility\"\n\n        - name: \"github_create_issue\"\n          enabled: true\n          description: \"Create GitHub issues\"\n          category: \"collaboration\"\n          requirements: [\"github_token\"]\n```\n\n#### 2. Template Generation Logic\n```handlebars\n{{!-- mcp-tools.md.hbs --}}\n# Available MCP Tools\n\nBased on your current configuration (**{{toolConfig}}**), you have access to:\n\n## Local Tools (Always Available)\n\n{{#each localTools}}\n{{#if enabled}}\n### 🔧 {{name}}\n\n**Description:** {{description}}\n**Category:** {{category}}\n**Risk Level:** {{riskLevel}}\n\n**Usage Guidelines:**\n{{#each usageGuidelines}}\n- {{this}}\n{{/each}}\n\n{{#if conditionalUsage}}\n**When to Use:**\n{{#each conditionalUsage}}\n- **{{condition}}**: {{recommendation}}\n{{/each}}\n{{/if}}\n\n**Examples:**\n{{#each examples}}\n- {{this}}\n{{/each}}\n\n---\n{{/if}}\n{{/each}}\n\n## Remote Tools (Network Required)\n\n{{#if remoteTools}}\n{{#each remoteTools}}\n{{#if enabled}}\n### 🌐 {{name}}\n\n**Description:** {{description}}\n**Category:** {{category}}\n{{#if requirements}}**Requirements:** {{join requirements \", \"}}{{/if}}\n\n**Usage Guidelines:**\n{{#each usageGuidelines}}\n- {{this}}\n{{/each}}\n\n---\n{{/if}}\n{{/each}}\n{{else}}\n*No remote tools enabled in {{toolConfig}} configuration.*\n{{/if}}\n\n## Tool Selection Strategy\n\n{{#if (eq toolConfig \"minimal\")}}\n**Minimal Configuration Strategy:**\n- Focus on core file operations (read, edit)\n- Use terminal commands only when necessary\n- Rely on built-in capabilities\n- Prioritize simple, direct approaches\n{{/if}}\n\n{{#if (eq toolConfig \"advanced\")}}\n**Advanced Configuration Strategy:**\n- Leverage semantic search for code understanding\n- Use web search for current best practices\n- Consider remote tools for enhanced capabilities\n- Balance efficiency with available tooling\n{{/if}}\n\n## Best Practices\n\n1. **Start with Low-Risk Tools**: Always try `read_file` and `codebase_search` first\n2. **Understand Before Acting**: Read existing code before making changes\n3. **Verify Changes**: Use `read_file` to confirm edits worked as expected\n4. **Progressive Enhancement**: Use higher-risk tools only when necessary\n5. **Document Decisions**: Explain tool choices in your implementation notes\n\n## Tool Combinations\n\n**For Understanding Code:**\n1. `codebase_search` → Find relevant files/patterns\n2. `read_file` → Examine specific implementations\n3. `web_search` → Research unfamiliar patterns (if available)\n\n**For Making Changes:**\n1. `read_file` → Understand current state\n2. `edit_file` → Make targeted changes\n3. `read_file` → Verify changes\n4. `run_terminal_cmd` → Test/build (if needed)\n\n**For Research & Documentation:**\n1. `web_search` → Find current best practices (if available)\n2. `codebase_search` → Find existing patterns in project\n3. `read_file` → Study implementation details\n```\n\n#### 3. Integration with Container Script\n```bash\n# In container.sh.hbs\n# Generate MCP tools documentation based on current tool config\necho \"🔧 Generating MCP tools documentation for {{toolConfig}} configuration...\"\n\n# Template rendering would happen during ConfigMap creation\n# The resulting mcp-tools.md would be available via @ pointer\n```\n\n#### 4. CLAUDE.md Integration\n```markdown\n# Claude Code Project Memory\n\n## Tool Capabilities\nSee @mcp-tools.md for your available tools and usage guidelines\n\n## Project Guidelines & Standards\nSee @coding-guidelines.md for project coding standards and best practices\nSee @github-guidelines.md for git workflow and commit message standards\n\n## Current Task Documentation\nSee @task/task.md for requirements and description\n```\n\n### Benefits of This Approach\n\n✅ **Automatic Synchronization**: Documentation always matches actual tool availability\n✅ **Configuration-Aware**: Different docs for minimal vs advanced setups\n✅ **Usage Guidance**: Not just \"what\" tools but \"when\" and \"how\" to use them\n✅ **Risk Management**: Clear guidance on tool risk levels and best practices\n✅ **Contextual Help**: Tool combinations and workflow recommendations\n✅ **Maintenance-Free**: No manual documentation updates needed\n\n### Template Rendering Process\n\n1. **ConfigMap Generation**: Helm renders tool config into tool documentation template\n2. **File Creation**: Generated `mcp-tools.md` included in task ConfigMap\n3. **Claude Memory**: Loaded via `@mcp-tools.md` pointer in CLAUDE.md\n4. **Dynamic Adaptation**: Each task gets documentation matching its tool configuration\n\nThis creates a **self-documenting** system where the tool configuration itself becomes the source of truth for both deployment and Claude's understanding of capabilities.\n\n## Original Approach: ConfigMap Tool Catalog\n\n### Core Approach\n\nStore a comprehensive catalog of both local and remote MCP tools in the Helm chart ConfigMap. This catalog would be rendered into Claude's memory to inform it of exact capabilities.\n\n### Implementation Strategy\n\n#### 1. Tool Catalog Structure\n```yaml\n# In values.yaml or dedicated config\nmcpTools:\n  local:\n    - name: \"bash\"\n      description: \"Execute shell commands\"\n      category: \"system\"\n      riskLevel: \"high\"\n      examples: [\"ls -la\", \"cd /workspace\", \"npm install\"]\n\n    - name: \"edit\"\n      description: \"Edit files with diff-based changes\"\n      category: \"file\"\n      riskLevel: \"medium\"\n      examples: [\"edit src/index.js\", \"modify configuration\"]\n\n    - name: \"read\"\n      description: \"Read file contents\"\n      category: \"file\"\n      riskLevel: \"low\"\n      examples: [\"read package.json\", \"view source code\"]\n\n  remote:\n    - name: \"github_create_issue\"\n      description: \"Create GitHub issues\"\n      category: \"github\"\n      riskLevel: \"medium\"\n      requirements: [\"github_token\"]\n\n    - name: \"rustdocs_query\"\n      description: \"Query Rust documentation\"\n      category: \"documentation\"\n      riskLevel: \"low\"\n```\n\n#### 2. Template Generation\n```handlebars\n# Available MCP Tools\n\nYou have access to the following tools:\n\n## Local Tools\n{{#each mcpTools.local}}\n### {{name}}\n**Description:** {{description}}\n**Category:** {{category}}\n**Risk Level:** {{riskLevel}}\n{{#if examples}}\n**Examples:** {{join examples \", \"}}\n{{/if}}\n\n{{/each}}\n\n## Remote Tools\n{{#each mcpTools.remote}}\n### {{name}}\n**Description:** {{description}}\n**Category:** {{category}}\n**Risk Level:** {{riskLevel}}\n{{#if requirements}}\n**Requirements:** {{join requirements \", \"}}\n{{/if}}\n\n{{/each}}\n\n## Tool Usage Guidelines\n- Prefer low-risk tools when possible\n- Always verify file changes with read operations\n- Use bash sparingly and with caution\n- Check remote tool requirements before use\n```\n\n### Advantages\n\n✅ **Complete Visibility**: Both local and remote tools cataloged\n✅ **Easy Maintenance**: Centralized in Helm values\n✅ **Version Control**: Tool catalog versioned with infrastructure\n✅ **Flexible Rendering**: Can generate different templates per task type\n✅ **Risk Awareness**: Claude understands tool risk levels\n✅ **Conditional Logic**: Templates can adapt based on available tools\n\n### Disadvantages\n\n❌ **Manual Maintenance**: Requires updating when tools change\n❌ **Sync Risk**: Catalog can drift from actual available tools\n❌ **Static Nature**: Can't detect runtime tool availability changes\n\n## Alternative Approaches\n\n### 1. Dynamic Tool Discovery\n**Concept**: Query MCP server at runtime for available tools\n```bash\n# Hypothetical\nmcp-client list-tools --format=json\n```\n**Pros**: Always accurate, no maintenance\n**Cons**: Complex implementation, runtime dependency, local tools still problematic\n\n### 2. Tool Introspection API\n**Concept**: Claude Code exposes API to query available tools\n```bash\ncurl localhost:8080/available-tools\n```\n**Pros**: Real-time accuracy\n**Cons**: Requires Claude Code modification, complex orchestration\n\n### 3. Hybrid Approach\n**Concept**: ConfigMap catalog + runtime validation\n- Use ConfigMap as base catalog\n- Validate availability at container startup\n- Generate warnings for missing tools\n\n**Implementation**:\n```bash\n# In container startup\nfor tool in ${EXPECTED_TOOLS}; do\n  if ! mcp-client check-tool \"$tool\"; then\n    echo \"⚠️ Tool $tool not available\"\n  fi\ndone\n```\n\n### 4. Tool Provider Manifests\n**Concept**: Each MCP server provides a manifest of tools\n```yaml\n# mcp-server-manifest.yaml\ntools:\n  - name: github_create_issue\n    description: \"Create GitHub issues\"\n    parameters:\n      - title: string\n      - body: string\n```\n**Pros**: Self-documenting, accurate\n**Cons**: Requires MCP server modifications\n\n### 5. Template Variants by Tool Configuration\n**Concept**: Pre-generate templates for common tool combinations\n```yaml\ntoolConfigurations:\n  minimal: [\"read\", \"edit\", \"bash\"]\n  advanced: [\"read\", \"edit\", \"bash\", \"github_*\", \"rustdocs_*\"]\n  development: [\"read\", \"edit\", \"bash\", \"npm\", \"git\", \"docker\"]\n```\n\n## Recommended Implementation Plan\n\n### Phase 1: ConfigMap Catalog (Immediate)\n1. Define tool catalog schema in values.yaml\n2. Create template that renders tool documentation\n3. Include in CLAUDE.md via @ pointer\n4. Manual maintenance process\n\n### Phase 2: Enhanced Metadata (Future)\n1. Add tool usage patterns and best practices\n2. Include conditional logic for task types\n3. Risk-based tool recommendations\n4. Integration examples\n\n### Phase 3: Validation Layer (Future)\n1. Container startup tool validation\n2. Runtime availability checking\n3. Graceful degradation for missing tools\n4. Tool usage analytics\n\n## Template Integration\n\nThe generated MCP tools documentation would be included in Claude's memory:\n\n```markdown\n# CLAUDE.md\nSee @coding-guidelines.md for project standards\nSee @github-guidelines.md for git workflow\nSee @mcp-tools.md for available capabilities    # <-- New addition\nSee @task/task.md for current requirements\n```\n\nThis ensures Claude has complete visibility into its capabilities while maintaining the clean @ pointer architecture.\n\n## Maintenance Workflow\n\n1. **Tool Addition**: Update values.yaml, test template rendering\n2. **Tool Removal**: Remove from catalog, update documentation\n3. **Tool Changes**: Modify descriptions and examples\n4. **Version Releases**: Review and update entire catalog\n\n## Future Enhancements\n\n- **Tool Usage Analytics**: Track which tools are used most frequently\n- **Smart Recommendations**: Suggest optimal tools for task types\n- **Performance Metrics**: Include tool execution time estimates\n- **Dependency Mapping**: Show tool interdependencies\n- **Security Profiles**: Tool access control based on task sensitivity"
        }
      ],
      "dependencies": [],
      "description": "documentation configuration and files",
      "line_count": 728
    }
  ],
  "apis": [
    {
      "name": "routes",
      "file_path": "orchestrator/core/src/main.rs",
      "endpoints": [
        {
          "method": "POST",
          "path": "/pm/tasks",
          "handler": ".route(\"/pm/tasks\", post(submit_code_task))",
          "line_number": 71
        },
        {
          "method": "POST",
          "path": "/pm/docs/generate",
          "handler": ".route(\"/pm/docs/generate\", post(generate_docs))",
          "line_number": 72
        },
        {
          "method": "GET",
          "path": "/health",
          "handler": ".route(\"/health\", get(health_check)) // Root health check for load balancers",
          "line_number": 110
        }
      ],
      "data_models": []
    }
  ],
  "configurations": [
    {
      "name": "kustomization.yaml",
      "path": "infra/talos/local-path-provisioner/kustomization.yaml",
      "config_type": "yaml",
      "content": "apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n- github.com/rancher/local-path-provisioner/deploy?ref=v0.0.31\npatches:\n- patch: |-\n    kind: ConfigMap\n    apiVersion: v1\n    metadata:\n      name: local-path-config\n      namespace: local-path-storage\n    data:\n      config.json: |-\n        {\n                \"nodePathMap\":[\n                {\n                        \"node\":\"DEFAULT_PATH_FOR_NON_LISTED_NODES\",\n                        \"paths\":[\"/var/mnt/local-path-provisioner\"]\n                }\n                ]\n        }\n- patch: |-\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n      name: local-path\n      annotations:\n        storageclass.kubernetes.io/is-default-class: \"true\"\n- patch: |-\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      name: local-path-storage\n      labels:\n        pod-security.kubernetes.io/enforce: privileged"
    },
    {
      "name": "local-path-storage.yaml",
      "path": "infra/talos/local-path-provisioner/local-path-storage.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1alpha1\nkind: UserVolumeConfig\nname: local-path-provisioner\nprovisioning:\n  diskSelector:\n    match: disk.transport == 'nvme'\n  minSize: 100GB\n  maxSize: 100GB"
    },
    {
      "name": "worker.yaml",
      "path": "infra/talos/config/simple/worker.yaml",
      "config_type": "yaml",
      "content": "version: v1alpha1\ndebug: false\npersist: true\nmachine:\n  type: worker\n  token: qt315g.8f9e1kb2r4p79efs\n  ca:\n    crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJQakNCOGFBREFnRUNBaEJ2TFQ0dzN2cnp1NE50UUUrcDZGeVhNQVVHQXl0bGNEQVFNUTR3REFZRFZRUUsKRXdWMFlXeHZjekFlRncweU5UQTJNekF5TXpBeE1UZGFGdzB6TlRBMk1qZ3lNekF4TVRkYU1CQXhEakFNQmdOVgpCQW9UQlhSaGJHOXpNQ293QlFZREsyVndBeUVBckNVc2YxeGZxenhwWnpFSFRsQXVCSllLSTh5UVpnS0RwZEJyCkFPY1JRZ2lqWVRCZk1BNEdBMVVkRHdFQi93UUVBd0lDaERBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUkKS3dZQkJRVUhBd0l3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVa1pBa2xPcVM2YnNmYjROdAo3ekNJTUR5cXVETXdCUVlESzJWd0EwRUFlbXJHVlpDa3RKeXRpdmJZNjV1TFJDODVFUThpbFpsOVd0WHpldjM3CmdjR1lpVkFzT1pDdzRXV21GMld6SWgrOVlGT1F3ZEZJblRSOFJIak93RHZIQ3c9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    key: \"\"\n  certSANs: []\n  kubelet:\n    image: ghcr.io/siderolabs/kubelet:v1.33.1\n    defaultRuntimeSeccompProfileEnabled: true\n    disableManifestsDirectory: true\n    nodeIP:\n      validSubnets:\n        - 192.168.1.0/24\n  network:\n    interfaces:\n      - interface: enp4s0\n        dhcp: true\n  install:\n    disk: /dev/nvme0n1\n    image: ghcr.io/siderolabs/installer:v1.10.4\n    wipe: true\n    extraKernelArgs:\n      - talos.install.disk=/dev/nvme0n1\n  features:\n    rbac: true\n    stableHostname: true\n    apidCheckExtKeyUsage: true\n    diskQuotaSupport: true\n    kubePrism:\n      enabled: true\n      port: 7445\n    hostDNS:\n      enabled: true\n      forwardKubeDNSToHost: true\ncluster:\n  id: wcWr92csTh7HmKPHHX1rKIQn2mHHS7dHYNXdAUZ5NXY=\n  secret: UPKt0QVDtJGdy3SVFCfGVJ6NV5/dSHCL9SFx1VweX7k=\n  controlPlane:\n    endpoint: https://192.168.1.77:6443\n  clusterName: simple-cluster\n  network:\n    dnsDomain: cluster.local\n    podSubnets:\n      - 10.244.0.0/16\n    serviceSubnets:\n      - 10.96.0.0/12\n    # cni: {}  # Let cluster decide CNI\n  token: 9c3zc1.fj82jlf3xfqwz8kf\n  ca:\n    crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpakNDQVRDZ0F3SUJBZ0lSQU1PQnFOeTV2V1FWN20vK2pBSHh0amd3Q2dZSUtvWkl6ajBFQXdJd0ZURVQKTUJFR0ExVUVDaE1LYTNWaVpYSnVaWFJsY3pBZUZ3MHlOVEEyTXpBeU16QXhNVGRhRncwek5UQTJNamd5TXpBeApNVGRhTUJVeEV6QVJCZ05WQkFvVENtdDFZbVZ5Ym1WMFpYTXdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CCkJ3TkNBQVFmTGJ2S25LUEZWb1lMRFduM1phY2ZidGhzU1JxRGJvVDgrY1YrdEFWTUs5L1lNSUNlQStaMUxERVkKVVJUK092enB0RWtQWVpiendCM0NxY09KQ3Z1cW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXdIUVlEVlIwbApCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPCkJCWUVGSHgzNitwNkpzNEN6dEZUL25hVHdyQXFsSVVzTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDSUVnUUJUdjkKK0c4MmhYdHUzRHpUemdtN3RpblhLcXhzbzZNQnVFWTFDeGdRQWlFQXVlWHBaeWRnNi9QdEovaHlZbjNsQ0xpSAppbTVLMHBGS0RlQWtVaG5DQndrPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    key: \"\"\n  discovery:\n    enabled: true\n    registries:\n      kubernetes:\n        disabled: true\n      service: {}"
    },
    {
      "name": "controlplane.yaml",
      "path": "infra/talos/config/simple/controlplane.yaml",
      "config_type": "yaml",
      "content": "version: v1alpha1 # Indicates the schema used to decode the contents.\ndebug: false # Enable verbose logging to the console.\npersist: true\n# Provides machine specific configuration options.\nmachine:\n    type: controlplane # Defines the role of the machine within the cluster.\n    token: qt315g.8f9e1kb2r4p79efs # The `token` is used by a machine to join the PKI of the cluster.\n    # The root certificate authority of the PKI.\n    ca:\n        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJQakNCOGFBREFnRUNBaEJ2TFQ0dzN2cnp1NE50UUUrcDZGeVhNQVVHQXl0bGNEQVFNUTR3REFZRFZRUUsKRXdWMFlXeHZjekFlRncweU5UQTJNekF5TXpBeE1UZGFGdzB6TlRBMk1qZ3lNekF4TVRkYU1CQXhEakFNQmdOVgpCQW9UQlhSaGJHOXpNQ293QlFZREsyVndBeUVBckNVc2YxeGZxenhwWnpFSFRsQXVCSllLSTh5UVpnS0RwZEJyCkFPY1JRZ2lqWVRCZk1BNEdBMVVkRHdFQi93UUVBd0lDaERBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUkKS3dZQkJRVUhBd0l3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVa1pBa2xPcVM2YnNmYjROdAo3ekNJTUR5cXVETXdCUVlESzJWd0EwRUFlbXJHVlpDa3RKeXRpdmJZNjV1TFJDODVFUThpbFpsOVd0WHpldjM3CmdjR1lpVkFzT1pDdzRXV21GMld6SWgrOVlGT1F3ZEZJblRSOFJIak93RHZIQ3c9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n        key: LS0tLS1CRUdJTiBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0KTUM0Q0FRQXdCUVlESzJWd0JDSUVJSjQrNGQyM2lNSTlHdlNZNnl2VU1xdjhqQlQyLzZGRGwrMTZaZHB6RHVRaAotLS0tLUVORCBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0K\n    # Extra certificate subject alternative names for the machine's certificate.\n    certSANs: []\n    #   # Uncomment this to enable SANs.\n    #   - 10.0.0.10\n    #   - 172.16.0.10\n    #   - 192.168.0.10\n\n    # Used to provide additional options to the kubelet.\n    kubelet:\n        image: ghcr.io/siderolabs/kubelet:v1.33.1 # The `image` field is an optional reference to an alternative kubelet image.\n        defaultRuntimeSeccompProfileEnabled: true # Enable container runtime default Seccomp profile.\n        disableManifestsDirectory: true # The `disableManifestsDirectory` field configures the kubelet to get static pod manifests from the /etc/kubernetes/manifests directory.\n        \n        # # The `ClusterDNS` field is an optional reference to an alternative kubelet clusterDNS ip list.\n        # clusterDNS:\n        #     - 10.96.0.10\n        #     - 169.254.2.53\n\n        # # The `extraArgs` field is used to provide additional flags to the kubelet.\n        # extraArgs:\n        #     key: value\n\n        # # The `extraMounts` field is used to add additional mounts to the kubelet container.\n        # extraMounts:\n        #     - destination: /var/lib/example # Destination is the absolute path where the mount will be placed in the container.\n        #       type: bind # Type specifies the mount kind.\n        #       source: /var/lib/example # Source specifies the source path of the mount.\n        #       # Options are fstab style mount options.\n        #       options:\n        #         - bind\n        #         - rshared\n        #         - rw\n\n        # # The `extraConfig` field is used to provide kubelet configuration overrides.\n        # extraConfig:\n        #     serverTLSBootstrap: true\n\n        # # The `KubeletCredentialProviderConfig` field is used to provide kubelet credential configuration.\n        # credentialProviderConfig:\n        #     apiVersion: kubelet.config.k8s.io/v1\n        #     kind: CredentialProviderConfig\n        #     providers:\n        #         - apiVersion: credentialprovider.kubelet.k8s.io/v1\n        #           defaultCacheDuration: 12h\n        #           matchImages:\n        #             - '*.dkr.ecr.*.amazonaws.com'\n        #             - '*.dkr.ecr.*.amazonaws.com.cn'\n        #             - '*.dkr.ecr-fips.*.amazonaws.com'\n        #             - '*.dkr.ecr.us-iso-east-1.c2s.ic.gov'\n        #             - '*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov'\n        #           name: ecr-credential-provider\n\n        # # The `nodeIP` field is used to configure `--node-ip` flag for the kubelet.\n        # nodeIP:\n        #     # The `validSubnets` field configures the networks to pick kubelet node IP from.\n        #     validSubnets:\n        #         - 10.0.0.0/8\n        #         - '!10.0.0.3/32'\n        #         - fdc7::/16\n    # Provides machine specific network configuration options.\n    network: {}\n    # # `interfaces` is used to define the network interface configuration.\n    # interfaces:\n    #     - interface: enp0s1 # The interface name.\n    #       # Assigns static IP addresses to the interface.\n    #       addresses:\n    #         - 192.168.2.0/24\n    #       # A list of routes associated with the interface.\n    #       routes:\n    #         - network: 0.0.0.0/0 # The route's network (destination).\n    #           gateway: 192.168.2.1 # The route's gateway (if empty, creates link scope route).\n    #           metric: 1024 # The optional metric for the route.\n    #       mtu: 1500 # The interface's MTU.\n    #       \n    #       # # Picks a network device using the selector.\n\n    #       # # select a device with bus prefix 00:*.\n    #       # deviceSelector:\n    #       #     busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.\n    #       # # select a device with mac address matching `*:f0:ab` and `virtio` kernel driver.\n    #       # deviceSelector:\n    #       #     hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.\n    #       #     driver: virtio_net # Kernel driver, supports matching by wildcard.\n    #       # # select a device with bus prefix 00:*, a device with mac address matching `*:f0:ab` and `virtio` kernel driver.\n    #       # deviceSelector:\n    #       #     - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.\n    #       #     - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.\n    #       #       driver: virtio_net # Kernel driver, supports matching by wildcard.\n\n    #       # # Bond specific options.\n    #       # bond:\n    #       #     # The interfaces that make up the bond.\n    #       #     interfaces:\n    #       #         - enp2s0\n    #       #         - enp2s1\n    #       #     # Picks a network device using the selector.\n    #       #     deviceSelectors:\n    #       #         - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.\n    #       #         - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.\n    #       #           driver: virtio_net # Kernel driver, supports matching by wildcard.\n    #       #     mode: 802.3ad # A bond option.\n    #       #     lacpRate: fast # A bond option.\n\n    #       # # Bridge specific options.\n    #       # bridge:\n    #       #     # The interfaces that make up the bridge.\n    #       #     interfaces:\n    #       #         - enxda4042ca9a51\n    #       #         - enxae2a6774c259\n    #       #     # Enable STP on this bridge.\n    #       #     stp:\n    #       #         enabled: true # Whether Spanning Tree Protocol (STP) is enabled.\n\n    #       # # Configure this device as a bridge port.\n    #       # bridgePort:\n    #       #     master: br0 # The name of the bridge master interface\n\n    #       # # Indicates if DHCP should be used to configure the interface.\n    #       # dhcp: true\n\n    #       # # DHCP specific options.\n    #       # dhcpOptions:\n    #       #     routeMetric: 1024 # The priority of all routes received via DHCP.\n\n    #       # # Wireguard specific configuration.\n\n    #       # # wireguard server example\n    #       # wireguard:\n    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).\n    #       #     listenPort: 51111 # Specifies a device's listening port.\n    #       #     # Specifies a list of peer configurations to apply to a device.\n    #       #     peers:\n    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.\n    #       #           endpoint: 192.168.1.3 # Specifies the endpoint of this peer entry.\n    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.\n    #       #           allowedIPs:\n    #       #             - 192.168.1.0/24\n    #       # # wireguard peer example\n    #       # wireguard:\n    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).\n    #       #     # Specifies a list of peer configurations to apply to a device.\n    #       #     peers:\n    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.\n    #       #           endpoint: 192.168.1.2:51822 # Specifies the endpoint of this peer entry.\n    #       #           persistentKeepaliveInterval: 10s # Specifies the persistent keepalive interval for this peer.\n    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.\n    #       #           allowedIPs:\n    #       #             - 192.168.1.0/24\n\n    #       # # Virtual (shared) IP address configuration.\n\n    #       # # layer2 vip example\n    #       # vip:\n    #       #     ip: 172.16.199.55 # Specifies the IP address to be used.\n\n    # # Used to statically set the nameservers for the machine.\n    # nameservers:\n    #     - 8.8.8.8\n    #     - 1.1.1.1\n\n    # # Used to statically set arbitrary search domains.\n    # searchDomains:\n    #     - example.org\n    #     - example.com\n\n    # # Allows for extra entries to be added to the `/etc/hosts` file\n    # extraHostEntries:\n    #     - ip: 192.168.1.100 # The IP of the host.\n    #       # The host alias.\n    #       aliases:\n    #         - example\n    #         - example.domain.tld\n\n    # # Configures KubeSpan feature.\n    # kubespan:\n    #     enabled: true # Enable the KubeSpan feature.\n\n    # Used to provide instructions for installations.\n    install:\n        disk: /dev/sda # The disk used for installations.\n        image: ghcr.io/siderolabs/installer:v1.10.4 # Allows for supplying the image used to perform the installation.\n        wipe: false # Indicates if the installation disk should be wiped at installation time.\n        \n        # # Look up disk using disk attributes like model, size, serial and others.\n        # diskSelector:\n        #     size: 4GB # Disk size.\n        #     model: WDC* # Disk model `/sys/block/<dev>/device/model`.\n        #     busPath: /pci0000:00/0000:00:17.0/ata1/host0/target0:0:0/0:0:0:0 # Disk bus path.\n\n        # # Allows for supplying extra kernel args via the bootloader.\n        # extraKernelArgs:\n        #     - talos.platform=metal\n        #     - reboot=k\n    # Used to configure the machine's container image registry mirrors.\n    registries: {}\n    # # Specifies mirror configuration for each registry host namespace.\n    # mirrors:\n    #     ghcr.io:\n    #         # List of endpoints (URLs) for registry mirrors to use.\n    #         endpoints:\n    #             - https://registry.insecure\n    #             - https://ghcr.io/v2/\n\n    # # Specifies TLS & auth configuration for HTTPS image registries.\n    # config:\n    #     registry.insecure:\n    #         # The TLS configuration for the registry.\n    #         tls:\n    #             insecureSkipVerify: true # Skip TLS server certificate verification (not recommended).\n    #             \n    #             # # Enable mutual TLS authentication with the registry.\n    #             # clientIdentity:\n    #             #     crt: LS0tIEVYQU1QTEUgQ0VSVElGSUNBVEUgLS0t\n    #             #     key: LS0tIEVYQU1QTEUgS0VZIC0tLQ==\n    #         \n    #         # # The auth configuration for this registry.\n    #         # auth:\n    #         #     username: username # Optional registry authentication.\n    #         #     password: password # Optional registry authentication.\n\n    # Features describe individual Talos features that can be switched on or off.\n    features:\n        rbac: true # Enable role-based access control (RBAC).\n        stableHostname: true # Enable stable default hostname.\n        apidCheckExtKeyUsage: true # Enable checks for extended key usage of client certificates in apid.\n        diskQuotaSupport: true # Enable XFS project quota support for EPHEMERAL partition and user disks.\n        # KubePrism - local proxy/load balancer on defined port that will distribute\n        kubePrism:\n            enabled: true # Enable KubePrism support - will start local load balancing proxy.\n            port: 7445 # KubePrism port.\n        # Configures host DNS caching resolver.\n        hostDNS:\n            enabled: true # Enable host DNS caching resolver.\n            forwardKubeDNSToHost: true # Use the host DNS resolver as upstream for Kubernetes CoreDNS pods.\n        \n        # # Configure Talos API access from Kubernetes pods.\n        # kubernetesTalosAPIAccess:\n        #     enabled: true # Enable Talos API access from Kubernetes pods.\n        #     # The list of Talos API roles which can be granted for access from Kubernetes pods.\n        #     allowedRoles:\n        #         - os:reader\n        #     # The list of Kubernetes namespaces Talos API access is available from.\n        #     allowedKubernetesNamespaces:\n        #         - kube-system\n    # Configures the node labels for the machine.\n    nodeLabels:\n        node.kubernetes.io/exclude-from-external-load-balancers: \"\"\n    \n    # # Provides machine specific control plane configuration options.\n\n    # # ControlPlane definition example.\n    # controlPlane:\n    #     # Controller manager machine specific configuration options.\n    #     controllerManager:\n    #         disabled: false # Disable kube-controller-manager on the node.\n    #     # Scheduler machine specific configuration options.\n    #     scheduler:\n    #         disabled: true # Disable kube-scheduler on the node.\n\n    # # Used to provide static pod definitions to be run by the kubelet directly bypassing the kube-apiserver.\n\n    # # nginx static pod.\n    # pods:\n    #     - apiVersion: v1\n    #       kind: pod\n    #       metadata:\n    #         name: nginx\n    #       spec:\n    #         containers:\n    #             - image: nginx\n    #               name: nginx\n\n    # # Allows the addition of user specified files.\n\n    # # MachineFiles usage example.\n    # files:\n    #     - content: '...' # The contents of the file.\n    #       permissions: 0o666 # The file's permissions in octal.\n    #       path: /tmp/file.txt # The path of the file.\n    #       op: append # The operation to use\n\n    # # The `env` field allows for the addition of environment variables.\n\n    # # Environment variables definition examples.\n    # env:\n    #     GRPC_GO_LOG_SEVERITY_LEVEL: info\n    #     GRPC_GO_LOG_VERBOSITY_LEVEL: \"99\"\n    #     https_proxy: http://SERVER:PORT/\n    # env:\n    #     GRPC_GO_LOG_SEVERITY_LEVEL: error\n    #     https_proxy: https://USERNAME:PASSWORD@SERVER:PORT/\n    # env:\n    #     https_proxy: http://DOMAIN\\USERNAME:PASSWORD@SERVER:PORT/\n\n    # # Used to configure the machine's time settings.\n\n    # # Example configuration for cloudflare ntp server.\n    # time:\n    #     disabled: false # Indicates if the time service is disabled for the machine.\n    #     # description: |\n    #     servers:\n    #         - time.cloudflare.com\n    #     bootTimeout: 2m0s # Specifies the timeout when the node time is considered to be in sync unlocking the boot sequence.\n\n    # # Used to configure the machine's sysctls.\n\n    # # MachineSysctls usage example.\n    # sysctls:\n    #     kernel.domainname: talos.dev\n    #     net.ipv4.ip_forward: \"0\"\n    #     net/ipv6/conf/eth0.100/disable_ipv6: \"1\"\n\n    # # Used to configure the machine's sysfs.\n\n    # # MachineSysfs usage example.\n    # sysfs:\n    #     devices.system.cpu.cpu0.cpufreq.scaling_governor: performance\n\n    # # Machine system disk encryption configuration.\n    # systemDiskEncryption:\n    #     # Ephemeral partition encryption.\n    #     ephemeral:\n    #         provider: luks2 # Encryption provider to use for the encryption.\n    #         # Defines the encryption keys generation and storage method.\n    #         keys:\n    #             - # Deterministically generated key from the node UUID and PartitionLabel.\n    #               nodeID: {}\n    #               slot: 0 # Key slot number for LUKS2 encryption.\n    #               \n    #               # # KMS managed encryption key.\n    #               # kms:\n    #               #     endpoint: https://192.168.88.21:4443 # KMS endpoint to Seal/Unseal the key.\n    #         \n    #         # # Cipher kind to use for the encryption. Depends on the encryption provider.\n    #         # cipher: aes-xts-plain64\n\n    #         # # Defines the encryption sector size.\n    #         # blockSize: 4096\n\n    #         # # Additional --perf parameters for the LUKS2 encryption.\n    #         # options:\n    #         #     - no_read_workqueue\n    #         #     - no_write_workqueue\n\n    # # Configures the udev system.\n    # udev:\n    #     # List of udev rules to apply to the udev system\n    #     rules:\n    #         - SUBSYSTEM==\"drm\", KERNEL==\"renderD*\", GROUP=\"44\", MODE=\"0660\"\n\n    # # Configures the logging system.\n    # logging:\n    #     # Logging destination.\n    #     destinations:\n    #         - endpoint: tcp://1.2.3.4:12345 # Where to send logs. Supported protocols are \"tcp\" and \"udp\".\n    #           format: json_lines # Logs format.\n\n    # # Configures the kernel.\n    # kernel:\n    #     # Kernel modules to load.\n    #     modules:\n    #         - name: brtfs # Module name.\n\n    # # Configures the seccomp profiles for the machine.\n    # seccompProfiles:\n    #     - name: audit.json # The `name` field is used to provide the file name of the seccomp profile.\n    #       # The `value` field is used to provide the seccomp profile.\n    #       value:\n    #         defaultAction: SCMP_ACT_LOG\n\n    # # Override (patch) settings in the default OCI runtime spec for CRI containers.\n\n    # # override default open file limit\n    # baseRuntimeSpecOverrides:\n    #     process:\n    #         rlimits:\n    #             - hard: 1024\n    #               soft: 1024\n    #               type: RLIMIT_NOFILE\n\n    # # Configures the node annotations for the machine.\n\n    # # node annotations example.\n    # nodeAnnotations:\n    #     customer.io/rack: r13a25\n\n    # # Configures the node taints for the machine. Effect is optional.\n\n    # # node taints example.\n    # nodeTaints:\n    #     exampleTaint: exampleTaintValue:NoSchedule\n# Provides cluster specific configuration options.\ncluster:\n    id: wcWr92csTh7HmKPHHX1rKIQn2mHHS7dHYNXdAUZ5NXY= # Globally unique identifier for this cluster (base64 encoded random 32 bytes).\n    secret: UPKt0QVDtJGdy3SVFCfGVJ6NV5/dSHCL9SFx1VweX7k= # Shared secret of cluster (base64 encoded random 32 bytes).\n    # Provides control plane specific configuration options.\n    controlPlane:\n        endpoint: https://192.168.1.77:6443 # Endpoint is the canonical controlplane endpoint, which can be an IP address or a DNS hostname.\n    clusterName: simple-cluster # Configures the cluster's name.\n    # Provides cluster specific network configuration options.\n    network:\n        dnsDomain: cluster.local # The domain used by Kubernetes DNS.\n        # The pod subnet CIDR.\n        podSubnets:\n            - 10.244.0.0/16\n        # The service subnet CIDR.\n        serviceSubnets:\n            - 10.96.0.0/12\n        \n        # # The CNI used.\n        # cni:\n        #     name: custom # Name of CNI to use.\n        #     # URLs containing manifests to apply for the CNI.\n        #     urls:\n        #         - https://docs.projectcalico.org/archive/v3.20/manifests/canal.yaml\n    token: 9c3zc1.fj82jlf3xfqwz8kf # The [bootstrap token](https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/) used to join the cluster.\n    secretboxEncryptionSecret: vjL8HJNiPgQy+MQeayXUvsJG+CPUUsxqb8klUinVoa0= # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).\n    # The base64 encoded root certificate authority used by Kubernetes.\n    ca:\n        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpakNDQVRDZ0F3SUJBZ0lSQU1PQnFOeTV2V1FWN20vK2pBSHh0amd3Q2dZSUtvWkl6ajBFQXdJd0ZURVQKTUJFR0ExVUVDaE1LYTNWaVpYSnVaWFJsY3pBZUZ3MHlOVEEyTXpBeU16QXhNVGRhRncwek5UQTJNamd5TXpBeApNVGRhTUJVeEV6QVJCZ05WQkFvVENtdDFZbVZ5Ym1WMFpYTXdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CCkJ3TkNBQVFmTGJ2S25LUEZWb1lMRFduM1phY2ZidGhzU1JxRGJvVDgrY1YrdEFWTUs5L1lNSUNlQStaMUxERVkKVVJUK092enB0RWtQWVpiendCM0NxY09KQ3Z1cW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXdIUVlEVlIwbApCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPCkJCWUVGSHgzNitwNkpzNEN6dEZUL25hVHdyQXFsSVVzTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDSUVnUUJUdjkKK0c4MmhYdHUzRHpUemdtN3RpblhLcXhzbzZNQnVFWTFDeGdRQWlFQXVlWHBaeWRnNi9QdEovaHlZbjNsQ0xpSAppbTVLMHBGS0RlQWtVaG5DQndrPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUFzc0xTT1R6bTFpMkl5bVllM0R4YXdHU1lYcWpQd3JqZzk4dDcvOUExTi9vQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFSHkyN3lweWp4VmFHQ3cxcDkyV25IMjdZYkVrYWcyNkUvUG5GZnJRRlRDdmYyRENBbmdQbQpkU3d4R0ZFVS9qcjg2YlJKRDJHVzg4QWR3cW5EaVFyN3FnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=\n    # The base64 encoded aggregator certificate authority used by Kubernetes for front-proxy certificate generation.\n    aggregatorCA:\n        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJZRENDQVFhZ0F3SUJBZ0lSQU1ZQmp3R2lFVXI1bmx4VVN6Z25kNWd3Q2dZSUtvWkl6ajBFQXdJd0FEQWUKRncweU5UQTJNekF5TXpBeE1UZGFGdzB6TlRBMk1qZ3lNekF4TVRkYU1BQXdXVEFUQmdjcWhrak9QUUlCQmdncQpoa2pPUFFNQkJ3TkNBQVRMejJMUHhnNWpQME9yMUlHZHF0eFVtd2JMeWU4dUxDNlkxU0h3bEs3MXJiTit4ZytkCmFVcE9oNWJxckhad0J5cFJrNGRNMzI5YjNQUjI1MHVRRGVKWW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXcKSFFZRFZSMGxCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4dwpIUVlEVlIwT0JCWUVGR0ZnUmFCd2pST1hsbGtrNFpDWWpERTlQWm5FTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDCklRRFBRbldTVlJLU2pzcEcwcVJxSzNBK2R4OWliVjdTV1VWVTEvRlhGc0ZUSndJZ0FqSWtITnVsdWo2T2NtYjIKYXNLaElZUmpsZGE4YXBCazN2RTRsZEIrdmk0PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUdYZ2kxdlhLMmpITVZjdlQ3a2tVWTQ1K3JVeCs1VzB1NTl3YXc5SVBVcy9vQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFeTg5aXo4WU9ZejlEcTlTQm5hcmNWSnNHeThudkxpd3VtTlVoOEpTdTlhMnpmc1lQbldsSwpUb2VXNnF4MmNBY3FVWk9IVE45dlc5ejBkdWRMa0EzaVdBPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=\n    # The base64 encoded private key for service account token generation.\n    serviceAccount:\n        key: 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\n    # API server specific configuration options.\n    apiServer:\n        image: registry.k8s.io/kube-apiserver:v1.33.1 # The container image used in the API server manifest.\n        # Extra certificate subject alternative names for the API server's certificate.\n        certSANs:\n            - 192.168.1.77\n        disablePodSecurityPolicy: true # Disable PodSecurityPolicy in the API server and default manifests.\n        # Configure the API server admission plugins.\n        admissionControl:\n            - name: PodSecurity # Name is the name of the admission controller.\n              # Configuration is an embedded configuration object to be used as the plugin's\n              configuration:\n                apiVersion: pod-security.admission.config.k8s.io/v1alpha1\n                defaults:\n                    audit: restricted\n                    audit-version: latest\n                    enforce: baseline\n                    enforce-version: latest\n                    warn: restricted\n                    warn-version: latest\n                exemptions:\n                    namespaces:\n                        - kube-system\n                    runtimeClasses: []\n                    usernames: []\n                kind: PodSecurityConfiguration\n        # Configure the API server audit policy.\n        auditPolicy:\n            apiVersion: audit.k8s.io/v1\n            kind: Policy\n            rules:\n                - level: Metadata\n        \n        # # Configure the API server authorization config. Node and RBAC authorizers are always added irrespective of the configuration.\n        # authorizationConfig:\n        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.\n        #       name: webhook # Name is used to describe the authorizer.\n        #       # webhook is the configuration for the webhook authorizer.\n        #       webhook:\n        #         connectionInfo:\n        #             type: InClusterConfig\n        #         failurePolicy: Deny\n        #         matchConditionSubjectAccessReviewVersion: v1\n        #         matchConditions:\n        #             - expression: has(request.resourceAttributes)\n        #             - expression: '!(\\''system:serviceaccounts:kube-system\\'' in request.groups)'\n        #         subjectAccessReviewVersion: v1\n        #         timeout: 3s\n        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.\n        #       name: in-cluster-authorizer # Name is used to describe the authorizer.\n        #       # webhook is the configuration for the webhook authorizer.\n        #       webhook:\n        #         connectionInfo:\n        #             type: InClusterConfig\n        #         failurePolicy: NoOpinion\n        #         matchConditionSubjectAccessReviewVersion: v1\n        #         subjectAccessReviewVersion: v1\n        #         timeout: 3s\n    # Controller manager server specific configuration options.\n    controllerManager:\n        image: registry.k8s.io/kube-controller-manager:v1.33.1 # The container image used in the controller manager manifest.\n    # Kube-proxy server-specific configuration options\n    proxy:\n        image: registry.k8s.io/kube-proxy:v1.33.1 # The container image used in the kube-proxy manifest.\n        \n        # # Disable kube-proxy deployment on cluster bootstrap.\n        # disabled: false\n    # Scheduler server specific configuration options.\n    scheduler:\n        image: registry.k8s.io/kube-scheduler:v1.33.1 # The container image used in the scheduler manifest.\n    # Configures cluster member discovery.\n    discovery:\n        enabled: true # Enable the cluster membership discovery feature.\n        # Configure registries used for cluster member discovery.\n        registries:\n            # Kubernetes registry uses Kubernetes API server to discover cluster members and stores additional information\n            kubernetes:\n                disabled: true # Disable Kubernetes discovery registry.\n            # Service registry is using an external service to push and pull information about cluster members.\n            service: {}\n            # # External service endpoint.\n            # endpoint: https://discovery.talos.dev/\n    # Etcd specific configuration options.\n    etcd:\n        # The `ca` is the root certificate authority of the PKI.\n        ca:\n            crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJmVENDQVNTZ0F3SUJBZ0lSQU9qMVg0SEFzZnhrQlZybGdzUm9lTDR3Q2dZSUtvWkl6ajBFQXdJd0R6RU4KTUFzR0ExVUVDaE1FWlhSalpEQWVGdzB5TlRBMk16QXlNekF4TVRkYUZ3MHpOVEEyTWpneU16QXhNVGRhTUE4eApEVEFMQmdOVkJBb1RCR1YwWTJRd1dUQVRCZ2NxaGtqT1BRSUJCZ2dxaGtqT1BRTUJCd05DQUFUMytZdy9NVmwyCnFhQmN3OWFIaDI3M3lIZXdCNU9ramZyNWZMZGtoa2w0TDk0c0Rvem5uUGpXeW1USXhpckhZU3FZTTJSL1FaM1IKZEVzL3ZjMTlTNFJ5bzJFd1h6QU9CZ05WSFE4QkFmOEVCQU1DQW9Rd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSApBd0VHQ0NzR0FRVUZCd01DTUE4R0ExVWRFd0VCL3dRRk1BTUJBZjh3SFFZRFZSME9CQllFRkxGaHRFWitkMWxtCkhKaENYSWtEaGpYWW5UQldNQW9HQ0NxR1NNNDlCQU1DQTBjQU1FUUNJRWVsRXE4R25IMm9KcWNpMTl3NHN2OVAKYUNHNDZJdVVweGZTNW1kM1g0aXFBaUJXU3Z4RzYrTEtNSnREL3owVlYzeDlvM0l5enFCNFJPZm1aYSt1S3VUNQppUT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n            key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUlNYnd0T1VBMmpuR3UxUUxraDJwS0dZSm02VHBzRkhNZGw0VXFkaUx0VVJvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFOS9tTVB6RlpkcW1nWE1QV2g0ZHU5OGgzc0FlVHBJMzYrWHkzWklaSmVDL2VMQTZNNTV6NAoxc3BreU1ZcXgyRXFtRE5rZjBHZDBYUkxQNzNOZlV1RWNnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=\n        \n        # # The container image used to create the etcd service.\n        # image: gcr.io/etcd-development/etcd:v3.5.21\n\n        # # The `advertisedSubnets` field configures the networks to pick etcd advertised IP from.\n        # advertisedSubnets:\n        #     - 10.0.0.0/8\n    # A list of urls that point to additional manifests.\n    extraManifests: []\n    #   - https://www.example.com/manifest1.yaml\n    #   - https://www.example.com/manifest2.yaml\n\n    # A list of inline Kubernetes manifests.\n    inlineManifests: []\n    #   - name: namespace-ci # Name of the manifest.\n    #     contents: |- # Manifest contents as a string.\n    #       apiVersion: v1\n    #       kind: Namespace\n    #       metadata:\n    #       \tname: ci\n\n    \n    # # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).\n\n    # # Decryption secret example (do not use in production!).\n    # aescbcEncryptionSecret: z01mye6j16bspJYtTB/5SFX8j7Ph4JXxM2Xuu4vsBPM=\n\n    # # Core DNS specific configuration options.\n    # coreDNS:\n    #     image: registry.k8s.io/coredns/coredns:v1.12.1 # The `image` field is an override to the default coredns image.\n\n    # # External cloud provider configuration.\n    # externalCloudProvider:\n    #     enabled: true # Enable external cloud provider.\n    #     # A list of urls that point to additional manifests for an external cloud provider.\n    #     manifests:\n    #         - https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/v1.20.0-alpha.0/manifests/rbac.yaml\n    #         - https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/v1.20.0-alpha.0/manifests/aws-cloud-controller-manager-daemonset.yaml\n\n    # # A map of key value pairs that will be added while fetching the extraManifests.\n    # extraManifestHeaders:\n    #     Token: \"1234567\"\n    #     X-ExtraInfo: info\n\n    # # Settings for admin kubeconfig generation.\n    # adminKubeconfig:\n    #     certLifetime: 1h0m0s # Admin kubeconfig certificate lifetime (default is 1 year).\n\n    # # Allows running workload on control-plane nodes.\n    # allowSchedulingOnControlPlanes: true\n"
    },
    {
      "name": "platform-crds.yaml",
      "path": "infra/charts/orchestrator/crds/platform-crds.yaml",
      "config_type": "yaml",
      "content": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: coderuns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: coderuns\n    singular: coderun\n    kind: CodeRun\n    shortNames:\n    - cr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Task\n      type: integer\n      jsonPath: .spec.taskId\n    - name: Service\n      type: string\n      jsonPath: .spec.service\n    - name: Model\n      type: string\n      jsonPath: .spec.model\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"taskId\", \"service\", \"repositoryUrl\", \"docsRepositoryUrl\", \"workingDirectory\", \"model\", \"githubUser\"]\n            properties:\n              taskId:\n                type: integer\n                description: \"Task ID to implement\"\n              service:\n                type: string\n                description: \"Target service name\"\n              repositoryUrl:\n                type: string\n                description: \"Target project repository URL (where implementation work happens)\"\n              docsRepositoryUrl:\n                type: string\n                description: \"Documentation repository URL (where Task Master definitions come from)\"\n              docsProjectDirectory:\n                type: string\n                description: \"Project directory within docs repository (e.g. '_projects/simple-api')\"\n              docsBranch:\n                type: string\n                default: \"main\"\n                description: \"Docs branch to use (e.g., 'main', 'feature/branch')\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within target repository (defaults to service name if not specified)\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n              localTools:\n                type: string\n                description: \"Local MCP tools/servers to enable (comma-separated)\"\n              remoteTools:\n                type: string\n                description: \"Remote MCP tools/servers to enable (comma-separated)\"\n              contextVersion:\n                type: integer\n                default: 1\n                description: \"Context version for retry attempts (incremented on each retry)\"\n              promptModification:\n                type: string\n                description: \"Additional context for retry attempts\"\n              continueSession:\n                type: boolean\n                default: false\n                description: \"Whether to continue a previous session\"\n              overwriteMemory:\n                type: boolean\n                default: false\n                description: \"Whether to overwrite memory before starting\"\n              env:\n                type: object\n                additionalProperties:\n                  type: string\n                description: \"Environment variables to set in the container\"\n              envFromSecrets:\n                type: array\n                items:\n                  type: object\n                  properties:\n                    name:\n                      type: string\n                      description: \"Name of the environment variable\"\n                    secretName:\n                      type: string\n                      description: \"Name of the secret\"\n                    secretKey:\n                      type: string\n                      description: \"Key within the secret\"\n                  required:\n                    - name\n                    - secretName\n                    - secretKey\n                description: \"Environment variables from secrets\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the code implementation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              retryCount:\n                type: integer\n                description: \"Current retry attempt (if applicable)\"\n              conditions:\n                type: array\n                description: \"Conditions for the CodeRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\"\n              contextVersion:\n                type: integer\n                description: \"Version of the context and prompt used\"\n              promptModification:\n                type: string\n                description: \"Modification to the prompt if any\"\n              promptMode:\n                type: string\n                description: \"Mode of prompt (e.g., direct, indirect)\"\n              sessionId:\n                type: string\n                description: \"Session ID for tracking\"\n---\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: docsruns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: docsruns\n    singular: docsrun\n    kind: DocsRun\n    shortNames:\n    - dr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"repositoryUrl\", \"workingDirectory\", \"sourceBranch\", \"model\", \"githubUser\"]\n            properties:\n              repositoryUrl:\n                type: string\n                description: \"Repository URL for documentation generation\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within repository\"\n              sourceBranch:\n                type: string\n                description: \"Source branch to analyze\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the documentation generation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              conditions:\n                type: array\n                description: \"Conditions for the DocsRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\""
    },
    {
      "name": "coderun-crd.yaml",
      "path": "infra/charts/orchestrator/crds/coderun-crd.yaml",
      "config_type": "yaml",
      "content": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: coderuns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: coderuns\n    singular: coderun\n    kind: CodeRun\n    shortNames:\n    - cr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Task\n      type: integer\n      jsonPath: .spec.taskId\n    - name: Service\n      type: string\n      jsonPath: .spec.service\n    - name: Model\n      type: string\n      jsonPath: .spec.model\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"taskId\", \"service\", \"repositoryUrl\", \"docsRepositoryUrl\", \"workingDirectory\", \"model\", \"githubUser\"]\n            properties:\n              taskId:\n                type: integer\n                description: \"Task ID to implement\"\n              service:\n                type: string\n                description: \"Target service name\"\n              repositoryUrl:\n                type: string\n                description: \"Target project repository URL (where implementation work happens)\"\n              docsRepositoryUrl:\n                type: string\n                description: \"Documentation repository URL (where Task Master definitions come from)\"\n              docsProjectDirectory:\n                type: string\n                description: \"Project directory within docs repository (e.g. '_projects/simple-api')\"\n              docsBranch:\n                type: string\n                default: \"main\"\n                description: \"Docs branch to use (e.g., 'main', 'feature/branch')\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within target repository (defaults to service name if not specified)\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n              localTools:\n                type: string\n                description: \"Local MCP tools/servers to enable (comma-separated)\"\n              remoteTools:\n                type: string\n                description: \"Remote MCP tools/servers to enable (comma-separated)\"\n              contextVersion:\n                type: integer\n                default: 1\n                description: \"Context version for retry attempts (incremented on each retry)\"\n              promptModification:\n                type: string\n                description: \"Additional context for retry attempts\"\n              continueSession:\n                type: boolean\n                default: false\n                description: \"Whether to continue a previous session\"\n              overwriteMemory:\n                type: boolean\n                default: false\n                description: \"Whether to overwrite memory before starting\"\n              env:\n                type: object\n                additionalProperties:\n                  type: string\n                description: \"Environment variables to set in the container\"\n              envFromSecrets:\n                type: array\n                items:\n                  type: object\n                  properties:\n                    name:\n                      type: string\n                      description: \"Name of the environment variable\"\n                    secretName:\n                      type: string\n                      description: \"Name of the secret\"\n                    secretKey:\n                      type: string\n                      description: \"Key within the secret\"\n                  required:\n                    - name\n                    - secretName\n                    - secretKey\n                description: \"Environment variables from secrets\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the code implementation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              retryCount:\n                type: integer\n                description: \"Current retry attempt (if applicable)\"\n              conditions:\n                type: array\n                description: \"Conditions for the CodeRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\"\n              contextVersion:\n                type: integer\n                description: \"Version of the context and prompt used\"\n              promptModification:\n                type: string\n                description: \"Modification to the prompt if any\"\n              promptMode:\n                type: string\n                description: \"Mode of prompt (e.g., direct, indirect)\"\n              sessionId:\n                type: string\n                description: \"Session ID for tracking\""
    },
    {
      "name": "docsrun-crd.yaml",
      "path": "infra/charts/orchestrator/crds/docsrun-crd.yaml",
      "config_type": "yaml",
      "content": "apiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: docsruns.orchestrator.platform\nspec:\n  group: orchestrator.platform\n  scope: Namespaced\n  names:\n    plural: docsruns\n    singular: docsrun\n    kind: DocsRun\n    shortNames:\n    - dr\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    subresources:\n      status: {}\n    additionalPrinterColumns:\n    - name: Phase\n      type: string\n      jsonPath: .status.phase\n    - name: Age\n      type: date\n      jsonPath: .metadata.creationTimestamp\n    schema:\n      openAPIV3Schema:\n        type: object\n        required: [\"spec\"]\n        properties:\n          spec:\n            type: object\n            required: [\"repositoryUrl\", \"workingDirectory\", \"sourceBranch\", \"model\", \"githubUser\"]\n            properties:\n              repositoryUrl:\n                type: string\n                description: \"Repository URL for documentation generation\"\n              workingDirectory:\n                type: string\n                description: \"Working directory within repository\"\n              sourceBranch:\n                type: string\n                description: \"Source branch to analyze\"\n              model:\n                type: string\n                description: \"Claude model to use (full model name like 'claude-3-5-sonnet-20241022')\"\n              githubUser:\n                type: string\n                description: \"GitHub username for authentication and commits\"\n          status:\n            type: object\n            properties:\n              phase:\n                type: string\n                description: \"Current phase of the documentation generation\"\n              message:\n                type: string\n                description: \"Human-readable message about the current state\"\n              lastUpdate:\n                type: string\n                description: \"Timestamp when this phase was reached\"\n              jobName:\n                type: string\n                description: \"Associated Kubernetes Job name\"\n              pullRequestUrl:\n                type: string\n                description: \"Pull request URL if created\"\n              conditions:\n                type: array\n                description: \"Conditions for the DocsRun\"\n                items:\n                  type: object\n                  required: [\"type\", \"status\"]\n                  properties:\n                    type:\n                      type: string\n                      description: \"Type of condition\"\n                    status:\n                      type: string\n                      description: \"Status of the condition (True, False, or Unknown)\"\n                    lastTransitionTime:\n                      type: string\n                      description: \"Last time the condition transitioned (RFC3339 format)\"\n                    reason:\n                      type: string\n                      description: \"Reason for the condition's last transition\"\n                    message:\n                      type: string\n                      description: \"Human-readable message about the condition\"\n              configmapName:\n                type: string\n                description: \"Name of the ConfigMap containing the prompt and context\""
    },
    {
      "name": "Chart.yaml",
      "path": "infra/charts/orchestrator/Chart.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v2\nname: orchestrator\ndescription: A Helm chart for the Platform Orchestrator - manages Claude Code agents via TaskRun CRDs\ntype: application\nversion: 0.1.1\nappVersion: \"latest\"\n\nkeywords:\n  - orchestrator\n  - claude-code\n  - task-management\n  - kubernetes\n  - automation\n\nhome: https://github.com/5dlabs/platform\nmaintainers:\n  - name: Platform Team\n    email: platform@5dlabs.com\n\nsources:\n  - https://github.com/5dlabs/platform\n\ndependencies: []"
    },
    {
      "name": "deployment.yaml",
      "path": "infra/charts/orchestrator/templates/deployment.yaml",
      "config_type": "yaml",
      "content": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nspec:\n  {{- if not .Values.autoscaling.enabled }}\n  replicas: {{ .Values.replicaCount }}\n  {{- end }}\n  selector:\n    matchLabels:\n      {{- include \"orchestrator.selectorLabels\" . | nindent 6 }}\n  template:\n    metadata:\n      annotations:\n        # Force pod restart when claude-templates ConfigMap changes\n        claude-templates/checksum: {{ include (print $.Template.BasePath \"/claude-templates-configmap.yaml\") . | sha256sum }}\n        # Force pod restart when controller config changes\n        controller-config/checksum: {{ include (print $.Template.BasePath \"/task-controller-config.yaml\") . | sha256sum }}\n        {{- with .Values.podAnnotations }}\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      labels:\n        {{- include \"orchestrator.selectorLabels\" . | nindent 8 }}\n    spec:\n      {{- with .Values.imagePullSecrets }}\n      imagePullSecrets:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      serviceAccountName: {{ include \"orchestrator.serviceAccountName\" . }}\n      securityContext:\n        {{- toYaml .Values.podSecurityContext | nindent 8 }}\n      containers:\n        - name: {{ .Chart.Name }}\n          securityContext:\n            {{- toYaml .Values.securityContext | nindent 12 }}\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n          imagePullPolicy: {{ .Values.image.pullPolicy }}\n          command: [\"/app/orchestrator\"]\n          ports:\n            - name: {{ .Values.service.name }}\n              containerPort: {{ .Values.service.targetPort }}\n              protocol: TCP\n          env:\n            # Kubernetes configuration\n            - name: KUBERNETES_NAMESPACE\n              valueFrom:\n                configMapKeyRef:\n                  name: {{ include \"orchestrator.fullname\" . }}-config\n                  key: KUBERNETES_NAMESPACE\n            - name: RUST_LOG\n              valueFrom:\n                configMapKeyRef:\n                  name: {{ include \"orchestrator.fullname\" . }}-config\n                  key: RUST_LOG\n            # Secrets for agents\n            {{- if .Values.secrets.anthropicApiKey }}\n            - name: ANTHROPIC_API_KEY\n              valueFrom:\n                secretKeyRef:\n                  {{- if eq .Values.secrets.anthropicApiKey \"use-existing\" }}\n                  name: orchestrator-secrets\n                  {{- else }}\n                  name: {{ include \"orchestrator.fullname\" . }}-secrets\n                  {{- end }}\n                  key: ANTHROPIC_API_KEY\n            {{- end }}\n          volumeMounts:\n            # Mount claude templates ConfigMap\n            - name: claude-templates\n              mountPath: /claude-templates\n              readOnly: true\n            # Mount controller configuration ConfigMap\n            - name: controller-config\n              mountPath: /config\n              readOnly: true\n          {{- if .Values.healthCheck.enabled }}\n          livenessProbe:\n            httpGet:\n              path: {{ .Values.healthCheck.path }}\n              port: {{ .Values.service.name }}\n            initialDelaySeconds: {{ .Values.healthCheck.livenessProbe.initialDelaySeconds }}\n            periodSeconds: {{ .Values.healthCheck.livenessProbe.periodSeconds }}\n            timeoutSeconds: {{ .Values.healthCheck.livenessProbe.timeoutSeconds }}\n            successThreshold: {{ .Values.healthCheck.livenessProbe.successThreshold }}\n            failureThreshold: {{ .Values.healthCheck.livenessProbe.failureThreshold }}\n          readinessProbe:\n            httpGet:\n              path: {{ .Values.healthCheck.path }}\n              port: {{ .Values.service.name }}\n            initialDelaySeconds: {{ .Values.healthCheck.readinessProbe.initialDelaySeconds }}\n            periodSeconds: {{ .Values.healthCheck.readinessProbe.periodSeconds }}\n            timeoutSeconds: {{ .Values.healthCheck.readinessProbe.timeoutSeconds }}\n            successThreshold: {{ .Values.healthCheck.readinessProbe.successThreshold }}\n            failureThreshold: {{ .Values.healthCheck.readinessProbe.failureThreshold }}\n          {{- end }}\n          resources:\n            {{- toYaml .Values.resources | nindent 12 }}\n      volumes:\n        # Mount claude templates ConfigMap\n        - name: claude-templates\n          configMap:\n            name: {{ include \"orchestrator.fullname\" . }}-claude-templates\n        # Mount controller configuration ConfigMap\n        - name: controller-config\n          configMap:\n            name: {{ include \"orchestrator.fullname\" . }}-task-controller-config\n      {{- with .Values.nodeSelector }}\n      nodeSelector:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.affinity }}\n      affinity:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.tolerations }}\n      tolerations:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}"
    },
    {
      "name": "ingress.yaml",
      "path": "infra/charts/orchestrator/templates/ingress.yaml",
      "config_type": "yaml",
      "content": "{{- if .Values.ingress.enabled -}}\n{{- $fullName := include \"orchestrator.fullname\" . -}}\n{{- $svcPort := .Values.service.port -}}\n{{- if and .Values.ingress.className (not (hasKey .Values.ingress.annotations \"kubernetes.io/ingress.class\")) }}\n  {{- $_ := set .Values.ingress.annotations \"kubernetes.io/ingress.class\" .Values.ingress.className}}\n{{- end }}\n{{- if semverCompare \">=1.19-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1\n{{- else if semverCompare \">=1.14-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1beta1\n{{- else -}}\napiVersion: extensions/v1beta1\n{{- end }}\nkind: Ingress\nmetadata:\n  name: {{ $fullName }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\n  {{- with .Values.ingress.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  {{- if and .Values.ingress.className (semverCompare \">=1.18-0\" .Capabilities.KubeVersion.GitVersion) }}\n  ingressClassName: {{ .Values.ingress.className }}\n  {{- end }}\n  {{- if .Values.ingress.tls }}\n  tls:\n    {{- range .Values.ingress.tls }}\n    - hosts:\n        {{- range .hosts }}\n        - {{ . | quote }}\n        {{- end }}\n      secretName: {{ .secretName }}\n    {{- end }}\n  {{- end }}\n  rules:\n    {{- range .Values.ingress.hosts }}\n    - host: {{ .host | quote }}\n      http:\n        paths:\n          {{- range .paths }}\n          - path: {{ .path }}\n            {{- if and .pathType (semverCompare \">=1.18-0\" $.Capabilities.KubeVersion.GitVersion) }}\n            pathType: {{ .pathType }}\n            {{- end }}\n            backend:\n              {{- if semverCompare \">=1.19-0\" $.Capabilities.KubeVersion.GitVersion }}\n              service:\n                name: {{ $fullName }}\n                port:\n                  number: {{ $svcPort }}\n              {{- else }}\n              serviceName: {{ $fullName }}\n              servicePort: {{ $svcPort }}\n              {{- end }}\n          {{- end }}\n    {{- end }}\n{{- end }}"
    },
    {
      "name": "service.yaml",
      "path": "infra/charts/orchestrator/templates/service.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nspec:\n  type: {{ .Values.service.type }}\n  ports:\n    - port: {{ .Values.service.port }}\n      targetPort: {{ .Values.service.name }}\n      protocol: TCP\n      name: {{ .Values.service.name }}\n  selector:\n    {{- include \"orchestrator.selectorLabels\" . | nindent 4 }}"
    },
    {
      "name": "task-controller-config.yaml",
      "path": "infra/charts/orchestrator/templates/task-controller-config.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-task-controller-config\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ndata:\n  config.yaml: |\n    # Task Controller Configuration\n    # Simplified configuration for CodeRun and DocsRun controllers\n\n    # Job configuration\n    job:\n      activeDeadlineSeconds: 3600  # 1 hour timeout\n\n    # Claude agent configuration\n    agent:\n      image:\n        repository: {{ .Values.agent.image.repository | quote }}\n        tag: {{ .Values.agent.image.tag | quote }}\n      imagePullSecrets:\n        {{- range .Values.imagePullSecrets }}\n        - {{ .name | quote }}\n        {{- end }}\n\n    # Secrets configuration (references Kubernetes secrets)\n    secrets:\n      apiKeySecretName: \"{{ include \"orchestrator.fullname\" . }}-secrets\"\n      apiKeySecretKey: \"ANTHROPIC_API_KEY\"\n\n    # Tool permissions configuration (only used when agentToolsOverride=true)\n    # When false: uses hardcoded list in settings.json.hbs template\n    # When true: uses this configuration\n    permissions:\n      agentToolsOverride: false\n      allow:\n        - \"Bash\"\n        - \"Edit\"\n        - \"Read\"\n        - \"Write\"\n        - \"MultiEdit\"\n        - \"Glob\"\n        - \"Grep\"\n        - \"LS\"\n        - \"Task\"\n        - \"ExitPlanMode\"\n        - \"NotebookRead\"\n        - \"NotebookEdit\"\n        - \"WebFetch\"\n        - \"WebSearch\"\n        - \"TodoRead\"\n        - \"TodoWrite\"\n      deny: []\n\n    # Telemetry configuration (used in templates)\n    telemetry:\n      enabled: true\n      otlpEndpoint: \"otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317\"\n      otlpProtocol: \"grpc\"\n      logsEndpoint: \"otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317\"\n      logsProtocol: \"grpc\"\n\n    # Storage configuration\n    storage:\n      {{- if .Values.storage.storageClassName }}\n      storageClassName: {{ .Values.storage.storageClassName | quote }}\n      {{- end }}\n      workspaceSize: {{ .Values.storage.workspaceSize | default \"10Gi\" | quote }}\n\n    # Cleanup configuration (event-driven cleanup by controller)\n    cleanup:\n      enabled: {{ .Values.cleanup.enabled | default true }}\n      completedJobDelayMinutes: {{ .Values.cleanup.completedJobDelayMinutes | default 5 }}\n      failedJobDelayMinutes: {{ .Values.cleanup.failedJobDelayMinutes | default 60 }}\n      deleteConfigMap: {{ .Values.cleanup.deleteConfigMap | default true }}"
    },
    {
      "name": "rbac.yaml",
      "path": "infra/charts/orchestrator/templates/rbac.yaml",
      "config_type": "yaml",
      "content": "{{- if .Values.rbac.create -}}\n{{- if .Values.rbac.namespaced }}\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nrules:\n{{- toYaml .Values.rbac.rules | nindent 2 }}\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: {{ include \"orchestrator.roleName\" . }}\nsubjects:\n- kind: ServiceAccount\n  name: {{ include \"orchestrator.serviceAccountName\" . }}\n  namespace: {{ .Release.Namespace }}\n{{- else }}\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nrules:\n{{- toYaml .Values.rbac.rules | nindent 2 }}\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: {{ include \"orchestrator.roleName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: {{ include \"orchestrator.roleName\" . }}\nsubjects:\n- kind: ServiceAccount\n  name: {{ include \"orchestrator.serviceAccountName\" . }}\n  namespace: {{ .Release.Namespace }}\n{{- end }}\n{{- end }}"
    },
    {
      "name": "claude-templates-configmap.yaml",
      "path": "infra/charts/orchestrator/templates/claude-templates-configmap.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-claude-templates\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ndata:\n{{- range $path, $content := .Files.Glob \"claude-templates/**/*.hbs\" }}\n  {{ $path | trimPrefix \"claude-templates/\" | replace \"/\" \"_\" }}: |\n{{ $.Files.Get $path | nindent 4 }}\n{{- end }}"
    },
    {
      "name": "serviceaccount.yaml",
      "path": "infra/charts/orchestrator/templates/serviceaccount.yaml",
      "config_type": "yaml",
      "content": "{{- if .Values.serviceAccount.create -}}\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: {{ include \"orchestrator.serviceAccountName\" . }}\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\n  {{- with .Values.serviceAccount.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\n{{- end }}"
    },
    {
      "name": "configmap.yaml",
      "path": "infra/charts/orchestrator/templates/configmap.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-config\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ndata:\n  KUBERNETES_NAMESPACE: {{ .Values.config.kubernetesNamespace | quote }}\n  SERVER_HOST: {{ .Values.config.serverHost | quote }}\n  SERVER_PORT: {{ .Values.config.serverPort | quote }}\n  RUST_LOG: {{ .Values.config.rustLog | quote }}\n  DEFAULT_DOCS_MODEL: {{ .Values.models.defaultDocsModel | quote }}\n  DEFAULT_CODE_MODEL: {{ .Values.models.defaultCodeModel | quote }}"
    },
    {
      "name": "secret.yaml",
      "path": "infra/charts/orchestrator/templates/secret.yaml",
      "config_type": "yaml",
      "content": "{{- if and .Values.secrets.anthropicApiKey (ne .Values.secrets.anthropicApiKey \"use-existing\") }}\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ include \"orchestrator.fullname\" . }}-secrets\n  labels:\n    {{- include \"orchestrator.labels\" . | nindent 4 }}\ntype: Opaque\nstringData:\n  {{- if .Values.secrets.anthropicApiKey }}\n  ANTHROPIC_API_KEY: {{ .Values.secrets.anthropicApiKey | quote }}\n  {{- end }}\n{{- end }}"
    },
    {
      "name": "values.yaml",
      "path": "infra/charts/orchestrator/values.yaml",
      "config_type": "yaml",
      "content": "# Default values for orchestrator.\n# This is a YAML-formatted file.\n# Declare variables to be passed into your templates.\n\nreplicaCount: 1\n\nimage:\n  repository: ghcr.io/5dlabs/platform/orchestrator\n  pullPolicy: Always\n  # Overrides the image tag whose default is the chart appVersion.\n  tag: \"latest\"\n\n# Agent/Task Runner image configuration (used by controller to create Jobs)\nagent:\n  image:\n    repository: ghcr.io/5dlabs/platform/claude-code\n    tag: \"1.0.56\"\n    pullPolicy: Always\n\n# Storage configuration for workspace PVCs\nstorage:\n  # Storage class name (e.g., \"local-path\" for local development, leave empty for default)\n  storageClassName: \"local-path\"\n  # Size of workspace PVCs\n  workspaceSize: \"10Gi\"\n\n# Cleanup configuration (controller-based event-driven cleanup)\ncleanup:\n  # Whether to enable automatic cleanup of completed jobs\n  enabled: true\n  # Minutes to wait before cleaning up successful jobs (default: 5 minutes)\n  completedJobDelayMinutes: 5\n  # Minutes to wait before cleaning up failed jobs (default: 60 minutes)\n  failedJobDelayMinutes: 60\n  # Whether to delete associated ConfigMaps when cleaning up jobs\n  deleteConfigMap: true\n\nimagePullSecrets:\n  - name: ghcr-secret\n\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: \"orchestrator\"\n\npodAnnotations:\n  kubectl.kubernetes.io/restartedAt: \"\"\n\npodSecurityContext:\n  fsGroup: 2000\n  runAsNonRoot: true\n  runAsUser: 1000\n\nsecurityContext:\n  allowPrivilegeEscalation: false\n  readOnlyRootFilesystem: false\n  runAsNonRoot: true\n  runAsUser: 1000\n  capabilities:\n    drop:\n    - ALL\n  seccompProfile:\n    type: RuntimeDefault\n\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 8080\n  name: http\n\ningress:\n  enabled: false\n  className: \"nginx\"\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n  hosts:\n    - host: orchestrator.local\n      paths:\n        - path: /\n          pathType: Prefix\n  tls: []\n\nresources:\n  limits:\n    cpu: 500m\n    memory: 512Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 100\n  targetCPUUtilizationPercentage: 80\n  # targetMemoryUtilizationPercentage: 80\n\nnodeSelector: {}\n\ntolerations:\n  - key: node-role.kubernetes.io/control-plane\n    operator: Exists\n    effect: NoSchedule\n\naffinity: {}\n\n# Configuration for the orchestrator service\nconfig:\n  # Kubernetes namespace (auto-populated in most cases)\n  kubernetesNamespace: \"orchestrator\"\n\n  # Server configuration\n  serverHost: \"0.0.0.0\"\n  serverPort: \"8080\"\n\n  # Logging\n  rustLog: \"orchestrator=debug,tower_http=debug,axum=debug,kube=info\"\n\n# Default model configurations\nmodels:\n  # Default model for documentation generation\n  defaultDocsModel: \"claude-opus-4-20250514\"\n  # Default model for code tasks\n  defaultCodeModel: \"claude-sonnet-4-20250514\"\n\n# Secret configuration for API keys\nsecrets:\n  # REQUIRED: Set your Anthropic API key\n  anthropicApiKey: \"\"\n  # Note: GitHub secrets (SSH keys + tokens) are managed externally per agent\n  # See infra/scripts/setup-agent-secrets.sh for setup instructions\n\n# RBAC configuration\nrbac:\n  # Create RBAC resources\n  create: true\n  # Use Role/RoleBinding (true) or ClusterRole/ClusterRoleBinding (false)\n  namespaced: true\n  rules:\n    # CodeRun and DocsRun CRD management\n    - apiGroups: [\"orchestrator.platform\"]\n      resources: [\"coderuns\", \"docsruns\"]\n      verbs: [\"create\", \"get\", \"list\", \"watch\", \"update\", \"patch\", \"delete\"]\n    - apiGroups: [\"orchestrator.platform\"]\n      resources: [\"coderuns/status\", \"docsruns/status\"]\n      verbs: [\"get\", \"update\", \"patch\"]\n    # Job management in orchestrator namespace\n    - apiGroups: [\"batch\"]\n      resources: [\"jobs\"]\n      verbs: [\"create\", \"get\", \"list\", \"watch\", \"delete\", \"patch\", \"update\"]\n    # ConfigMap and Secret access (for agent configuration and task files)\n    - apiGroups: [\"\"]\n      resources: [\"configmaps\", \"secrets\"]\n      verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\", \"watch\", \"patch\"]\n    # ServiceAccount management (required for Helm operations)\n    - apiGroups: [\"\"]\n      resources: [\"serviceaccounts\"]\n      verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\", \"patch\"]\n    # Service management (required for Helm operations)\n    - apiGroups: [\"\"]\n      resources: [\"services\"]\n      verbs: [\"get\", \"list\", \"create\", \"update\", \"delete\", \"patch\"]\n    # Pod monitoring\n    - apiGroups: [\"\"]\n      resources: [\"pods\", \"pods/log\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n    # PVC management for agent workspaces\n    - apiGroups: [\"\"]\n      resources: [\"persistentvolumeclaims\"]\n      verbs: [\"create\", \"get\", \"list\", \"delete\"]\n    # Events for debugging\n    - apiGroups: [\"\"]\n      resources: [\"events\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n\n# Health checks\nhealthCheck:\n  enabled: true\n  path: \"/health\"\n  port: 8080\n  livenessProbe:\n    initialDelaySeconds: 30\n    periodSeconds: 60\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n  readinessProbe:\n    initialDelaySeconds: 10\n    periodSeconds: 30\n    timeoutSeconds: 1\n    successThreshold: 1\n    failureThreshold: 3\n"
    },
    {
      "name": "otel-collector-metrics-service.yaml",
      "path": "infra/cluster-config/otel-collector-metrics-service.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: otel-collector-metrics\n  namespace: telemetry\n  labels:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector\nspec:\n  type: ClusterIP\n  ports:\n  - name: metrics\n    port: 8890\n    targetPort: 8890\n    protocol: TCP\n  selector:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector"
    },
    {
      "name": "otel-prometheus-service.yaml",
      "path": "infra/cluster-config/otel-prometheus-service.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: otel-collector-metrics\n  namespace: telemetry\n  labels:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector\nspec:\n  type: ClusterIP\n  ports:\n    - name: prometheus\n      port: 8889\n      targetPort: 8889\n      protocol: TCP\n    - name: internal-metrics\n      port: 8890\n      targetPort: 8890\n      protocol: TCP\n  selector:\n    app.kubernetes.io/name: opentelemetry-collector\n    app.kubernetes.io/instance: otel-collector"
    },
    {
      "name": "local-path-config-patch.yaml",
      "path": "infra/cluster-config/local-path-config-patch.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: local-path-config\n  namespace: local-path-storage\ndata:\n  config.json: |-\n    {\n            \"nodePathMap\":[\n            {\n                    \"node\":\"DEFAULT_PATH_FOR_NON_LISTED_NODES\",\n                    \"paths\":[\"/var/mnt/local-path-provisioner\"]\n            }\n            ]\n    }\n  helperPod.yaml: |-\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: helper-pod\n    spec:\n      priorityClassName: system-node-critical\n      tolerations:\n        - key: node.kubernetes.io/disk-pressure\n          operator: Exists\n          effect: NoSchedule\n      securityContext:\n        fsGroup: 0\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: helper-pod\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n  setup: |-\n    #!/bin/sh\n    set -eu\n    mkdir -m 0777 -p \"$VOL_DIR\"\n  teardown: |-\n    #!/bin/sh\n    set -eu\n    rm -rf \"$VOL_DIR\""
    },
    {
      "name": "talos-local-path-volume.yaml",
      "path": "infra/cluster-config/talos-local-path-volume.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1alpha1\nkind: UserVolumeConfig\nname: local-path-provisioner\nprovisioning:\n  diskSelector:\n    match: \"!system_disk\"\n  minSize: 100GB\n  maxSize: 100GB"
    },
    {
      "name": "Chart.yaml",
      "path": "infra/telemetry/telemetry-dashboards/Chart.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v2\nname: telemetry-dashboards\ndescription: Claude Code Telemetry Dashboards for Grafana\ntype: application\nversion: 0.1.0\nappVersion: \"1.0\""
    },
    {
      "name": "dashboard-configmap.yaml",
      "path": "infra/telemetry/telemetry-dashboards/dashboards/dashboard-configmap.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: claude-code-dashboards\n  namespace: telemetry\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  executive-overview.json: |\n    {\n      \"annotations\": {\n        \"list\": [\n          {\n            \"builtIn\": 1,\n            \"datasource\": {\n              \"type\": \"grafana\",\n              \"uid\": \"-- Grafana --\"\n            },\n            \"enable\": true,\n            \"hide\": true,\n            \"iconColor\": \"rgba(0, 211, 255, 1)\",\n            \"name\": \"Annotations & Alerts\",\n            \"type\": \"dashboard\"\n          }\n        ]\n      },\n      \"editable\": true,\n      \"fiscalYearStartMonth\": 0,\n      \"graphTooltip\": 0,\n      \"id\": null,\n      \"links\": [],\n      \"liveNow\": false,\n      \"panels\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"short\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 0,\n            \"y\": 0\n          },\n          \"id\": 2,\n          \"options\": {\n            \"colorMode\": \"value\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(increase(claude_code_session_count[24h]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Sessions Today\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"short\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 6,\n            \"y\": 0\n          },\n          \"id\": 3,\n          \"options\": {\n            \"colorMode\": \"value\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"count(count by (user_account_uuid) (claude_code_session_count))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Active Users\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"decimals\": 2,\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"yellow\",\n                    \"value\": 1000\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 5000\n                  }\n                ]\n              },\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 12,\n            \"y\": 0\n          },\n          \"id\": 4,\n          \"options\": {\n            \"colorMode\": \"value\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(increase(claude_code_cost_usage[24h]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Cost Today\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"decimals\": 2,\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  },\n                  {\n                    \"color\": \"yellow\",\n                    \"value\": 10000\n                  },\n                  {\n                    \"color\": \"red\",\n                    \"value\": 50000\n                  }\n                ]\n              },\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 4,\n            \"w\": 6,\n            \"x\": 18,\n            \"y\": 0\n          },\n          \"id\": 5,\n          \"options\": {\n            \"colorMode\": \"value\",\n            \"graphMode\": \"area\",\n            \"justifyMode\": \"auto\",\n            \"orientation\": \"auto\",\n            \"reduceOptions\": {\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\",\n              \"values\": false\n            },\n            \"text\": {},\n            \"textMode\": \"auto\"\n          },\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum(increase(claude_code_cost_usage[30d]))\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Monthly Cost\",\n          \"type\": \"stat\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"axisCenteredZero\": false,\n                \"axisColorMode\": \"text\",\n                \"axisLabel\": \"\",\n                \"axisPlacement\": \"auto\",\n                \"barAlignment\": 0,\n                \"drawStyle\": \"line\",\n                \"fillOpacity\": 10,\n                \"gradientMode\": \"none\",\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                },\n                \"lineInterpolation\": \"linear\",\n                \"lineWidth\": 1,\n                \"pointSize\": 5,\n                \"scaleDistribution\": {\n                  \"type\": \"linear\"\n                },\n                \"showPoints\": \"never\",\n                \"spanNulls\": false,\n                \"stacking\": {\n                  \"group\": \"A\",\n                  \"mode\": \"none\"\n                },\n                \"thresholdsStyle\": {\n                  \"mode\": \"off\"\n                }\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              },\n              \"unit\": \"short\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 0,\n            \"y\": 4\n          },\n          \"id\": 6,\n          \"options\": {\n            \"legend\": {\n              \"calcs\": [],\n              \"displayMode\": \"list\",\n              \"placement\": \"bottom\",\n              \"showLegend\": true\n            },\n            \"tooltip\": {\n              \"mode\": \"single\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"count(count by (user_account_uuid) (claude_code_session_count))\",\n              \"legendFormat\": \"Active Users\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Daily Active Users Trend\",\n          \"type\": \"timeseries\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"palette-classic\"\n              },\n              \"custom\": {\n                \"hideFrom\": {\n                  \"tooltip\": false,\n                  \"viz\": false,\n                  \"legend\": false\n                }\n              },\n              \"mappings\": [],\n              \"unit\": \"currencyUSD\"\n            },\n            \"overrides\": []\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 12,\n            \"x\": 12,\n            \"y\": 4\n          },\n          \"id\": 7,\n          \"options\": {\n            \"displayLabels\": [\"name\", \"percent\"],\n            \"legend\": {\n              \"displayMode\": \"list\",\n              \"placement\": \"right\",\n              \"showLegend\": true,\n              \"values\": [\"value\"]\n            },\n            \"pieType\": \"pie\",\n            \"reduceOptions\": {\n              \"values\": false,\n              \"calcs\": [\n                \"lastNotNull\"\n              ],\n              \"fields\": \"\"\n            },\n            \"tooltip\": {\n              \"mode\": \"single\",\n              \"sort\": \"none\"\n            }\n          },\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"sum by (model) (claude_code_cost_usage)\",\n              \"legendFormat\": \"{{model}}\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Cost by Model\",\n          \"type\": \"piechart\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"fieldConfig\": {\n            \"defaults\": {\n              \"color\": {\n                \"mode\": \"thresholds\"\n              },\n              \"custom\": {\n                \"align\": \"auto\",\n                \"cellOptions\": {\n                  \"type\": \"auto\"\n                },\n                \"inspect\": false\n              },\n              \"mappings\": [],\n              \"thresholds\": {\n                \"mode\": \"absolute\",\n                \"steps\": [\n                  {\n                    \"color\": \"green\",\n                    \"value\": null\n                  }\n                ]\n              }\n            },\n            \"overrides\": [\n              {\n                \"matcher\": {\n                  \"id\": \"byName\",\n                  \"options\": \"Cost\"\n                },\n                \"properties\": [\n                  {\n                    \"id\": \"unit\",\n                    \"value\": \"currencyUSD\"\n                  },\n                  {\n                    \"id\": \"decimals\",\n                    \"value\": 2\n                  }\n                ]\n              }\n            ]\n          },\n          \"gridPos\": {\n            \"h\": 8,\n            \"w\": 24,\n            \"x\": 0,\n            \"y\": 12\n          },\n          \"id\": 8,\n          \"options\": {\n            \"showHeader\": true,\n            \"sortBy\": [\n              {\n                \"desc\": true,\n                \"displayName\": \"Cost\"\n              }\n            ]\n          },\n          \"pluginVersion\": \"10.0.0\",\n          \"targets\": [\n            {\n              \"datasource\": {\n                \"type\": \"prometheus\",\n                \"uid\": \"${datasource}\"\n              },\n              \"editorMode\": \"code\",\n              \"expr\": \"topk(10, sum by (user_account_uuid) (claude_code_cost_usage))\",\n              \"format\": \"table\",\n              \"refId\": \"A\"\n            }\n          ],\n          \"title\": \"Top Users by Cost\",\n          \"transformations\": [\n            {\n              \"id\": \"organize\",\n              \"options\": {\n                \"excludeByName\": {\n                  \"Time\": true\n                },\n                \"indexByName\": {},\n                \"renameByName\": {\n                  \"Value\": \"Cost\",\n                  \"user_account_uuid\": \"User\"\n                }\n              }\n            }\n          ],\n          \"type\": \"table\"\n        }\n      ],\n      \"refresh\": \"30s\",\n      \"schemaVersion\": 38,\n      \"style\": \"dark\",\n      \"tags\": [\"claude-code\", \"executive\"],\n      \"templating\": {\n        \"list\": [\n          {\n            \"current\": {\n              \"selected\": false,\n              \"text\": \"VictoriaMetrics\",\n              \"value\": \"VictoriaMetrics\"\n            },\n            \"hide\": 0,\n            \"includeAll\": false,\n            \"label\": \"Data Source\",\n            \"multi\": false,\n            \"name\": \"datasource\",\n            \"options\": [],\n            \"query\": \"prometheus\",\n            \"refresh\": 1,\n            \"regex\": \"\",\n            \"skipUrlSync\": false,\n            \"type\": \"datasource\"\n          }\n        ]\n      },\n      \"time\": {\n        \"from\": \"now-24h\",\n        \"to\": \"now\"\n      },\n      \"timepicker\": {},\n      \"timezone\": \"\",\n      \"title\": \"Claude Code - Executive Overview\",\n      \"uid\": \"claude-code-exec\",\n      \"version\": 1,\n      \"weekStart\": \"\"\n    }"
    },
    {
      "name": "engineering-dashboard-configmap.yaml",
      "path": "infra/telemetry/telemetry-dashboards/templates/engineering-dashboard-configmap.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: engineering-metrics-dashboard\n  namespace: telemetry\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  engineering-metrics.json: |\n{{ .Files.Get \"dashboards/engineering-metrics-dashboard.json\" | indent 4 }}"
    },
    {
      "name": "otel-collector.yaml",
      "path": "infra/telemetry/values/otel-collector.yaml",
      "config_type": "yaml",
      "content": "# OpenTelemetry Collector Helm Values for Claude Code Telemetry\nmode: deployment\nreplicaCount: 1\n\n# Image configuration\nimage:\n  repository: otel/opentelemetry-collector-contrib\n  pullPolicy: IfNotPresent\n  tag: \"0.105.0\"\n\n# Resource allocation - adjusted for development environment\nresources:\n  limits:\n    cpu: 1000m\n    memory: 2Gi\n  requests:\n    cpu: 500m\n    memory: 1Gi\n\n# Service configuration\nports:\n  otlp:\n    enabled: true\n    containerPort: 4317\n    servicePort: 4317\n    hostPort: 4317\n    protocol: TCP\n  otlp-http:\n    enabled: true\n    containerPort: 4318\n    servicePort: 4318\n    hostPort: 4318\n    protocol: TCP\n  prometheus:\n    enabled: true\n    containerPort: 8889\n    servicePort: 8889\n    protocol: TCP\n\n# OpenTelemetry Collector configuration\nconfig:\n  receivers:\n    otlp:\n      protocols:\n        grpc:\n          endpoint: 0.0.0.0:4317\n          max_recv_msg_size_mib: 64\n        http:\n          endpoint: 0.0.0.0:4318\n          cors:\n            allowed_origins:\n              - \"*\"\n\n  processors:\n    batch:\n      timeout: 10s\n      send_batch_size: 1024\n      send_batch_max_size: 2048\n    \n    memory_limiter:\n      check_interval: 1s\n      limit_mib: 1500\n      spike_limit_mib: 512\n    \n    resource:\n      attributes:\n        - key: cluster.name\n          value: telemetry-dev\n          action: insert\n        - key: deployment.environment\n          value: development\n          action: insert\n    \n    # Transform metric names from dots to underscores for Prometheus compatibility\n    # NOTE: Claude Code emits metrics WITHOUT the claude_code prefix!\n    transform/metrics:\n      metric_statements:\n        - context: datapoint\n          statements:\n            # Transform actual metric names (no prefix) to Prometheus format with prefix\n            - set(metric.name, \"claude_code_lines_of_code_count\") where metric.name == \"lines_of_code.count\"\n            - set(metric.name, \"claude_code_cost_usage\") where metric.name == \"cost.usage\"\n            - set(metric.name, \"claude_code_token_usage\") where metric.name == \"token.usage\"\n            - set(metric.name, \"claude_code_session_count\") where metric.name == \"session.count\"\n            - set(metric.name, \"claude_code_commit_count\") where metric.name == \"commit.count\"\n            - set(metric.name, \"claude_code_pull_request_count\") where metric.name == \"pull_request.count\"\n            - set(metric.name, \"claude_code_code_edit_tool_decision\") where metric.name == \"code_edit_tool.decision\"\n\n  exporters:\n    prometheus:\n      endpoint: \"0.0.0.0:8889\"\n      send_timestamps: true\n    \n    # VictoriaMetrics native OpenTelemetry exporter\n    otlphttp/victoriametrics:\n      metrics_endpoint: http://victoria-metrics-victoria-metrics-single-server:8428/opentelemetry/v1/metrics\n      compression: gzip\n      encoding: proto\n      tls:\n        insecure: true\n      timeout: 30s\n      retry_on_failure:\n        enabled: true\n        initial_interval: 5s\n        max_interval: 30s\n        max_elapsed_time: 300s\n    \n    # VictoriaLogs exporter using OTLP/HTTP\n    otlphttp:\n      logs_endpoint: http://victoria-logs-victoria-logs-single-server:9428/insert/opentelemetry/v1/logs\n      tls:\n        insecure: true\n      retry_on_failure:\n        enabled: true\n        initial_interval: 5s\n        max_interval: 30s\n        max_elapsed_time: 300s\n      headers:\n        VL-Stream-Fields: \"cluster.name,deployment.environment,service.name,service.namespace\"\n    \n    # Debug exporter for troubleshooting\n    debug:\n      verbosity: detailed\n      sampling_initial: 5\n      sampling_thereafter: 200\n\n  extensions:\n    health_check:\n      endpoint: 0.0.0.0:13133\n    pprof:\n      endpoint: 0.0.0.0:1777\n    zpages:\n      endpoint: 0.0.0.0:55679\n\n  service:\n    extensions: [health_check, pprof, zpages]\n    pipelines:\n      metrics:\n        receivers: [otlp]\n        processors: [memory_limiter, batch, resource, transform/metrics]\n        exporters: [otlphttp/victoriametrics, prometheus, debug]\n      logs:\n        receivers: [otlp]\n        processors: [memory_limiter, batch, resource]\n        exporters: [otlphttp, debug]\n      traces:\n        receivers: [otlp]\n        processors: [memory_limiter, batch, resource]\n        exporters: [debug]\n    telemetry:\n      metrics:\n        level: detailed\n        address: 0.0.0.0:8890\n\n# Pod annotations for monitoring\npodAnnotations:\n  prometheus.io/scrape: \"true\"\n  prometheus.io/port: \"8890\"\n  prometheus.io/path: \"/metrics\"\n\n# Liveness and readiness probes\nlivenessProbe:\n  httpGet:\n    path: /\n    port: 13133\n  initialDelaySeconds: 30\n  periodSeconds: 10\n\nreadinessProbe:\n  httpGet:\n    path: /\n    port: 13133\n  initialDelaySeconds: 5\n  periodSeconds: 5\n\n# Ingress configuration for OTLP endpoints\ningress:\n  enabled: true\n  ingressClassName: nginx\n  annotations:\n    nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n    nginx.ingress.kubernetes.io/grpc-backend: \"true\"\n  hosts:\n    - host: otel-grpc.local\n      paths:\n        - path: /\n          pathType: Prefix\n          port: 4317\n    - host: otel-http.local\n      paths:\n        - path: /\n          pathType: Prefix\n          port: 4318"
    },
    {
      "name": "victoria-logs.yaml",
      "path": "infra/telemetry/values/victoria-logs.yaml",
      "config_type": "yaml",
      "content": "# VictoriaLogs Single Server Helm Values for Claude Code Telemetry\n\n# Server configuration\nserver:\n  # Enable single server mode\n  enabled: true\n  \n  # Image configuration\n  image:\n    repository: victoriametrics/victoria-logs\n    tag: v1.24.0-victorialogs\n    pullPolicy: IfNotPresent\n  \n  # Resource allocation - adjusted for development environment\n  resources:\n    limits:\n      cpu: 2000m\n      memory: 4Gi\n    requests:\n      cpu: 1000m\n      memory: 2Gi\n  \n  # Data retention period\n  retentionPeriod: 6M  # 6 months\n  \n  # Storage configuration\n  persistentVolume:\n    enabled: true\n    size: 20Gi\n    storageClass: local-path  # Using local-path provisioner\n    \n  # Extra arguments for VictoriaLogs\n  extraArgs:\n    httpListenAddr: \":9428\"\n    retentionPeriod: \"6\"\n    loggerLevel: \"INFO\"\n    search.maxQueryDuration: \"30s\"\n    \n  # Service configuration\n  service:\n    type: ClusterIP\n    servicePort: 9428\n    \n  # Security context\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 65534\n    \n  # Liveness and readiness probes\n  livenessProbe:\n    httpGet:\n      path: /health\n      port: 9428\n    initialDelaySeconds: 30\n    periodSeconds: 30\n    \n  readinessProbe:\n    httpGet:\n      path: /health  \n      port: 9428\n    initialDelaySeconds: 5\n    periodSeconds: 5\n\n# Disable fluent-bit by default\nfluent-bit:\n  enabled: false\n\n# Ingress configuration\ningress:\n  enabled: true\n  ingressClassName: nginx\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n  hosts:\n    - host: victoria-logs.local\n      paths:\n        - path: /\n          pathType: Prefix\n  tls: []"
    },
    {
      "name": "grafana.yaml",
      "path": "infra/telemetry/values/grafana.yaml",
      "config_type": "yaml",
      "content": "# Grafana Helm Values for Claude Code Telemetry\n\n# Admin credentials\nadminUser: admin\nadminPassword: admin123!  # Change this in production\n\n# Resource allocation - adjusted for development environment\nresources:\n  limits:\n    cpu: 1000m\n    memory: 1Gi\n  requests:\n    cpu: 500m\n    memory: 512Mi\n\n# Persistence for dashboards and settings\npersistence:\n  enabled: true\n  size: 10Gi\n  storageClassName: local-path\n  # Fix for permission issues in Kind\n  extraPvcLabels: {}\n  inMemory:\n    enabled: false\n\n# Service configuration\nservice:\n  type: ClusterIP\n  port: 80\n\n# Ingress configuration\ningress:\n  enabled: true\n  ingressClassName: nginx\n  annotations: {}\n  hosts:\n    - grafana.local\n  path: /\n  pathType: Prefix\n  tls: []\n\n# Data sources configuration\ndatasources:\n  datasources.yaml:\n    apiVersion: 1\n    datasources:\n      # VictoriaMetrics as Prometheus datasource\n      - name: VictoriaMetrics\n        type: prometheus\n        access: proxy\n        url: http://victoria-metrics-victoria-metrics-single-server:8428\n        isDefault: true\n        editable: false\n        jsonData:\n          timeInterval: \"15s\"\n          queryTimeout: \"60s\"\n          httpMethod: POST\n      \n      # VictoriaLogs datasource\n      - name: VictoriaLogs\n        type: victoriametrics-logs-datasource\n        access: proxy\n        url: http://victoria-logs-victoria-logs-single-server:9428\n        editable: false\n\n# Dashboard providers configuration\n# dashboardProviders:\n#   dashboardproviders.yaml:\n#     apiVersion: 1\n#     providers:\n#       - name: 'claude-code-dashboards'\n#         orgId: 1\n#         folder: 'Claude Code'\n#         type: file\n#         disableDeletion: false\n#         editable: true\n#         options:\n#           path: /var/lib/grafana/dashboards/claude-code\n\n# Dashboard configuration as ConfigMap\n# dashboardsConfigMaps:\n#   engineering-metrics: engineering-metrics-dashboard\n\n# Plugins to install\nplugins:\n  - grafana-piechart-panel\n  - grafana-worldmap-panel\n  - victoriametrics-logs-datasource\n\n# RBAC configuration\nrbac:\n  create: true\n  pspEnabled: false\n\n# Service account\nserviceAccount:\n  create: true\n  name: grafana\n\n# Security context\nsecurityContext:\n  runAsNonRoot: true\n  runAsUser: 472\n  fsGroup: 472\n\n# Environment variables\nenv:\n  GF_EXPLORE_ENABLED: true\n  GF_ALERTING_ENABLED: true\n  GF_UNIFIED_ALERTING_ENABLED: true\n  GF_INSTALL_PLUGINS: victoriametrics-logs-datasource\n\n# Init containers - removed custom init to avoid permission issues\n\n# Grafana.ini configuration\ngrafana.ini:\n  server:\n    domain: grafana.local\n    root_url: \"%(protocol)s://%(domain)s/\"\n  \n  analytics:\n    reporting_enabled: false\n    check_for_updates: false\n  \n  log:\n    mode: console\n    level: info\n  \n  unified_alerting:\n    enabled: true\n  \n  feature_toggles:\n    enable: ngalert\n\n# Sidecar for dynamic dashboard/datasource provisioning\nsidecar:\n  dashboards:\n    enabled: true\n    label: grafana_dashboard\n    folder: /tmp/dashboards\n    provider:\n      name: sidecarProvider\n      orgId: 1\n      folder: 'Claude Code'\n      type: file\n      disableDeletion: false\n      allowUiUpdates: true\n  \n  datasources:\n    enabled: true\n    label: grafana_datasource\n\n# Readiness and liveness probes\nreadinessProbe:\n  httpGet:\n    path: /api/health\n    port: 3000\n\nlivenessProbe:\n  httpGet:\n    path: /api/health\n    port: 3000\n  initialDelaySeconds: 60\n  timeoutSeconds: 30\n  failureThreshold: 10"
    },
    {
      "name": "claude-code-telemetry.yaml",
      "path": "infra/telemetry/values/claude-code-telemetry.yaml",
      "config_type": "yaml",
      "content": "# Claude Code deployment with telemetry integration\n\n# Secret configuration for API keys\nsecrets:\n  # Using PAT as ANTHROPIC_API_KEY per user's instruction\n  anthropicApiKey: \"YOUR_ANTHROPIC_API_KEY\"\n  githubToken: \"YOUR_GITHUB_TOKEN\"\n\n# Image configuration\nimage:\n  repository: ghcr.io/5dlabs/platform/claude-code\n  pullPolicy: IfNotPresent\n  tag: \"latest\"\n\n# Image pull secret for ghcr.io\nimagePullSecrets:\n  - name: ghcr-secret\n\n# Resources - conservative for testing\nresources:\n  limits:\n    cpu: 1000m\n    memory: 2Gi\n  requests:\n    cpu: 500m\n    memory: 1Gi\n\n# Persistence - using local-path storage\npersistence:\n  enabled: true\n  storageClass: \"local-path\"\n  accessMode: ReadWriteOnce\n  size: 20Gi\n  mountPath: /data\n\n# Telemetry configuration - CRITICAL FOR VALIDATION\ntelemetry:\n  enabled: true\n  # Using internal service endpoint\n  otlpEndpoint: \"otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317\"\n  otlpProtocol: \"grpc\"\n  otlpInsecure: true\n  \n  # Service identification\n  serviceName: \"claude-code\"\n  serviceVersion: \"1.0.0\"\n  serviceNamespace: \"claude-code\"\n  \n  # Team/Organization attributes\n  teamName: \"platform\"\n  department: \"engineering\"\n  environment: \"production\"\n  costCenter: \"eng-001\"\n  \n  # Developer/Agent identification\n  githubUser: \"claude-agent-001\"\n  workingService: \"telemetry-validation\"\n  \n  # Export intervals (milliseconds)\n  metricsExportInterval: \"10000\"  # 10 seconds for faster validation\n  metricsExportTimeout: \"5000\"    # 5 seconds\n  logsExportInterval: \"5000\"       # 5 seconds\n  logsExportTimeout: \"5000\"        # 5 seconds\n  \n  # Cardinality control\n  includeSessionId: true\n  includeAccountUuid: true\n  includeVersion: true\n  \n  # Additional OTEL configuration\n  logLevel: \"debug\"  # Debug for validation\n  logUserPrompts: true  # Enable for testing\n  \n  # Custom attributes for testing\n  customAttributes: \"test.mode=validation,test.phase=initial\"\n  \n  # Cluster name\n  clusterName: \"talos-prod\"\n\n# Development mode for testing\ndevelopmentMode:\n  enabled: false\n  command: [\"/bin/sh\"]\n  args:\n    - \"-c\"\n    - |\n      echo \"Starting Claude Code with telemetry validation...\"\n      echo \"OTLP Endpoint: $OTEL_EXPORTER_OTLP_ENDPOINT\"\n      echo \"Service Name: $OTEL_SERVICE_NAME\"\n      echo \"Telemetry Enabled: $CLAUDE_CODE_TELEMETRY_ENABLED\"\n      \n      # Create workspace directory\n      mkdir -p /workspace\n      cd /workspace\n      \n      # Since we don't have a valid Anthropic API key, just test telemetry emission\n      echo \"Testing telemetry configuration...\"\n      echo \"CLAUDE_CODE_ENABLE_TELEMETRY=$CLAUDE_CODE_ENABLE_TELEMETRY\"\n      echo \"OTEL_SERVICE_NAME=$OTEL_SERVICE_NAME\"\n      echo \"OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=$OTEL_EXPORTER_OTLP_METRICS_ENDPOINT\"\n      echo \"OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=$OTEL_EXPORTER_OTLP_LOGS_ENDPOINT\"\n      \n      # Keep container running for telemetry testing\n      echo \"Container will stay running for telemetry validation...\"\n      while true; do\n        echo \"Claude Code telemetry test running... $(date)\"\n        sleep 60\n      done\n\n# Extra environment variables for debugging\nextraEnvVars:\n  - name: OTEL_LOG_LEVEL\n    value: \"debug\"\n  - name: OTEL_TRACES_EXPORTER\n    value: \"otlp\"\n  - name: OTEL_METRICS_EXPORTER\n    value: \"otlp\"\n  - name: OTEL_LOGS_EXPORTER\n    value: \"otlp\"\n  - name: DEBUG_TELEMETRY\n    value: \"true\"\n\n# Log file configuration\nlogFile:\n  enabled: true\n  path: /var/log/claude-code\n  filename: telemetry-validation.log\n\n# Service configuration\nservice:\n  type: ClusterIP\n  port: 8080\n  targetPort: 8080\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"8080\"\n    prometheus.io/path: \"/metrics\"\n\n"
    },
    {
      "name": "victoria-metrics.yaml",
      "path": "infra/telemetry/values/victoria-metrics.yaml",
      "config_type": "yaml",
      "content": "# VictoriaMetrics Single Server Helm Values for Claude Code Telemetry\n\n# Server configuration\nserver:\n  # Enable single server mode\n  enabled: true\n  \n  # Image configuration\n  image:\n    repository: victoriametrics/victoria-metrics\n    tag: v1.101.0\n    pullPolicy: IfNotPresent\n  \n  # Resource allocation - adjusted for development environment\n  resources:\n    limits:\n      cpu: 2000m\n      memory: 4Gi\n    requests:\n      cpu: 1000m\n      memory: 2Gi\n  \n  # Data retention period\n  retentionPeriod: 12  # 12 months\n  \n  # Storage configuration\n  persistentVolume:\n    enabled: true\n    size: 50Gi\n    storageClass: standard  # Kind default storage class\n    \n  # Extra arguments for VictoriaMetrics\n  extraArgs:\n    maxLabelsPerTimeseries: \"50\"\n    search.maxQueryDuration: \"30s\"\n    search.maxConcurrentRequests: \"16\"\n    dedup.minScrapeInterval: \"1s\"\n    promscrape.streamParse: \"true\"\n    # Enable Prometheus naming for OpenTelemetry metrics\n    opentelemetry.usePrometheusNaming: \"true\"\n    \n  # Service configuration\n  service:\n    type: ClusterIP\n    port: 8428\n    annotations:\n      prometheus.io/scrape: \"true\"\n      prometheus.io/port: \"8428\"\n      prometheus.io/path: \"/metrics\"\n  \n  # Enable metrics scraping\n  scrape:\n    enabled: true\n    config:\n      global:\n        scrape_interval: 15s\n        scrape_timeout: 10s\n      \n      scrape_configs:\n        # Scrape VictoriaMetrics itself\n        - job_name: victoria-metrics\n          static_configs:\n            - targets:\n                - localhost:8428\n        \n        # Scrape OpenTelemetry Collector metrics\n        - job_name: otel-collector  \n          static_configs:\n            - targets:\n                - otel-collector-metrics.telemetry.svc.cluster.local:8890\n              labels:\n                namespace: telemetry\n                service: otel-collector\n        \n        # Scrape Claude Code metrics from OTLP collector's Prometheus endpoint\n        - job_name: claude-code-metrics\n          static_configs:\n            - targets:\n                - otel-collector-metrics.telemetry.svc.cluster.local:8889\n          metric_relabel_configs:\n            # Only keep claude_code metrics\n            - source_labels: [__name__]\n              regex: 'claude_code.*'\n              action: keep\n\n  # Security context\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 65534\n    fsGroup: 65534\n    \n  # Liveness and readiness probes\n  livenessProbe:\n    httpGet:\n      path: /health\n      port: 8428\n    initialDelaySeconds: 30\n    periodSeconds: 30\n    \n  readinessProbe:\n    httpGet:\n      path: /health  \n      port: 8428\n    initialDelaySeconds: 5\n    periodSeconds: 5\n    \n  # Pod annotations\n  podAnnotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"8428\"\n\n# Disable unnecessary components for single-server setup\nvmselect:\n  enabled: false\n  \nvminsert:\n  enabled: false\n  \nvmstorage:\n  enabled: false\n\n# Ingress configuration\ningress:\n  enabled: true\n  ingressClassName: nginx\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n  hosts:\n    - host: victoria-metrics.local\n      paths:\n        - path: /\n          pathType: Prefix\n  \n# Service Monitor for Prometheus Operator (if available)\nserviceMonitor:\n  enabled: false"
    },
    {
      "name": "claude-code-alerts.yaml",
      "path": "infra/telemetry/alerts/claude-code-alerts.yaml",
      "config_type": "yaml",
      "content": "groups:\n  - name: claude_code_api\n    interval: 30s\n    rules:\n      # High API error rate alert\n      - alert: ClaudeCodeHighErrorRate\n        expr: |\n          (\n            sum(rate(claude_code_api_error[5m])) by (github_user, working_service)\n            /\n            sum(rate(claude_code_api_request[5m])) by (github_user, working_service)\n          ) * 100 > 5\n        for: 5m\n        labels:\n          severity: warning\n          component: claude-code\n        annotations:\n          summary: \"High API error rate for {{ $labels.github_user }}\"\n          description: \"Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 5%)\"\n      \n      # Critical API error rate alert\n      - alert: ClaudeCodeCriticalErrorRate\n        expr: |\n          (\n            sum(rate(claude_code_api_error[5m])) by (github_user, working_service)\n            /\n            sum(rate(claude_code_api_request[5m])) by (github_user, working_service)\n          ) * 100 > 20\n        for: 2m\n        labels:\n          severity: critical\n          component: claude-code\n        annotations:\n          summary: \"Critical API error rate for {{ $labels.github_user }}\"\n          description: \"Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 20%)\"\n\n  - name: claude_code_cost\n    interval: 1m\n    rules:\n      # User spending over $100/hour\n      - alert: ClaudeCodeHighUserSpend\n        expr: |\n          sum(increase(claude_code_cost_usage[1h])) by (github_user, working_service) > 100\n        for: 5m\n        labels:\n          severity: warning\n          component: claude-code\n          cost_alert: \"true\"\n        annotations:\n          summary: \"High spending detected for {{ $labels.github_user }}\"\n          description: \"User {{ $labels.github_user }} has spent ${{ $value | humanize }} in the last hour on service {{ $labels.working_service }}\"\n      \n      # Total platform spending over $500/hour\n      - alert: ClaudeCodeHighPlatformSpend\n        expr: |\n          sum(increase(claude_code_cost_usage[1h])) > 500\n        for: 5m\n        labels:\n          severity: critical\n          component: claude-code\n          cost_alert: \"true\"\n        annotations:\n          summary: \"High platform-wide spending detected\"\n          description: \"Total Claude Code spending is ${{ $value | humanize }} in the last hour (threshold: $500/hour)\"\n      \n      # Daily budget approaching limit\n      - alert: ClaudeCodeDailyBudgetWarning\n        expr: |\n          sum(increase(claude_code_cost_usage[24h])) > 800\n        for: 10m\n        labels:\n          severity: warning\n          component: claude-code\n          cost_alert: \"true\"\n        annotations:\n          summary: \"Daily budget approaching limit\"\n          description: \"Claude Code has spent ${{ $value | humanize }} today (80% of $1000 daily budget)\"\n\n  - name: infrastructure_health\n    interval: 30s\n    rules:\n      # OTLP Collector down\n      - alert: OTLPCollectorDown\n        expr: up{job=\"otel-collector\",namespace=\"telemetry\"} == 0\n        for: 2m\n        labels:\n          severity: critical\n          component: otel-collector\n        annotations:\n          summary: \"OTLP Collector is down\"\n          description: \"OpenTelemetry Collector in namespace telemetry has been down for more than 2 minutes\"\n      \n      # VictoriaMetrics down\n      - alert: VictoriaMetricsDown\n        expr: up{job=\"victoria-metrics\"} == 0\n        for: 2m\n        labels:\n          severity: critical\n          component: victoria-metrics\n        annotations:\n          summary: \"VictoriaMetrics is down\"\n          description: \"VictoriaMetrics server has been down for more than 2 minutes\"\n      \n      # VictoriaLogs down\n      - alert: VictoriaLogsDown\n        expr: up{instance=~\"victoria-logs.*\"} == 0\n        for: 2m\n        labels:\n          severity: critical\n          component: victoria-logs\n        annotations:\n          summary: \"VictoriaLogs is down\"\n          description: \"VictoriaLogs server has been down for more than 2 minutes\"\n      \n      # Grafana down\n      - alert: GrafanaDown\n        expr: up{job=\"grafana\"} == 0\n        for: 5m\n        labels:\n          severity: warning\n          component: grafana\n        annotations:\n          summary: \"Grafana is down\"\n          description: \"Grafana dashboard has been down for more than 5 minutes\"\n\n  - name: resource_usage\n    interval: 30s\n    rules:\n      # High memory usage\n      - alert: HighMemoryUsage\n        expr: |\n          (\n            container_memory_working_set_bytes{namespace=\"telemetry\",container!=\"\"}\n            / \n            container_spec_memory_limit_bytes{namespace=\"telemetry\",container!=\"\"}\n          ) * 100 > 80\n        for: 5m\n        labels:\n          severity: warning\n          component: infrastructure\n        annotations:\n          summary: \"High memory usage in {{ $labels.pod }}\"\n          description: \"Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit\"\n      \n      # Critical memory usage\n      - alert: CriticalMemoryUsage\n        expr: |\n          (\n            container_memory_working_set_bytes{namespace=\"telemetry\",container!=\"\"}\n            / \n            container_spec_memory_limit_bytes{namespace=\"telemetry\",container!=\"\"}\n          ) * 100 > 95\n        for: 2m\n        labels:\n          severity: critical\n          component: infrastructure\n        annotations:\n          summary: \"Critical memory usage in {{ $labels.pod }}\"\n          description: \"Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit\"\n      \n      # Disk space usage (VictoriaMetrics)\n      - alert: VictoriaMetricsDiskSpaceWarning\n        expr: |\n          (\n            1 - (node_filesystem_avail_bytes{mountpoint=\"/var/lib/victoria-metrics-data\"} / node_filesystem_size_bytes{mountpoint=\"/var/lib/victoria-metrics-data\"})\n          ) * 100 > 80\n        for: 10m\n        labels:\n          severity: warning\n          component: victoria-metrics\n        annotations:\n          summary: \"VictoriaMetrics disk space running low\"\n          description: \"VictoriaMetrics data directory is {{ $value | humanize }}% full\"\n      \n      # Disk space usage (VictoriaLogs)\n      - alert: VictoriaLogsDiskSpaceWarning\n        expr: |\n          (\n            1 - (node_filesystem_avail_bytes{mountpoint=\"/victoria-logs-data\"} / node_filesystem_size_bytes{mountpoint=\"/victoria-logs-data\"})\n          ) * 100 > 80\n        for: 10m\n        labels:\n          severity: warning\n          component: victoria-logs\n        annotations:\n          summary: \"VictoriaLogs disk space running low\"\n          description: \"VictoriaLogs data directory is {{ $value | humanize }}% full\"\n\n  - name: data_ingestion\n    interval: 30s\n    rules:\n      # No metrics ingestion\n      - alert: NoMetricsIngestion\n        expr: |\n          rate(prometheus_tsdb_samples_appended_total[5m]) == 0\n        for: 10m\n        labels:\n          severity: warning\n          component: victoria-metrics\n        annotations:\n          summary: \"No metrics being ingested\"\n          description: \"VictoriaMetrics has not received any new metrics for 10 minutes\"\n      \n      # No logs ingestion\n      - alert: NoLogsIngestion\n        expr: |\n          rate(victoria_logs_rows_inserted_total[5m]) == 0\n        for: 10m\n        labels:\n          severity: warning\n          component: victoria-logs\n        annotations:\n          summary: \"No logs being ingested\"\n          description: \"VictoriaLogs has not received any new logs for 10 minutes\"\n      \n      # High ingestion rate warning\n      - alert: HighMetricsIngestionRate\n        expr: |\n          rate(prometheus_tsdb_samples_appended_total[1m]) * 60 > 100000\n        for: 5m\n        labels:\n          severity: warning\n          component: victoria-metrics\n        annotations:\n          summary: \"High metrics ingestion rate\"\n          description: \"Metrics ingestion rate is {{ $value | humanize }} samples/minute\""
    },
    {
      "name": "alerting-rules-configmap.yaml",
      "path": "infra/telemetry/alerts/alerting-rules-configmap.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: claude-code-alerting-rules\n  namespace: telemetry\n  labels:\n    app: alerting\n    component: rules\ndata:\n  claude-code-alerts.yaml: |\n    groups:\n      - name: claude_code_api\n        interval: 30s\n        rules:\n          # High API error rate alert\n          - alert: ClaudeCodeHighErrorRate\n            expr: |\n              (\n                sum(rate(claude_code_api_error[5m])) by (github_user, working_service)\n                /\n                sum(rate(claude_code_api_request[5m])) by (github_user, working_service)\n              ) * 100 > 5\n            for: 5m\n            labels:\n              severity: warning\n              component: claude-code\n            annotations:\n              summary: \"High API error rate for {{ $labels.github_user }}\"\n              description: \"Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 5%)\"\n          \n          # Critical API error rate alert\n          - alert: ClaudeCodeCriticalErrorRate\n            expr: |\n              (\n                sum(rate(claude_code_api_error[5m])) by (github_user, working_service)\n                /\n                sum(rate(claude_code_api_request[5m])) by (github_user, working_service)\n              ) * 100 > 20\n            for: 2m\n            labels:\n              severity: critical\n              component: claude-code\n            annotations:\n              summary: \"Critical API error rate for {{ $labels.github_user }}\"\n              description: \"Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 20%)\"\n\n      - name: claude_code_cost\n        interval: 1m\n        rules:\n          # User spending over $100/hour\n          - alert: ClaudeCodeHighUserSpend\n            expr: |\n              sum(increase(claude_code_cost_usage[1h])) by (github_user, working_service) > 100\n            for: 5m\n            labels:\n              severity: warning\n              component: claude-code\n              cost_alert: \"true\"\n            annotations:\n              summary: \"High spending detected for {{ $labels.github_user }}\"\n              description: \"User {{ $labels.github_user }} has spent ${{ $value | humanize }} in the last hour on service {{ $labels.working_service }}\"\n          \n          # Total platform spending over $500/hour\n          - alert: ClaudeCodeHighPlatformSpend\n            expr: |\n              sum(increase(claude_code_cost_usage[1h])) > 500\n            for: 5m\n            labels:\n              severity: critical\n              component: claude-code\n              cost_alert: \"true\"\n            annotations:\n              summary: \"High platform-wide spending detected\"\n              description: \"Total Claude Code spending is ${{ $value | humanize }} in the last hour (threshold: $500/hour)\"\n          \n          # Daily budget approaching limit\n          - alert: ClaudeCodeDailyBudgetWarning\n            expr: |\n              sum(increase(claude_code_cost_usage[24h])) > 800\n            for: 10m\n            labels:\n              severity: warning\n              component: claude-code\n              cost_alert: \"true\"\n            annotations:\n              summary: \"Daily budget approaching limit\"\n              description: \"Claude Code has spent ${{ $value | humanize }} today (80% of $1000 daily budget)\"\n\n      - name: infrastructure_health\n        interval: 30s\n        rules:\n          # OTLP Collector down\n          - alert: OTLPCollectorDown\n            expr: up{job=\"otel-collector\",namespace=\"telemetry\"} == 0\n            for: 2m\n            labels:\n              severity: critical\n              component: otel-collector\n            annotations:\n              summary: \"OTLP Collector is down\"\n              description: \"OpenTelemetry Collector in namespace telemetry has been down for more than 2 minutes\"\n          \n          # VictoriaMetrics down\n          - alert: VictoriaMetricsDown\n            expr: up{job=\"victoria-metrics\"} == 0\n            for: 2m\n            labels:\n              severity: critical\n              component: victoria-metrics\n            annotations:\n              summary: \"VictoriaMetrics is down\"\n              description: \"VictoriaMetrics server has been down for more than 2 minutes\"\n          \n          # VictoriaLogs down\n          - alert: VictoriaLogsDown\n            expr: up{instance=~\"victoria-logs.*\"} == 0\n            for: 2m\n            labels:\n              severity: critical\n              component: victoria-logs\n            annotations:\n              summary: \"VictoriaLogs is down\"\n              description: \"VictoriaLogs server has been down for more than 2 minutes\"\n          \n          # Grafana down\n          - alert: GrafanaDown\n            expr: up{job=\"grafana\"} == 0\n            for: 5m\n            labels:\n              severity: warning\n              component: grafana\n            annotations:\n              summary: \"Grafana is down\"\n              description: \"Grafana dashboard has been down for more than 5 minutes\"\n\n      - name: resource_usage\n        interval: 30s\n        rules:\n          # High memory usage\n          - alert: HighMemoryUsage\n            expr: |\n              (\n                container_memory_working_set_bytes{namespace=\"telemetry\",container!=\"\"}\n                / \n                container_spec_memory_limit_bytes{namespace=\"telemetry\",container!=\"\"}\n              ) * 100 > 80\n            for: 5m\n            labels:\n              severity: warning\n              component: infrastructure\n            annotations:\n              summary: \"High memory usage in {{ $labels.pod }}\"\n              description: \"Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit\"\n          \n          # Critical memory usage\n          - alert: CriticalMemoryUsage\n            expr: |\n              (\n                container_memory_working_set_bytes{namespace=\"telemetry\",container!=\"\"}\n                / \n                container_spec_memory_limit_bytes{namespace=\"telemetry\",container!=\"\"}\n              ) * 100 > 95\n            for: 2m\n            labels:\n              severity: critical\n              component: infrastructure\n            annotations:\n              summary: \"Critical memory usage in {{ $labels.pod }}\"\n              description: \"Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit\"\n          \n          # Disk space usage (VictoriaMetrics)\n          - alert: VictoriaMetricsDiskSpaceWarning\n            expr: |\n              (\n                1 - (node_filesystem_avail_bytes{mountpoint=\"/var/lib/victoria-metrics-data\"} / node_filesystem_size_bytes{mountpoint=\"/var/lib/victoria-metrics-data\"})\n              ) * 100 > 80\n            for: 10m\n            labels:\n              severity: warning\n              component: victoria-metrics\n            annotations:\n              summary: \"VictoriaMetrics disk space running low\"\n              description: \"VictoriaMetrics data directory is {{ $value | humanize }}% full\"\n          \n          # Disk space usage (VictoriaLogs)\n          - alert: VictoriaLogsDiskSpaceWarning\n            expr: |\n              (\n                1 - (node_filesystem_avail_bytes{mountpoint=\"/victoria-logs-data\"} / node_filesystem_size_bytes{mountpoint=\"/victoria-logs-data\"})\n              ) * 100 > 80\n            for: 10m\n            labels:\n              severity: warning\n              component: victoria-logs\n            annotations:\n              summary: \"VictoriaLogs disk space running low\"\n              description: \"VictoriaLogs data directory is {{ $value | humanize }}% full\"\n\n      - name: data_ingestion\n        interval: 30s\n        rules:\n          # No metrics ingestion\n          - alert: NoMetricsIngestion\n            expr: |\n              rate(prometheus_tsdb_samples_appended_total[5m]) == 0\n            for: 10m\n            labels:\n              severity: warning\n              component: victoria-metrics\n            annotations:\n              summary: \"No metrics being ingested\"\n              description: \"VictoriaMetrics has not received any new metrics for 10 minutes\"\n          \n          # No logs ingestion\n          - alert: NoLogsIngestion\n            expr: |\n              rate(victoria_logs_rows_inserted_total[5m]) == 0\n            for: 10m\n            labels:\n              severity: warning\n              component: victoria-logs\n            annotations:\n              summary: \"No logs being ingested\"\n              description: \"VictoriaLogs has not received any new logs for 10 minutes\"\n          \n          # High ingestion rate warning\n          - alert: HighMetricsIngestionRate\n            expr: |\n              rate(prometheus_tsdb_samples_appended_total[1m]) * 60 > 100000\n            for: 5m\n            labels:\n              severity: warning\n              component: victoria-metrics\n            annotations:\n              summary: \"High metrics ingestion rate\"\n              description: \"Metrics ingestion rate is {{ $value | humanize }} samples/minute\""
    },
    {
      "name": "arc-org-runners.yaml",
      "path": "infra/arc/arc-org-runners.yaml",
      "config_type": "yaml",
      "content": "---\n# Consolidated ARC organization runner setup for 5dlabs\n# Single file with all optimizations and org-level configuration\n\n# Namespace with privileged pod security for Docker-in-Docker\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: arc-systems\n  labels:\n    pod-security.kubernetes.io/enforce: privileged\n    pod-security.kubernetes.io/warn: privileged\n    pod-security.kubernetes.io/audit: privileged\n---\n# Service account for runners\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: github-runner\n  namespace: arc-systems\n---\n# ClusterRole for deployment permissions\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: github-runner-deploy\nrules:\n  # Core resources\n  - apiGroups: [\"\"]\n    resources: [\"namespaces\", \"services\", \"secrets\", \"configmaps\", \"persistentvolumeclaims\", \"serviceaccounts\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\", \"delete\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"pods/log\", \"nodes\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources: [\"events\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n  # Apps resources\n  - apiGroups: [\"apps\"]\n    resources: [\"deployments\", \"daemonsets\", \"replicasets\", \"statefulsets\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\", \"delete\"]\n  # Batch resources\n  - apiGroups: [\"batch\"]\n    resources: [\"jobs\", \"cronjobs\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\", \"delete\", \"watch\"]\n  # RBAC resources\n  - apiGroups: [\"rbac.authorization.k8s.io\"]\n    resources: [\"roles\", \"rolebindings\", \"clusterroles\", \"clusterrolebindings\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\", \"delete\"]\n  # CRDs\n  - apiGroups: [\"apiextensions.k8s.io\"]\n    resources: [\"customresourcedefinitions\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\", \"delete\"]\n  # Orchestrator CRDs\n  - apiGroups: [\"orchestrator.platform\"]\n    resources: [\"coderuns\", \"docsruns\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\", \"delete\", \"watch\"]\n  - apiGroups: [\"orchestrator.platform\"]\n    resources: [\"coderuns/status\", \"docsruns/status\"]\n    verbs: [\"get\", \"update\", \"patch\"]\n  # Helm resources\n  - apiGroups: [\"helm.sh\"]\n    resources: [\"*\"]\n    verbs: [\"*\"]\n---\n# Bind ClusterRole to service account\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: github-runner-deploy\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: github-runner-deploy\nsubjects:\n  - kind: ServiceAccount\n    name: github-runner\n    namespace: arc-systems\n---\n# Persistent Volume Claim for Rust caching\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: rust-cache-pvc\n  namespace: arc-systems\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n  storageClassName: local-path\n---\n# Organization-level runners with optimizations\napiVersion: actions.summerwind.dev/v1alpha1\nkind: RunnerDeployment\nmetadata:\n  name: org-runners\n  namespace: arc-systems\nspec:\n  replicas: 4  # Scaled up for better parallelism\n  template:\n    spec:\n      # FIXED: Organization-level configuration (not repository-specific)\n      organization: 5dlabs\n\n      # GitHub authentication using the existing secret\n      githubAPICredentialsFrom:\n        secretRef:\n          name: controller-manager\n\n      # Enhanced runner labels for identification\n      labels:\n        - self-hosted\n        - linux\n        - x64\n        - k8s-runner\n        - rust-builder\n        - org-runner\n        - optimized\n\n      # Enhanced resources for better performance\n      resources:\n        limits:\n          cpu: \"4\"\n          memory: \"8Gi\"\n        requests:\n          cpu: \"2\"\n          memory: \"4Gi\"\n\n      # Use the working rust-builder image\n      image: ghcr.io/5dlabs/platform/rust-builder:1.2.0\n      imagePullPolicy: Always\n      dockerEnabled: true\n      dockerdWithinRunnerContainer: true\n\n      # Optimized environment variables\n      env:\n        - name: RUNNER_FEATURE_FLAG_EPHEMERAL\n          value: \"true\"\n        - name: PATH\n          value: \"/home/runner/.cargo/bin:/shared/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n        # Rust optimizations\n        - name: CARGO_HOME\n          value: \"/cache/cargo\"\n        - name: RUSTUP_HOME\n          value: \"/cache/rustup\"\n        - name: SCCACHE_DIR\n          value: \"/cache/sccache\"\n        - name: SCCACHE_CACHE_SIZE\n          value: \"40G\"\n        - name: RUSTC_WRAPPER\n          value: \"sccache\"\n        - name: CARGO_TARGET_DIR\n          value: \"/cache/target\"\n\n      # Service account\n      serviceAccountName: github-runner\n\n      # Image pull secrets for private registries\n      imagePullSecrets:\n        - name: ghcr-secret\n\n      # Init containers for cache setup and tool installation\n      initContainers:\n        - name: setup-cache\n          image: ghcr.io/5dlabs/platform/rust-builder:1.2.0\n          command: [\"/bin/sh\", \"-c\"]\n          args:\n            - |\n              echo \"Setting up cache directories...\"\n              mkdir -p /cache/cargo /cache/rustup /cache/sccache /cache/target\n              chown -R 1000:1000 /cache\n              chmod -R 755 /cache\n              echo \"Cache setup complete\"\n          volumeMounts:\n            - name: rust-cache\n              mountPath: /cache\n              subPath: rust-cache\n          securityContext:\n            runAsUser: 0\n            runAsGroup: 0\n        - name: install-tools\n          image: alpine:3.19\n          command: [\"/bin/sh\", \"-c\"]\n          args:\n            - |\n              echo \"Installing additional tools...\"\n              apk add --no-cache wget tar\n              mkdir -p /shared/bin\n\n              # kubectl\n              wget -qO /shared/bin/kubectl https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl\n              chmod +x /shared/bin/kubectl\n\n              # helm\n              wget -qO- https://get.helm.sh/helm-v3.14.0-linux-amd64.tar.gz | tar xz\n              mv linux-amd64/helm /shared/bin/helm\n              chmod +x /shared/bin/helm\n\n              # GitHub CLI\n              wget -qO- https://github.com/cli/cli/releases/download/v2.40.0/gh_2.40.0_linux_amd64.tar.gz | tar xz\n              mv gh_2.40.0_linux_amd64/bin/gh /shared/bin/gh\n              chmod +x /shared/bin/gh\n\n              echo \"Tools installed:\"\n              ls -la /shared/bin/\n          volumeMounts:\n            - name: shared-tools\n              mountPath: /shared\n\n      # Volumes for caching and tools\n      volumes:\n        - name: rust-cache\n          persistentVolumeClaim:\n            claimName: rust-cache-pvc\n        - name: shared-tools\n          emptyDir: {}\n\n      volumeMounts:\n        - name: rust-cache\n          mountPath: /cache\n          subPath: rust-cache\n        - name: shared-tools\n          mountPath: /shared\n\n      # Security context\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n"
    },
    {
      "name": "test-docsrun.yaml",
      "path": "infra/test-resources/crds/test-docsrun.yaml",
      "config_type": "yaml",
      "content": "apiVersion: orchestrator.platform/v1\nkind: DocsRun\nmetadata:\n  name: test-docsrun-ci\n  namespace: test-platform\nspec:\n  repositoryUrl: \"https://github.com/5dlabs/platform.git\"\n  workingDirectory: \"_projects/test-service\"\n  sourceBranch: \"main\"\n  targetBranch: \"docs/test-auto-docs\"\n  model: \"sonnet\"\n  githubUser: \"test-user\""
    },
    {
      "name": "test-coderun.yaml",
      "path": "infra/test-resources/crds/test-coderun.yaml",
      "config_type": "yaml",
      "content": "apiVersion: orchestrator.platform/v1\nkind: CodeRun\nmetadata:\n  name: test-coderun-ci\n  namespace: test-platform\nspec:\n  taskId: 9999\n  service: \"test-service\"\n  repositoryUrl: \"https://github.com/5dlabs/platform.git\"\n  docsRepositoryUrl: \"https://github.com/5dlabs/platform.git\"\n  workingDirectory: \"_projects/test-service\"\n  model: \"sonnet\"\n  githubUser: \"test-user\"\n  localTools: \"mcp-orchestrator\"\n  remoteTools: \"taskmaster\"\n  contextVersion: 1\n  continueSession: false\n  overwriteMemory: false"
    },
    {
      "name": "claude-code-full-simulator.yaml",
      "path": "infra/test-resources/simulators/claude-code-full-simulator.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: full-simulator\n  namespace: claude-code\ndata:\n  simulate-full-metrics.sh: |\n    #!/bin/bash\n    echo \"Starting Claude Code full metric simulation...\"\n    \n    # Function to send metrics to OTLP\n    send_metric() {\n      local metric_name=$1\n      local value=$2\n      local attributes=$3\n      local timestamp=$(date +%s)000000000\n      \n      # Build attributes JSON\n      local attr_json=\"\"\n      if [ -n \"$attributes\" ]; then\n        attr_json=', \"attributes\": ['$attributes']'\n      fi\n      \n      cat <<EOF > /tmp/metrics.json\n    {\n      \"resource_metrics\": [{\n        \"resource\": {\n          \"attributes\": [{\n            \"key\": \"service.name\",\n            \"value\": { \"string_value\": \"claude-code\" }\n          }, {\n            \"key\": \"github.user\", \n            \"value\": { \"string_value\": \"test-user-001\" }\n          }, {\n            \"key\": \"environment\",\n            \"value\": { \"string_value\": \"production\" }\n          }]\n        },\n        \"scope_metrics\": [{\n          \"scope\": {\n            \"name\": \"claude-code-simulator\"\n          },\n          \"metrics\": [{\n            \"name\": \"$metric_name\",\n            \"unit\": \"1\",\n            \"gauge\": {\n              \"data_points\": [{\n                \"time_unix_nano\": \"$timestamp\",\n                \"as_double\": $value\n                $attr_json\n              }]\n            }\n          }]\n        }]\n      }]\n    }\n    EOF\n      \n      curl -X POST http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318/v1/metrics \\\n        -H \"Content-Type: application/json\" \\\n        -d @/tmp/metrics.json \\\n        --silent --show-error > /dev/null 2>&1\n    }\n    \n    # Initialize counters\n    session_count=1\n    total_lines=0\n    total_tokens=0\n    total_cost=0\n    commit_count=0\n    pr_count=0\n    \n    # Send initial session metric\n    send_metric \"session.count\" \"$session_count\"\n    \n    while true; do\n      echo \"$(date): Simulating Claude Code activity...\"\n      \n      # Simulate code editing with language attributes\n      languages=(\"python\" \"javascript\" \"go\" \"rust\" \"typescript\")\n      for lang in \"${languages[@]}\"; do\n        if [ $((RANDOM % 3)) -lt 2 ]; then\n          lines=$((RANDOM % 50 + 10))\n          total_lines=$((total_lines + lines))\n          operation=$( [ $((RANDOM % 2)) -eq 0 ] && echo \"add\" || echo \"remove\" )\n          \n          attr='{\"key\": \"operation\", \"value\": {\"string_value\": \"'$operation'\"}}, {\"key\": \"language\", \"value\": {\"string_value\": \"'$lang'\"}}'\n          send_metric \"lines_of_code.count\" \"$total_lines\" \"$attr\"\n          echo \"  Code modified: $lines lines of $lang ($operation)\"\n        fi\n      done\n      \n      # Simulate token usage with model attributes\n      models=(\"claude-3-5-sonnet-20241022\" \"claude-3-opus-20240229\" \"claude-3-haiku-20240307\")\n      selected_model=${models[$RANDOM % ${#models[@]}]}\n      tokens=$((RANDOM % 500 + 100))\n      total_tokens=$((total_tokens + tokens))\n      \n      # Token usage with type\n      for token_type in \"input\" \"output\"; do\n        type_tokens=$((tokens / 2))\n        attr='{\"key\": \"type\", \"value\": {\"string_value\": \"'$token_type'\"}}, {\"key\": \"model\", \"value\": {\"string_value\": \"'$selected_model'\"}}'\n        send_metric \"token.usage\" \"$total_tokens\" \"$attr\"\n      done\n      echo \"  Tokens used: $tokens (model: $selected_model)\"\n      \n      # Simulate cost\n      cost=$(echo \"scale=4; $tokens * 0.00001\" | bc)\n      total_cost=$(echo \"scale=4; $total_cost + $cost\" | bc)\n      attr='{\"key\": \"model\", \"value\": {\"string_value\": \"'$selected_model'\"}}'\n      send_metric \"cost.usage\" \"$total_cost\" \"$attr\"\n      echo \"  Cost incurred: \\$$cost\"\n      \n      # Simulate commits (every 3rd iteration)\n      if [ $((RANDOM % 3)) -eq 0 ]; then\n        commit_count=$((commit_count + 1))\n        send_metric \"commit.count\" \"$commit_count\"\n        echo \"  Git commit created (#$commit_count)\"\n      fi\n      \n      # Simulate pull requests (every 5th iteration)\n      if [ $((RANDOM % 5)) -eq 0 ]; then\n        pr_count=$((pr_count + 1))\n        send_metric \"pull_request.count\" \"$pr_count\"\n        echo \"  Pull request created (#$pr_count)\"\n      fi\n      \n      # Simulate tool usage decisions\n      tools=(\"Read\" \"Write\" \"Edit\" \"MultiEdit\" \"Bash\")\n      decisions=(\"accepted\" \"rejected\")\n      for i in {1..3}; do\n        tool=${tools[$RANDOM % ${#tools[@]}]}\n        decision=${decisions[$RANDOM % ${#decisions[@]}]}\n        language=${languages[$RANDOM % ${#languages[@]}]}\n        \n        attr='{\"key\": \"tool\", \"value\": {\"string_value\": \"'$tool'\"}}, {\"key\": \"decision\", \"value\": {\"string_value\": \"'$decision'\"}}, {\"key\": \"language\", \"value\": {\"string_value\": \"'$language'\"}}'\n        send_metric \"code_edit_tool.decision\" \"1\" \"$attr\"\n        echo \"  Tool decision: $tool - $decision (language: $language)\"\n      done\n      \n      echo \"Metrics sent. Waiting 15 seconds...\"\n      sleep 15\n    done\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: claude-code-full-simulator\n  namespace: claude-code\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: full-simulator\n  template:\n    metadata:\n      labels:\n        app: full-simulator\n    spec:\n      containers:\n      - name: simulator\n        image: alpine:3.19\n        command: [\"/bin/sh\"]\n        args: \n          - -c\n          - |\n            apk add --no-cache curl bc bash\n            bash /scripts/simulate-full-metrics.sh\n        volumeMounts:\n        - name: scripts\n          mountPath: /scripts\n        resources:\n          limits:\n            cpu: 100m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n      volumes:\n      - name: scripts\n        configMap:\n          name: full-simulator"
    },
    {
      "name": "claude-code-metric-simulator.yaml",
      "path": "infra/test-resources/simulators/claude-code-metric-simulator.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: metric-simulator\n  namespace: claude-code\ndata:\n  simulate-metrics.sh: |\n    #!/bin/bash\n    echo \"Starting Claude Code metric simulation...\"\n    \n    # Function to send metrics to OTLP\n    send_metric() {\n      local metric_name=$1\n      local value=$2\n      local timestamp=$(date +%s)000000000\n      \n      cat <<EOF > /tmp/metrics.json\n    {\n      \"resource_metrics\": [{\n        \"resource\": {\n          \"attributes\": [{\n            \"key\": \"service.name\",\n            \"value\": { \"string_value\": \"claude-code\" }\n          }]\n        },\n        \"scope_metrics\": [{\n          \"scope\": {\n            \"name\": \"claude-code-simulator\"\n          },\n          \"metrics\": [{\n            \"name\": \"$metric_name\",\n            \"unit\": \"1\",\n            \"gauge\": {\n              \"data_points\": [{\n                \"time_unix_nano\": \"$timestamp\",\n                \"as_double\": $value,\n                \"attributes\": []\n              }]\n            }\n          }]\n        }]\n      }]\n    }\n    EOF\n      \n      # Send to OTLP collector\n      curl -X POST http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318/v1/metrics \\\n        -H \"Content-Type: application/json\" \\\n        -d @/tmp/metrics.json \\\n        --silent --show-error\n    }\n    \n    # Simulate metrics every 10 seconds\n    while true; do\n      echo \"$(date): Sending simulated metrics...\"\n      \n      # Simulate session count\n      send_metric \"session.count\" \"1\"\n      \n      # Simulate lines of code (random between 10-100)\n      lines=$((RANDOM % 91 + 10))\n      send_metric \"lines_of_code.count\" \"$lines\"\n      \n      # Simulate token usage (random between 100-1000)\n      tokens=$((RANDOM % 901 + 100))\n      send_metric \"token.usage\" \"$tokens\"\n      \n      # Simulate cost (random between 0.01-0.10)\n      cost=$(echo \"scale=2; ($(($RANDOM % 10)) + 1) / 100\" | bc)\n      send_metric \"cost.usage\" \"$cost\"\n      \n      echo \"Metrics sent: session=1, lines=$lines, tokens=$tokens, cost=$cost\"\n      \n      sleep 10\n    done\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: claude-code-metric-simulator\n  namespace: claude-code\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: metric-simulator\n  template:\n    metadata:\n      labels:\n        app: metric-simulator\n    spec:\n      containers:\n      - name: simulator\n        image: alpine:3.19\n        command: [\"/bin/sh\"]\n        args: \n          - -c\n          - |\n            apk add --no-cache curl bc bash\n            bash /scripts/simulate-metrics.sh\n        volumeMounts:\n        - name: scripts\n          mountPath: /scripts\n        resources:\n          limits:\n            cpu: 100m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n      volumes:\n      - name: scripts\n        configMap:\n          name: metric-simulator"
    },
    {
      "name": "claude-code-log-simulator.yaml",
      "path": "infra/test-resources/simulators/claude-code-log-simulator.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: log-simulator\n  namespace: claude-code\ndata:\n  simulate-logs.sh: |\n    #!/bin/bash\n    echo \"Starting Claude Code log simulation...\"\n    \n    # Function to send logs to OTLP\n    send_log() {\n      local severity=$1\n      local message=$2\n      local timestamp=$(date +%s)000000000\n      local iso_time=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n      \n      cat <<EOF > /tmp/logs.json\n    {\n      \"resource_logs\": [{\n        \"resource\": {\n          \"attributes\": [{\n            \"key\": \"service.name\",\n            \"value\": { \"string_value\": \"claude-code\" }\n          }, {\n            \"key\": \"service.namespace\",\n            \"value\": { \"string_value\": \"claude-code\" }\n          }, {\n            \"key\": \"github.user\",\n            \"value\": { \"string_value\": \"claude-agent-001\" }\n          }, {\n            \"key\": \"environment\",\n            \"value\": { \"string_value\": \"production\" }\n          }]\n        },\n        \"scope_logs\": [{\n          \"scope\": {\n            \"name\": \"claude-code-logger\"\n          },\n          \"log_records\": [{\n            \"time_unix_nano\": \"$timestamp\",\n            \"severity_number\": $severity,\n            \"severity_text\": \"$1\",\n            \"body\": {\n              \"string_value\": \"$message\"\n            },\n            \"attributes\": [{\n              \"key\": \"timestamp\",\n              \"value\": { \"string_value\": \"$iso_time\" }\n            }, {\n              \"key\": \"event.type\",\n              \"value\": { \"string_value\": \"claude.log\" }\n            }]\n          }]\n        }]\n      }]\n    }\n    EOF\n      \n      # Send to OTLP collector\n      curl -X POST http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318/v1/logs \\\n        -H \"Content-Type: application/json\" \\\n        -d @/tmp/logs.json \\\n        --silent --show-error\n    }\n    \n    # Simulate various log messages\n    while true; do\n      echo \"$(date): Sending simulated logs...\"\n      \n      # Info log - Session started\n      send_log 9 \"INFO\" \"Claude Code session started\"\n      sleep 2\n      \n      # Info log - Task execution\n      task_type=(\"code_generation\" \"code_review\" \"debugging\" \"refactoring\")\n      selected_task=${task_type[$RANDOM % ${#task_type[@]}]}\n      send_log 9 \"INFO\" \"Executing task: $selected_task\"\n      sleep 3\n      \n      # Debug log - Tool usage\n      tools=(\"Read\" \"Write\" \"Edit\" \"Bash\" \"Search\")\n      selected_tool=${tools[$RANDOM % ${#tools[@]}]}\n      send_log 5 \"DEBUG\" \"Tool invoked: $selected_tool\"\n      sleep 2\n      \n      # Info log - Metrics\n      lines=$((RANDOM % 100 + 10))\n      send_log 9 \"INFO\" \"Code modified: $lines lines\"\n      sleep 2\n      \n      # Occasional warning\n      if [ $((RANDOM % 5)) -eq 0 ]; then\n        send_log 13 \"WARN\" \"Rate limit approaching: 80% of quota used\"\n        sleep 1\n      fi\n      \n      # Info log - Completion\n      send_log 9 \"INFO\" \"Task completed successfully\"\n      \n      echo \"Log batch sent\"\n      sleep 10\n    done\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: claude-code-log-simulator\n  namespace: claude-code\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: log-simulator\n  template:\n    metadata:\n      labels:\n        app: log-simulator\n    spec:\n      containers:\n      - name: simulator\n        image: alpine:3.19\n        command: [\"/bin/sh\"]\n        args: \n          - -c\n          - |\n            apk add --no-cache curl bash\n            bash /scripts/simulate-logs.sh\n        volumeMounts:\n        - name: scripts\n          mountPath: /scripts\n        resources:\n          limits:\n            cpu: 100m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n      volumes:\n      - name: scripts\n        configMap:\n          name: log-simulator"
    },
    {
      "name": "test-volume-pod.yaml",
      "path": "infra/test-resources/test-pods/test-volume-pod.yaml",
      "config_type": "yaml",
      "content": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-volume\n  namespace: telemetry\nspec:\n  nodeSelector:\n    kubernetes.io/hostname: talos-a43-ee1  # Force to worker node\n  containers:\n  - name: test\n    image: busybox\n    command: [\"sh\", \"-c\", \"ls -la /var/mnt/ && sleep 3600\"]\n    volumeMounts:\n    - name: host-var\n      mountPath: /var/mnt\n      readOnly: true\n  volumes:\n  - name: host-var\n    hostPath:\n      path: /var/mnt\n      type: Directory"
    },
    {
      "name": "create-storage-dirs.yaml",
      "path": "infra/test-resources/create-storage-dirs.yaml",
      "config_type": "yaml",
      "content": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: create-storage-dirs\n  namespace: telemetry\nspec:\n  template:\n    metadata:\n      labels:\n        app: create-dirs\n    spec:\n      nodeSelector:\n        kubernetes.io/hostname: talos-a43-ee1\n      restartPolicy: Never\n      containers:\n      - name: create-dirs\n        image: busybox\n        command: \n        - sh\n        - -c\n        - |\n          mkdir -p /host/var/telemetry-storage/victoria-metrics\n          mkdir -p /host/var/telemetry-storage/victoria-logs\n          mkdir -p /host/var/telemetry-storage/grafana\n          mkdir -p /host/var/telemetry-storage/claude-code-workspace\n          chmod -R 777 /host/var/telemetry-storage\n          ls -la /host/var/telemetry-storage/\n        volumeMounts:\n        - name: host-var\n          mountPath: /host/var\n        securityContext:\n          privileged: true\n      volumes:\n      - name: host-var\n        hostPath:\n          path: /var\n          type: Directory"
    },
    {
      "name": "claude-code-telemetry-test-job.yaml",
      "path": "infra/test-resources/claude-code-telemetry-test-job.yaml",
      "config_type": "yaml",
      "content": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: claude-code-telemetry-test\n  namespace: claude-code\nspec:\n  template:\n    metadata:\n      labels:\n        app: claude-code-test\n    spec:\n      restartPolicy: Never\n      imagePullSecrets:\n      - name: ghcr-secret\n      containers:\n      - name: claude-code\n        image: ghcr.io/5dlabs/platform/claude-code:latest\n        command: [\"claude\"]\n        args:\n          - \"-p\"\n          - \"Create a Python script that calculates fibonacci numbers. Include proper documentation. Save it as fibonacci.py\"\n        env:\n        - name: ANTHROPIC_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: claude-code-secret\n              key: ANTHROPIC_API_KEY\n        - name: CLAUDE_CODE_ENABLE_TELEMETRY\n          value: \"1\"\n        - name: OTEL_METRICS_EXPORTER\n          value: \"otlp\"\n        - name: OTEL_LOGS_EXPORTER\n          value: \"otlp\"\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: \"http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318\"\n        - name: OTEL_EXPORTER_OTLP_PROTOCOL\n          value: \"http/protobuf\"\n        - name: OTEL_SERVICE_NAME\n          value: \"claude-code\"\n        - name: OTEL_RESOURCE_ATTRIBUTES\n          value: \"service.name=claude-code,environment=production,github.user=test-job\"\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 2Gi\n          requests:\n            cpu: 500m\n            memory: 1Gi"
    },
    {
      "name": "dist-workspace.toml",
      "path": "dist-workspace.toml",
      "config_type": "toml",
      "content": "[workspace]\nmembers = [\"cargo:orchestrator/tools\"]\n\n# Config for 'dist'\n[dist]\n# The preferred dist version to use in CI (Cargo.toml SemVer syntax)\ncargo-dist-version = \"0.28.2\"\n# CI backends to support\nci = \"github\"\n# The installers to generate for each app\ninstallers = [\"shell\"]\n# Target platforms to build apps for (Rust target-triple syntax)\ntargets = [\"aarch64-apple-darwin\", \"aarch64-unknown-linux-gnu\", \"x86_64-apple-darwin\", \"x86_64-unknown-linux-gnu\", \"x86_64-pc-windows-msvc\"]\n# Path that installers should place binaries in\ninstall-path = \"CARGO_HOME\"\n# Where to host releases\nhosting = \"github\"\n# Whether to install an updater program\ninstall-updater = false\n# Allow manual customizations to release.yml\nallow-dirty = [\"ci\"]\n"
    },
    {
      "name": "Cargo.toml",
      "path": "orchestrator/Cargo.toml",
      "config_type": "toml",
      "content": "[workspace]\nresolver = \"2\"\nmembers = [\n    \"core\",\n    \"tools\",\n    \"common\",\n]\n\n[workspace.package]\nversion = \"0.1.0\"\nedition = \"2021\"\nauthors = [\"5D team\"]\nlicense = \"AGPL-3.0\"\nrepository = \"https://github.com/5dlabs/platform\"\n\n[workspace.dependencies]\n# Web framework\naxum = \"0.8.4\"\ntokio = { version = \"1.40\", features = [\"full\"] }\ntower = \"0.5\"\ntower-http = { version = \"0.5\", features = [\"trace\", \"cors\", \"limit\", \"timeout\"] }\n\n# Kubernetes\nkube = { version = \"0.93\", features = [\"runtime\", \"derive\", \"client\", \"ws\"] }\nkube-derive = \"0.93\"\nk8s-openapi = { version = \"0.22\", features = [\"v1_30\"] }\nschemars = \"0.8\"\n\n# Serialization\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\nserde_yaml = \"0.9\"\ntoml = \"0.8\"\n\n# Error handling\nanyhow = \"1.0\"\nthiserror = \"2.0.12\"\n\n# Logging and tracing\ntracing = \"0.1\"\ntracing-subscriber = { version = \"0.3\", features = [\"env-filter\", \"json\"] }\n\n# OpenTelemetry\nopentelemetry = \"0.30.0\"\nopentelemetry-otlp = { version = \"0.17\", features = [\"tonic\"] }\nopentelemetry_sdk = { version = \"0.24\", features = [\"rt-tokio\"] }\ntracing-opentelemetry = \"0.31.0\"\n\n# CLI\nclap = { version = \"4.5\", features = [\"derive\", \"env\", \"cargo\"] }\ndialoguer = \"0.11\"\nindicatif = \"0.17\"\ncolored = \"3.0.0\"\n\n# HTTP Client\nreqwest = { version = \"0.12\", features = [\"json\", \"stream\", \"rustls-tls\"], default-features = false }\neventsource-client = \"0.15.0\"\n\n# Async utilities\nfutures = \"0.3\"\nasync-trait = \"0.1\"\n\n# Time handling\nchrono = { version = \"0.4\", features = [\"serde\"] }\n\n# Text processing\nregex = \"1.10\"\nhandlebars = \"6.3.2\"\n\n# Testing\nmockall = \"0.13\"\nwiremock = \"0.6\"\n\n# UUID generation\nuuid = { version = \"1.10\", features = [\"v4\", \"serde\"] }\n\n[profile.release]\nlto = true\nopt-level = 3\ncodegen-units = 1\n\n# The profile that 'dist' will build with\n[profile.dist]\ninherits = \"release\"\nlto = \"thin\"\n"
    },
    {
      "name": "Cargo.toml",
      "path": "orchestrator/tools/Cargo.toml",
      "config_type": "toml",
      "content": "[package]\nname = \"fivedlabs-tools\"\nversion.workspace = true\nedition.workspace = true\nauthors.workspace = true\nlicense.workspace = true\nrepository.workspace = true\ndescription = \"5D Labs platform tools: CLI and MCP server for AI development workflows\"\nhomepage = \"https://github.com/5dlabs/platform\"\n\n# CLI binary\n[[bin]]\nname = \"fdl\"\npath = \"src/cli/main.rs\"\n\n# MCP server binary\n[[bin]]\nname = \"fdl-mcp\"\npath = \"src/mcp/main.rs\"\n\n[dependencies]\n# CLI\nclap = { workspace = true }\ncolored = { workspace = true }\n\n# HTTP Client\nreqwest = { workspace = true }\n\n# Serialization\nserde = { workspace = true }\nserde_json = { workspace = true }\n\n# Error handling\nanyhow = { workspace = true }\n\n# Logging\ntracing = { workspace = true }\ntracing-subscriber = { workspace = true }\n\n# Async runtime\ntokio = { workspace = true }\n\n# Time handling\nchrono = { workspace = true }\n\n# Internal dependencies\ncommon = { path = \"../common\" }"
    },
    {
      "name": "rustfmt.toml",
      "path": "orchestrator/rustfmt.toml",
      "config_type": "toml",
      "content": "# Rust formatting configuration\nedition = \"2021\"\nmax_width = 100\nuse_small_heuristics = \"Default\""
    },
    {
      "name": "Cargo.toml",
      "path": "orchestrator/core/Cargo.toml",
      "config_type": "toml",
      "content": "[package]\nname = \"core\"\nversion.workspace = true\nedition.workspace = true\nauthors.workspace = true\nlicense.workspace = true\nrepository.workspace = true\ndescription = \"5D Labs platform orchestrator core API server (for Kubernetes deployment)\"\nhomepage = \"https://github.com/5dlabs/platform\"\n\n[[bin]]\nname = \"orchestrator-core\"\npath = \"src/main.rs\"\n\n[package.metadata.dist]\n# Don't distribute this package - it's for Docker deployment, not end users\ndist = false\n\n[dependencies]\n# Web framework\naxum = { workspace = true }\ntokio = { workspace = true }\ntower = { workspace = true }\ntower-http = { workspace = true }\n\n# Kubernetes\nkube = { workspace = true }\nkube-derive = { workspace = true }\nk8s-openapi = { workspace = true }\nschemars = { workspace = true }\n\n# Serialization\nserde = { workspace = true }\nserde_json = { workspace = true }\nserde_yaml = { workspace = true }\n\n# Error handling\nanyhow = { workspace = true }\nthiserror = { workspace = true }\n\n# Logging and tracing\ntracing = { workspace = true }\ntracing-subscriber = { workspace = true }\n\n# OpenTelemetry\nopentelemetry = { workspace = true }\nopentelemetry-otlp = { workspace = true }\nopentelemetry_sdk = { workspace = true }\ntracing-opentelemetry = { workspace = true }\n\n# HTTP Client\nreqwest = { workspace = true }\n\n# Async utilities\nfutures = { workspace = true }\nasync-trait = { workspace = true }\n\n# Time handling\nchrono = { workspace = true }\n\n# Text processing\nregex = { workspace = true }\nhandlebars = { workspace = true }\n\n# File system\ntempfile = \"3.8\"\n\n# Internal dependencies\ncommon = { path = \"../common\" }\n\n[dev-dependencies]\ntokio-test = \"0.4\"\nmockall = { workspace = true }\nwiremock = { workspace = true }\nuuid = { workspace = true }"
    },
    {
      "name": "Cargo.toml",
      "path": "orchestrator/common/Cargo.toml",
      "config_type": "toml",
      "content": "[package]\nname = \"common\"\nversion.workspace = true\nedition.workspace = true\nauthors.workspace = true\nlicense.workspace = true\n\n[dependencies]\n# Serialization\nserde = { workspace = true }\nserde_json = { workspace = true }\n\n# Error handling\nanyhow = { workspace = true }\nthiserror = { workspace = true }\n\n# Time handling\nchrono = { workspace = true }\n\n# Kubernetes types (for shared models)\nk8s-openapi = { workspace = true }\n\n# Async trait\nasync-trait = { workspace = true }\n\n# UUID generation\nuuid = { version = \"1.10\", features = [\"v4\", \"serde\"] }\n\n[dev-dependencies]\nserde_test = \"1.0\""
    },
    {
      "name": "clippy.toml",
      "path": "orchestrator/clippy.toml",
      "config_type": "toml",
      "content": "# Clippy configuration for consistent linting\n\n# Set the maximum cognitive complexity allowed\ncognitive-complexity-threshold = 30\n\n# Set maximum function arguments\ntoo-many-arguments-threshold = 7\n\n# Set maximum lines for functions\ntoo-many-lines-threshold = 100\n\n# Disallow certain macros\ndisallowed-macros = [\n    # We prefer tracing over println for logging\n    { path = \"std::println\", reason = \"use tracing::info! instead\" },\n    { path = \"std::eprintln\", reason = \"use tracing::error! instead\" },\n]"
    },
    {
      "name": "engineering-metrics-dashboard.json",
      "path": "infra/telemetry/telemetry-dashboards/dashboards/engineering-metrics-dashboard.json",
      "config_type": "json",
      "content": "{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations & Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 20,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"normal\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (operation) (rate(claude_code_lines_of_code_count{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[5m]))\",\n          \"legendFormat\": \"{{operation}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Lines of Code Modified\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_pull_request_count{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[24h]))\",\n          \"legendFormat\": \"Pull Requests\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Pull Requests (24h)\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_commit_count{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[24h]))\",\n          \"legendFormat\": \"Commits\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Commits (24h)\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            }\n          }\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 4\n      },\n      \"id\": 4,\n      \"options\": {\n        \"calculate\": false,\n        \"cellGap\": 1,\n        \"cellValues\": {\n          \"unit\": \"short\"\n        },\n        \"color\": {\n          \"exponent\": 0.5,\n          \"fill\": \"dark-orange\",\n          \"mode\": \"scheme\",\n          \"reverse\": false,\n          \"scale\": \"exponential\",\n          \"scheme\": \"Oranges\",\n          \"steps\": 64\n        },\n        \"exemplars\": {\n          \"color\": \"rgba(255,0,255,0.7)\"\n        },\n        \"filterValues\": {\n          \"le\": 1e-9\n        },\n        \"legend\": {\n          \"show\": true\n        },\n        \"rowsFrame\": {\n          \"layout\": \"auto\"\n        },\n        \"tooltip\": {\n          \"show\": true,\n          \"yHistogram\": false\n        },\n        \"yAxis\": {\n          \"axisPlacement\": \"left\",\n          \"reverse\": false,\n          \"unit\": \"short\"\n        }\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (hour) (increase(claude_code_commit_count{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[1h]))\",\n          \"format\": \"heatmap\",\n          \"legendFormat\": \"{{hour}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Commit Patterns (Heatmap)\",\n      \"type\": \"heatmap\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": []\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 8\n      },\n      \"id\": 5,\n      \"options\": {\n        \"displayLabels\": [\"name\", \"percent\"],\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\": []\n        },\n        \"pieType\": \"pie\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (tool) (claude_code_code_edit_tool_decision{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"})\",\n          \"legendFormat\": \"{{tool}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Tool Usage Distribution\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 12\n      },\n      \"id\": 6,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (token_type) (rate(claude_code_token_usage{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[5m]))\",\n          \"legendFormat\": \"{{token_type}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Token Usage by Type\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"victoriametrics-logs-datasource\",\n        \"uid\": \"${logs_datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"_time\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 180\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"github.user\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 150\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"working.service\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 150\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 7,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\"sum\"],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"victoriametrics-logs-datasource\",\n            \"uid\": \"${logs_datasource}\"\n          },\n          \"expr\": \"_msg:claude_code.user_prompt AND github.user:\\\"$github_user\\\" AND working.service:\\\"$service\\\" | fields _time, github.user, working.service, prompt_preview | sort by (_time desc) | limit 100\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Developer Activity Timeline\",\n      \"type\": \"table\"\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"claude-code\", \"engineering\"],\n  \"templating\": {\n    \"list\": [\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"VictoriaMetrics\",\n          \"value\": \"VictoriaMetrics\"\n        },\n        \"hide\": 0,\n        \"includeAll\": false,\n        \"label\": \"Metrics Datasource\",\n        \"multi\": false,\n        \"name\": \"datasource\",\n        \"options\": [],\n        \"query\": \"prometheus\",\n        \"queryValue\": \"\",\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"datasource\"\n      },\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"VictoriaLogs\",\n          \"value\": \"VictoriaLogs\"\n        },\n        \"hide\": 0,\n        \"includeAll\": false,\n        \"label\": \"Logs Datasource\",\n        \"multi\": false,\n        \"name\": \"logs_datasource\",\n        \"options\": [],\n        \"query\": \"victoriametrics-logs-datasource\",\n        \"queryValue\": \"\",\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"datasource\"\n      },\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"All\",\n          \"value\": \"$__all\"\n        },\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"${datasource}\"\n        },\n        \"definition\": \"label_values(github.user)\",\n        \"hide\": 0,\n        \"includeAll\": true,\n        \"label\": \"GitHub User\",\n        \"multi\": false,\n        \"name\": \"github_user\",\n        \"options\": [],\n        \"query\": {\n          \"query\": \"label_values(github.user)\",\n          \"refId\": \"PrometheusVariableQueryEditor-VariableQuery\"\n        },\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"sort\": 0,\n        \"type\": \"query\"\n      },\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"All\",\n          \"value\": \"$__all\"\n        },\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"${datasource}\"\n        },\n        \"definition\": \"label_values(working.service)\",\n        \"hide\": 0,\n        \"includeAll\": true,\n        \"label\": \"Service\",\n        \"multi\": false,\n        \"name\": \"service\",\n        \"options\": [],\n        \"query\": {\n          \"query\": \"label_values(working.service)\",\n          \"refId\": \"PrometheusVariableQueryEditor-VariableQuery\"\n        },\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"sort\": 0,\n        \"type\": \"query\"\n      }\n    ]\n  },\n  \"time\": {\n    \"from\": \"now-24h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"Claude Code - Engineering Metrics\",\n  \"uid\": \"engineering-metrics\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}"
    },
    {
      "name": "cost-management-dashboard.json",
      "path": "infra/telemetry/telemetry-dashboards/dashboards/cost-management-dashboard.json",
      "config_type": "json",
      "content": "{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations & Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 50\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 100\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[1h]))\",\n          \"legendFormat\": \"Current Hour Spend\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Current Hour Spend\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 500\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 1000\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[24h]))\",\n          \"legendFormat\": \"Today's Total\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Today's Total Spend\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 15000\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 30000\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[30d]))\",\n          \"legendFormat\": \"Monthly Total\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Monthly Total Spend\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"continuous-GrYlRd\"\n          },\n          \"mappings\": [],\n          \"max\": 100,\n          \"min\": 0,\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 50\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"showThresholdLabels\": true,\n        \"showThresholdMarkers\": true,\n        \"text\": {}\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"(sum(increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[24h])) / 1000) * 100\",\n          \"legendFormat\": \"Budget Used %\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Daily Budget Burn Rate\",\n      \"type\": \"gauge\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 20,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 2,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"normal\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 6\n      },\n      \"id\": 5,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"sum\"],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (day) (increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[1d]))\",\n          \"legendFormat\": \"Daily Cost\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Daily Cost Trend\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"fillOpacity\": 80,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineWidth\": 1,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 6\n      },\n      \"id\": 6,\n      \"options\": {\n        \"barRadius\": 0,\n        \"barWidth\": 0.97,\n        \"fullHighlight\": false,\n        \"groupWidth\": 0.7,\n        \"legend\": {\n          \"calcs\": [\"sum\"],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"orientation\": \"auto\",\n        \"showValue\": \"auto\",\n        \"stacking\": \"normal\",\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        },\n        \"xTickLabelRotation\": 0,\n        \"xTickLabelSpacing\": 0\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (model) (increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[24h]))\",\n          \"legendFormat\": \"{{model}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Cost by Model (24h)\",\n      \"type\": \"barchart\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 14\n      },\n      \"id\": 7,\n      \"options\": {\n        \"displayLabels\": [\"name\", \"value\"],\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\": [\"value\"]\n        },\n        \"pieType\": \"donut\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (working_service) (increase(claude_code_cost_usage{github_user=~\\\"$github_user\\\",working_service=~\\\"$service\\\"}[24h]))\",\n          \"legendFormat\": \"{{working_service}}\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Cost by Service (24h)\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"color-text\"\n            },\n            \"inspect\": false\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 50\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 100\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"GitHub User\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 200\n              }\n            ]\n          },\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Service\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 200\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 14\n      },\n      \"id\": 8,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\"sum\"],\n          \"show\": true\n        },\n        \"showHeader\": true,\n        \"sortBy\": [\n          {\n            \"desc\": true,\n            \"displayName\": \"Cost (24h)\"\n          }\n        ]\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"topk(20, sum by (github_user, working_service) (increase(claude_code_cost_usage[24h])))\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"__auto\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Top Spenders (24h)\",\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"Value\": \"Cost (24h)\",\n              \"github_user\": \"GitHub User\",\n              \"working_service\": \"Service\"\n            }\n          }\n        }\n      ],\n      \"type\": \"table\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"color-background\"\n            },\n            \"inspect\": false\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"yellow\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 100\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 6,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 22\n      },\n      \"id\": 9,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\"sum\"],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (github_user, working_service) (increase(claude_code_cost_usage[1h])) > 100\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"__auto\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"⚠️ Cost Anomalies - Users Spending >$100/hour\",\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"Value\": \"Hourly Cost\",\n              \"github_user\": \"GitHub User\",\n              \"working_service\": \"Service\"\n            }\n          }\n        }\n      ],\n      \"type\": \"table\"\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"claude-code\", \"cost\", \"budget\"],\n  \"templating\": {\n    \"list\": [\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"VictoriaMetrics\",\n          \"value\": \"VictoriaMetrics\"\n        },\n        \"hide\": 0,\n        \"includeAll\": false,\n        \"label\": \"Datasource\",\n        \"multi\": false,\n        \"name\": \"datasource\",\n        \"options\": [],\n        \"query\": \"prometheus\",\n        \"queryValue\": \"\",\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"datasource\"\n      },\n      {\n        \"current\": {\n          \"selected\": true,\n          \"text\": [\"All\"],\n          \"value\": [\"$__all\"]\n        },\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"${datasource}\"\n        },\n        \"definition\": \"label_values(claude_code_cost_usage, github_user)\",\n        \"hide\": 0,\n        \"includeAll\": true,\n        \"label\": \"GitHub User\",\n        \"multi\": true,\n        \"name\": \"github_user\",\n        \"options\": [],\n        \"query\": {\n          \"query\": \"label_values(claude_code_cost_usage, github_user)\",\n          \"refId\": \"PrometheusVariableQueryEditor-VariableQuery\"\n        },\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"sort\": 1,\n        \"type\": \"query\"\n      },\n      {\n        \"current\": {\n          \"selected\": true,\n          \"text\": [\"All\"],\n          \"value\": [\"$__all\"]\n        },\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"${datasource}\"\n        },\n        \"definition\": \"label_values(claude_code_cost_usage, working_service)\",\n        \"hide\": 0,\n        \"includeAll\": true,\n        \"label\": \"Service\",\n        \"multi\": true,\n        \"name\": \"service\",\n        \"options\": [],\n        \"query\": {\n          \"query\": \"label_values(claude_code_cost_usage, working_service)\",\n          \"refId\": \"PrometheusVariableQueryEditor-VariableQuery\"\n        },\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"sort\": 1,\n        \"type\": \"query\"\n      }\n    ]\n  },\n  \"time\": {\n    \"from\": \"now-24h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"Claude Code - Cost Management\",\n  \"uid\": \"cost-management\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}"
    },
    {
      "name": "executive-overview.json",
      "path": "infra/telemetry/telemetry-dashboards/dashboards/executive-overview.json",
      "config_type": "json",
      "content": "{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations & Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_session_count[24h]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Sessions Today\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"count(count by (user_account_uuid) (claude_code_session_count))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Active Users\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 1000\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 5000\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_cost_usage[24h]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Cost Today\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"decimals\": 2,\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 10000\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 50000\n              }\n            ]\n          },\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 5,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\",\n          \"values\": false\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum(increase(claude_code_cost_usage[30d]))\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Monthly Cost\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"never\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 4\n      },\n      \"id\": 6,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"count(count by (user_account_uuid) (claude_code_session_count))\",\n          \"legendFormat\": \"Active Users\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Daily Active Users Trend\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            }\n          },\n          \"mappings\": [],\n          \"unit\": \"currencyUSD\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 4\n      },\n      \"id\": 7,\n      \"options\": {\n        \"displayLabels\": [\"name\", \"percent\"],\n        \"legend\": {\n          \"displayMode\": \"list\",\n          \"placement\": \"right\",\n          \"showLegend\": true,\n          \"values\": [\"value\"]\n        },\n        \"pieType\": \"pie\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\n            \"lastNotNull\"\n          ],\n          \"fields\": \"\"\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"sum by (model) (claude_code_cost_usage)\",\n          \"legendFormat\": \"{{model}}\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Cost by Model\",\n      \"type\": \"piechart\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Cost\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"unit\",\n                \"value\": \"currencyUSD\"\n              },\n              {\n                \"id\": \"decimals\",\n                \"value\": 2\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 12\n      },\n      \"id\": 8,\n      \"options\": {\n        \"showHeader\": true,\n        \"sortBy\": [\n          {\n            \"desc\": true,\n            \"displayName\": \"Cost\"\n          }\n        ]\n      },\n      \"pluginVersion\": \"10.0.0\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"topk(10, sum by (user_account_uuid) (claude_code_cost_usage))\",\n          \"format\": \"table\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Top Users by Cost\",\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"Value\": \"Cost\",\n              \"user_account_uuid\": \"User\"\n            }\n          }\n        }\n      ],\n      \"type\": \"table\"\n    }\n  ],\n  \"refresh\": \"30s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"claude-code\", \"executive\"],\n  \"templating\": {\n    \"list\": [\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"VictoriaMetrics\",\n          \"value\": \"VictoriaMetrics\"\n        },\n        \"hide\": 0,\n        \"includeAll\": false,\n        \"label\": \"Data Source\",\n        \"multi\": false,\n        \"name\": \"datasource\",\n        \"options\": [],\n        \"query\": \"prometheus\",\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"datasource\"\n      }\n    ]\n  },\n  \"time\": {\n    \"from\": \"now-24h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"Claude Code - Executive Overview\",\n  \"uid\": \"claude-code-exec\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}"
    },
    {
      "name": "operations-monitoring-dashboard.json",
      "path": "infra/telemetry/telemetry-dashboards/dashboards/operations-monitoring-dashboard.json",
      "config_type": "json",
      "content": "{\n  \"annotations\": {\n    \"list\": [\n      {\n        \"builtIn\": 1,\n        \"datasource\": {\n          \"type\": \"grafana\",\n          \"uid\": \"-- Grafana --\"\n        },\n        \"enable\": true,\n        \"hide\": true,\n        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n        \"name\": \"Annotations & Alerts\",\n        \"type\": \"dashboard\"\n      }\n    ]\n  },\n  \"editable\": true,\n  \"fiscalYearStartMonth\": 0,\n  \"graphTooltip\": 0,\n  \"id\": null,\n  \"links\": [],\n  \"liveNow\": false,\n  \"panels\": [\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"red\",\n                  \"index\": 1,\n                  \"text\": \"DOWN\"\n                },\n                \"1\": {\n                  \"color\": \"green\",\n                  \"index\": 0,\n                  \"text\": \"UP\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 0\n      },\n      \"id\": 1,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"up{job=\\\"otel-collector\\\",namespace=\\\"telemetry\\\"}\",\n          \"legendFormat\": \"OTLP Collector\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"OTLP Collector Health\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"red\",\n                  \"index\": 1,\n                  \"text\": \"DOWN\"\n                },\n                \"1\": {\n                  \"color\": \"green\",\n                  \"index\": 0,\n                  \"text\": \"UP\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 0\n      },\n      \"id\": 2,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"up{job=\\\"victoria-metrics\\\"}\",\n          \"legendFormat\": \"VictoriaMetrics\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"VictoriaMetrics Health\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [\n            {\n              \"options\": {\n                \"0\": {\n                  \"color\": \"red\",\n                  \"index\": 1,\n                  \"text\": \"DOWN\"\n                },\n                \"1\": {\n                  \"color\": \"green\",\n                  \"index\": 0,\n                  \"text\": \"UP\"\n                }\n              },\n              \"type\": \"value\"\n            }\n          ],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"red\",\n                \"value\": null\n              },\n              {\n                \"color\": \"green\",\n                \"value\": 1\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 12,\n        \"y\": 0\n      },\n      \"id\": 3,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"up{instance=~\\\"victoria-logs.*\\\"}\",\n          \"legendFormat\": \"VictoriaLogs\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"VictoriaLogs Health\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 18,\n        \"y\": 0\n      },\n      \"id\": 4,\n      \"options\": {\n        \"colorMode\": \"background\",\n        \"graphMode\": \"none\",\n        \"justifyMode\": \"center\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"count(up == 1)\",\n          \"legendFormat\": \"Healthy Services\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Total Healthy Services\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"line\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 2,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"area\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 1\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 5\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 0,\n        \"y\": 4\n      },\n      \"id\": 5,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [\"mean\", \"lastNotNull\"],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"(rate(claude_code_api_error{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[5m]) / rate(claude_code_api_request{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[5m])) * 100\",\n          \"legendFormat\": \"Error Rate %\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Claude Code Error Rate\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"palette-classic\"\n          },\n          \"custom\": {\n            \"axisCenteredZero\": false,\n            \"axisColorMode\": \"text\",\n            \"axisLabel\": \"\",\n            \"axisPlacement\": \"auto\",\n            \"barAlignment\": 0,\n            \"drawStyle\": \"bars\",\n            \"fillOpacity\": 10,\n            \"gradientMode\": \"none\",\n            \"hideFrom\": {\n              \"tooltip\": false,\n              \"viz\": false,\n              \"legend\": false\n            },\n            \"insertNulls\": false,\n            \"lineInterpolation\": \"linear\",\n            \"lineWidth\": 1,\n            \"pointSize\": 5,\n            \"scaleDistribution\": {\n              \"type\": \"linear\"\n            },\n            \"showPoints\": \"auto\",\n            \"spanNulls\": false,\n            \"stacking\": {\n              \"group\": \"A\",\n              \"mode\": \"none\"\n            },\n            \"thresholdsStyle\": {\n              \"mode\": \"off\"\n            }\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          },\n          \"unit\": \"ms\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 4\n      },\n      \"id\": 6,\n      \"options\": {\n        \"legend\": {\n          \"calcs\": [],\n          \"displayMode\": \"list\",\n          \"placement\": \"bottom\",\n          \"showLegend\": true\n        },\n        \"tooltip\": {\n          \"mode\": \"single\",\n          \"sort\": \"none\"\n        }\n      },\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"histogram_quantile(0.95, sum(rate(api_request_duration_bucket{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[5m])) by (le))\",\n          \"legendFormat\": \"p95 Response Time\",\n          \"range\": true,\n          \"refId\": \"A\"\n        },\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"histogram_quantile(0.99, sum(rate(api_request_duration_bucket{github_user=\\\"$github_user\\\",working_service=\\\"$service\\\"}[5m])) by (le))\",\n          \"legendFormat\": \"p99 Response Time\",\n          \"range\": true,\n          \"refId\": \"B\"\n        }\n      ],\n      \"title\": \"API Response Times\",\n      \"type\": \"timeseries\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 1000\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 5000\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 0,\n        \"y\": 12\n      },\n      \"id\": 7,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(prometheus_tsdb_samples_appended_total[1m]) * 60\",\n          \"legendFormat\": \"Metrics/min\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Metrics Ingestion Rate\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 10000\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 50000\n              }\n            ]\n          },\n          \"unit\": \"short\"\n        },\n        \"overrides\": []\n      },\n      \"gridPos\": {\n        \"h\": 4,\n        \"w\": 6,\n        \"x\": 6,\n        \"y\": 12\n      },\n      \"id\": 8,\n      \"options\": {\n        \"colorMode\": \"value\",\n        \"graphMode\": \"area\",\n        \"justifyMode\": \"auto\",\n        \"orientation\": \"auto\",\n        \"reduceOptions\": {\n          \"values\": false,\n          \"calcs\": [\"lastNotNull\"],\n          \"fields\": \"\"\n        },\n        \"text\": {},\n        \"textMode\": \"auto\"\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"rate(victoria_logs_rows_inserted_total[1m]) * 60\",\n          \"legendFormat\": \"Logs/min\",\n          \"range\": true,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Logs Ingestion Rate\",\n      \"type\": \"stat\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"prometheus\",\n        \"uid\": \"${datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"color\": {\n            \"mode\": \"thresholds\"\n          },\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"color-text\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              },\n              {\n                \"color\": \"yellow\",\n                \"value\": 50\n              },\n              {\n                \"color\": \"red\",\n                \"value\": 80\n              }\n            ]\n          },\n          \"unit\": \"percent\"\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"Pod\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 300\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 12,\n        \"x\": 12,\n        \"y\": 12\n      },\n      \"id\": 9,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\"sum\"],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"prometheus\",\n            \"uid\": \"${datasource}\"\n          },\n          \"editorMode\": \"code\",\n          \"expr\": \"100 * (container_memory_working_set_bytes{namespace=\\\"telemetry\\\",container!=\\\"\\\"} / container_spec_memory_limit_bytes{namespace=\\\"telemetry\\\",container!=\\\"\\\"})\",\n          \"format\": \"table\",\n          \"instant\": true,\n          \"legendFormat\": \"{{pod}} - {{container}}\",\n          \"range\": false,\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Component Memory Usage\",\n      \"transformations\": [\n        {\n          \"id\": \"organize\",\n          \"options\": {\n            \"excludeByName\": {\n              \"Time\": true,\n              \"container\": true,\n              \"endpoint\": true,\n              \"id\": true,\n              \"image\": true,\n              \"instance\": true,\n              \"job\": true,\n              \"metrics_path\": true,\n              \"name\": true,\n              \"namespace\": true,\n              \"service\": true\n            },\n            \"indexByName\": {},\n            \"renameByName\": {\n              \"Value\": \"Memory %\",\n              \"pod\": \"Pod\"\n            }\n          }\n        }\n      ],\n      \"type\": \"table\"\n    },\n    {\n      \"datasource\": {\n        \"type\": \"victoriametrics-logs-datasource\",\n        \"uid\": \"${logs_datasource}\"\n      },\n      \"fieldConfig\": {\n        \"defaults\": {\n          \"custom\": {\n            \"align\": \"auto\",\n            \"cellOptions\": {\n              \"type\": \"auto\"\n            },\n            \"inspect\": false\n          },\n          \"mappings\": [],\n          \"thresholds\": {\n            \"mode\": \"absolute\",\n            \"steps\": [\n              {\n                \"color\": \"green\",\n                \"value\": null\n              }\n            ]\n          }\n        },\n        \"overrides\": [\n          {\n            \"matcher\": {\n              \"id\": \"byName\",\n              \"options\": \"_time\"\n            },\n            \"properties\": [\n              {\n                \"id\": \"custom.width\",\n                \"value\": 180\n              }\n            ]\n          }\n        ]\n      },\n      \"gridPos\": {\n        \"h\": 8,\n        \"w\": 24,\n        \"x\": 0,\n        \"y\": 16\n      },\n      \"id\": 10,\n      \"options\": {\n        \"cellHeight\": \"sm\",\n        \"footer\": {\n          \"countRows\": false,\n          \"fields\": \"\",\n          \"reducer\": [\"sum\"],\n          \"show\": false\n        },\n        \"showHeader\": true\n      },\n      \"pluginVersion\": \"10.2.2\",\n      \"targets\": [\n        {\n          \"datasource\": {\n            \"type\": \"victoriametrics-logs-datasource\",\n            \"uid\": \"${logs_datasource}\"\n          },\n          \"expr\": \"_msg:\\\"claude_code.api_error\\\" | fields _time, github.user, working.service, error_message, status_code | sort by (_time desc) | limit 50\",\n          \"refId\": \"A\"\n        }\n      ],\n      \"title\": \"Recent API Errors\",\n      \"type\": \"table\"\n    }\n  ],\n  \"refresh\": \"10s\",\n  \"schemaVersion\": 38,\n  \"style\": \"dark\",\n  \"tags\": [\"claude-code\", \"operations\"],\n  \"templating\": {\n    \"list\": [\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"VictoriaMetrics\",\n          \"value\": \"VictoriaMetrics\"\n        },\n        \"hide\": 0,\n        \"includeAll\": false,\n        \"label\": \"Metrics Datasource\",\n        \"multi\": false,\n        \"name\": \"datasource\",\n        \"options\": [],\n        \"query\": \"prometheus\",\n        \"queryValue\": \"\",\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"datasource\"\n      },\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"VictoriaLogs\",\n          \"value\": \"VictoriaLogs\"\n        },\n        \"hide\": 0,\n        \"includeAll\": false,\n        \"label\": \"Logs Datasource\",\n        \"multi\": false,\n        \"name\": \"logs_datasource\",\n        \"options\": [],\n        \"query\": \"victoriametrics-logs-datasource\",\n        \"queryValue\": \"\",\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"type\": \"datasource\"\n      },\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"All\",\n          \"value\": \"$__all\"\n        },\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"${datasource}\"\n        },\n        \"definition\": \"label_values(github.user)\",\n        \"hide\": 0,\n        \"includeAll\": true,\n        \"label\": \"GitHub User\",\n        \"multi\": false,\n        \"name\": \"github_user\",\n        \"options\": [],\n        \"query\": {\n          \"query\": \"label_values(github.user)\",\n          \"refId\": \"PrometheusVariableQueryEditor-VariableQuery\"\n        },\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"sort\": 0,\n        \"type\": \"query\"\n      },\n      {\n        \"current\": {\n          \"selected\": false,\n          \"text\": \"All\",\n          \"value\": \"$__all\"\n        },\n        \"datasource\": {\n          \"type\": \"prometheus\",\n          \"uid\": \"${datasource}\"\n        },\n        \"definition\": \"label_values(working.service)\",\n        \"hide\": 0,\n        \"includeAll\": true,\n        \"label\": \"Service\",\n        \"multi\": false,\n        \"name\": \"service\",\n        \"options\": [],\n        \"query\": {\n          \"query\": \"label_values(working.service)\",\n          \"refId\": \"PrometheusVariableQueryEditor-VariableQuery\"\n        },\n        \"refresh\": 1,\n        \"regex\": \"\",\n        \"skipUrlSync\": false,\n        \"sort\": 0,\n        \"type\": \"query\"\n      }\n    ]\n  },\n  \"time\": {\n    \"from\": \"now-1h\",\n    \"to\": \"now\"\n  },\n  \"timepicker\": {},\n  \"timezone\": \"\",\n  \"title\": \"Claude Code - Operations Monitoring\",\n  \"uid\": \"operations-monitoring\",\n  \"version\": 1,\n  \"weekStart\": \"\"\n}"
    }
  ]
}
```

## YAML Files

### kustomization.yaml (infra/talos/local-path-provisioner/kustomization.yaml)

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- github.com/rancher/local-path-provisioner/deploy?ref=v0.0.31
patches:
- patch: |-
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: local-path-config
      namespace: local-path-storage
    data:
      config.json: |-
        {
                "nodePathMap":[
                {
                        "node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",
                        "paths":["/var/mnt/local-path-provisioner"]
                }
                ]
        }
- patch: |-
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: local-path
      annotations:
        storageclass.kubernetes.io/is-default-class: "true"
- patch: |-
    apiVersion: v1
    kind: Namespace
    metadata:
      name: local-path-storage
      labels:
        pod-security.kubernetes.io/enforce: privileged
```

### local-path-storage.yaml (infra/talos/local-path-provisioner/local-path-storage.yaml)

```yaml
apiVersion: v1alpha1
kind: UserVolumeConfig
name: local-path-provisioner
provisioning:
  diskSelector:
    match: disk.transport == 'nvme'
  minSize: 100GB
  maxSize: 100GB
```

### worker.yaml (infra/talos/config/simple/worker.yaml)

```yaml
version: v1alpha1
debug: false
persist: true
machine:
  type: worker
  token: qt315g.8f9e1kb2r4p79efs
  ca:
    crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJQakNCOGFBREFnRUNBaEJ2TFQ0dzN2cnp1NE50UUUrcDZGeVhNQVVHQXl0bGNEQVFNUTR3REFZRFZRUUsKRXdWMFlXeHZjekFlRncweU5UQTJNekF5TXpBeE1UZGFGdzB6TlRBMk1qZ3lNekF4TVRkYU1CQXhEakFNQmdOVgpCQW9UQlhSaGJHOXpNQ293QlFZREsyVndBeUVBckNVc2YxeGZxenhwWnpFSFRsQXVCSllLSTh5UVpnS0RwZEJyCkFPY1JRZ2lqWVRCZk1BNEdBMVVkRHdFQi93UUVBd0lDaERBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUkKS3dZQkJRVUhBd0l3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVa1pBa2xPcVM2YnNmYjROdAo3ekNJTUR5cXVETXdCUVlESzJWd0EwRUFlbXJHVlpDa3RKeXRpdmJZNjV1TFJDODVFUThpbFpsOVd0WHpldjM3CmdjR1lpVkFzT1pDdzRXV21GMld6SWgrOVlGT1F3ZEZJblRSOFJIak93RHZIQ3c9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    key: ""
  certSANs: []
  kubelet:
    image: ghcr.io/siderolabs/kubelet:v1.33.1
    defaultRuntimeSeccompProfileEnabled: true
    disableManifestsDirectory: true
    nodeIP:
      validSubnets:
        - 192.168.1.0/24
  network:
    interfaces:
      - interface: enp4s0
        dhcp: true
  install:
    disk: /dev/nvme0n1
    image: ghcr.io/siderolabs/installer:v1.10.4
    wipe: true
    extraKernelArgs:
      - talos.install.disk=/dev/nvme0n1
  features:
    rbac: true
    stableHostname: true
    apidCheckExtKeyUsage: true
    diskQuotaSupport: true
    kubePrism:
      enabled: true
      port: 7445
    hostDNS:
      enabled: true
      forwardKubeDNSToHost: true
cluster:
  id: wcWr92csTh7HmKPHHX1rKIQn2mHHS7dHYNXdAUZ5NXY=
  secret: UPKt0QVDtJGdy3SVFCfGVJ6NV5/dSHCL9SFx1VweX7k=
  controlPlane:
    endpoint: https://192.168.1.77:6443
  clusterName: simple-cluster
  network:
    dnsDomain: cluster.local
    podSubnets:
      - 10.244.0.0/16
    serviceSubnets:
      - 10.96.0.0/12
    # cni: {}  # Let cluster decide CNI
  token: 9c3zc1.fj82jlf3xfqwz8kf
  ca:
    crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpakNDQVRDZ0F3SUJBZ0lSQU1PQnFOeTV2V1FWN20vK2pBSHh0amd3Q2dZSUtvWkl6ajBFQXdJd0ZURVQKTUJFR0ExVUVDaE1LYTNWaVpYSnVaWFJsY3pBZUZ3MHlOVEEyTXpBeU16QXhNVGRhRncwek5UQTJNamd5TXpBeApNVGRhTUJVeEV6QVJCZ05WQkFvVENtdDFZbVZ5Ym1WMFpYTXdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CCkJ3TkNBQVFmTGJ2S25LUEZWb1lMRFduM1phY2ZidGhzU1JxRGJvVDgrY1YrdEFWTUs5L1lNSUNlQStaMUxERVkKVVJUK092enB0RWtQWVpiendCM0NxY09KQ3Z1cW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXdIUVlEVlIwbApCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPCkJCWUVGSHgzNitwNkpzNEN6dEZUL25hVHdyQXFsSVVzTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDSUVnUUJUdjkKK0c4MmhYdHUzRHpUemdtN3RpblhLcXhzbzZNQnVFWTFDeGdRQWlFQXVlWHBaeWRnNi9QdEovaHlZbjNsQ0xpSAppbTVLMHBGS0RlQWtVaG5DQndrPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    key: ""
  discovery:
    enabled: true
    registries:
      kubernetes:
        disabled: true
      service: {}
```

### controlplane.yaml (infra/talos/config/simple/controlplane.yaml)

```yaml
version: v1alpha1 # Indicates the schema used to decode the contents.
debug: false # Enable verbose logging to the console.
persist: true
# Provides machine specific configuration options.
machine:
    type: controlplane # Defines the role of the machine within the cluster.
    token: qt315g.8f9e1kb2r4p79efs # The `token` is used by a machine to join the PKI of the cluster.
    # The root certificate authority of the PKI.
    ca:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJQakNCOGFBREFnRUNBaEJ2TFQ0dzN2cnp1NE50UUUrcDZGeVhNQVVHQXl0bGNEQVFNUTR3REFZRFZRUUsKRXdWMFlXeHZjekFlRncweU5UQTJNekF5TXpBeE1UZGFGdzB6TlRBMk1qZ3lNekF4TVRkYU1CQXhEakFNQmdOVgpCQW9UQlhSaGJHOXpNQ293QlFZREsyVndBeUVBckNVc2YxeGZxenhwWnpFSFRsQXVCSllLSTh5UVpnS0RwZEJyCkFPY1JRZ2lqWVRCZk1BNEdBMVVkRHdFQi93UUVBd0lDaERBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUkKS3dZQkJRVUhBd0l3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVa1pBa2xPcVM2YnNmYjROdAo3ekNJTUR5cXVETXdCUVlESzJWd0EwRUFlbXJHVlpDa3RKeXRpdmJZNjV1TFJDODVFUThpbFpsOVd0WHpldjM3CmdjR1lpVkFzT1pDdzRXV21GMld6SWgrOVlGT1F3ZEZJblRSOFJIak93RHZIQ3c9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0KTUM0Q0FRQXdCUVlESzJWd0JDSUVJSjQrNGQyM2lNSTlHdlNZNnl2VU1xdjhqQlQyLzZGRGwrMTZaZHB6RHVRaAotLS0tLUVORCBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0K
    # Extra certificate subject alternative names for the machine's certificate.
    certSANs: []
    #   # Uncomment this to enable SANs.
    #   - 10.0.0.10
    #   - 172.16.0.10
    #   - 192.168.0.10

    # Used to provide additional options to the kubelet.
    kubelet:
        image: ghcr.io/siderolabs/kubelet:v1.33.1 # The `image` field is an optional reference to an alternative kubelet image.
        defaultRuntimeSeccompProfileEnabled: true # Enable container runtime default Seccomp profile.
        disableManifestsDirectory: true # The `disableManifestsDirectory` field configures the kubelet to get static pod manifests from the /etc/kubernetes/manifests directory.
        
        # # The `ClusterDNS` field is an optional reference to an alternative kubelet clusterDNS ip list.
        # clusterDNS:
        #     - 10.96.0.10
        #     - 169.254.2.53

        # # The `extraArgs` field is used to provide additional flags to the kubelet.
        # extraArgs:
        #     key: value

        # # The `extraMounts` field is used to add additional mounts to the kubelet container.
        # extraMounts:
        #     - destination: /var/lib/example # Destination is the absolute path where the mount will be placed in the container.
        #       type: bind # Type specifies the mount kind.
        #       source: /var/lib/example # Source specifies the source path of the mount.
        #       # Options are fstab style mount options.
        #       options:
        #         - bind
        #         - rshared
        #         - rw

        # # The `extraConfig` field is used to provide kubelet configuration overrides.
        # extraConfig:
        #     serverTLSBootstrap: true

        # # The `KubeletCredentialProviderConfig` field is used to provide kubelet credential configuration.
        # credentialProviderConfig:
        #     apiVersion: kubelet.config.k8s.io/v1
        #     kind: CredentialProviderConfig
        #     providers:
        #         - apiVersion: credentialprovider.kubelet.k8s.io/v1
        #           defaultCacheDuration: 12h
        #           matchImages:
        #             - '*.dkr.ecr.*.amazonaws.com'
        #             - '*.dkr.ecr.*.amazonaws.com.cn'
        #             - '*.dkr.ecr-fips.*.amazonaws.com'
        #             - '*.dkr.ecr.us-iso-east-1.c2s.ic.gov'
        #             - '*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov'
        #           name: ecr-credential-provider

        # # The `nodeIP` field is used to configure `--node-ip` flag for the kubelet.
        # nodeIP:
        #     # The `validSubnets` field configures the networks to pick kubelet node IP from.
        #     validSubnets:
        #         - 10.0.0.0/8
        #         - '!10.0.0.3/32'
        #         - fdc7::/16
    # Provides machine specific network configuration options.
    network: {}
    # # `interfaces` is used to define the network interface configuration.
    # interfaces:
    #     - interface: enp0s1 # The interface name.
    #       # Assigns static IP addresses to the interface.
    #       addresses:
    #         - 192.168.2.0/24
    #       # A list of routes associated with the interface.
    #       routes:
    #         - network: 0.0.0.0/0 # The route's network (destination).
    #           gateway: 192.168.2.1 # The route's gateway (if empty, creates link scope route).
    #           metric: 1024 # The optional metric for the route.
    #       mtu: 1500 # The interface's MTU.
    #       
    #       # # Picks a network device using the selector.

    #       # # select a device with bus prefix 00:*.
    #       # deviceSelector:
    #       #     busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       # # select a device with mac address matching `*:f0:ab` and `virtio` kernel driver.
    #       # deviceSelector:
    #       #     hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #     driver: virtio_net # Kernel driver, supports matching by wildcard.
    #       # # select a device with bus prefix 00:*, a device with mac address matching `*:f0:ab` and `virtio` kernel driver.
    #       # deviceSelector:
    #       #     - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       #     - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #       driver: virtio_net # Kernel driver, supports matching by wildcard.

    #       # # Bond specific options.
    #       # bond:
    #       #     # The interfaces that make up the bond.
    #       #     interfaces:
    #       #         - enp2s0
    #       #         - enp2s1
    #       #     # Picks a network device using the selector.
    #       #     deviceSelectors:
    #       #         - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       #         - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #           driver: virtio_net # Kernel driver, supports matching by wildcard.
    #       #     mode: 802.3ad # A bond option.
    #       #     lacpRate: fast # A bond option.

    #       # # Bridge specific options.
    #       # bridge:
    #       #     # The interfaces that make up the bridge.
    #       #     interfaces:
    #       #         - enxda4042ca9a51
    #       #         - enxae2a6774c259
    #       #     # Enable STP on this bridge.
    #       #     stp:
    #       #         enabled: true # Whether Spanning Tree Protocol (STP) is enabled.

    #       # # Configure this device as a bridge port.
    #       # bridgePort:
    #       #     master: br0 # The name of the bridge master interface

    #       # # Indicates if DHCP should be used to configure the interface.
    #       # dhcp: true

    #       # # DHCP specific options.
    #       # dhcpOptions:
    #       #     routeMetric: 1024 # The priority of all routes received via DHCP.

    #       # # Wireguard specific configuration.

    #       # # wireguard server example
    #       # wireguard:
    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).
    #       #     listenPort: 51111 # Specifies a device's listening port.
    #       #     # Specifies a list of peer configurations to apply to a device.
    #       #     peers:
    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.
    #       #           endpoint: 192.168.1.3 # Specifies the endpoint of this peer entry.
    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.
    #       #           allowedIPs:
    #       #             - 192.168.1.0/24
    #       # # wireguard peer example
    #       # wireguard:
    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).
    #       #     # Specifies a list of peer configurations to apply to a device.
    #       #     peers:
    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.
    #       #           endpoint: 192.168.1.2:51822 # Specifies the endpoint of this peer entry.
    #       #           persistentKeepaliveInterval: 10s # Specifies the persistent keepalive interval for this peer.
    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.
    #       #           allowedIPs:
    #       #             - 192.168.1.0/24

    #       # # Virtual (shared) IP address configuration.

    #       # # layer2 vip example
    #       # vip:
    #       #     ip: 172.16.199.55 # Specifies the IP address to be used.

    # # Used to statically set the nameservers for the machine.
    # nameservers:
    #     - 8.8.8.8
    #     - 1.1.1.1

    # # Used to statically set arbitrary search domains.
    # searchDomains:
    #     - example.org
    #     - example.com

    # # Allows for extra entries to be added to the `/etc/hosts` file
    # extraHostEntries:
    #     - ip: 192.168.1.100 # The IP of the host.
    #       # The host alias.
    #       aliases:
    #         - example
    #         - example.domain.tld

    # # Configures KubeSpan feature.
    # kubespan:
    #     enabled: true # Enable the KubeSpan feature.

    # Used to provide instructions for installations.
    install:
        disk: /dev/sda # The disk used for installations.
        image: ghcr.io/siderolabs/installer:v1.10.4 # Allows for supplying the image used to perform the installation.
        wipe: false # Indicates if the installation disk should be wiped at installation time.
        
        # # Look up disk using disk attributes like model, size, serial and others.
        # diskSelector:
        #     size: 4GB # Disk size.
        #     model: WDC* # Disk model `/sys/block/<dev>/device/model`.
        #     busPath: /pci0000:00/0000:00:17.0/ata1/host0/target0:0:0/0:0:0:0 # Disk bus path.

        # # Allows for supplying extra kernel args via the bootloader.
        # extraKernelArgs:
        #     - talos.platform=metal
        #     - reboot=k
    # Used to configure the machine's container image registry mirrors.
    registries: {}
    # # Specifies mirror configuration for each registry host namespace.
    # mirrors:
    #     ghcr.io:
    #         # List of endpoints (URLs) for registry mirrors to use.
    #         endpoints:
    #             - https://registry.insecure
    #             - https://ghcr.io/v2/

    # # Specifies TLS & auth configuration for HTTPS image registries.
    # config:
    #     registry.insecure:
    #         # The TLS configuration for the registry.
    #         tls:
    #             insecureSkipVerify: true # Skip TLS server certificate verification (not recommended).
    #             
    #             # # Enable mutual TLS authentication with the registry.
    #             # clientIdentity:
    #             #     crt: LS0tIEVYQU1QTEUgQ0VSVElGSUNBVEUgLS0t
    #             #     key: LS0tIEVYQU1QTEUgS0VZIC0tLQ==
    #         
    #         # # The auth configuration for this registry.
    #         # auth:
    #         #     username: username # Optional registry authentication.
    #         #     password: password # Optional registry authentication.

    # Features describe individual Talos features that can be switched on or off.
    features:
        rbac: true # Enable role-based access control (RBAC).
        stableHostname: true # Enable stable default hostname.
        apidCheckExtKeyUsage: true # Enable checks for extended key usage of client certificates in apid.
        diskQuotaSupport: true # Enable XFS project quota support for EPHEMERAL partition and user disks.
        # KubePrism - local proxy/load balancer on defined port that will distribute
        kubePrism:
            enabled: true # Enable KubePrism support - will start local load balancing proxy.
            port: 7445 # KubePrism port.
        # Configures host DNS caching resolver.
        hostDNS:
            enabled: true # Enable host DNS caching resolver.
            forwardKubeDNSToHost: true # Use the host DNS resolver as upstream for Kubernetes CoreDNS pods.
        
        # # Configure Talos API access from Kubernetes pods.
        # kubernetesTalosAPIAccess:
        #     enabled: true # Enable Talos API access from Kubernetes pods.
        #     # The list of Talos API roles which can be granted for access from Kubernetes pods.
        #     allowedRoles:
        #         - os:reader
        #     # The list of Kubernetes namespaces Talos API access is available from.
        #     allowedKubernetesNamespaces:
        #         - kube-system
    # Configures the node labels for the machine.
    nodeLabels:
        node.kubernetes.io/exclude-from-external-load-balancers: ""
    
    # # Provides machine specific control plane configuration options.

    # # ControlPlane definition example.
    # controlPlane:
    #     # Controller manager machine specific configuration options.
    #     controllerManager:
    #         disabled: false # Disable kube-controller-manager on the node.
    #     # Scheduler machine specific configuration options.
    #     scheduler:
    #         disabled: true # Disable kube-scheduler on the node.

    # # Used to provide static pod definitions to be run by the kubelet directly bypassing the kube-apiserver.

    # # nginx static pod.
    # pods:
    #     - apiVersion: v1
    #       kind: pod
    #       metadata:
    #         name: nginx
    #       spec:
    #         containers:
    #             - image: nginx
    #               name: nginx

    # # Allows the addition of user specified files.

    # # MachineFiles usage example.
    # files:
    #     - content: '...' # The contents of the file.
    #       permissions: 0o666 # The file's permissions in octal.
    #       path: /tmp/file.txt # The path of the file.
    #       op: append # The operation to use

    # # The `env` field allows for the addition of environment variables.

    # # Environment variables definition examples.
    # env:
    #     GRPC_GO_LOG_SEVERITY_LEVEL: info
    #     GRPC_GO_LOG_VERBOSITY_LEVEL: "99"
    #     https_proxy: http://SERVER:PORT/
    # env:
    #     GRPC_GO_LOG_SEVERITY_LEVEL: error
    #     https_proxy: https://USERNAME:PASSWORD@SERVER:PORT/
    # env:
    #     https_proxy: http://DOMAIN\USERNAME:PASSWORD@SERVER:PORT/

    # # Used to configure the machine's time settings.

    # # Example configuration for cloudflare ntp server.
    # time:
    #     disabled: false # Indicates if the time service is disabled for the machine.
    #     # description: |
    #     servers:
    #         - time.cloudflare.com
    #     bootTimeout: 2m0s # Specifies the timeout when the node time is considered to be in sync unlocking the boot sequence.

    # # Used to configure the machine's sysctls.

    # # MachineSysctls usage example.
    # sysctls:
    #     kernel.domainname: talos.dev
    #     net.ipv4.ip_forward: "0"
    #     net/ipv6/conf/eth0.100/disable_ipv6: "1"

    # # Used to configure the machine's sysfs.

    # # MachineSysfs usage example.
    # sysfs:
    #     devices.system.cpu.cpu0.cpufreq.scaling_governor: performance

    # # Machine system disk encryption configuration.
    # systemDiskEncryption:
    #     # Ephemeral partition encryption.
    #     ephemeral:
    #         provider: luks2 # Encryption provider to use for the encryption.
    #         # Defines the encryption keys generation and storage method.
    #         keys:
    #             - # Deterministically generated key from the node UUID and PartitionLabel.
    #               nodeID: {}
    #               slot: 0 # Key slot number for LUKS2 encryption.
    #               
    #               # # KMS managed encryption key.
    #               # kms:
    #               #     endpoint: https://192.168.88.21:4443 # KMS endpoint to Seal/Unseal the key.
    #         
    #         # # Cipher kind to use for the encryption. Depends on the encryption provider.
    #         # cipher: aes-xts-plain64

    #         # # Defines the encryption sector size.
    #         # blockSize: 4096

    #         # # Additional --perf parameters for the LUKS2 encryption.
    #         # options:
    #         #     - no_read_workqueue
    #         #     - no_write_workqueue

    # # Configures the udev system.
    # udev:
    #     # List of udev rules to apply to the udev system
    #     rules:
    #         - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"

    # # Configures the logging system.
    # logging:
    #     # Logging destination.
    #     destinations:
    #         - endpoint: tcp://1.2.3.4:12345 # Where to send logs. Supported protocols are "tcp" and "udp".
    #           format: json_lines # Logs format.

    # # Configures the kernel.
    # kernel:
    #     # Kernel modules to load.
    #     modules:
    #         - name: brtfs # Module name.

    # # Configures the seccomp profiles for the machine.
    # seccompProfiles:
    #     - name: audit.json # The `name` field is used to provide the file name of the seccomp profile.
    #       # The `value` field is used to provide the seccomp profile.
    #       value:
    #         defaultAction: SCMP_ACT_LOG

    # # Override (patch) settings in the default OCI runtime spec for CRI containers.

    # # override default open file limit
    # baseRuntimeSpecOverrides:
    #     process:
    #         rlimits:
    #             - hard: 1024
    #               soft: 1024
    #               type: RLIMIT_NOFILE

    # # Configures the node annotations for the machine.

    # # node annotations example.
    # nodeAnnotations:
    #     customer.io/rack: r13a25

    # # Configures the node taints for the machine. Effect is optional.

    # # node taints example.
    # nodeTaints:
    #     exampleTaint: exampleTaintValue:NoSchedule
# Provides cluster specific configuration options.
cluster:
    id: wcWr92csTh7HmKPHHX1rKIQn2mHHS7dHYNXdAUZ5NXY= # Globally unique identifier for this cluster (base64 encoded random 32 bytes).
    secret: UPKt0QVDtJGdy3SVFCfGVJ6NV5/dSHCL9SFx1VweX7k= # Shared secret of cluster (base64 encoded random 32 bytes).
    # Provides control plane specific configuration options.
    controlPlane:
        endpoint: https://192.168.1.77:6443 # Endpoint is the canonical controlplane endpoint, which can be an IP address or a DNS hostname.
    clusterName: simple-cluster # Configures the cluster's name.
    # Provides cluster specific network configuration options.
    network:
        dnsDomain: cluster.local # The domain used by Kubernetes DNS.
        # The pod subnet CIDR.
        podSubnets:
            - 10.244.0.0/16
        # The service subnet CIDR.
        serviceSubnets:
            - 10.96.0.0/12
        
        # # The CNI used.
        # cni:
        #     name: custom # Name of CNI to use.
        #     # URLs containing manifests to apply for the CNI.
        #     urls:
        #         - https://docs.projectcalico.org/archive/v3.20/manifests/canal.yaml
    token: 9c3zc1.fj82jlf3xfqwz8kf # The [bootstrap token](https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/) used to join the cluster.
    secretboxEncryptionSecret: vjL8HJNiPgQy+MQeayXUvsJG+CPUUsxqb8klUinVoa0= # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).
    # The base64 encoded root certificate authority used by Kubernetes.
    ca:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpakNDQVRDZ0F3SUJBZ0lSQU1PQnFOeTV2V1FWN20vK2pBSHh0amd3Q2dZSUtvWkl6ajBFQXdJd0ZURVQKTUJFR0ExVUVDaE1LYTNWaVpYSnVaWFJsY3pBZUZ3MHlOVEEyTXpBeU16QXhNVGRhRncwek5UQTJNamd5TXpBeApNVGRhTUJVeEV6QVJCZ05WQkFvVENtdDFZbVZ5Ym1WMFpYTXdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CCkJ3TkNBQVFmTGJ2S25LUEZWb1lMRFduM1phY2ZidGhzU1JxRGJvVDgrY1YrdEFWTUs5L1lNSUNlQStaMUxERVkKVVJUK092enB0RWtQWVpiendCM0NxY09KQ3Z1cW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXdIUVlEVlIwbApCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPCkJCWUVGSHgzNitwNkpzNEN6dEZUL25hVHdyQXFsSVVzTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDSUVnUUJUdjkKK0c4MmhYdHUzRHpUemdtN3RpblhLcXhzbzZNQnVFWTFDeGdRQWlFQXVlWHBaeWRnNi9QdEovaHlZbjNsQ0xpSAppbTVLMHBGS0RlQWtVaG5DQndrPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUFzc0xTT1R6bTFpMkl5bVllM0R4YXdHU1lYcWpQd3JqZzk4dDcvOUExTi9vQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFSHkyN3lweWp4VmFHQ3cxcDkyV25IMjdZYkVrYWcyNkUvUG5GZnJRRlRDdmYyRENBbmdQbQpkU3d4R0ZFVS9qcjg2YlJKRDJHVzg4QWR3cW5EaVFyN3FnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # The base64 encoded aggregator certificate authority used by Kubernetes for front-proxy certificate generation.
    aggregatorCA:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJZRENDQVFhZ0F3SUJBZ0lSQU1ZQmp3R2lFVXI1bmx4VVN6Z25kNWd3Q2dZSUtvWkl6ajBFQXdJd0FEQWUKRncweU5UQTJNekF5TXpBeE1UZGFGdzB6TlRBMk1qZ3lNekF4TVRkYU1BQXdXVEFUQmdjcWhrak9QUUlCQmdncQpoa2pPUFFNQkJ3TkNBQVRMejJMUHhnNWpQME9yMUlHZHF0eFVtd2JMeWU4dUxDNlkxU0h3bEs3MXJiTit4ZytkCmFVcE9oNWJxckhad0J5cFJrNGRNMzI5YjNQUjI1MHVRRGVKWW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXcKSFFZRFZSMGxCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4dwpIUVlEVlIwT0JCWUVGR0ZnUmFCd2pST1hsbGtrNFpDWWpERTlQWm5FTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDCklRRFBRbldTVlJLU2pzcEcwcVJxSzNBK2R4OWliVjdTV1VWVTEvRlhGc0ZUSndJZ0FqSWtITnVsdWo2T2NtYjIKYXNLaElZUmpsZGE4YXBCazN2RTRsZEIrdmk0PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUdYZ2kxdlhLMmpITVZjdlQ3a2tVWTQ1K3JVeCs1VzB1NTl3YXc5SVBVcy9vQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFeTg5aXo4WU9ZejlEcTlTQm5hcmNWSnNHeThudkxpd3VtTlVoOEpTdTlhMnpmc1lQbldsSwpUb2VXNnF4MmNBY3FVWk9IVE45dlc5ejBkdWRMa0EzaVdBPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # The base64 encoded private key for service account token generation.
    serviceAccount:
        key: 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
    # API server specific configuration options.
    apiServer:
        image: registry.k8s.io/kube-apiserver:v1.33.1 # The container image used in the API server manifest.
        # Extra certificate subject alternative names for the API server's certificate.
        certSANs:
            - 192.168.1.77
        disablePodSecurityPolicy: true # Disable PodSecurityPolicy in the API server and default manifests.
        # Configure the API server admission plugins.
        admissionControl:
            - name: PodSecurity # Name is the name of the admission controller.
              # Configuration is an embedded configuration object to be used as the plugin's
              configuration:
                apiVersion: pod-security.admission.config.k8s.io/v1alpha1
                defaults:
                    audit: restricted
                    audit-version: latest
                    enforce: baseline
                    enforce-version: latest
                    warn: restricted
                    warn-version: latest
                exemptions:
                    namespaces:
                        - kube-system
                    runtimeClasses: []
                    usernames: []
                kind: PodSecurityConfiguration
        # Configure the API server audit policy.
        auditPolicy:
            apiVersion: audit.k8s.io/v1
            kind: Policy
            rules:
                - level: Metadata
        
        # # Configure the API server authorization config. Node and RBAC authorizers are always added irrespective of the configuration.
        # authorizationConfig:
        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.
        #       name: webhook # Name is used to describe the authorizer.
        #       # webhook is the configuration for the webhook authorizer.
        #       webhook:
        #         connectionInfo:
        #             type: InClusterConfig
        #         failurePolicy: Deny
        #         matchConditionSubjectAccessReviewVersion: v1
        #         matchConditions:
        #             - expression: has(request.resourceAttributes)
        #             - expression: '!(\''system:serviceaccounts:kube-system\'' in request.groups)'
        #         subjectAccessReviewVersion: v1
        #         timeout: 3s
        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.
        #       name: in-cluster-authorizer # Name is used to describe the authorizer.
        #       # webhook is the configuration for the webhook authorizer.
        #       webhook:
        #         connectionInfo:
        #             type: InClusterConfig
        #         failurePolicy: NoOpinion
        #         matchConditionSubjectAccessReviewVersion: v1
        #         subjectAccessReviewVersion: v1
        #         timeout: 3s
    # Controller manager server specific configuration options.
    controllerManager:
        image: registry.k8s.io/kube-controller-manager:v1.33.1 # The container image used in the controller manager manifest.
    # Kube-proxy server-specific configuration options
    proxy:
        image: registry.k8s.io/kube-proxy:v1.33.1 # The container image used in the kube-proxy manifest.
        
        # # Disable kube-proxy deployment on cluster bootstrap.
        # disabled: false
    # Scheduler server specific configuration options.
    scheduler:
        image: registry.k8s.io/kube-scheduler:v1.33.1 # The container image used in the scheduler manifest.
    # Configures cluster member discovery.
    discovery:
        enabled: true # Enable the cluster membership discovery feature.
        # Configure registries used for cluster member discovery.
        registries:
            # Kubernetes registry uses Kubernetes API server to discover cluster members and stores additional information
            kubernetes:
                disabled: true # Disable Kubernetes discovery registry.
            # Service registry is using an external service to push and pull information about cluster members.
            service: {}
            # # External service endpoint.
            # endpoint: https://discovery.talos.dev/
    # Etcd specific configuration options.
    etcd:
        # The `ca` is the root certificate authority of the PKI.
        ca:
            crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJmVENDQVNTZ0F3SUJBZ0lSQU9qMVg0SEFzZnhrQlZybGdzUm9lTDR3Q2dZSUtvWkl6ajBFQXdJd0R6RU4KTUFzR0ExVUVDaE1FWlhSalpEQWVGdzB5TlRBMk16QXlNekF4TVRkYUZ3MHpOVEEyTWpneU16QXhNVGRhTUE4eApEVEFMQmdOVkJBb1RCR1YwWTJRd1dUQVRCZ2NxaGtqT1BRSUJCZ2dxaGtqT1BRTUJCd05DQUFUMytZdy9NVmwyCnFhQmN3OWFIaDI3M3lIZXdCNU9ramZyNWZMZGtoa2w0TDk0c0Rvem5uUGpXeW1USXhpckhZU3FZTTJSL1FaM1IKZEVzL3ZjMTlTNFJ5bzJFd1h6QU9CZ05WSFE4QkFmOEVCQU1DQW9Rd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSApBd0VHQ0NzR0FRVUZCd01DTUE4R0ExVWRFd0VCL3dRRk1BTUJBZjh3SFFZRFZSME9CQllFRkxGaHRFWitkMWxtCkhKaENYSWtEaGpYWW5UQldNQW9HQ0NxR1NNNDlCQU1DQTBjQU1FUUNJRWVsRXE4R25IMm9KcWNpMTl3NHN2OVAKYUNHNDZJdVVweGZTNW1kM1g0aXFBaUJXU3Z4RzYrTEtNSnREL3owVlYzeDlvM0l5enFCNFJPZm1aYSt1S3VUNQppUT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
            key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUlNYnd0T1VBMmpuR3UxUUxraDJwS0dZSm02VHBzRkhNZGw0VXFkaUx0VVJvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFOS9tTVB6RlpkcW1nWE1QV2g0ZHU5OGgzc0FlVHBJMzYrWHkzWklaSmVDL2VMQTZNNTV6NAoxc3BreU1ZcXgyRXFtRE5rZjBHZDBYUkxQNzNOZlV1RWNnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
        
        # # The container image used to create the etcd service.
        # image: gcr.io/etcd-development/etcd:v3.5.21

        # # The `advertisedSubnets` field configures the networks to pick etcd advertised IP from.
        # advertisedSubnets:
        #     - 10.0.0.0/8
    # A list of urls that point to additional manifests.
    extraManifests: []
    #   - https://www.example.com/manifest1.yaml
    #   - https://www.example.com/manifest2.yaml

    # A list of inline Kubernetes manifests.
    inlineManifests: []
    #   - name: namespace-ci # Name of the manifest.
    #     contents: |- # Manifest contents as a string.
    #       apiVersion: v1
    #       kind: Namespace
    #       metadata:
    #       	name: ci

    
    # # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).

    # # Decryption secret example (do not use in production!).
    # aescbcEncryptionSecret: z01mye6j16bspJYtTB/5SFX8j7Ph4JXxM2Xuu4vsBPM=

    # # Core DNS specific configuration options.
    # coreDNS:
    #     image: registry.k8s.io/coredns/coredns:v1.12.1 # The `image` field is an override to the default coredns image.

    # # External cloud provider configuration.
    # externalCloudProvider:
    #     enabled: true # Enable external cloud provider.
    #     # A list of urls that point to additional manifests for an external cloud provider.
    #     manifests:
    #         - https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/v1.20.0-alpha.0/manifests/rbac.yaml
    #         - https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/v1.20.0-alpha.0/manifests/aws-cloud-controller-manager-daemonset.yaml

    # # A map of key value pairs that will be added while fetching the extraManifests.
    # extraManifestHeaders:
    #     Token: "1234567"
    #     X-ExtraInfo: info

    # # Settings for admin kubeconfig generation.
    # adminKubeconfig:
    #     certLifetime: 1h0m0s # Admin kubeconfig certificate lifetime (default is 1 year).

    # # Allows running workload on control-plane nodes.
    # allowSchedulingOnControlPlanes: true

```

### platform-crds.yaml (infra/charts/orchestrator/crds/platform-crds.yaml)

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: coderuns.orchestrator.platform
spec:
  group: orchestrator.platform
  scope: Namespaced
  names:
    plural: coderuns
    singular: coderun
    kind: CodeRun
    shortNames:
    - cr
  versions:
  - name: v1
    served: true
    storage: true
    subresources:
      status: {}
    additionalPrinterColumns:
    - name: Task
      type: integer
      jsonPath: .spec.taskId
    - name: Service
      type: string
      jsonPath: .spec.service
    - name: Model
      type: string
      jsonPath: .spec.model
    - name: Phase
      type: string
      jsonPath: .status.phase
    - name: Age
      type: date
      jsonPath: .metadata.creationTimestamp
    schema:
      openAPIV3Schema:
        type: object
        required: ["spec"]
        properties:
          spec:
            type: object
            required: ["taskId", "service", "repositoryUrl", "docsRepositoryUrl", "workingDirectory", "model", "githubUser"]
            properties:
              taskId:
                type: integer
                description: "Task ID to implement"
              service:
                type: string
                description: "Target service name"
              repositoryUrl:
                type: string
                description: "Target project repository URL (where implementation work happens)"
              docsRepositoryUrl:
                type: string
                description: "Documentation repository URL (where Task Master definitions come from)"
              docsProjectDirectory:
                type: string
                description: "Project directory within docs repository (e.g. '_projects/simple-api')"
              docsBranch:
                type: string
                default: "main"
                description: "Docs branch to use (e.g., 'main', 'feature/branch')"
              workingDirectory:
                type: string
                description: "Working directory within target repository (defaults to service name if not specified)"
              model:
                type: string
                description: "Claude model to use (full model name like 'claude-3-5-sonnet-20241022')"
              githubUser:
                type: string
                description: "GitHub username for authentication and commits"
              localTools:
                type: string
                description: "Local MCP tools/servers to enable (comma-separated)"
              remoteTools:
                type: string
                description: "Remote MCP tools/servers to enable (comma-separated)"
              contextVersion:
                type: integer
                default: 1
                description: "Context version for retry attempts (incremented on each retry)"
              promptModification:
                type: string
                description: "Additional context for retry attempts"
              continueSession:
                type: boolean
                default: false
                description: "Whether to continue a previous session"
              overwriteMemory:
                type: boolean
                default: false
                description: "Whether to overwrite memory before starting"
              env:
                type: object
                additionalProperties:
                  type: string
                description: "Environment variables to set in the container"
              envFromSecrets:
                type: array
                items:
                  type: object
                  properties:
                    name:
                      type: string
                      description: "Name of the environment variable"
                    secretName:
                      type: string
                      description: "Name of the secret"
                    secretKey:
                      type: string
                      description: "Key within the secret"
                  required:
                    - name
                    - secretName
                    - secretKey
                description: "Environment variables from secrets"
          status:
            type: object
            properties:
              phase:
                type: string
                description: "Current phase of the code implementation"
              message:
                type: string
                description: "Human-readable message about the current state"
              lastUpdate:
                type: string
                description: "Timestamp when this phase was reached"
              jobName:
                type: string
                description: "Associated Kubernetes Job name"
              pullRequestUrl:
                type: string
                description: "Pull request URL if created"
              retryCount:
                type: integer
                description: "Current retry attempt (if applicable)"
              conditions:
                type: array
                description: "Conditions for the CodeRun"
                items:
                  type: object
                  required: ["type", "status"]
                  properties:
                    type:
                      type: string
                      description: "Type of condition"
                    status:
                      type: string
                      description: "Status of the condition (True, False, or Unknown)"
                    lastTransitionTime:
                      type: string
                      description: "Last time the condition transitioned (RFC3339 format)"
                    reason:
                      type: string
                      description: "Reason for the condition's last transition"
                    message:
                      type: string
                      description: "Human-readable message about the condition"
              configmapName:
                type: string
                description: "Name of the ConfigMap containing the prompt and context"
              contextVersion:
                type: integer
                description: "Version of the context and prompt used"
              promptModification:
                type: string
                description: "Modification to the prompt if any"
              promptMode:
                type: string
                description: "Mode of prompt (e.g., direct, indirect)"
              sessionId:
                type: string
                description: "Session ID for tracking"
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: docsruns.orchestrator.platform
spec:
  group: orchestrator.platform
  scope: Namespaced
  names:
    plural: docsruns
    singular: docsrun
    kind: DocsRun
    shortNames:
    - dr
  versions:
  - name: v1
    served: true
    storage: true
    subresources:
      status: {}
    additionalPrinterColumns:
    - name: Phase
      type: string
      jsonPath: .status.phase
    - name: Age
      type: date
      jsonPath: .metadata.creationTimestamp
    schema:
      openAPIV3Schema:
        type: object
        required: ["spec"]
        properties:
          spec:
            type: object
            required: ["repositoryUrl", "workingDirectory", "sourceBranch", "model", "githubUser"]
            properties:
              repositoryUrl:
                type: string
                description: "Repository URL for documentation generation"
              workingDirectory:
                type: string
                description: "Working directory within repository"
              sourceBranch:
                type: string
                description: "Source branch to analyze"
              model:
                type: string
                description: "Claude model to use (full model name like 'claude-3-5-sonnet-20241022')"
              githubUser:
                type: string
                description: "GitHub username for authentication and commits"
          status:
            type: object
            properties:
              phase:
                type: string
                description: "Current phase of the documentation generation"
              message:
                type: string
                description: "Human-readable message about the current state"
              lastUpdate:
                type: string
                description: "Timestamp when this phase was reached"
              jobName:
                type: string
                description: "Associated Kubernetes Job name"
              pullRequestUrl:
                type: string
                description: "Pull request URL if created"
              conditions:
                type: array
                description: "Conditions for the DocsRun"
                items:
                  type: object
                  required: ["type", "status"]
                  properties:
                    type:
                      type: string
                      description: "Type of condition"
                    status:
                      type: string
                      description: "Status of the condition (True, False, or Unknown)"
                    lastTransitionTime:
                      type: string
                      description: "Last time the condition transitioned (RFC3339 format)"
                    reason:
                      type: string
                      description: "Reason for the condition's last transition"
                    message:
                      type: string
                      description: "Human-readable message about the condition"
              configmapName:
                type: string
                description: "Name of the ConfigMap containing the prompt and context"
```

### coderun-crd.yaml (infra/charts/orchestrator/crds/coderun-crd.yaml)

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: coderuns.orchestrator.platform
spec:
  group: orchestrator.platform
  scope: Namespaced
  names:
    plural: coderuns
    singular: coderun
    kind: CodeRun
    shortNames:
    - cr
  versions:
  - name: v1
    served: true
    storage: true
    subresources:
      status: {}
    additionalPrinterColumns:
    - name: Task
      type: integer
      jsonPath: .spec.taskId
    - name: Service
      type: string
      jsonPath: .spec.service
    - name: Model
      type: string
      jsonPath: .spec.model
    - name: Phase
      type: string
      jsonPath: .status.phase
    - name: Age
      type: date
      jsonPath: .metadata.creationTimestamp
    schema:
      openAPIV3Schema:
        type: object
        required: ["spec"]
        properties:
          spec:
            type: object
            required: ["taskId", "service", "repositoryUrl", "docsRepositoryUrl", "workingDirectory", "model", "githubUser"]
            properties:
              taskId:
                type: integer
                description: "Task ID to implement"
              service:
                type: string
                description: "Target service name"
              repositoryUrl:
                type: string
                description: "Target project repository URL (where implementation work happens)"
              docsRepositoryUrl:
                type: string
                description: "Documentation repository URL (where Task Master definitions come from)"
              docsProjectDirectory:
                type: string
                description: "Project directory within docs repository (e.g. '_projects/simple-api')"
              docsBranch:
                type: string
                default: "main"
                description: "Docs branch to use (e.g., 'main', 'feature/branch')"
              workingDirectory:
                type: string
                description: "Working directory within target repository (defaults to service name if not specified)"
              model:
                type: string
                description: "Claude model to use (full model name like 'claude-3-5-sonnet-20241022')"
              githubUser:
                type: string
                description: "GitHub username for authentication and commits"
              localTools:
                type: string
                description: "Local MCP tools/servers to enable (comma-separated)"
              remoteTools:
                type: string
                description: "Remote MCP tools/servers to enable (comma-separated)"
              contextVersion:
                type: integer
                default: 1
                description: "Context version for retry attempts (incremented on each retry)"
              promptModification:
                type: string
                description: "Additional context for retry attempts"
              continueSession:
                type: boolean
                default: false
                description: "Whether to continue a previous session"
              overwriteMemory:
                type: boolean
                default: false
                description: "Whether to overwrite memory before starting"
              env:
                type: object
                additionalProperties:
                  type: string
                description: "Environment variables to set in the container"
              envFromSecrets:
                type: array
                items:
                  type: object
                  properties:
                    name:
                      type: string
                      description: "Name of the environment variable"
                    secretName:
                      type: string
                      description: "Name of the secret"
                    secretKey:
                      type: string
                      description: "Key within the secret"
                  required:
                    - name
                    - secretName
                    - secretKey
                description: "Environment variables from secrets"
          status:
            type: object
            properties:
              phase:
                type: string
                description: "Current phase of the code implementation"
              message:
                type: string
                description: "Human-readable message about the current state"
              lastUpdate:
                type: string
                description: "Timestamp when this phase was reached"
              jobName:
                type: string
                description: "Associated Kubernetes Job name"
              pullRequestUrl:
                type: string
                description: "Pull request URL if created"
              retryCount:
                type: integer
                description: "Current retry attempt (if applicable)"
              conditions:
                type: array
                description: "Conditions for the CodeRun"
                items:
                  type: object
                  required: ["type", "status"]
                  properties:
                    type:
                      type: string
                      description: "Type of condition"
                    status:
                      type: string
                      description: "Status of the condition (True, False, or Unknown)"
                    lastTransitionTime:
                      type: string
                      description: "Last time the condition transitioned (RFC3339 format)"
                    reason:
                      type: string
                      description: "Reason for the condition's last transition"
                    message:
                      type: string
                      description: "Human-readable message about the condition"
              configmapName:
                type: string
                description: "Name of the ConfigMap containing the prompt and context"
              contextVersion:
                type: integer
                description: "Version of the context and prompt used"
              promptModification:
                type: string
                description: "Modification to the prompt if any"
              promptMode:
                type: string
                description: "Mode of prompt (e.g., direct, indirect)"
              sessionId:
                type: string
                description: "Session ID for tracking"
```

### docsrun-crd.yaml (infra/charts/orchestrator/crds/docsrun-crd.yaml)

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: docsruns.orchestrator.platform
spec:
  group: orchestrator.platform
  scope: Namespaced
  names:
    plural: docsruns
    singular: docsrun
    kind: DocsRun
    shortNames:
    - dr
  versions:
  - name: v1
    served: true
    storage: true
    subresources:
      status: {}
    additionalPrinterColumns:
    - name: Phase
      type: string
      jsonPath: .status.phase
    - name: Age
      type: date
      jsonPath: .metadata.creationTimestamp
    schema:
      openAPIV3Schema:
        type: object
        required: ["spec"]
        properties:
          spec:
            type: object
            required: ["repositoryUrl", "workingDirectory", "sourceBranch", "model", "githubUser"]
            properties:
              repositoryUrl:
                type: string
                description: "Repository URL for documentation generation"
              workingDirectory:
                type: string
                description: "Working directory within repository"
              sourceBranch:
                type: string
                description: "Source branch to analyze"
              model:
                type: string
                description: "Claude model to use (full model name like 'claude-3-5-sonnet-20241022')"
              githubUser:
                type: string
                description: "GitHub username for authentication and commits"
          status:
            type: object
            properties:
              phase:
                type: string
                description: "Current phase of the documentation generation"
              message:
                type: string
                description: "Human-readable message about the current state"
              lastUpdate:
                type: string
                description: "Timestamp when this phase was reached"
              jobName:
                type: string
                description: "Associated Kubernetes Job name"
              pullRequestUrl:
                type: string
                description: "Pull request URL if created"
              conditions:
                type: array
                description: "Conditions for the DocsRun"
                items:
                  type: object
                  required: ["type", "status"]
                  properties:
                    type:
                      type: string
                      description: "Type of condition"
                    status:
                      type: string
                      description: "Status of the condition (True, False, or Unknown)"
                    lastTransitionTime:
                      type: string
                      description: "Last time the condition transitioned (RFC3339 format)"
                    reason:
                      type: string
                      description: "Reason for the condition's last transition"
                    message:
                      type: string
                      description: "Human-readable message about the condition"
              configmapName:
                type: string
                description: "Name of the ConfigMap containing the prompt and context"
```

### Chart.yaml (infra/charts/orchestrator/Chart.yaml)

```yaml
apiVersion: v2
name: orchestrator
description: A Helm chart for the Platform Orchestrator - manages Claude Code agents via TaskRun CRDs
type: application
version: 0.1.1
appVersion: "latest"

keywords:
  - orchestrator
  - claude-code
  - task-management
  - kubernetes
  - automation

home: https://github.com/5dlabs/platform
maintainers:
  - name: Platform Team
    email: platform@5dlabs.com

sources:
  - https://github.com/5dlabs/platform

dependencies: []
```

### deployment.yaml (infra/charts/orchestrator/templates/deployment.yaml)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "orchestrator.fullname" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "orchestrator.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      annotations:
        # Force pod restart when claude-templates ConfigMap changes
        claude-templates/checksum: {{ include (print $.Template.BasePath "/claude-templates-configmap.yaml") . | sha256sum }}
        # Force pod restart when controller config changes
        controller-config/checksum: {{ include (print $.Template.BasePath "/task-controller-config.yaml") . | sha256sum }}
        {{- with .Values.podAnnotations }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "orchestrator.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "orchestrator.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["/app/orchestrator"]
          ports:
            - name: {{ .Values.service.name }}
              containerPort: {{ .Values.service.targetPort }}
              protocol: TCP
          env:
            # Kubernetes configuration
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                configMapKeyRef:
                  name: {{ include "orchestrator.fullname" . }}-config
                  key: KUBERNETES_NAMESPACE
            - name: RUST_LOG
              valueFrom:
                configMapKeyRef:
                  name: {{ include "orchestrator.fullname" . }}-config
                  key: RUST_LOG
            # Secrets for agents
            {{- if .Values.secrets.anthropicApiKey }}
            - name: ANTHROPIC_API_KEY
              valueFrom:
                secretKeyRef:
                  {{- if eq .Values.secrets.anthropicApiKey "use-existing" }}
                  name: orchestrator-secrets
                  {{- else }}
                  name: {{ include "orchestrator.fullname" . }}-secrets
                  {{- end }}
                  key: ANTHROPIC_API_KEY
            {{- end }}
          volumeMounts:
            # Mount claude templates ConfigMap
            - name: claude-templates
              mountPath: /claude-templates
              readOnly: true
            # Mount controller configuration ConfigMap
            - name: controller-config
              mountPath: /config
              readOnly: true
          {{- if .Values.healthCheck.enabled }}
          livenessProbe:
            httpGet:
              path: {{ .Values.healthCheck.path }}
              port: {{ .Values.service.name }}
            initialDelaySeconds: {{ .Values.healthCheck.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.livenessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.livenessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.healthCheck.livenessProbe.successThreshold }}
            failureThreshold: {{ .Values.healthCheck.livenessProbe.failureThreshold }}
          readinessProbe:
            httpGet:
              path: {{ .Values.healthCheck.path }}
              port: {{ .Values.service.name }}
            initialDelaySeconds: {{ .Values.healthCheck.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.readinessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.healthCheck.readinessProbe.successThreshold }}
            failureThreshold: {{ .Values.healthCheck.readinessProbe.failureThreshold }}
          {{- end }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
      volumes:
        # Mount claude templates ConfigMap
        - name: claude-templates
          configMap:
            name: {{ include "orchestrator.fullname" . }}-claude-templates
        # Mount controller configuration ConfigMap
        - name: controller-config
          configMap:
            name: {{ include "orchestrator.fullname" . }}-task-controller-config
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
```

### ingress.yaml (infra/charts/orchestrator/templates/ingress.yaml)

```yaml
{{- if .Values.ingress.enabled -}}
{{- $fullName := include "orchestrator.fullname" . -}}
{{- $svcPort := .Values.service.port -}}
{{- if and .Values.ingress.className (not (hasKey .Values.ingress.annotations "kubernetes.io/ingress.class")) }}
  {{- $_ := set .Values.ingress.annotations "kubernetes.io/ingress.class" .Values.ingress.className}}
{{- end }}
{{- if semverCompare ">=1.19-0" .Capabilities.KubeVersion.GitVersion -}}
apiVersion: networking.k8s.io/v1
{{- else if semverCompare ">=1.14-0" .Capabilities.KubeVersion.GitVersion -}}
apiVersion: networking.k8s.io/v1beta1
{{- else -}}
apiVersion: extensions/v1beta1
{{- end }}
kind: Ingress
metadata:
  name: {{ $fullName }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
  {{- with .Values.ingress.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  {{- if and .Values.ingress.className (semverCompare ">=1.18-0" .Capabilities.KubeVersion.GitVersion) }}
  ingressClassName: {{ .Values.ingress.className }}
  {{- end }}
  {{- if .Values.ingress.tls }}
  tls:
    {{- range .Values.ingress.tls }}
    - hosts:
        {{- range .hosts }}
        - {{ . | quote }}
        {{- end }}
      secretName: {{ .secretName }}
    {{- end }}
  {{- end }}
  rules:
    {{- range .Values.ingress.hosts }}
    - host: {{ .host | quote }}
      http:
        paths:
          {{- range .paths }}
          - path: {{ .path }}
            {{- if and .pathType (semverCompare ">=1.18-0" $.Capabilities.KubeVersion.GitVersion) }}
            pathType: {{ .pathType }}
            {{- end }}
            backend:
              {{- if semverCompare ">=1.19-0" $.Capabilities.KubeVersion.GitVersion }}
              service:
                name: {{ $fullName }}
                port:
                  number: {{ $svcPort }}
              {{- else }}
              serviceName: {{ $fullName }}
              servicePort: {{ $svcPort }}
              {{- end }}
          {{- end }}
    {{- end }}
{{- end }}
```

### service.yaml (infra/charts/orchestrator/templates/service.yaml)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ include "orchestrator.fullname" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: {{ .Values.service.name }}
      protocol: TCP
      name: {{ .Values.service.name }}
  selector:
    {{- include "orchestrator.selectorLabels" . | nindent 4 }}
```

### task-controller-config.yaml (infra/charts/orchestrator/templates/task-controller-config.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "orchestrator.fullname" . }}-task-controller-config
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
data:
  config.yaml: |
    # Task Controller Configuration
    # Simplified configuration for CodeRun and DocsRun controllers

    # Job configuration
    job:
      activeDeadlineSeconds: 3600  # 1 hour timeout

    # Claude agent configuration
    agent:
      image:
        repository: {{ .Values.agent.image.repository | quote }}
        tag: {{ .Values.agent.image.tag | quote }}
      imagePullSecrets:
        {{- range .Values.imagePullSecrets }}
        - {{ .name | quote }}
        {{- end }}

    # Secrets configuration (references Kubernetes secrets)
    secrets:
      apiKeySecretName: "{{ include "orchestrator.fullname" . }}-secrets"
      apiKeySecretKey: "ANTHROPIC_API_KEY"

    # Tool permissions configuration (only used when agentToolsOverride=true)
    # When false: uses hardcoded list in settings.json.hbs template
    # When true: uses this configuration
    permissions:
      agentToolsOverride: false
      allow:
        - "Bash"
        - "Edit"
        - "Read"
        - "Write"
        - "MultiEdit"
        - "Glob"
        - "Grep"
        - "LS"
        - "Task"
        - "ExitPlanMode"
        - "NotebookRead"
        - "NotebookEdit"
        - "WebFetch"
        - "WebSearch"
        - "TodoRead"
        - "TodoWrite"
      deny: []

    # Telemetry configuration (used in templates)
    telemetry:
      enabled: true
      otlpEndpoint: "otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317"
      otlpProtocol: "grpc"
      logsEndpoint: "otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317"
      logsProtocol: "grpc"

    # Storage configuration
    storage:
      {{- if .Values.storage.storageClassName }}
      storageClassName: {{ .Values.storage.storageClassName | quote }}
      {{- end }}
      workspaceSize: {{ .Values.storage.workspaceSize | default "10Gi" | quote }}

    # Cleanup configuration (event-driven cleanup by controller)
    cleanup:
      enabled: {{ .Values.cleanup.enabled | default true }}
      completedJobDelayMinutes: {{ .Values.cleanup.completedJobDelayMinutes | default 5 }}
      failedJobDelayMinutes: {{ .Values.cleanup.failedJobDelayMinutes | default 60 }}
      deleteConfigMap: {{ .Values.cleanup.deleteConfigMap | default true }}
```

### rbac.yaml (infra/charts/orchestrator/templates/rbac.yaml)

```yaml
{{- if .Values.rbac.create -}}
{{- if .Values.rbac.namespaced }}
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: {{ include "orchestrator.roleName" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
rules:
{{- toYaml .Values.rbac.rules | nindent 2 }}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: {{ include "orchestrator.roleName" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: {{ include "orchestrator.roleName" . }}
subjects:
- kind: ServiceAccount
  name: {{ include "orchestrator.serviceAccountName" . }}
  namespace: {{ .Release.Namespace }}
{{- else }}
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ include "orchestrator.roleName" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
rules:
{{- toYaml .Values.rbac.rules | nindent 2 }}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: {{ include "orchestrator.roleName" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: {{ include "orchestrator.roleName" . }}
subjects:
- kind: ServiceAccount
  name: {{ include "orchestrator.serviceAccountName" . }}
  namespace: {{ .Release.Namespace }}
{{- end }}
{{- end }}
```

### claude-templates-configmap.yaml (infra/charts/orchestrator/templates/claude-templates-configmap.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "orchestrator.fullname" . }}-claude-templates
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
data:
{{- range $path, $content := .Files.Glob "claude-templates/**/*.hbs" }}
  {{ $path | trimPrefix "claude-templates/" | replace "/" "_" }}: |
{{ $.Files.Get $path | nindent 4 }}
{{- end }}
```

### serviceaccount.yaml (infra/charts/orchestrator/templates/serviceaccount.yaml)

```yaml
{{- if .Values.serviceAccount.create -}}
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ include "orchestrator.serviceAccountName" . }}
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
  {{- with .Values.serviceAccount.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
{{- end }}
```

### configmap.yaml (infra/charts/orchestrator/templates/configmap.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "orchestrator.fullname" . }}-config
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
data:
  KUBERNETES_NAMESPACE: {{ .Values.config.kubernetesNamespace | quote }}
  SERVER_HOST: {{ .Values.config.serverHost | quote }}
  SERVER_PORT: {{ .Values.config.serverPort | quote }}
  RUST_LOG: {{ .Values.config.rustLog | quote }}
  DEFAULT_DOCS_MODEL: {{ .Values.models.defaultDocsModel | quote }}
  DEFAULT_CODE_MODEL: {{ .Values.models.defaultCodeModel | quote }}
```

### secret.yaml (infra/charts/orchestrator/templates/secret.yaml)

```yaml
{{- if and .Values.secrets.anthropicApiKey (ne .Values.secrets.anthropicApiKey "use-existing") }}
apiVersion: v1
kind: Secret
metadata:
  name: {{ include "orchestrator.fullname" . }}-secrets
  labels:
    {{- include "orchestrator.labels" . | nindent 4 }}
type: Opaque
stringData:
  {{- if .Values.secrets.anthropicApiKey }}
  ANTHROPIC_API_KEY: {{ .Values.secrets.anthropicApiKey | quote }}
  {{- end }}
{{- end }}
```

### values.yaml (infra/charts/orchestrator/values.yaml)

```yaml
# Default values for orchestrator.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/5dlabs/platform/orchestrator
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

# Agent/Task Runner image configuration (used by controller to create Jobs)
agent:
  image:
    repository: ghcr.io/5dlabs/platform/claude-code
    tag: "1.0.56"
    pullPolicy: Always

# Storage configuration for workspace PVCs
storage:
  # Storage class name (e.g., "local-path" for local development, leave empty for default)
  storageClassName: "local-path"
  # Size of workspace PVCs
  workspaceSize: "10Gi"

# Cleanup configuration (controller-based event-driven cleanup)
cleanup:
  # Whether to enable automatic cleanup of completed jobs
  enabled: true
  # Minutes to wait before cleaning up successful jobs (default: 5 minutes)
  completedJobDelayMinutes: 5
  # Minutes to wait before cleaning up failed jobs (default: 60 minutes)
  failedJobDelayMinutes: 60
  # Whether to delete associated ConfigMaps when cleaning up jobs
  deleteConfigMap: true

imagePullSecrets:
  - name: ghcr-secret

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "orchestrator"

podAnnotations:
  kubectl.kubernetes.io/restartedAt: ""

podSecurityContext:
  fsGroup: 2000
  runAsNonRoot: true
  runAsUser: 1000

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL
  seccompProfile:
    type: RuntimeDefault

service:
  type: ClusterIP
  port: 80
  targetPort: 8080
  name: http

ingress:
  enabled: false
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
  hosts:
    - host: orchestrator.local
      paths:
        - path: /
          pathType: Prefix
  tls: []

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule

affinity: {}

# Configuration for the orchestrator service
config:
  # Kubernetes namespace (auto-populated in most cases)
  kubernetesNamespace: "orchestrator"

  # Server configuration
  serverHost: "0.0.0.0"
  serverPort: "8080"

  # Logging
  rustLog: "orchestrator=debug,tower_http=debug,axum=debug,kube=info"

# Default model configurations
models:
  # Default model for documentation generation
  defaultDocsModel: "claude-opus-4-20250514"
  # Default model for code tasks
  defaultCodeModel: "claude-sonnet-4-20250514"

# Secret configuration for API keys
secrets:
  # REQUIRED: Set your Anthropic API key
  anthropicApiKey: ""
  # Note: GitHub secrets (SSH keys + tokens) are managed externally per agent
  # See infra/scripts/setup-agent-secrets.sh for setup instructions

# RBAC configuration
rbac:
  # Create RBAC resources
  create: true
  # Use Role/RoleBinding (true) or ClusterRole/ClusterRoleBinding (false)
  namespaced: true
  rules:
    # CodeRun and DocsRun CRD management
    - apiGroups: ["orchestrator.platform"]
      resources: ["coderuns", "docsruns"]
      verbs: ["create", "get", "list", "watch", "update", "patch", "delete"]
    - apiGroups: ["orchestrator.platform"]
      resources: ["coderuns/status", "docsruns/status"]
      verbs: ["get", "update", "patch"]
    # Job management in orchestrator namespace
    - apiGroups: ["batch"]
      resources: ["jobs"]
      verbs: ["create", "get", "list", "watch", "delete", "patch", "update"]
    # ConfigMap and Secret access (for agent configuration and task files)
    - apiGroups: [""]
      resources: ["configmaps", "secrets"]
      verbs: ["get", "list", "create", "update", "delete", "watch", "patch"]
    # ServiceAccount management (required for Helm operations)
    - apiGroups: [""]
      resources: ["serviceaccounts"]
      verbs: ["get", "list", "create", "update", "delete", "patch"]
    # Service management (required for Helm operations)
    - apiGroups: [""]
      resources: ["services"]
      verbs: ["get", "list", "create", "update", "delete", "patch"]
    # Pod monitoring
    - apiGroups: [""]
      resources: ["pods", "pods/log"]
      verbs: ["get", "list", "watch"]
    # PVC management for agent workspaces
    - apiGroups: [""]
      resources: ["persistentvolumeclaims"]
      verbs: ["create", "get", "list", "delete"]
    # Events for debugging
    - apiGroups: [""]
      resources: ["events"]
      verbs: ["get", "list", "watch"]

# Health checks
healthCheck:
  enabled: true
  path: "/health"
  port: 8080
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3

```

### otel-collector-metrics-service.yaml (infra/cluster-config/otel-collector-metrics-service.yaml)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: otel-collector-metrics
  namespace: telemetry
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: otel-collector
spec:
  type: ClusterIP
  ports:
  - name: metrics
    port: 8890
    targetPort: 8890
    protocol: TCP
  selector:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: otel-collector
```

### otel-prometheus-service.yaml (infra/cluster-config/otel-prometheus-service.yaml)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: otel-collector-metrics
  namespace: telemetry
  labels:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: otel-collector
spec:
  type: ClusterIP
  ports:
    - name: prometheus
      port: 8889
      targetPort: 8889
      protocol: TCP
    - name: internal-metrics
      port: 8890
      targetPort: 8890
      protocol: TCP
  selector:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: otel-collector
```

### local-path-config-patch.yaml (infra/cluster-config/local-path-config-patch.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-path-config
  namespace: local-path-storage
data:
  config.json: |-
    {
            "nodePathMap":[
            {
                    "node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",
                    "paths":["/var/mnt/local-path-provisioner"]
            }
            ]
    }
  helperPod.yaml: |-
    apiVersion: v1
    kind: Pod
    metadata:
      name: helper-pod
    spec:
      priorityClassName: system-node-critical
      tolerations:
        - key: node.kubernetes.io/disk-pressure
          operator: Exists
          effect: NoSchedule
      securityContext:
        fsGroup: 0
        runAsUser: 0
        runAsGroup: 0
      containers:
      - name: helper-pod
        image: busybox
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: true
  setup: |-
    #!/bin/sh
    set -eu
    mkdir -m 0777 -p "$VOL_DIR"
  teardown: |-
    #!/bin/sh
    set -eu
    rm -rf "$VOL_DIR"
```

### talos-local-path-volume.yaml (infra/cluster-config/talos-local-path-volume.yaml)

```yaml
apiVersion: v1alpha1
kind: UserVolumeConfig
name: local-path-provisioner
provisioning:
  diskSelector:
    match: "!system_disk"
  minSize: 100GB
  maxSize: 100GB
```

### Chart.yaml (infra/telemetry/telemetry-dashboards/Chart.yaml)

```yaml
apiVersion: v2
name: telemetry-dashboards
description: Claude Code Telemetry Dashboards for Grafana
type: application
version: 0.1.0
appVersion: "1.0"
```

### dashboard-configmap.yaml (infra/telemetry/telemetry-dashboards/dashboards/dashboard-configmap.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: claude-code-dashboards
  namespace: telemetry
  labels:
    grafana_dashboard: "1"
data:
  executive-overview.json: |
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": null,
      "links": [],
      "liveNow": false,
      "panels": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "10.0.0",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "sum(increase(claude_code_session_count[24h]))",
              "refId": "A"
            }
          ],
          "title": "Sessions Today",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 6,
            "y": 0
          },
          "id": 3,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "10.0.0",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "count(count by (user_account_uuid) (claude_code_session_count))",
              "refId": "A"
            }
          ],
          "title": "Active Users",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "decimals": 2,
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "yellow",
                    "value": 1000
                  },
                  {
                    "color": "red",
                    "value": 5000
                  }
                ]
              },
              "unit": "currencyUSD"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 12,
            "y": 0
          },
          "id": 4,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "10.0.0",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "sum(increase(claude_code_cost_usage[24h]))",
              "refId": "A"
            }
          ],
          "title": "Cost Today",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "decimals": 2,
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "yellow",
                    "value": 10000
                  },
                  {
                    "color": "red",
                    "value": 50000
                  }
                ]
              },
              "unit": "currencyUSD"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 18,
            "y": 0
          },
          "id": 5,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "10.0.0",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "sum(increase(claude_code_cost_usage[30d]))",
              "refId": "A"
            }
          ],
          "title": "Monthly Cost",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "drawStyle": "line",
                "fillOpacity": 10,
                "gradientMode": "none",
                "hideFrom": {
                  "tooltip": false,
                  "viz": false,
                  "legend": false
                },
                "lineInterpolation": "linear",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "never",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 4
          },
          "id": 6,
          "options": {
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": true
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "count(count by (user_account_uuid) (claude_code_session_count))",
              "legendFormat": "Active Users",
              "refId": "A"
            }
          ],
          "title": "Daily Active Users Trend",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "hideFrom": {
                  "tooltip": false,
                  "viz": false,
                  "legend": false
                }
              },
              "mappings": [],
              "unit": "currencyUSD"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 4
          },
          "id": 7,
          "options": {
            "displayLabels": ["name", "percent"],
            "legend": {
              "displayMode": "list",
              "placement": "right",
              "showLegend": true,
              "values": ["value"]
            },
            "pieType": "pie",
            "reduceOptions": {
              "values": false,
              "calcs": [
                "lastNotNull"
              ],
              "fields": ""
            },
            "tooltip": {
              "mode": "single",
              "sort": "none"
            }
          },
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "sum by (model) (claude_code_cost_usage)",
              "legendFormat": "{{model}}",
              "refId": "A"
            }
          ],
          "title": "Cost by Model",
          "type": "piechart"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "${datasource}"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "cellOptions": {
                  "type": "auto"
                },
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Cost"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "currencyUSD"
                  },
                  {
                    "id": "decimals",
                    "value": 2
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 8,
            "w": 24,
            "x": 0,
            "y": 12
          },
          "id": 8,
          "options": {
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Cost"
              }
            ]
          },
          "pluginVersion": "10.0.0",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "${datasource}"
              },
              "editorMode": "code",
              "expr": "topk(10, sum by (user_account_uuid) (claude_code_cost_usage))",
              "format": "table",
              "refId": "A"
            }
          ],
          "title": "Top Users by Cost",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "Time": true
                },
                "indexByName": {},
                "renameByName": {
                  "Value": "Cost",
                  "user_account_uuid": "User"
                }
              }
            }
          ],
          "type": "table"
        }
      ],
      "refresh": "30s",
      "schemaVersion": 38,
      "style": "dark",
      "tags": ["claude-code", "executive"],
      "templating": {
        "list": [
          {
            "current": {
              "selected": false,
              "text": "VictoriaMetrics",
              "value": "VictoriaMetrics"
            },
            "hide": 0,
            "includeAll": false,
            "label": "Data Source",
            "multi": false,
            "name": "datasource",
            "options": [],
            "query": "prometheus",
            "refresh": 1,
            "regex": "",
            "skipUrlSync": false,
            "type": "datasource"
          }
        ]
      },
      "time": {
        "from": "now-24h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "Claude Code - Executive Overview",
      "uid": "claude-code-exec",
      "version": 1,
      "weekStart": ""
    }
```

### engineering-dashboard-configmap.yaml (infra/telemetry/telemetry-dashboards/templates/engineering-dashboard-configmap.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: engineering-metrics-dashboard
  namespace: telemetry
  labels:
    grafana_dashboard: "1"
data:
  engineering-metrics.json: |
{{ .Files.Get "dashboards/engineering-metrics-dashboard.json" | indent 4 }}
```

### otel-collector.yaml (infra/telemetry/values/otel-collector.yaml)

```yaml
# OpenTelemetry Collector Helm Values for Claude Code Telemetry
mode: deployment
replicaCount: 1

# Image configuration
image:
  repository: otel/opentelemetry-collector-contrib
  pullPolicy: IfNotPresent
  tag: "0.105.0"

# Resource allocation - adjusted for development environment
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

# Service configuration
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    protocol: TCP
  prometheus:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    protocol: TCP

# OpenTelemetry Collector configuration
config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
          max_recv_msg_size_mib: 64
        http:
          endpoint: 0.0.0.0:4318
          cors:
            allowed_origins:
              - "*"

  processors:
    batch:
      timeout: 10s
      send_batch_size: 1024
      send_batch_max_size: 2048
    
    memory_limiter:
      check_interval: 1s
      limit_mib: 1500
      spike_limit_mib: 512
    
    resource:
      attributes:
        - key: cluster.name
          value: telemetry-dev
          action: insert
        - key: deployment.environment
          value: development
          action: insert
    
    # Transform metric names from dots to underscores for Prometheus compatibility
    # NOTE: Claude Code emits metrics WITHOUT the claude_code prefix!
    transform/metrics:
      metric_statements:
        - context: datapoint
          statements:
            # Transform actual metric names (no prefix) to Prometheus format with prefix
            - set(metric.name, "claude_code_lines_of_code_count") where metric.name == "lines_of_code.count"
            - set(metric.name, "claude_code_cost_usage") where metric.name == "cost.usage"
            - set(metric.name, "claude_code_token_usage") where metric.name == "token.usage"
            - set(metric.name, "claude_code_session_count") where metric.name == "session.count"
            - set(metric.name, "claude_code_commit_count") where metric.name == "commit.count"
            - set(metric.name, "claude_code_pull_request_count") where metric.name == "pull_request.count"
            - set(metric.name, "claude_code_code_edit_tool_decision") where metric.name == "code_edit_tool.decision"

  exporters:
    prometheus:
      endpoint: "0.0.0.0:8889"
      send_timestamps: true
    
    # VictoriaMetrics native OpenTelemetry exporter
    otlphttp/victoriametrics:
      metrics_endpoint: http://victoria-metrics-victoria-metrics-single-server:8428/opentelemetry/v1/metrics
      compression: gzip
      encoding: proto
      tls:
        insecure: true
      timeout: 30s
      retry_on_failure:
        enabled: true
        initial_interval: 5s
        max_interval: 30s
        max_elapsed_time: 300s
    
    # VictoriaLogs exporter using OTLP/HTTP
    otlphttp:
      logs_endpoint: http://victoria-logs-victoria-logs-single-server:9428/insert/opentelemetry/v1/logs
      tls:
        insecure: true
      retry_on_failure:
        enabled: true
        initial_interval: 5s
        max_interval: 30s
        max_elapsed_time: 300s
      headers:
        VL-Stream-Fields: "cluster.name,deployment.environment,service.name,service.namespace"
    
    # Debug exporter for troubleshooting
    debug:
      verbosity: detailed
      sampling_initial: 5
      sampling_thereafter: 200

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133
    pprof:
      endpoint: 0.0.0.0:1777
    zpages:
      endpoint: 0.0.0.0:55679

  service:
    extensions: [health_check, pprof, zpages]
    pipelines:
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, batch, resource, transform/metrics]
        exporters: [otlphttp/victoriametrics, prometheus, debug]
      logs:
        receivers: [otlp]
        processors: [memory_limiter, batch, resource]
        exporters: [otlphttp, debug]
      traces:
        receivers: [otlp]
        processors: [memory_limiter, batch, resource]
        exporters: [debug]
    telemetry:
      metrics:
        level: detailed
        address: 0.0.0.0:8890

# Pod annotations for monitoring
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8890"
  prometheus.io/path: "/metrics"

# Liveness and readiness probes
livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 5

# Ingress configuration for OTLP endpoints
ingress:
  enabled: true
  ingressClassName: nginx
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/grpc-backend: "true"
  hosts:
    - host: otel-grpc.local
      paths:
        - path: /
          pathType: Prefix
          port: 4317
    - host: otel-http.local
      paths:
        - path: /
          pathType: Prefix
          port: 4318
```

### victoria-logs.yaml (infra/telemetry/values/victoria-logs.yaml)

```yaml
# VictoriaLogs Single Server Helm Values for Claude Code Telemetry

# Server configuration
server:
  # Enable single server mode
  enabled: true
  
  # Image configuration
  image:
    repository: victoriametrics/victoria-logs
    tag: v1.24.0-victorialogs
    pullPolicy: IfNotPresent
  
  # Resource allocation - adjusted for development environment
  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 1000m
      memory: 2Gi
  
  # Data retention period
  retentionPeriod: 6M  # 6 months
  
  # Storage configuration
  persistentVolume:
    enabled: true
    size: 20Gi
    storageClass: local-path  # Using local-path provisioner
    
  # Extra arguments for VictoriaLogs
  extraArgs:
    httpListenAddr: ":9428"
    retentionPeriod: "6"
    loggerLevel: "INFO"
    search.maxQueryDuration: "30s"
    
  # Service configuration
  service:
    type: ClusterIP
    servicePort: 9428
    
  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    
  # Liveness and readiness probes
  livenessProbe:
    httpGet:
      path: /health
      port: 9428
    initialDelaySeconds: 30
    periodSeconds: 30
    
  readinessProbe:
    httpGet:
      path: /health  
      port: 9428
    initialDelaySeconds: 5
    periodSeconds: 5

# Disable fluent-bit by default
fluent-bit:
  enabled: false

# Ingress configuration
ingress:
  enabled: true
  ingressClassName: nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  hosts:
    - host: victoria-logs.local
      paths:
        - path: /
          pathType: Prefix
  tls: []
```

### grafana.yaml (infra/telemetry/values/grafana.yaml)

```yaml
# Grafana Helm Values for Claude Code Telemetry

# Admin credentials
adminUser: admin
adminPassword: admin123!  # Change this in production

# Resource allocation - adjusted for development environment
resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 500m
    memory: 512Mi

# Persistence for dashboards and settings
persistence:
  enabled: true
  size: 10Gi
  storageClassName: local-path
  # Fix for permission issues in Kind
  extraPvcLabels: {}
  inMemory:
    enabled: false

# Service configuration
service:
  type: ClusterIP
  port: 80

# Ingress configuration
ingress:
  enabled: true
  ingressClassName: nginx
  annotations: {}
  hosts:
    - grafana.local
  path: /
  pathType: Prefix
  tls: []

# Data sources configuration
datasources:
  datasources.yaml:
    apiVersion: 1
    datasources:
      # VictoriaMetrics as Prometheus datasource
      - name: VictoriaMetrics
        type: prometheus
        access: proxy
        url: http://victoria-metrics-victoria-metrics-single-server:8428
        isDefault: true
        editable: false
        jsonData:
          timeInterval: "15s"
          queryTimeout: "60s"
          httpMethod: POST
      
      # VictoriaLogs datasource
      - name: VictoriaLogs
        type: victoriametrics-logs-datasource
        access: proxy
        url: http://victoria-logs-victoria-logs-single-server:9428
        editable: false

# Dashboard providers configuration
# dashboardProviders:
#   dashboardproviders.yaml:
#     apiVersion: 1
#     providers:
#       - name: 'claude-code-dashboards'
#         orgId: 1
#         folder: 'Claude Code'
#         type: file
#         disableDeletion: false
#         editable: true
#         options:
#           path: /var/lib/grafana/dashboards/claude-code

# Dashboard configuration as ConfigMap
# dashboardsConfigMaps:
#   engineering-metrics: engineering-metrics-dashboard

# Plugins to install
plugins:
  - grafana-piechart-panel
  - grafana-worldmap-panel
  - victoriametrics-logs-datasource

# RBAC configuration
rbac:
  create: true
  pspEnabled: false

# Service account
serviceAccount:
  create: true
  name: grafana

# Security context
securityContext:
  runAsNonRoot: true
  runAsUser: 472
  fsGroup: 472

# Environment variables
env:
  GF_EXPLORE_ENABLED: true
  GF_ALERTING_ENABLED: true
  GF_UNIFIED_ALERTING_ENABLED: true
  GF_INSTALL_PLUGINS: victoriametrics-logs-datasource

# Init containers - removed custom init to avoid permission issues

# Grafana.ini configuration
grafana.ini:
  server:
    domain: grafana.local
    root_url: "%(protocol)s://%(domain)s/"
  
  analytics:
    reporting_enabled: false
    check_for_updates: false
  
  log:
    mode: console
    level: info
  
  unified_alerting:
    enabled: true
  
  feature_toggles:
    enable: ngalert

# Sidecar for dynamic dashboard/datasource provisioning
sidecar:
  dashboards:
    enabled: true
    label: grafana_dashboard
    folder: /tmp/dashboards
    provider:
      name: sidecarProvider
      orgId: 1
      folder: 'Claude Code'
      type: file
      disableDeletion: false
      allowUiUpdates: true
  
  datasources:
    enabled: true
    label: grafana_datasource

# Readiness and liveness probes
readinessProbe:
  httpGet:
    path: /api/health
    port: 3000

livenessProbe:
  httpGet:
    path: /api/health
    port: 3000
  initialDelaySeconds: 60
  timeoutSeconds: 30
  failureThreshold: 10
```

### claude-code-telemetry.yaml (infra/telemetry/values/claude-code-telemetry.yaml)

```yaml
# Claude Code deployment with telemetry integration

# Secret configuration for API keys
secrets:
  # Using PAT as ANTHROPIC_API_KEY per user's instruction
  anthropicApiKey: "YOUR_ANTHROPIC_API_KEY"
  githubToken: "YOUR_GITHUB_TOKEN"

# Image configuration
image:
  repository: ghcr.io/5dlabs/platform/claude-code
  pullPolicy: IfNotPresent
  tag: "latest"

# Image pull secret for ghcr.io
imagePullSecrets:
  - name: ghcr-secret

# Resources - conservative for testing
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

# Persistence - using local-path storage
persistence:
  enabled: true
  storageClass: "local-path"
  accessMode: ReadWriteOnce
  size: 20Gi
  mountPath: /data

# Telemetry configuration - CRITICAL FOR VALIDATION
telemetry:
  enabled: true
  # Using internal service endpoint
  otlpEndpoint: "otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317"
  otlpProtocol: "grpc"
  otlpInsecure: true
  
  # Service identification
  serviceName: "claude-code"
  serviceVersion: "1.0.0"
  serviceNamespace: "claude-code"
  
  # Team/Organization attributes
  teamName: "platform"
  department: "engineering"
  environment: "production"
  costCenter: "eng-001"
  
  # Developer/Agent identification
  githubUser: "claude-agent-001"
  workingService: "telemetry-validation"
  
  # Export intervals (milliseconds)
  metricsExportInterval: "10000"  # 10 seconds for faster validation
  metricsExportTimeout: "5000"    # 5 seconds
  logsExportInterval: "5000"       # 5 seconds
  logsExportTimeout: "5000"        # 5 seconds
  
  # Cardinality control
  includeSessionId: true
  includeAccountUuid: true
  includeVersion: true
  
  # Additional OTEL configuration
  logLevel: "debug"  # Debug for validation
  logUserPrompts: true  # Enable for testing
  
  # Custom attributes for testing
  customAttributes: "test.mode=validation,test.phase=initial"
  
  # Cluster name
  clusterName: "talos-prod"

# Development mode for testing
developmentMode:
  enabled: false
  command: ["/bin/sh"]
  args:
    - "-c"
    - |
      echo "Starting Claude Code with telemetry validation..."
      echo "OTLP Endpoint: $OTEL_EXPORTER_OTLP_ENDPOINT"
      echo "Service Name: $OTEL_SERVICE_NAME"
      echo "Telemetry Enabled: $CLAUDE_CODE_TELEMETRY_ENABLED"
      
      # Create workspace directory
      mkdir -p /workspace
      cd /workspace
      
      # Since we don't have a valid Anthropic API key, just test telemetry emission
      echo "Testing telemetry configuration..."
      echo "CLAUDE_CODE_ENABLE_TELEMETRY=$CLAUDE_CODE_ENABLE_TELEMETRY"
      echo "OTEL_SERVICE_NAME=$OTEL_SERVICE_NAME"
      echo "OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=$OTEL_EXPORTER_OTLP_METRICS_ENDPOINT"
      echo "OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=$OTEL_EXPORTER_OTLP_LOGS_ENDPOINT"
      
      # Keep container running for telemetry testing
      echo "Container will stay running for telemetry validation..."
      while true; do
        echo "Claude Code telemetry test running... $(date)"
        sleep 60
      done

# Extra environment variables for debugging
extraEnvVars:
  - name: OTEL_LOG_LEVEL
    value: "debug"
  - name: OTEL_TRACES_EXPORTER
    value: "otlp"
  - name: OTEL_METRICS_EXPORTER
    value: "otlp"
  - name: OTEL_LOGS_EXPORTER
    value: "otlp"
  - name: DEBUG_TELEMETRY
    value: "true"

# Log file configuration
logFile:
  enabled: true
  path: /var/log/claude-code
  filename: telemetry-validation.log

# Service configuration
service:
  type: ClusterIP
  port: 8080
  targetPort: 8080
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"


```

### victoria-metrics.yaml (infra/telemetry/values/victoria-metrics.yaml)

```yaml
# VictoriaMetrics Single Server Helm Values for Claude Code Telemetry

# Server configuration
server:
  # Enable single server mode
  enabled: true
  
  # Image configuration
  image:
    repository: victoriametrics/victoria-metrics
    tag: v1.101.0
    pullPolicy: IfNotPresent
  
  # Resource allocation - adjusted for development environment
  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 1000m
      memory: 2Gi
  
  # Data retention period
  retentionPeriod: 12  # 12 months
  
  # Storage configuration
  persistentVolume:
    enabled: true
    size: 50Gi
    storageClass: standard  # Kind default storage class
    
  # Extra arguments for VictoriaMetrics
  extraArgs:
    maxLabelsPerTimeseries: "50"
    search.maxQueryDuration: "30s"
    search.maxConcurrentRequests: "16"
    dedup.minScrapeInterval: "1s"
    promscrape.streamParse: "true"
    # Enable Prometheus naming for OpenTelemetry metrics
    opentelemetry.usePrometheusNaming: "true"
    
  # Service configuration
  service:
    type: ClusterIP
    port: 8428
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "8428"
      prometheus.io/path: "/metrics"
  
  # Enable metrics scraping
  scrape:
    enabled: true
    config:
      global:
        scrape_interval: 15s
        scrape_timeout: 10s
      
      scrape_configs:
        # Scrape VictoriaMetrics itself
        - job_name: victoria-metrics
          static_configs:
            - targets:
                - localhost:8428
        
        # Scrape OpenTelemetry Collector metrics
        - job_name: otel-collector  
          static_configs:
            - targets:
                - otel-collector-metrics.telemetry.svc.cluster.local:8890
              labels:
                namespace: telemetry
                service: otel-collector
        
        # Scrape Claude Code metrics from OTLP collector's Prometheus endpoint
        - job_name: claude-code-metrics
          static_configs:
            - targets:
                - otel-collector-metrics.telemetry.svc.cluster.local:8889
          metric_relabel_configs:
            # Only keep claude_code metrics
            - source_labels: [__name__]
              regex: 'claude_code.*'
              action: keep

  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    fsGroup: 65534
    
  # Liveness and readiness probes
  livenessProbe:
    httpGet:
      path: /health
      port: 8428
    initialDelaySeconds: 30
    periodSeconds: 30
    
  readinessProbe:
    httpGet:
      path: /health  
      port: 8428
    initialDelaySeconds: 5
    periodSeconds: 5
    
  # Pod annotations
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8428"

# Disable unnecessary components for single-server setup
vmselect:
  enabled: false
  
vminsert:
  enabled: false
  
vmstorage:
  enabled: false

# Ingress configuration
ingress:
  enabled: true
  ingressClassName: nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  hosts:
    - host: victoria-metrics.local
      paths:
        - path: /
          pathType: Prefix
  
# Service Monitor for Prometheus Operator (if available)
serviceMonitor:
  enabled: false
```

### claude-code-alerts.yaml (infra/telemetry/alerts/claude-code-alerts.yaml)

```yaml
groups:
  - name: claude_code_api
    interval: 30s
    rules:
      # High API error rate alert
      - alert: ClaudeCodeHighErrorRate
        expr: |
          (
            sum(rate(claude_code_api_error[5m])) by (github_user, working_service)
            /
            sum(rate(claude_code_api_request[5m])) by (github_user, working_service)
          ) * 100 > 5
        for: 5m
        labels:
          severity: warning
          component: claude-code
        annotations:
          summary: "High API error rate for {{ $labels.github_user }}"
          description: "Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 5%)"
      
      # Critical API error rate alert
      - alert: ClaudeCodeCriticalErrorRate
        expr: |
          (
            sum(rate(claude_code_api_error[5m])) by (github_user, working_service)
            /
            sum(rate(claude_code_api_request[5m])) by (github_user, working_service)
          ) * 100 > 20
        for: 2m
        labels:
          severity: critical
          component: claude-code
        annotations:
          summary: "Critical API error rate for {{ $labels.github_user }}"
          description: "Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 20%)"

  - name: claude_code_cost
    interval: 1m
    rules:
      # User spending over $100/hour
      - alert: ClaudeCodeHighUserSpend
        expr: |
          sum(increase(claude_code_cost_usage[1h])) by (github_user, working_service) > 100
        for: 5m
        labels:
          severity: warning
          component: claude-code
          cost_alert: "true"
        annotations:
          summary: "High spending detected for {{ $labels.github_user }}"
          description: "User {{ $labels.github_user }} has spent ${{ $value | humanize }} in the last hour on service {{ $labels.working_service }}"
      
      # Total platform spending over $500/hour
      - alert: ClaudeCodeHighPlatformSpend
        expr: |
          sum(increase(claude_code_cost_usage[1h])) > 500
        for: 5m
        labels:
          severity: critical
          component: claude-code
          cost_alert: "true"
        annotations:
          summary: "High platform-wide spending detected"
          description: "Total Claude Code spending is ${{ $value | humanize }} in the last hour (threshold: $500/hour)"
      
      # Daily budget approaching limit
      - alert: ClaudeCodeDailyBudgetWarning
        expr: |
          sum(increase(claude_code_cost_usage[24h])) > 800
        for: 10m
        labels:
          severity: warning
          component: claude-code
          cost_alert: "true"
        annotations:
          summary: "Daily budget approaching limit"
          description: "Claude Code has spent ${{ $value | humanize }} today (80% of $1000 daily budget)"

  - name: infrastructure_health
    interval: 30s
    rules:
      # OTLP Collector down
      - alert: OTLPCollectorDown
        expr: up{job="otel-collector",namespace="telemetry"} == 0
        for: 2m
        labels:
          severity: critical
          component: otel-collector
        annotations:
          summary: "OTLP Collector is down"
          description: "OpenTelemetry Collector in namespace telemetry has been down for more than 2 minutes"
      
      # VictoriaMetrics down
      - alert: VictoriaMetricsDown
        expr: up{job="victoria-metrics"} == 0
        for: 2m
        labels:
          severity: critical
          component: victoria-metrics
        annotations:
          summary: "VictoriaMetrics is down"
          description: "VictoriaMetrics server has been down for more than 2 minutes"
      
      # VictoriaLogs down
      - alert: VictoriaLogsDown
        expr: up{instance=~"victoria-logs.*"} == 0
        for: 2m
        labels:
          severity: critical
          component: victoria-logs
        annotations:
          summary: "VictoriaLogs is down"
          description: "VictoriaLogs server has been down for more than 2 minutes"
      
      # Grafana down
      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 5m
        labels:
          severity: warning
          component: grafana
        annotations:
          summary: "Grafana is down"
          description: "Grafana dashboard has been down for more than 5 minutes"

  - name: resource_usage
    interval: 30s
    rules:
      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (
            container_memory_working_set_bytes{namespace="telemetry",container!=""}
            / 
            container_spec_memory_limit_bytes{namespace="telemetry",container!=""}
          ) * 100 > 80
        for: 5m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "High memory usage in {{ $labels.pod }}"
          description: "Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit"
      
      # Critical memory usage
      - alert: CriticalMemoryUsage
        expr: |
          (
            container_memory_working_set_bytes{namespace="telemetry",container!=""}
            / 
            container_spec_memory_limit_bytes{namespace="telemetry",container!=""}
          ) * 100 > 95
        for: 2m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "Critical memory usage in {{ $labels.pod }}"
          description: "Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit"
      
      # Disk space usage (VictoriaMetrics)
      - alert: VictoriaMetricsDiskSpaceWarning
        expr: |
          (
            1 - (node_filesystem_avail_bytes{mountpoint="/var/lib/victoria-metrics-data"} / node_filesystem_size_bytes{mountpoint="/var/lib/victoria-metrics-data"})
          ) * 100 > 80
        for: 10m
        labels:
          severity: warning
          component: victoria-metrics
        annotations:
          summary: "VictoriaMetrics disk space running low"
          description: "VictoriaMetrics data directory is {{ $value | humanize }}% full"
      
      # Disk space usage (VictoriaLogs)
      - alert: VictoriaLogsDiskSpaceWarning
        expr: |
          (
            1 - (node_filesystem_avail_bytes{mountpoint="/victoria-logs-data"} / node_filesystem_size_bytes{mountpoint="/victoria-logs-data"})
          ) * 100 > 80
        for: 10m
        labels:
          severity: warning
          component: victoria-logs
        annotations:
          summary: "VictoriaLogs disk space running low"
          description: "VictoriaLogs data directory is {{ $value | humanize }}% full"

  - name: data_ingestion
    interval: 30s
    rules:
      # No metrics ingestion
      - alert: NoMetricsIngestion
        expr: |
          rate(prometheus_tsdb_samples_appended_total[5m]) == 0
        for: 10m
        labels:
          severity: warning
          component: victoria-metrics
        annotations:
          summary: "No metrics being ingested"
          description: "VictoriaMetrics has not received any new metrics for 10 minutes"
      
      # No logs ingestion
      - alert: NoLogsIngestion
        expr: |
          rate(victoria_logs_rows_inserted_total[5m]) == 0
        for: 10m
        labels:
          severity: warning
          component: victoria-logs
        annotations:
          summary: "No logs being ingested"
          description: "VictoriaLogs has not received any new logs for 10 minutes"
      
      # High ingestion rate warning
      - alert: HighMetricsIngestionRate
        expr: |
          rate(prometheus_tsdb_samples_appended_total[1m]) * 60 > 100000
        for: 5m
        labels:
          severity: warning
          component: victoria-metrics
        annotations:
          summary: "High metrics ingestion rate"
          description: "Metrics ingestion rate is {{ $value | humanize }} samples/minute"
```

### alerting-rules-configmap.yaml (infra/telemetry/alerts/alerting-rules-configmap.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: claude-code-alerting-rules
  namespace: telemetry
  labels:
    app: alerting
    component: rules
data:
  claude-code-alerts.yaml: |
    groups:
      - name: claude_code_api
        interval: 30s
        rules:
          # High API error rate alert
          - alert: ClaudeCodeHighErrorRate
            expr: |
              (
                sum(rate(claude_code_api_error[5m])) by (github_user, working_service)
                /
                sum(rate(claude_code_api_request[5m])) by (github_user, working_service)
              ) * 100 > 5
            for: 5m
            labels:
              severity: warning
              component: claude-code
            annotations:
              summary: "High API error rate for {{ $labels.github_user }}"
              description: "Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 5%)"
          
          # Critical API error rate alert
          - alert: ClaudeCodeCriticalErrorRate
            expr: |
              (
                sum(rate(claude_code_api_error[5m])) by (github_user, working_service)
                /
                sum(rate(claude_code_api_request[5m])) by (github_user, working_service)
              ) * 100 > 20
            for: 2m
            labels:
              severity: critical
              component: claude-code
            annotations:
              summary: "Critical API error rate for {{ $labels.github_user }}"
              description: "Claude Code API error rate is {{ $value | humanize }}% for user {{ $labels.github_user }} on service {{ $labels.working_service }} (threshold: 20%)"

      - name: claude_code_cost
        interval: 1m
        rules:
          # User spending over $100/hour
          - alert: ClaudeCodeHighUserSpend
            expr: |
              sum(increase(claude_code_cost_usage[1h])) by (github_user, working_service) > 100
            for: 5m
            labels:
              severity: warning
              component: claude-code
              cost_alert: "true"
            annotations:
              summary: "High spending detected for {{ $labels.github_user }}"
              description: "User {{ $labels.github_user }} has spent ${{ $value | humanize }} in the last hour on service {{ $labels.working_service }}"
          
          # Total platform spending over $500/hour
          - alert: ClaudeCodeHighPlatformSpend
            expr: |
              sum(increase(claude_code_cost_usage[1h])) > 500
            for: 5m
            labels:
              severity: critical
              component: claude-code
              cost_alert: "true"
            annotations:
              summary: "High platform-wide spending detected"
              description: "Total Claude Code spending is ${{ $value | humanize }} in the last hour (threshold: $500/hour)"
          
          # Daily budget approaching limit
          - alert: ClaudeCodeDailyBudgetWarning
            expr: |
              sum(increase(claude_code_cost_usage[24h])) > 800
            for: 10m
            labels:
              severity: warning
              component: claude-code
              cost_alert: "true"
            annotations:
              summary: "Daily budget approaching limit"
              description: "Claude Code has spent ${{ $value | humanize }} today (80% of $1000 daily budget)"

      - name: infrastructure_health
        interval: 30s
        rules:
          # OTLP Collector down
          - alert: OTLPCollectorDown
            expr: up{job="otel-collector",namespace="telemetry"} == 0
            for: 2m
            labels:
              severity: critical
              component: otel-collector
            annotations:
              summary: "OTLP Collector is down"
              description: "OpenTelemetry Collector in namespace telemetry has been down for more than 2 minutes"
          
          # VictoriaMetrics down
          - alert: VictoriaMetricsDown
            expr: up{job="victoria-metrics"} == 0
            for: 2m
            labels:
              severity: critical
              component: victoria-metrics
            annotations:
              summary: "VictoriaMetrics is down"
              description: "VictoriaMetrics server has been down for more than 2 minutes"
          
          # VictoriaLogs down
          - alert: VictoriaLogsDown
            expr: up{instance=~"victoria-logs.*"} == 0
            for: 2m
            labels:
              severity: critical
              component: victoria-logs
            annotations:
              summary: "VictoriaLogs is down"
              description: "VictoriaLogs server has been down for more than 2 minutes"
          
          # Grafana down
          - alert: GrafanaDown
            expr: up{job="grafana"} == 0
            for: 5m
            labels:
              severity: warning
              component: grafana
            annotations:
              summary: "Grafana is down"
              description: "Grafana dashboard has been down for more than 5 minutes"

      - name: resource_usage
        interval: 30s
        rules:
          # High memory usage
          - alert: HighMemoryUsage
            expr: |
              (
                container_memory_working_set_bytes{namespace="telemetry",container!=""}
                / 
                container_spec_memory_limit_bytes{namespace="telemetry",container!=""}
              ) * 100 > 80
            for: 5m
            labels:
              severity: warning
              component: infrastructure
            annotations:
              summary: "High memory usage in {{ $labels.pod }}"
              description: "Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit"
          
          # Critical memory usage
          - alert: CriticalMemoryUsage
            expr: |
              (
                container_memory_working_set_bytes{namespace="telemetry",container!=""}
                / 
                container_spec_memory_limit_bytes{namespace="telemetry",container!=""}
              ) * 100 > 95
            for: 2m
            labels:
              severity: critical
              component: infrastructure
            annotations:
              summary: "Critical memory usage in {{ $labels.pod }}"
              description: "Pod {{ $labels.pod }} container {{ $labels.container }} is using {{ $value | humanize }}% of its memory limit"
          
          # Disk space usage (VictoriaMetrics)
          - alert: VictoriaMetricsDiskSpaceWarning
            expr: |
              (
                1 - (node_filesystem_avail_bytes{mountpoint="/var/lib/victoria-metrics-data"} / node_filesystem_size_bytes{mountpoint="/var/lib/victoria-metrics-data"})
              ) * 100 > 80
            for: 10m
            labels:
              severity: warning
              component: victoria-metrics
            annotations:
              summary: "VictoriaMetrics disk space running low"
              description: "VictoriaMetrics data directory is {{ $value | humanize }}% full"
          
          # Disk space usage (VictoriaLogs)
          - alert: VictoriaLogsDiskSpaceWarning
            expr: |
              (
                1 - (node_filesystem_avail_bytes{mountpoint="/victoria-logs-data"} / node_filesystem_size_bytes{mountpoint="/victoria-logs-data"})
              ) * 100 > 80
            for: 10m
            labels:
              severity: warning
              component: victoria-logs
            annotations:
              summary: "VictoriaLogs disk space running low"
              description: "VictoriaLogs data directory is {{ $value | humanize }}% full"

      - name: data_ingestion
        interval: 30s
        rules:
          # No metrics ingestion
          - alert: NoMetricsIngestion
            expr: |
              rate(prometheus_tsdb_samples_appended_total[5m]) == 0
            for: 10m
            labels:
              severity: warning
              component: victoria-metrics
            annotations:
              summary: "No metrics being ingested"
              description: "VictoriaMetrics has not received any new metrics for 10 minutes"
          
          # No logs ingestion
          - alert: NoLogsIngestion
            expr: |
              rate(victoria_logs_rows_inserted_total[5m]) == 0
            for: 10m
            labels:
              severity: warning
              component: victoria-logs
            annotations:
              summary: "No logs being ingested"
              description: "VictoriaLogs has not received any new logs for 10 minutes"
          
          # High ingestion rate warning
          - alert: HighMetricsIngestionRate
            expr: |
              rate(prometheus_tsdb_samples_appended_total[1m]) * 60 > 100000
            for: 5m
            labels:
              severity: warning
              component: victoria-metrics
            annotations:
              summary: "High metrics ingestion rate"
              description: "Metrics ingestion rate is {{ $value | humanize }} samples/minute"
```

### arc-org-runners.yaml (infra/arc/arc-org-runners.yaml)

```yaml
---
# Consolidated ARC organization runner setup for 5dlabs
# Single file with all optimizations and org-level configuration

# Namespace with privileged pod security for Docker-in-Docker
apiVersion: v1
kind: Namespace
metadata:
  name: arc-systems
  labels:
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/warn: privileged
    pod-security.kubernetes.io/audit: privileged
---
# Service account for runners
apiVersion: v1
kind: ServiceAccount
metadata:
  name: github-runner
  namespace: arc-systems
---
# ClusterRole for deployment permissions
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: github-runner-deploy
rules:
  # Core resources
  - apiGroups: [""]
    resources: ["namespaces", "services", "secrets", "configmaps", "persistentvolumeclaims", "serviceaccounts"]
    verbs: ["get", "list", "create", "update", "patch", "delete", "watch"]
  - apiGroups: [""]
    resources: ["pods", "pods/log", "nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["get", "list", "watch"]
  # Apps resources
  - apiGroups: ["apps"]
    resources: ["deployments", "daemonsets", "replicasets", "statefulsets"]
    verbs: ["get", "list", "create", "update", "patch", "delete"]
  # Batch resources
  - apiGroups: ["batch"]
    resources: ["jobs", "cronjobs"]
    verbs: ["get", "list", "create", "update", "patch", "delete", "watch"]
  # RBAC resources
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["roles", "rolebindings", "clusterroles", "clusterrolebindings"]
    verbs: ["get", "list", "create", "update", "patch", "delete"]
  # CRDs
  - apiGroups: ["apiextensions.k8s.io"]
    resources: ["customresourcedefinitions"]
    verbs: ["get", "list", "create", "update", "patch", "delete"]
  # Orchestrator CRDs
  - apiGroups: ["orchestrator.platform"]
    resources: ["coderuns", "docsruns"]
    verbs: ["get", "list", "create", "update", "patch", "delete", "watch"]
  - apiGroups: ["orchestrator.platform"]
    resources: ["coderuns/status", "docsruns/status"]
    verbs: ["get", "update", "patch"]
  # Helm resources
  - apiGroups: ["helm.sh"]
    resources: ["*"]
    verbs: ["*"]
---
# Bind ClusterRole to service account
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: github-runner-deploy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: github-runner-deploy
subjects:
  - kind: ServiceAccount
    name: github-runner
    namespace: arc-systems
---
# Persistent Volume Claim for Rust caching
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rust-cache-pvc
  namespace: arc-systems
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: local-path
---
# Organization-level runners with optimizations
apiVersion: actions.summerwind.dev/v1alpha1
kind: RunnerDeployment
metadata:
  name: org-runners
  namespace: arc-systems
spec:
  replicas: 4  # Scaled up for better parallelism
  template:
    spec:
      # FIXED: Organization-level configuration (not repository-specific)
      organization: 5dlabs

      # GitHub authentication using the existing secret
      githubAPICredentialsFrom:
        secretRef:
          name: controller-manager

      # Enhanced runner labels for identification
      labels:
        - self-hosted
        - linux
        - x64
        - k8s-runner
        - rust-builder
        - org-runner
        - optimized

      # Enhanced resources for better performance
      resources:
        limits:
          cpu: "4"
          memory: "8Gi"
        requests:
          cpu: "2"
          memory: "4Gi"

      # Use the working rust-builder image
      image: ghcr.io/5dlabs/platform/rust-builder:1.2.0
      imagePullPolicy: Always
      dockerEnabled: true
      dockerdWithinRunnerContainer: true

      # Optimized environment variables
      env:
        - name: RUNNER_FEATURE_FLAG_EPHEMERAL
          value: "true"
        - name: PATH
          value: "/home/runner/.cargo/bin:/shared/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
        # Rust optimizations
        - name: CARGO_HOME
          value: "/cache/cargo"
        - name: RUSTUP_HOME
          value: "/cache/rustup"
        - name: SCCACHE_DIR
          value: "/cache/sccache"
        - name: SCCACHE_CACHE_SIZE
          value: "40G"
        - name: RUSTC_WRAPPER
          value: "sccache"
        - name: CARGO_TARGET_DIR
          value: "/cache/target"

      # Service account
      serviceAccountName: github-runner

      # Image pull secrets for private registries
      imagePullSecrets:
        - name: ghcr-secret

      # Init containers for cache setup and tool installation
      initContainers:
        - name: setup-cache
          image: ghcr.io/5dlabs/platform/rust-builder:1.2.0
          command: ["/bin/sh", "-c"]
          args:
            - |
              echo "Setting up cache directories..."
              mkdir -p /cache/cargo /cache/rustup /cache/sccache /cache/target
              chown -R 1000:1000 /cache
              chmod -R 755 /cache
              echo "Cache setup complete"
          volumeMounts:
            - name: rust-cache
              mountPath: /cache
              subPath: rust-cache
          securityContext:
            runAsUser: 0
            runAsGroup: 0
        - name: install-tools
          image: alpine:3.19
          command: ["/bin/sh", "-c"]
          args:
            - |
              echo "Installing additional tools..."
              apk add --no-cache wget tar
              mkdir -p /shared/bin

              # kubectl
              wget -qO /shared/bin/kubectl https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl
              chmod +x /shared/bin/kubectl

              # helm
              wget -qO- https://get.helm.sh/helm-v3.14.0-linux-amd64.tar.gz | tar xz
              mv linux-amd64/helm /shared/bin/helm
              chmod +x /shared/bin/helm

              # GitHub CLI
              wget -qO- https://github.com/cli/cli/releases/download/v2.40.0/gh_2.40.0_linux_amd64.tar.gz | tar xz
              mv gh_2.40.0_linux_amd64/bin/gh /shared/bin/gh
              chmod +x /shared/bin/gh

              echo "Tools installed:"
              ls -la /shared/bin/
          volumeMounts:
            - name: shared-tools
              mountPath: /shared

      # Volumes for caching and tools
      volumes:
        - name: rust-cache
          persistentVolumeClaim:
            claimName: rust-cache-pvc
        - name: shared-tools
          emptyDir: {}

      volumeMounts:
        - name: rust-cache
          mountPath: /cache
          subPath: rust-cache
        - name: shared-tools
          mountPath: /shared

      # Security context
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000

```

### test-docsrun.yaml (infra/test-resources/crds/test-docsrun.yaml)

```yaml
apiVersion: orchestrator.platform/v1
kind: DocsRun
metadata:
  name: test-docsrun-ci
  namespace: test-platform
spec:
  repositoryUrl: "https://github.com/5dlabs/platform.git"
  workingDirectory: "_projects/test-service"
  sourceBranch: "main"
  targetBranch: "docs/test-auto-docs"
  model: "sonnet"
  githubUser: "test-user"
```

### test-coderun.yaml (infra/test-resources/crds/test-coderun.yaml)

```yaml
apiVersion: orchestrator.platform/v1
kind: CodeRun
metadata:
  name: test-coderun-ci
  namespace: test-platform
spec:
  taskId: 9999
  service: "test-service"
  repositoryUrl: "https://github.com/5dlabs/platform.git"
  docsRepositoryUrl: "https://github.com/5dlabs/platform.git"
  workingDirectory: "_projects/test-service"
  model: "sonnet"
  githubUser: "test-user"
  localTools: "mcp-orchestrator"
  remoteTools: "taskmaster"
  contextVersion: 1
  continueSession: false
  overwriteMemory: false
```

### claude-code-full-simulator.yaml (infra/test-resources/simulators/claude-code-full-simulator.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: full-simulator
  namespace: claude-code
data:
  simulate-full-metrics.sh: |
    #!/bin/bash
    echo "Starting Claude Code full metric simulation..."
    
    # Function to send metrics to OTLP
    send_metric() {
      local metric_name=$1
      local value=$2
      local attributes=$3
      local timestamp=$(date +%s)000000000
      
      # Build attributes JSON
      local attr_json=""
      if [ -n "$attributes" ]; then
        attr_json=', "attributes": ['$attributes']'
      fi
      
      cat <<EOF > /tmp/metrics.json
    {
      "resource_metrics": [{
        "resource": {
          "attributes": [{
            "key": "service.name",
            "value": { "string_value": "claude-code" }
          }, {
            "key": "github.user", 
            "value": { "string_value": "test-user-001" }
          }, {
            "key": "environment",
            "value": { "string_value": "production" }
          }]
        },
        "scope_metrics": [{
          "scope": {
            "name": "claude-code-simulator"
          },
          "metrics": [{
            "name": "$metric_name",
            "unit": "1",
            "gauge": {
              "data_points": [{
                "time_unix_nano": "$timestamp",
                "as_double": $value
                $attr_json
              }]
            }
          }]
        }]
      }]
    }
    EOF
      
      curl -X POST http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318/v1/metrics \
        -H "Content-Type: application/json" \
        -d @/tmp/metrics.json \
        --silent --show-error > /dev/null 2>&1
    }
    
    # Initialize counters
    session_count=1
    total_lines=0
    total_tokens=0
    total_cost=0
    commit_count=0
    pr_count=0
    
    # Send initial session metric
    send_metric "session.count" "$session_count"
    
    while true; do
      echo "$(date): Simulating Claude Code activity..."
      
      # Simulate code editing with language attributes
      languages=("python" "javascript" "go" "rust" "typescript")
      for lang in "${languages[@]}"; do
        if [ $((RANDOM % 3)) -lt 2 ]; then
          lines=$((RANDOM % 50 + 10))
          total_lines=$((total_lines + lines))
          operation=$( [ $((RANDOM % 2)) -eq 0 ] && echo "add" || echo "remove" )
          
          attr='{"key": "operation", "value": {"string_value": "'$operation'"}}, {"key": "language", "value": {"string_value": "'$lang'"}}'
          send_metric "lines_of_code.count" "$total_lines" "$attr"
          echo "  Code modified: $lines lines of $lang ($operation)"
        fi
      done
      
      # Simulate token usage with model attributes
      models=("claude-3-5-sonnet-20241022" "claude-3-opus-20240229" "claude-3-haiku-20240307")
      selected_model=${models[$RANDOM % ${#models[@]}]}
      tokens=$((RANDOM % 500 + 100))
      total_tokens=$((total_tokens + tokens))
      
      # Token usage with type
      for token_type in "input" "output"; do
        type_tokens=$((tokens / 2))
        attr='{"key": "type", "value": {"string_value": "'$token_type'"}}, {"key": "model", "value": {"string_value": "'$selected_model'"}}'
        send_metric "token.usage" "$total_tokens" "$attr"
      done
      echo "  Tokens used: $tokens (model: $selected_model)"
      
      # Simulate cost
      cost=$(echo "scale=4; $tokens * 0.00001" | bc)
      total_cost=$(echo "scale=4; $total_cost + $cost" | bc)
      attr='{"key": "model", "value": {"string_value": "'$selected_model'"}}'
      send_metric "cost.usage" "$total_cost" "$attr"
      echo "  Cost incurred: \$$cost"
      
      # Simulate commits (every 3rd iteration)
      if [ $((RANDOM % 3)) -eq 0 ]; then
        commit_count=$((commit_count + 1))
        send_metric "commit.count" "$commit_count"
        echo "  Git commit created (#$commit_count)"
      fi
      
      # Simulate pull requests (every 5th iteration)
      if [ $((RANDOM % 5)) -eq 0 ]; then
        pr_count=$((pr_count + 1))
        send_metric "pull_request.count" "$pr_count"
        echo "  Pull request created (#$pr_count)"
      fi
      
      # Simulate tool usage decisions
      tools=("Read" "Write" "Edit" "MultiEdit" "Bash")
      decisions=("accepted" "rejected")
      for i in {1..3}; do
        tool=${tools[$RANDOM % ${#tools[@]}]}
        decision=${decisions[$RANDOM % ${#decisions[@]}]}
        language=${languages[$RANDOM % ${#languages[@]}]}
        
        attr='{"key": "tool", "value": {"string_value": "'$tool'"}}, {"key": "decision", "value": {"string_value": "'$decision'"}}, {"key": "language", "value": {"string_value": "'$language'"}}'
        send_metric "code_edit_tool.decision" "1" "$attr"
        echo "  Tool decision: $tool - $decision (language: $language)"
      done
      
      echo "Metrics sent. Waiting 15 seconds..."
      sleep 15
    done
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: claude-code-full-simulator
  namespace: claude-code
spec:
  replicas: 1
  selector:
    matchLabels:
      app: full-simulator
  template:
    metadata:
      labels:
        app: full-simulator
    spec:
      containers:
      - name: simulator
        image: alpine:3.19
        command: ["/bin/sh"]
        args: 
          - -c
          - |
            apk add --no-cache curl bc bash
            bash /scripts/simulate-full-metrics.sh
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 50m
            memory: 64Mi
      volumes:
      - name: scripts
        configMap:
          name: full-simulator
```

### claude-code-metric-simulator.yaml (infra/test-resources/simulators/claude-code-metric-simulator.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: metric-simulator
  namespace: claude-code
data:
  simulate-metrics.sh: |
    #!/bin/bash
    echo "Starting Claude Code metric simulation..."
    
    # Function to send metrics to OTLP
    send_metric() {
      local metric_name=$1
      local value=$2
      local timestamp=$(date +%s)000000000
      
      cat <<EOF > /tmp/metrics.json
    {
      "resource_metrics": [{
        "resource": {
          "attributes": [{
            "key": "service.name",
            "value": { "string_value": "claude-code" }
          }]
        },
        "scope_metrics": [{
          "scope": {
            "name": "claude-code-simulator"
          },
          "metrics": [{
            "name": "$metric_name",
            "unit": "1",
            "gauge": {
              "data_points": [{
                "time_unix_nano": "$timestamp",
                "as_double": $value,
                "attributes": []
              }]
            }
          }]
        }]
      }]
    }
    EOF
      
      # Send to OTLP collector
      curl -X POST http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318/v1/metrics \
        -H "Content-Type: application/json" \
        -d @/tmp/metrics.json \
        --silent --show-error
    }
    
    # Simulate metrics every 10 seconds
    while true; do
      echo "$(date): Sending simulated metrics..."
      
      # Simulate session count
      send_metric "session.count" "1"
      
      # Simulate lines of code (random between 10-100)
      lines=$((RANDOM % 91 + 10))
      send_metric "lines_of_code.count" "$lines"
      
      # Simulate token usage (random between 100-1000)
      tokens=$((RANDOM % 901 + 100))
      send_metric "token.usage" "$tokens"
      
      # Simulate cost (random between 0.01-0.10)
      cost=$(echo "scale=2; ($(($RANDOM % 10)) + 1) / 100" | bc)
      send_metric "cost.usage" "$cost"
      
      echo "Metrics sent: session=1, lines=$lines, tokens=$tokens, cost=$cost"
      
      sleep 10
    done
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: claude-code-metric-simulator
  namespace: claude-code
spec:
  replicas: 1
  selector:
    matchLabels:
      app: metric-simulator
  template:
    metadata:
      labels:
        app: metric-simulator
    spec:
      containers:
      - name: simulator
        image: alpine:3.19
        command: ["/bin/sh"]
        args: 
          - -c
          - |
            apk add --no-cache curl bc bash
            bash /scripts/simulate-metrics.sh
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 50m
            memory: 64Mi
      volumes:
      - name: scripts
        configMap:
          name: metric-simulator
```

### claude-code-log-simulator.yaml (infra/test-resources/simulators/claude-code-log-simulator.yaml)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: log-simulator
  namespace: claude-code
data:
  simulate-logs.sh: |
    #!/bin/bash
    echo "Starting Claude Code log simulation..."
    
    # Function to send logs to OTLP
    send_log() {
      local severity=$1
      local message=$2
      local timestamp=$(date +%s)000000000
      local iso_time=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
      
      cat <<EOF > /tmp/logs.json
    {
      "resource_logs": [{
        "resource": {
          "attributes": [{
            "key": "service.name",
            "value": { "string_value": "claude-code" }
          }, {
            "key": "service.namespace",
            "value": { "string_value": "claude-code" }
          }, {
            "key": "github.user",
            "value": { "string_value": "claude-agent-001" }
          }, {
            "key": "environment",
            "value": { "string_value": "production" }
          }]
        },
        "scope_logs": [{
          "scope": {
            "name": "claude-code-logger"
          },
          "log_records": [{
            "time_unix_nano": "$timestamp",
            "severity_number": $severity,
            "severity_text": "$1",
            "body": {
              "string_value": "$message"
            },
            "attributes": [{
              "key": "timestamp",
              "value": { "string_value": "$iso_time" }
            }, {
              "key": "event.type",
              "value": { "string_value": "claude.log" }
            }]
          }]
        }]
      }]
    }
    EOF
      
      # Send to OTLP collector
      curl -X POST http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318/v1/logs \
        -H "Content-Type: application/json" \
        -d @/tmp/logs.json \
        --silent --show-error
    }
    
    # Simulate various log messages
    while true; do
      echo "$(date): Sending simulated logs..."
      
      # Info log - Session started
      send_log 9 "INFO" "Claude Code session started"
      sleep 2
      
      # Info log - Task execution
      task_type=("code_generation" "code_review" "debugging" "refactoring")
      selected_task=${task_type[$RANDOM % ${#task_type[@]}]}
      send_log 9 "INFO" "Executing task: $selected_task"
      sleep 3
      
      # Debug log - Tool usage
      tools=("Read" "Write" "Edit" "Bash" "Search")
      selected_tool=${tools[$RANDOM % ${#tools[@]}]}
      send_log 5 "DEBUG" "Tool invoked: $selected_tool"
      sleep 2
      
      # Info log - Metrics
      lines=$((RANDOM % 100 + 10))
      send_log 9 "INFO" "Code modified: $lines lines"
      sleep 2
      
      # Occasional warning
      if [ $((RANDOM % 5)) -eq 0 ]; then
        send_log 13 "WARN" "Rate limit approaching: 80% of quota used"
        sleep 1
      fi
      
      # Info log - Completion
      send_log 9 "INFO" "Task completed successfully"
      
      echo "Log batch sent"
      sleep 10
    done
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: claude-code-log-simulator
  namespace: claude-code
spec:
  replicas: 1
  selector:
    matchLabels:
      app: log-simulator
  template:
    metadata:
      labels:
        app: log-simulator
    spec:
      containers:
      - name: simulator
        image: alpine:3.19
        command: ["/bin/sh"]
        args: 
          - -c
          - |
            apk add --no-cache curl bash
            bash /scripts/simulate-logs.sh
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 50m
            memory: 64Mi
      volumes:
      - name: scripts
        configMap:
          name: log-simulator
```

### test-volume-pod.yaml (infra/test-resources/test-pods/test-volume-pod.yaml)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-volume
  namespace: telemetry
spec:
  nodeSelector:
    kubernetes.io/hostname: talos-a43-ee1  # Force to worker node
  containers:
  - name: test
    image: busybox
    command: ["sh", "-c", "ls -la /var/mnt/ && sleep 3600"]
    volumeMounts:
    - name: host-var
      mountPath: /var/mnt
      readOnly: true
  volumes:
  - name: host-var
    hostPath:
      path: /var/mnt
      type: Directory
```

### create-storage-dirs.yaml (infra/test-resources/create-storage-dirs.yaml)

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: create-storage-dirs
  namespace: telemetry
spec:
  template:
    metadata:
      labels:
        app: create-dirs
    spec:
      nodeSelector:
        kubernetes.io/hostname: talos-a43-ee1
      restartPolicy: Never
      containers:
      - name: create-dirs
        image: busybox
        command: 
        - sh
        - -c
        - |
          mkdir -p /host/var/telemetry-storage/victoria-metrics
          mkdir -p /host/var/telemetry-storage/victoria-logs
          mkdir -p /host/var/telemetry-storage/grafana
          mkdir -p /host/var/telemetry-storage/claude-code-workspace
          chmod -R 777 /host/var/telemetry-storage
          ls -la /host/var/telemetry-storage/
        volumeMounts:
        - name: host-var
          mountPath: /host/var
        securityContext:
          privileged: true
      volumes:
      - name: host-var
        hostPath:
          path: /var
          type: Directory
```

### claude-code-telemetry-test-job.yaml (infra/test-resources/claude-code-telemetry-test-job.yaml)

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: claude-code-telemetry-test
  namespace: claude-code
spec:
  template:
    metadata:
      labels:
        app: claude-code-test
    spec:
      restartPolicy: Never
      imagePullSecrets:
      - name: ghcr-secret
      containers:
      - name: claude-code
        image: ghcr.io/5dlabs/platform/claude-code:latest
        command: ["claude"]
        args:
          - "-p"
          - "Create a Python script that calculates fibonacci numbers. Include proper documentation. Save it as fibonacci.py"
        env:
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: claude-code-secret
              key: ANTHROPIC_API_KEY
        - name: CLAUDE_CODE_ENABLE_TELEMETRY
          value: "1"
        - name: OTEL_METRICS_EXPORTER
          value: "otlp"
        - name: OTEL_LOGS_EXPORTER
          value: "otlp"
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4318"
        - name: OTEL_EXPORTER_OTLP_PROTOCOL
          value: "http/protobuf"
        - name: OTEL_SERVICE_NAME
          value: "claude-code"
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.name=claude-code,environment=production,github.user=test-job"
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
```

