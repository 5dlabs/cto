apiVersion: v1
kind: ServiceAccount
metadata:
  name: cleanup-sa
  namespace: orchestrator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cleanup-role
  namespace: orchestrator
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "delete"]
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["get", "list", "delete"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: cleanup-rolebinding
  namespace: orchestrator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cleanup-role
subjects:
- kind: ServiceAccount
  name: cleanup-sa
  namespace: orchestrator
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cleanup-script
  namespace: orchestrator
data:
  cleanup.sh: |
    #!/bin/bash
    set -e

    echo "Starting cleanup job at $(date)"

    # Configuration
    NAMESPACE="orchestrator"
    FAILED_POD_AGE_HOURS=24  # Delete failed pods older than 24 hours
    COMPLETED_POD_AGE_HOURS=1 # Delete completed pods older than 1 hour
    COMPLETED_JOB_AGE_DAYS=7 # Delete completed jobs older than 7 days
    ORPHANED_CM_AGE_DAYS=7   # Delete orphaned configmaps older than 7 days

    echo "Configuration:"
    echo "- Failed pods older than: ${FAILED_POD_AGE_HOURS} hours"
    echo "- Completed pods older than: ${COMPLETED_POD_AGE_HOURS} hour"
    echo "- Completed jobs older than: ${COMPLETED_JOB_AGE_DAYS} days"
    echo "- Orphaned ConfigMaps older than: ${ORPHANED_CM_AGE_DAYS} days"
    echo ""

    # Function to get age in seconds
    get_age_seconds() {
        local timestamp=$1
        local current=$(date +%s)
        local created=$(date -d "$timestamp" +%s 2>/dev/null || echo 0)
        echo $((current - created))
    }

    # Clean up failed pods
    echo "=== Cleaning up failed pods ==="
    FAILED_POD_COUNT=0
    kubectl get pods -n $NAMESPACE -o json | jq -r '.items[] | select(.status.phase == "Failed" or .status.phase == "Error") | "\(.metadata.name)|\(.metadata.creationTimestamp)"' | while IFS='|' read -r pod_name created_time; do
        age_seconds=$(get_age_seconds "$created_time")
        age_hours=$((age_seconds / 3600))

        if [ $age_hours -gt $FAILED_POD_AGE_HOURS ]; then
            echo "Deleting failed pod: $pod_name (age: ${age_hours}h)"
            kubectl delete pod -n $NAMESPACE "$pod_name" --grace-period=0 --force 2>/dev/null || true
            ((FAILED_POD_COUNT++))
        else
            echo "Keeping failed pod: $pod_name (age: ${age_hours}h)"
        fi
    done
    echo "Deleted $FAILED_POD_COUNT failed pods"
    echo ""

    # Clean up completed pods (not associated with jobs)
    echo "=== Cleaning up completed pods ==="
    COMPLETED_POD_COUNT=0
    kubectl get pods -n $NAMESPACE -o json | jq -r '.items[] | select(.status.phase == "Succeeded") | "\(.metadata.name)|\(.metadata.creationTimestamp)|\(.metadata.ownerReferences[0].kind // "none")"' | while IFS='|' read -r pod_name created_time owner_kind; do
        # Skip pods owned by jobs (they'll be cleaned up with their jobs)
        if [ "$owner_kind" != "Job" ]; then
            age_seconds=$(get_age_seconds "$created_time")
            age_hours=$((age_seconds / 3600))

            if [ $age_hours -gt $COMPLETED_POD_AGE_HOURS ]; then
                echo "Deleting completed pod: $pod_name (age: ${age_hours}h, owner: $owner_kind)"
                kubectl delete pod -n $NAMESPACE "$pod_name" --grace-period=0 --force 2>/dev/null || true
                ((COMPLETED_POD_COUNT++))
            else
                echo "Keeping completed pod: $pod_name (age: ${age_hours}h)"
            fi
        fi
    done
    echo "Deleted $COMPLETED_POD_COUNT completed pods"
    echo ""

    # Clean up completed jobs (and their pods)
    echo "=== Cleaning up completed jobs ==="
    COMPLETED_JOB_COUNT=0
    kubectl get jobs -n $NAMESPACE -o json | jq -r '.items[] | select(.status.succeeded > 0) | "\(.metadata.name)|\(.metadata.creationTimestamp)"' | while IFS='|' read -r job_name created_time; do
        age_seconds=$(get_age_seconds "$created_time")
        age_days=$((age_seconds / 86400))

        if [ $age_days -gt $COMPLETED_JOB_AGE_DAYS ]; then
            echo "Deleting completed job: $job_name (age: ${age_days}d)"
            kubectl delete job -n $NAMESPACE "$job_name" --cascade=background 2>/dev/null || true
            ((COMPLETED_JOB_COUNT++))
        else
            echo "Keeping completed job: $job_name (age: ${age_days}d)"
        fi
    done
    echo "Deleted $COMPLETED_JOB_COUNT completed jobs"
    echo ""

    # Clean up orphaned ConfigMaps (those without corresponding jobs)
    echo "=== Cleaning up orphaned ConfigMaps ==="
    ORPHANED_CM_COUNT=0

    # Get all jobs to build a list of expected ConfigMaps
    ACTIVE_CONFIGMAPS=$(kubectl get jobs -n $NAMESPACE -o json | jq -r '.items[].metadata.name' | sed 's/$//' | sort | uniq)

    # Check each ConfigMap that matches our pattern
    kubectl get configmaps -n $NAMESPACE -o json | jq -r '.items[] | select(.metadata.name | test("^[a-zA-Z0-9-]+-[0-9]+-v[0-9]+-files$")) | "\(.metadata.name)|\(.metadata.creationTimestamp)"' | while IFS='|' read -r cm_name created_time; do
        # Extract job name from ConfigMap name (format: service-taskid-version-files)
        job_base=$(echo "$cm_name" | sed 's/-files$//')

        # Check if corresponding job exists
        if ! kubectl get job -n $NAMESPACE "$job_base" &>/dev/null; then
            age_seconds=$(get_age_seconds "$created_time")
            age_days=$((age_seconds / 86400))

            if [ $age_days -gt $ORPHANED_CM_AGE_DAYS ]; then
                echo "Deleting orphaned ConfigMap: $cm_name (age: ${age_days}d)"
                kubectl delete configmap -n $NAMESPACE "$cm_name" 2>/dev/null || true
                ((ORPHANED_CM_COUNT++))
            else
                echo "Keeping orphaned ConfigMap: $cm_name (age: ${age_days}d)"
            fi
        fi
    done
    echo "Deleted $ORPHANED_CM_COUNT orphaned ConfigMaps"
    echo ""

    # Summary
    echo "=== Cleanup Summary ==="
    echo "Failed pods deleted: $FAILED_POD_COUNT"
    echo "Completed pods deleted: $COMPLETED_POD_COUNT"
    echo "Completed jobs deleted: $COMPLETED_JOB_COUNT"
    echo "Orphaned ConfigMaps deleted: $ORPHANED_CM_COUNT"
    echo ""

    # Show current resource usage
    echo "=== Current Resource Status ==="
    echo "Total Pods: $(kubectl get pods -n $NAMESPACE --no-headers | wc -l)"
    echo "  - Running: $(kubectl get pods -n $NAMESPACE --field-selector=status.phase=Running --no-headers | wc -l)"
    echo "  - Succeeded: $(kubectl get pods -n $NAMESPACE --field-selector=status.phase=Succeeded --no-headers | wc -l)"
    echo "  - Failed: $(kubectl get pods -n $NAMESPACE --field-selector=status.phase=Failed --no-headers | wc -l)"
    echo "  - Pending: $(kubectl get pods -n $NAMESPACE --field-selector=status.phase=Pending --no-headers | wc -l)"
    echo "Jobs: $(kubectl get jobs -n $NAMESPACE --no-headers | wc -l)"
    echo "ConfigMaps: $(kubectl get configmaps -n $NAMESPACE --no-headers | grep -E '^[a-zA-Z0-9-]+-[0-9]+-v[0-9]+-files' | wc -l)"
    echo ""

    echo "Cleanup completed at $(date)"
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: orchestrator-cleanup
  namespace: orchestrator
spec:
  # Run every day at 2 AM
  schedule: "0 2 * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      # Cleanup job itself should be cleaned up after 24 hours
      ttlSecondsAfterFinished: 86400
      template:
        spec:
          serviceAccountName: cleanup-sa
          containers:
          - name: cleanup
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - /scripts/cleanup.sh
            volumeMounts:
            - name: cleanup-script
              mountPath: /scripts
            env:
            - name: TZ
              value: "UTC"
          volumes:
          - name: cleanup-script
            configMap:
              name: cleanup-script
              defaultMode: 0755
          restartPolicy: OnFailure