---
# Example Redis Failover cluster for development environments
# This creates a Redis cluster with Sentinel for high availability
# Suitable for development and testing, NOT for production without modifications

apiVersion: databases.spotahome.com/v1
kind: RedisFailover
metadata:
  name: redis-dev
  namespace: databases
  labels:
    team: platform
    environment: development
    app.kubernetes.io/name: redis-dev
    app.kubernetes.io/component: cache
spec:
  # Sentinel configuration - manages failover
  sentinel:
    # Number of sentinels (should be odd number for quorum)
    replicas: 3
    
    # Sentinel resources
    resources:
      requests:
        cpu: 50m
        memory: 50Mi
      limits:
        cpu: 100m
        memory: 100Mi
    
    # Custom Sentinel configuration
    customConfig:
      - "down-after-milliseconds 5000"  # Time to consider master down
      - "failover-timeout 10000"         # Failover timeout
      - "parallel-syncs 1"               # Number of replicas to sync in parallel
    
    # Affinity rules to spread sentinels across nodes
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: redisfailover.databases.spotahome.com/name
                operator: In
                values:
                - redis-dev
              - key: redisfailover.databases.spotahome.com/component
                operator: In
                values:
                - sentinel
            topologyKey: kubernetes.io/hostname
  
  # Redis configuration
  redis:
    # Number of Redis instances (1 master + N-1 replicas)
    replicas: 3
    
    # Redis resources
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi
    
    # Redis version (image tag)
    image: redis:7.2-alpine
    imagePullPolicy: IfNotPresent
    
    # Custom Redis configuration
    customConfig:
      - "maxmemory 512mb"                    # Max memory limit
      - "maxmemory-policy allkeys-lru"       # Eviction policy when memory is full
      - "save 900 1"                          # Save after 900 sec if at least 1 key changed
      - "save 300 10"                         # Save after 300 sec if at least 10 keys changed
      - "save 60 10000"                       # Save after 60 sec if at least 10000 keys changed
      - "appendonly yes"                      # Enable AOF persistence
      - "appendfsync everysec"                # Fsync policy for AOF
      - "no-appendfsync-on-rewrite no"       # Fsync during AOF rewrite
      - "auto-aof-rewrite-percentage 100"     # AOF rewrite trigger (percentage)
      - "auto-aof-rewrite-min-size 64mb"      # AOF rewrite min size
      - "tcp-keepalive 60"                    # TCP keepalive
      - "tcp-backlog 511"                     # TCP listen backlog
      - "timeout 0"                           # Client idle timeout (0 = disabled)
      - "databases 16"                        # Number of databases
      - "slowlog-log-slower-than 10000"      # Slow query threshold (microseconds)
      - "slowlog-max-len 128"                # Max slow queries to keep
      
    # Storage configuration for persistence
    storage:
      persistentVolumeClaim:
        metadata:
          name: redis-data
        spec:
          accessModes:
            - ReadWriteOnce
          storageClassName: local-path  # Adjust based on your cluster
          resources:
            requests:
              storage: 10Gi
    
    # Service configuration
    service:
      type: ClusterIP
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9121"
        prometheus.io/path: "/metrics"
    
    # Pod disruption budget
    podDisruptionBudget:
      maxUnavailable: 1
    
    # Affinity rules to spread Redis instances across nodes
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: redisfailover.databases.spotahome.com/name
                operator: In
                values:
                - redis-dev
              - key: redisfailover.databases.spotahome.com/component
                operator: In
                values:
                - redis
            topologyKey: kubernetes.io/hostname
    
    # Security context
    securityContext:
      runAsUser: 999
      runAsGroup: 999
      fsGroup: 999
      runAsNonRoot: true
    
    # Tolerations (optional)
    # tolerations:
    #   - key: "database"
    #     operator: "Equal"
    #     value: "redis"
    #     effect: "NoSchedule"
    
    # Priority class (optional)
    # priorityClassName: "high-priority"
    
    # Volume mount for custom scripts (optional)
    # extraVolumes:
    #   - name: scripts
    #     configMap:
    #       name: redis-scripts
    # extraVolumeMounts:
    #   - name: scripts
    #     mountPath: /scripts
    
  # Authentication configuration (optional, recommended for production)
  # auth:
  #   secretPath: redis-auth
  
  # Exporter configuration for Prometheus metrics (optional)
  # exporter:
  #   enabled: true
  #   image: oliver006/redis_exporter:v1.55.0
  #   resources:
  #     requests:
  #       cpu: 50m
  #       memory: 50Mi
  #     limits:
  #       cpu: 100m
  #       memory: 100Mi

---
# ConfigMap for Redis connection info (optional)
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-dev-config
  namespace: databases
  labels:
    team: platform
    cluster-name: redis-dev
data:
  # Connection endpoints
  REDIS_MASTER_ENDPOINT: "rfs-redis-dev.databases.svc.cluster.local:26379"
  REDIS_SENTINEL_ENDPOINTS: "rfs-redis-dev.databases.svc.cluster.local:26379"
  REDIS_MASTER_NAME: "mymaster"
  
  # Connection example for applications
  connection-example: |
    # For applications using Sentinel-aware clients:
    redis://rfs-redis-dev.databases.svc.cluster.local:26379/mymaster
    
    # For direct connection (not recommended, use sentinel):
    redis://rfr-redis-dev.databases.svc.cluster.local:6379
    
    # Example code (Python with redis-py):
    from redis.sentinel import Sentinel
    sentinel = Sentinel([
        ('rfs-redis-dev.databases.svc.cluster.local', 26379)
    ])
    master = sentinel.master_for('mymaster', socket_timeout=0.1)
    master.set('key', 'value')
