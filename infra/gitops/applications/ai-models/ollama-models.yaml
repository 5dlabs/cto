---
# Ollama Operator Models - Deploy Ollama models via native Kubernetes CRDs
# Uses the ollama.ayaka.io/v1 Model CRD from Ollama Operator
# License: Apache 2.0 (Ollama Operator), MIT (Ollama runtime)
#
# Differences from KubeAI:
# - Native Ollama runtime (not vLLM)
# - Simpler CRD syntax
# - Better for CPU-only or mixed workloads
# - Model storage via PersistentVolumes
#
# Access models via:
#   kubectl port-forward svc/ollama-model-<name> 11434:11434
#   ollama run <model-name>
#   curl http://localhost:11434/v1/chat/completions

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama-models
  namespace: argocd
  labels:
    app.kubernetes.io/name: ollama-models
    app.kubernetes.io/part-of: platform
    app.kubernetes.io/component: ai-ml
  annotations:
    # Deploy after Ollama Operator is ready
    argocd.argoproj.io/sync-wave: "2"
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: platform

  source:
    repoURL: https://github.com/5dlabs/cto.git
    path: infra/gitops/applications/ai-models/ollama-model-crds
    targetRevision: develop

  destination:
    server: https://kubernetes.default.svc
    namespace: ollama-operator-system

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: true

    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true

    retry:
      limit: 3
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 1m

  revisionHistoryLimit: 5
