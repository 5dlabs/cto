# This file is auto-generated by scripts/generate-templates-configmap.sh
# DO NOT EDIT MANUALLY - edit the source files in claude-templates/ instead
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "controller.fullname" . }}-claude-templates
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "controller.labels" . | nindent 4 }}
  annotations:
    generated-at: "2025-08-31T03:55:56Z"
data:
  agents_system-prompt.md.hbs: |
    ---
    name: {{`{{`{{`}}`}}agent_name{{`}}`}}
    description: {{`{{`{{`}}`}}agent_description{{`}}`}}
    # tools: omitted to inherit all available tools
    ---
    
    {{`{{`{{`}}`}}system_prompt{{`}}`}}
  code_claude.md.hbs: |
    # Claude Code Project Memory
    
    ## Project Information
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Source Branch**: {{`{{`{{`}}`}}docs_branch{{`}}`}}
    - **GitHub App**: {{`{{`{{`}}`}}github_app{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    - **Implementation Target**: task {{`{{`{{`}}`}}task_id{{`}}`}}
    
    ## Tool Capabilities
    
    See @mcp-tools.md for your available tools and usage guidelines
    
    ## Project Guidelines & Standards
    
    See @coding-guidelines.md for project coding standards and best practices
    See @github-guidelines.md for git workflow and commit message standards
    
    ### Pre-PR Quality Gates (MUST PASS BEFORE PR)
    
    You may NOT create a PR until ALL of the following succeed locally:
    - Formatting check: `cargo fmt --all -- --check`
    - Clippy with pedantic lints and zero warnings: `cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic`
    - Tests passing and high coverage (target ≥95%, strive for ~100% on critical paths):
      - Recommended: `cargo llvm-cov --workspace --all-features --fail-under-lines 95`
      - Alternative: `cargo tarpaulin --all --fail-under 95`
    
    ## Current Task Documentation
    
    {{`{{`{{`}}`}}#if task_id{{`}}`}}
    **Your current task ({{`{{`{{`}}`}}task_id{{`}}`}}) documentation:**
    - See @task/task.md for requirements and description
    - See @task/acceptance-criteria.md for success criteria
    - See @task/architecture.md for technical approach and guidance
    {{`{{`{{`}}`}}else{{`}}`}}
    **General project documentation:**
    - See @README.md for project overview and setup instructions
    - See @.taskmaster/docs/architecture.md for system design patterns
    - See @.taskmaster/docs/prd.txt for product requirements
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    ## System Architecture & Context
    
    See @.taskmaster/docs/architecture.md for system design patterns and architectural decisions
    {{`{{`{{`}}`}}#if docsRepositoryUrl{{`}}`}}See @.taskmaster/docs/prd.txt for complete product requirements{{`{{`{{`}}`}}/if{{`}}`}}
    
    ## Implementation Workflow
    
    {{`{{`{{`}}`}}#if task_id{{`}}`}}
    ### Current Task Process
    1. **Understand**: Read @task/task.md for requirements
    2. **Plan**: Review @task/architecture.md for technical approach
    3. **Validate**: Check @task/acceptance-criteria.md for success criteria
    4. **Code**: Follow patterns in @coding-guidelines.md
    5. **Commit**: Use standards from @github-guidelines.md
    6. **Test**: Verify all acceptance criteria are met
    
    ### Task Context
    - **Task ID**: {{`{{`{{`}}`}}task_id{{`}}`}}
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Branch**: {{`{{`{{`}}`}}docs_branch{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    {{`{{`{{`}}`}}else{{`}}`}}
    ### General Development Process
    1. **Explore**: Understand existing codebase structure
    2. **Plan**: Follow established patterns and conventions
    3. **Implement**: Adhere to @coding-guidelines.md standards
    4. **Test**: Ensure changes meet project quality standards
    5. **Commit**: Follow @github-guidelines.md workflow
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    ## Quick Command Reference
    
    ### Testing & Quality
    ```bash
    # Rust: run tests
    cargo test --workspace --all-features
    
    # Rust: formatting (must pass before PR)
    cargo fmt --all -- --check
    
    # Rust: clippy with pedantic and deny warnings (must pass before PR)
    cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic
    
    # Optional: coverage targets (recommended ≥95%)
    cargo llvm-cov --workspace --all-features --fail-under-lines 95 || \
      cargo tarpaulin --all --fail-under 95
    
    # Build verification
    cargo build --workspace --all-features
    ```
    
    ### Git Workflow
    ```bash
    {{`{{`{{`}}`}}#if task_id{{`}}`}}
    # Commit with task-specific message (see @github-guidelines.md for details)
    git commit -m "feat(task-{{`{{`{{`}}`}}task_id{{`}}`}}): implement [brief description]
    
    - [specific changes made]
    - [tests added/updated]
    - [meets acceptance criteria: X, Y, Z]"
    {{`{{`{{`}}`}}else{{`}}`}}
    # Standard commit message (see @github-guidelines.md for format)
    git commit -m "feat: implement [brief description]"
    {{`{{`{{`}}`}}/if{{`}}`}}
    ```
    
    ## Pull Request Requirements
    
    **CRITICAL**: After completing implementation, create `PR_DESCRIPTION.md` in the working directory root with:
    
    1. Concise implementation summary (2-3 sentences)
    2. Key changes made (bullet points)
    3. Important reviewer notes
    4. Testing recommendations
    
    This file enables automatic pull request creation.
    
    **IMPORTANT PR HANDLING**:
    - Always check if a PR already exists for this task before creating PR_DESCRIPTION.md
    - Use `gh pr list --state all --label "task-{{`{{`{{`}}`}}task_id{{`}}`}}"` to find existing PRs for your task
    - If a PR exists and is OPEN: do NOT create PR_DESCRIPTION.md (continue working on the existing PR)
    - If a PR exists and is MERGED: the task is complete - do NOT create a new PR
    - If a PR exists and is CLOSED (not merged): create a new PR with PR_DESCRIPTION.md
    - Only create PR_DESCRIPTION.md when there's no open PR or when reopening after a closed (unmerged) PR
    
    Additional PR gating rules:
    - Do NOT open a PR unless: `cargo fmt --all -- --check` passes, `cargo clippy ... -D warnings -W clippy::pedantic` passes, and all tests pass
    - Aim for ≥95% coverage; target ~100% on critical code paths before PR
    
    ## Development Tools & Patterns
    
    ### Claude Code Integration
    - Use `LS` and `Glob` to explore codebase structure
    - Use `Read` to examine existing code patterns
    - Use `Grep` to find similar implementations
    - Use `Edit` for targeted changes, `MultiEdit` for related changes
    - Validate with `Bash` commands after each change
    
    ### Implementation Guidelines
    {{`{{`{{`}}`}}#if task_id{{`}}`}}
    - Focus on current task requirements in `task/` directory
    - Follow architectural guidance provided in @task/architecture.md
    - Ensure all acceptance criteria are met before completion
    - Use established patterns from @coding-guidelines.md
    {{`{{`{{`}}`}}else{{`}}`}}
    - Explore existing codebase structure before making changes
    - Follow established patterns and conventions
    - Ensure changes align with project architecture
    - Maintain backward compatibility unless explicitly changing interfaces
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    ---
    
    *All referenced files (@filename) are automatically imported into Claude's context. For detailed information on any topic, refer to the specific imported files above.*  code_client-config.json.hbs: |
    {
      {{`{{`{{`}}`}}#if remote_tools{{`}}`}}
      "remoteTools": [
        {{`{{`{{`}}`}}#each remote_tools{{`}}`}}
        "{{`{{`{{`}}`}}this{{`}}`}}"{{`{{`{{`}}`}}#unless @last{{`}}`}},{{`{{`{{`}}`}}/unless{{`}}`}}
        {{`{{`{{`}}`}}/each{{`}}`}}
      ]{{`{{`{{`}}`}}#if (eq tool_config "advanced"){{`}}`}},{{`{{`{{`}}`}}/if{{`}}`}}
      {{`{{`{{`}}`}}else{{`}}`}}
      {{`{{`{{`}}`}}#if (eq tool_config "minimal"){{`}}`}}
      "remoteTools": []{{`{{`{{`}}`}}#if (eq tool_config "advanced"){{`}}`}},{{`{{`{{`}}`}}/if{{`}}`}}
      {{`{{`{{`}}`}}else if (eq tool_config "default"){{`}}`}}
      "remoteTools": [
        "brave-search_brave_web_search",
        "memory_create_entities",
        "rustdocs_query_rust_docs"
      ]{{`{{`{{`}}`}}#if (eq tool_config "advanced"){{`}}`}},{{`{{`{{`}}`}}/if{{`}}`}}
      {{`{{`{{`}}`}}else if (eq tool_config "advanced"){{`}}`}}
      "remoteTools": [
        "brave-search_brave_web_search",
        "memory_create_entities",
        "rustdocs_query_rust_docs",
        "github_create_issue",
        "kubernetes_listResources",
        "terraform_list_providers"
      ],
      {{`{{`{{`}}`}}else{{`}}`}}
      "remoteTools": [
        "brave-search_brave_web_search",
        "memory_create_entities",
        "rustdocs_query_rust_docs"
      ]{{`{{`{{`}}`}}#if (eq tool_config "advanced"){{`}}`}},{{`{{`{{`}}`}}/if{{`}}`}}
      {{`{{`{{`}}`}}/if{{`}}`}}
      {{`{{`{{`}}`}}/if{{`}}`}}
      {{`{{`{{`}}`}}#if (eq tool_config "advanced"){{`}}`}}
      "localServers": {
        "filesystem": {
          "command": "npx",
          "args": ["-y", "@modelcontextprotocol/server-filesystem", "/workspace"],
          "tools": [
            {{`{{`{{`}}`}}#if local_tools{{`}}`}}
            {{`{{`{{`}}`}}#each local_tools{{`}}`}}
            "{{`{{`{{`}}`}}this{{`}}`}}"{{`{{`{{`}}`}}#unless @last{{`}}`}},{{`{{`{{`}}`}}/unless{{`}}`}}
            {{`{{`{{`}}`}}/each{{`}}`}}
            {{`{{`{{`}}`}}else{{`}}`}}
            "read_file",
            "write_file",
            "list_directory",
            "create_directory"
            {{`{{`{{`}}`}}/if{{`}}`}}
          ],
          "workingDirectory": "project_root"
        }
      }
      {{`{{`{{`}}`}}/if{{`}}`}}
    }  code_coding-guidelines.md.hbs: |
    # Rust Coding Guidelines
    
    This document provides coding standards and best practices for Rust development in this project.
    
    ## Pre-PR Quality Gates (MANDATORY)
    
    Before opening any pull request or requesting merge:
    
    - Ensure formatting passes:
      - Run: `cargo fmt --all -- --check`
    - Ensure Clippy passes with pedantic lints and no warnings:
      - Run: `cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic`
      - If a pedantic lint must be allowed, use the narrowest scope with `#[allow(clippy::lint_name)]` and include a short justification above the code. Avoid crate-wide allows.
    - Ensure tests pass and coverage is very high (strive for ~100% on critical code paths):
      - Run: `cargo test --workspace --all-features`
      - Recommended coverage tools:
        - If available: `cargo llvm-cov --workspace --all-features --fail-under-lines 95`
        - Alternatively: `cargo tarpaulin --all --fail-under 95`
    - Do not create a PR until all gates above are green locally.
    
    ## Code Quality Standards
    
    ### Error Handling
    - Use `Result<T, E>` for fallible operations
    - Use `anyhow::Result` for application-level errors
    - Use `thiserror` for library-level custom errors
    - Always handle errors explicitly - avoid `unwrap()` in production code
    - Use `?` operator for error propagation
    - Provide meaningful error messages with context
    
    ### Memory Management
    - Prefer owned types (`String`, `Vec<T>`) over borrowed types for struct fields
    - Use `Cow<str>` when you need flexibility between owned and borrowed strings
    - Minimize `clone()` calls - consider borrowing or moving when possible
    - Use `Arc<T>` for shared immutable data across threads
    - Use `Rc<T>` for shared data within single-threaded contexts
    
    ### Async Programming
    - Use `async`/`await` for I/O-bound operations
    - Use `tokio` runtime for async execution
    - Prefer `async fn` over `impl Future`
    - Use `tokio::spawn` for concurrent tasks
    - Handle cancellation with `tokio::select!` when appropriate
    
    ## Code Organization
    
    ### Module Structure
    ```rust
    // Public API at the top
    pub use self::public_types::*;
    
    // Private modules
    mod private_implementation;
    mod public_types;
    
    // Re-exports for convenience
    pub mod prelude {
        pub use super::{PublicType, PublicTrait};
    }
    ```
    
    ### Naming Conventions
    - Use `snake_case` for variables, functions, and modules
    - Use `PascalCase` for types, traits, and enum variants
    - Use `SCREAMING_SNAKE_CASE` for constants
    - Use descriptive names - avoid abbreviations
    - Prefix boolean functions with `is_`, `has_`, or `can_`
    
    ### Documentation
    - Document all public APIs with `///` comments
    - Include examples in documentation when helpful
    - Use `//!` for module-level documentation
    - Keep documentation up-to-date with code changes
    
    ## Performance Guidelines
    
    ### Allocations
    - Minimize heap allocations in hot paths
    - Use `Vec::with_capacity()` when size is known
    - Consider `SmallVec` for collections that are usually small
    - Use string formatting (`format!`) judiciously
    
    ### Collections
    - Use `HashMap` for general key-value storage
    - Use `BTreeMap` when ordering matters
    - Use `HashSet` for unique values
    - Use `VecDeque` for FIFO/LIFO operations
    
    ### Iterators
    - Prefer iterator chains over explicit loops when readable
    - Use `collect()` only when necessary
    - Consider `fold()` and `reduce()` for aggregations
    - Use `Iterator::find()` instead of filtering then taking first
    
    ## Testing Guidelines
    
    ### Unit Tests
    ```rust
    #[cfg(test)]
    mod tests {
        use super::*;
    
        #[test]
        fn test_function_name() {
            // Given
            let input = setup_test_data();
    
            // When
            let result = function_under_test(input);
    
            // Then
            assert_eq!(result, expected_value);
        }
    
        #[test]
        #[should_panic(expected = "specific error message")]
        fn test_error_conditions() {
            // Test error conditions
        }
    }
    ```
    
    ### Integration Tests
    - Place integration tests in `tests/` directory
    - Test public API only
    - Use realistic data and scenarios
    - Test error conditions and edge cases
    
    ## Security Guidelines
    
    ### Input Validation
    - Validate all external input
    - Use type-safe parsing (`str::parse()`)
    - Sanitize data before storage or transmission
    - Use prepared statements for database queries
    
    ### Secrets Management
    - Never hardcode secrets in source code
    - Use environment variables for configuration
    - Use secure random number generation (`rand::thread_rng()`)
    - Clear sensitive data from memory when possible
    
    ## Rust-Specific Best Practices
    
    ### Pattern Matching
    ```rust
    // Prefer exhaustive matching
    match value {
        Some(x) => handle_some(x),
        None => handle_none(),
    }
    
    // Use if-let for single pattern
    if let Some(value) = optional_value {
        process_value(value);
    }
    ```
    
    ### Ownership
    - Pass by reference (`&T`) for read-only access
    - Pass by mutable reference (`&mut T`) for modification
    - Pass by value (`T`) for ownership transfer
    - Use `Clone` when multiple ownership is needed
    
    ### Traits
    - Implement common traits (`Debug`, `Clone`, `PartialEq`)
    - Use trait bounds instead of concrete types in generics
    - Prefer composition over inheritance (use traits)
    
    ## Service Architecture Guidelines
    
    ### Project Structure
    ```
    src/
    ├── bin/           # Binary targets
    ├── lib.rs         # Library root
    ├── config/        # Configuration management
    ├── handlers/      # Request handlers
    ├── models/        # Data models
    ├── services/      # Business logic
    └── utils/         # Utility functions
    ```
    
    ### Configuration
    - Use `serde` for configuration deserialization
    - Support both file-based and environment-based config
    - Provide sensible defaults
    - Validate configuration on startup
    
    ### Logging
    - Use `tracing` for structured logging
    - Include relevant context in log messages
    - Use appropriate log levels (error, warn, info, debug, trace)
    - Avoid logging sensitive information
    
    ## Common Patterns
    
    ### Builder Pattern
    ```rust
    pub struct ConfigBuilder {
        host: Option<String>,
        port: Option<u16>,
    }
    
    impl ConfigBuilder {
        pub fn new() -> Self {
            Self { host: None, port: None }
        }
    
        pub fn host(mut self, host: impl Into<String>) -> Self {
            self.host = Some(host.into());
            self
        }
    
        pub fn port(mut self, port: u16) -> Self {
            self.port = Some(port);
            self
        }
    
        pub fn build(self) -> Result<Config> {
            Ok(Config {
                host: self.host.unwrap_or_else(|| "localhost".to_string()),
                port: self.port.unwrap_or(8080),
            })
        }
    }
    ```
    
    ### Resource Management
    ```rust
    // Use RAII for resource cleanup
    pub struct Database {
        connection: DatabaseConnection,
    }
    
    impl Database {
        pub fn new(url: &str) -> Result<Self> {
            let connection = DatabaseConnection::open(url)?;
            Ok(Self { connection })
        }
    }
    
    impl Drop for Database {
        fn drop(&mut self) {
            // Cleanup happens automatically
            self.connection.close();
        }
    }
    ```
    
    Remember: These guidelines promote code that is safe, performant, and maintainable. When in doubt, choose clarity over cleverness.
    
    ## Documentation-Driven Implementation
    
    When implementing or modifying code covered by these guidelines and when an internal document server is available:
    
    - Always query the document server for the recommended, best-practice approach before significant implementation work.
    - Prefer patterns and examples from the document server to reduce rework and testing iteration.
    - If a divergence from the recommended approach is necessary, document the rationale in the PR description and in code comments above the relevant implementation.
    - Re-check the document server for updates when addressing review feedback or refactoring.  code_container-cleo.sh.hbs: |
    #!/bin/sh
    
    # Ensure Rust environment is always properly set up
    echo "🔧 Setting up Rust environment..."
    
    # Source Rust environment if available (fixes cargo not found issues)
    if [ -f "$HOME/.cargo/env" ]; then
        . "$HOME/.cargo/env"
        echo "✓ Sourced Rust environment from $HOME/.cargo/env"
    fi
    
    # Also try root cargo env as fallback
    if [ -f "/root/.cargo/env" ]; then
        . "/root/.cargo/env"
        echo "✓ Sourced Rust environment from /root/.cargo/env"
    fi
    
    # Ensure rustup has a default toolchain set
    if command -v rustup >/dev/null 2>&1; then
        rustup default stable 2>/dev/null || true
        echo "✓ Ensured stable Rust toolchain is default"
    else
        echo "⚠️ rustup not found in PATH"
    fi
    
    # Verify Rust is available
    if command -v cargo >/dev/null 2>&1; then
        echo "✓ Cargo is available: $(cargo --version)"
    else
        echo "❌ Cargo not found in PATH"
        echo "Current PATH: $PATH"
        echo "Attempting to find cargo..."
        find /usr -name cargo 2>/dev/null | head -5 || echo "No cargo found in /usr"
        find /home -name cargo 2>/dev/null | head -5 || echo "No cargo found in /home"
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║              CLEO CODE QUALITY WORKFLOW STARTING             ║'
    echo '║     Code Quality & CI/CD Pipeline Enforcement Agent          ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "🎯 Agent: {{`{{`{{`}}`}}github_app{{`}}`}}"
    echo "🔍 Focus: Code quality, CI/CD setup, and Docker image building"
    echo "📋 Task ID: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "✅ Mission: Perfect code quality AND working CI/CD pipeline with Docker builds"
    
    # Clean up any leftover completion marker from previous runs
    # This prevents issues with sequential task executions on the same PVC
    if [ -f /workspace/.cleo-complete ]; then
        echo "🧹 Cleaning up completion marker from previous run"
        rm -f /workspace/.cleo-complete
    fi
    
    # Disable interactive Git prompts globally
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # Repository URL
    REPO_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    
    # GitHub App authentication is configured via environment variables
    echo "Using GitHub App authentication for code quality checks"
    
    # Authenticate with GitHub App
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        echo "Authenticating with GitHub App..."
    
        # Create temporary private key file (support escaped newlines)
        TEMP_KEY_FILE="/tmp/github-app-key.pem"
        printf '%b' "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
        chmod 600 "$TEMP_KEY_FILE"
    
        # Generate JWT token for GitHub App (fixed JWT generation for Linux containers)
        # JWT header
        JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # JWT payload with current time and expiration (10 minutes)
        NOW=$(date +%s)
        EXP=$((NOW + 600))
        JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # Sign the JWT
        JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
        JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
    
        # Get installation ID for the repository (robust parsing of owner/repo)
        INPUT_REPO="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        REPO_OWNER=""
        REPO_NAME=""
    
        if echo "$INPUT_REPO" | grep -qE '^https://github.com/'; then
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
        elif echo "$INPUT_REPO" | grep -qE '^git@github.com:'; then
            # SSH format git@github.com:owner/repo(.git)
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:[^/]+/([^/]+)(\.git)?|\1|')
        else
            # Fallback: assume slug owner/repo (possibly with .git)
            SLUG=$(echo "$INPUT_REPO" | sed -E 's|\.git$||')
            REPO_OWNER=$(echo "$SLUG" | cut -d'/' -f1)
            REPO_NAME=$(echo "$SLUG" | cut -d'/' -f2)
        fi
    
        echo "DEBUG: Parsed repository - Owner: '$REPO_OWNER', Name: '$REPO_NAME'"
    
        echo "Getting installation ID for $REPO_OWNER/$REPO_NAME..."
    
        # Get the installation ID (retry and follow redirects). Fallback to org installation.
        INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
            --connect-timeout 5 --max-time 12 \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
        INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "⚠️ Repo installation not found, trying org installation..."
            ORG_INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/orgs/$REPO_OWNER/installation")
            INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
        fi
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "❌ Failed to get installation ID for $REPO_OWNER/$REPO_NAME"
            echo "Response (repo): $INSTALLATION_RESPONSE"
            echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "Installation ID: $INSTALLATION_ID"
    
        # Get installation access token
        TOKEN_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
        GITHUB_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
        TOKEN_GENERATED_AT=$(date +%s)  # Track when token was generated for refresh logic
    
        if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ Failed to get installation access token"
            echo "Response: $TOKEN_RESPONSE"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "✅ Successfully authenticated with GitHub App"
    
        # Clean up temporary key file
        rm -f "$TEMP_KEY_FILE"
    
        # Export the token for git to use
        export GITHUB_TOKEN
    
        # Configure git to use the token (use --replace-all to handle multiple existing helpers)
        git config --global --replace-all credential.helper store
        echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
    
        # Also authenticate gh CLI with the token
        echo "$GITHUB_TOKEN" | gh auth login --with-token
    
        # Token refresh functions for long-running jobs
        refresh_github_token() {
            echo "🔄 Refreshing GitHub App token..."
    
            # Create temporary key file
            TEMP_KEY_FILE="/tmp/github-app-key-$$"
            echo "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
            chmod 600 "$TEMP_KEY_FILE"
    
            # Generate new JWT
            JWT_TOKEN=$(ruby -r openssl -r json -r base64 -e "
            key = OpenSSL::PKey::RSA.new(File.read('$TEMP_KEY_FILE'))
            payload = {
                iat: Time.now.to_i - 60,
                exp: Time.now.to_i + (10 * 60),
                iss: '$GITHUB_APP_ID'
            }
            header = { alg: 'RS256', typ: 'JWT' }
    
            header_enc = Base64.urlsafe_encode64(header.to_json).gsub('=', '')
            payload_enc = Base64.urlsafe_encode64(payload.to_json).gsub('=', '')
            signature = Base64.urlsafe_encode64(key.sign(OpenSSL::Digest::SHA256.new, \"#{header_enc}.#{payload_enc}\")).gsub('=', '')
    
            puts \"#{header_enc}.#{payload_enc}.#{signature}\"
            ")
    
            # Get installation ID (reuse logic from initial auth)
            INSTALLATION_ID=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation" | jq -r '.id')
    
            if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
                INSTALLATION_ID=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" \
                    -H "Accept: application/vnd.github+json" \
                    "https://api.github.com/orgs/$REPO_OWNER/installation" | jq -r '.id')
            fi
    
            # Get new installation token
            TOKEN_RESPONSE=$(curl -s -X POST \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
            NEW_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
    
            if [ "$NEW_TOKEN" != "null" ] && [ -n "$NEW_TOKEN" ]; then
                export GITHUB_TOKEN="$NEW_TOKEN"
                export TOKEN_GENERATED_AT=$(date +%s)
    
                # Update git credentials
                echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
                echo "$GITHUB_TOKEN" | gh auth login --with-token 2>/dev/null
    
                echo "✅ Token refreshed successfully"
                rm -f "$TEMP_KEY_FILE"
                return 0
            else
                echo "❌ Failed to refresh token: $TOKEN_RESPONSE"
                rm -f "$TEMP_KEY_FILE"
                return 1
            fi
        }
    
        # Check if token needs refresh (call before git operations)
        refresh_token_if_needed() {
            if [ -z "$TOKEN_GENERATED_AT" ]; then
                echo "⚠️ No token timestamp found, refreshing token..."
                refresh_github_token
                return
            fi
    
            NOW=$(date +%s)
            TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
    
            # Refresh if token is older than 50 minutes (tokens last 1 hour, refresh at 50 min to be safe)
            if [ $TOKEN_AGE -gt 3000 ]; then
                echo "🔄 Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
                refresh_github_token
            fi
        }
    
    else
        echo "❌ GitHub App credentials not found"
        exit 1
    fi
    
    # Target repository directory name - this is where the git repo will be
    TARGET_REPO_DIR="{{`{{`{{`}}`}}#if working_directory{{`}}`}}{{`{{`{{`}}`}}working_directory{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}{{`{{`{{`}}`}}service{{`}}`}}{{`{{`{{`}}`}}/if{{`}}`}}"
    
    # Set working directory for the agent - should match the repository location
    CLAUDE_WORK_DIR="/workspace/$TARGET_REPO_DIR"
    mkdir -p "$CLAUDE_WORK_DIR"
    cd "$CLAUDE_WORK_DIR"
    echo "🔧 Working directory set to: $CLAUDE_WORK_DIR"
    
    # Prepare environment for QA checks
    echo "════════════════════════════════════════════════════════════════"
    echo "📊 PREPARING CODE QUALITY ENVIRONMENT"
    echo "════════════════════════════════════════════════════════════════"
    
    # Configure Git identity
    git config --global user.email "cleo@5dlabs.com"
    git config --global user.name "5DLabs-Cleo"
    git config --global init.defaultBranch main
    
    # =============================================================================
    # AUTHENTICATION VERIFICATION
    # =============================================================================
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "🔐 AUTHENTICATION VERIFICATION"
    echo "═══════════════════════════════════════════════════════════════"
    echo ""
    
    # Repository URLs - Handle both full URLs and org/repo format
    # Check if repository_url already contains https://github.com/
    if echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        REPO_HTTP_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "\.git$"; then
            REPO_HTTP_URL="${REPO_HTTP_URL}.git"
        fi
    else
        REPO_HTTP_URL="https://github.com/{{`{{`{{`}}`}}repository_url{{`}}`}}.git"
    fi
    
    # Same for docs repository
    if echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        DOCS_HTTP_URL="{{`{{`{{`}}`}}docs_repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "\.git$"; then
            DOCS_HTTP_URL="${DOCS_HTTP_URL}.git"
        fi
    else
        DOCS_HTTP_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}.git"
    fi
    
    # DEBUG: Show what URLs are being constructed
    echo "🔍 DEBUG: URL Construction & Parameters"
    echo "  Input repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  Input docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  Input docs_project_directory: '{{`{{`{{`}}`}}docs_project_directory{{`}}`}}'"
    echo "  Input working_directory: '{{`{{`{{`}}`}}working_directory{{`}}`}}'"
    echo "  Input docs_branch: '{{`{{`{{`}}`}}docs_branch{{`}}`}}'"
    echo "  Input github_app: '{{`{{`{{`}}`}}github_app{{`}}`}}'"
    echo "  Input task_id: '{{`{{`{{`}}`}}task_id{{`}}`}}'"
    echo "  Input service: '{{`{{`{{`}}`}}service{{`}}`}}'"
    echo "  Constructed REPO_HTTP_URL: '$REPO_HTTP_URL'"
    echo "  Constructed DOCS_HTTP_URL: '$DOCS_HTTP_URL'"
    echo "  Current working directory: $(pwd)"
    echo "  Available environment variables:"
    env | grep -E "(GITHUB|ANTHROPIC)" | sort
    
    # Test HTTPS access to repository
    echo "🔍 DEBUG: Testing HTTPS repository access..."
    echo "  Command: git ls-remote \"$REPO_HTTP_URL\" HEAD"
    if git ls-remote "$REPO_HTTP_URL" HEAD > /tmp/repo_test.out 2>&1; then
      echo "✓ HTTPS repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Output: $(cat /tmp/repo_test.out | head -1)"
    else
      echo "❌ HTTPS repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Error output: $(cat /tmp/repo_test.out)"
      echo "  Git credential helper status:"
      git config --list | grep credential || echo "  No credential helpers configured"
      echo ""
      echo "🚫 ABORTING: Cannot access repository via HTTPS"
      exit 1
    fi
    
    # Test docs repository access
    echo "🔍 DEBUG: Testing docs repository access..."
    echo "  Command: git ls-remote \"$DOCS_HTTP_URL\" HEAD"
    if git ls-remote "$DOCS_HTTP_URL" HEAD > /tmp/docs_test.out 2>&1; then
      echo "✓ Docs repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Output: $(cat /tmp/docs_test.out | head -1)"
    else
      echo "❌ Docs repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Error output: $(cat /tmp/docs_test.out)"
      echo ""
      echo "🚫 ABORTING: Cannot access docs repository via HTTPS"
      exit 1
    fi
    
    # Clone or update repository
    if [ -d "$CLAUDE_WORK_DIR" ] && [ -d "$CLAUDE_WORK_DIR/.git" ]; then
        echo "📁 Found existing repository at '$CLAUDE_WORK_DIR', updating..."
        cd "$CLAUDE_WORK_DIR"
        git fetch origin
    else
        echo "📥 Cloning repository to '$CLAUDE_WORK_DIR'..."
        # Use the REPO_HTTP_URL constructed in authentication verification section
        if ! git clone "$REPO_HTTP_URL" "$CLAUDE_WORK_DIR"; then
            echo "❌ Failed to clone repository"
            exit 1
        fi
        cd "$CLAUDE_WORK_DIR"
    fi
    
    # Checkout PR branch for quality review
    if [ -n "$PR_NUMBER" ] && [ -n "$PR_URL" ]; then
        echo "🔄 Checking out PR #$PR_NUMBER for quality review..."
        cd "$CLAUDE_WORK_DIR"
    
        # Fetch all latest changes including PR branches
        git fetch origin --prune
    
        # Get PR branch information and checkout
        PR_BRANCH=$(gh pr view "$PR_NUMBER" --json headRefName --jq '.headRefName' 2>/dev/null || echo "")
        if [ -n "$PR_BRANCH" ]; then
            echo "📦 Checking out PR branch: $PR_BRANCH"
            if git checkout "$PR_BRANCH" 2>/dev/null; then
                echo "📥 Pulling latest changes from $PR_BRANCH..."
                git pull origin "$PR_BRANCH" || echo "⚠️  Could not pull latest changes"
            elif git checkout -b "$PR_BRANCH" "origin/$PR_BRANCH" 2>/dev/null; then
                echo "✅ Created and checked out tracking branch for $PR_BRANCH"
            else
                echo "⚠️  Branch checkout failed, trying GitHub CLI method..."
                gh pr checkout "$PR_NUMBER" || echo "❌ Failed to checkout PR via gh CLI"
            fi
        else
            echo "⚠️  Could not determine PR branch name, using GitHub CLI to checkout PR directly"
            gh pr checkout "$PR_NUMBER" || echo "❌ Failed to checkout PR"
        fi
    
        # Verify we're on the right commit
        CURRENT_SHA=$(git rev-parse HEAD)
        echo "📍 Current commit: $CURRENT_SHA"
    
        # Don't change directory yet - we'll cd to CLAUDE_WORK_DIR at the end
        echo "✅ Repository positioned at PR #$PR_NUMBER with latest changes"
    else
        echo "⚠️  No PR context found (PR_NUMBER=$PR_NUMBER, PR_URL=$PR_URL)"
        echo "📋 Will perform quality review on current repository state"
    fi
    
    echo "════════════════════════════════════════════════════════════════"
    echo "🔍 CODE QUALITY ANALYSIS PREPARATION"
    echo "════════════════════════════════════════════════════════════════"
    echo ""
    echo "MISSION: Enforce rigorous code quality standards:"
    echo "1. Run Clippy pedantic checks on all Rust code changes"
    echo "2. Verify code formatting with cargo fmt --check"
    echo "3. Execute all tests with cargo test"
    echo "4. Lint YAML files when YAML changes are detected"
    echo "5. Add 'ready-for-qa' label only when all quality checks pass"
    echo ""
    echo "Quality Standards:"
    echo "- Zero clippy warnings (pedantic level)"
    echo "- Perfect code formatting"
    echo "- 100% test passing rate"
    echo "- Clean YAML syntax and structure"
    echo ""
    echo "════════════════════════════════════════════════════════════════"
    
    # Task files should already be present in the project repository at /task
    echo "📋 Checking for task files in project repository..."
    if [ -d "$CLAUDE_WORK_DIR/task" ]; then
        echo "✓ Found task directory in project repository"
        ls -la "$CLAUDE_WORK_DIR/task/"
    else
        echo "⚠️ No /task directory found in project repository"
    fi
    
    # Ensure we're in the git repository working directory
    echo "✓ Working directly in git repository at: $CLAUDE_WORK_DIR"
    
    # Check if we should continue previous session
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    echo "📂 Continuing from previous session..."
    # Preserve existing CLAUDE.md if it exists
    if [ -f "/workspace/CLAUDE.md" ]; then
        echo "✓ Found existing CLAUDE.md, preserving session memory"
    fi
    {{`{{`{{`}}`}}else{{`}}`}}
    {{`{{`{{`}}`}}#if overwrite_memory{{`}}`}}
    echo "🔄 Overwriting session memory as requested..."
    rm -f /workspace/CLAUDE.md
    {{`{{`{{`}}`}}/if{{`}}`}}
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    # Generate configuration files from templates
    echo "🔧 Generating Cleo-specific configuration files..."
    
    # Enterprise managed settings are mounted directly from ConfigMap
    echo "=== ENTERPRISE MANAGED SETTINGS ==="
    echo "✓ Settings mounted directly from ConfigMap at: /etc/claude-code/managed-settings.json"
    echo "✓ No copying needed - mount automatically reflects latest ConfigMap changes"
    
    # Copy MCP client configuration from task files
    if [ -f "/task-files/client-config.json" ]; then
      cp /task-files/client-config.json "$CLAUDE_WORK_DIR/client-config.json"
      echo "✓ client-config.json copied from ConfigMap"
      export MCP_CLIENT_CONFIG="$CLAUDE_WORK_DIR/client-config.json"
      echo "✓ MCP_CLIENT_CONFIG set to: $MCP_CLIENT_CONFIG"
    else
      echo "⚠️ client-config.json not found in task-files - MCP client may not work correctly"
    fi
    
    # Check if CLAUDE.md already exists (created by controller)
    if [ -f "$CLAUDE_WORK_DIR/CLAUDE.md" ]; then
        echo "✓ CLAUDE.md already exists (from controller), using existing file"
    elif [ -f "/workspace/CLAUDE.md" ]; then
        echo "✓ Found CLAUDE.md in workspace, copying to working directory"
        cp "/workspace/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
    else
        echo "📝 Creating Cleo-specific CLAUDE.md memory file"
        cat > "$CLAUDE_WORK_DIR/CLAUDE.md" << 'EOF'
    # CLEO - Code Quality Enforcement Agent
    
    ## Agent Role
    - **Primary**: Rigorous code quality enforcement and CI/CD maintenance
    - **Focus**: Fix CI failures, resolve merge conflicts, enforce quality standards
    - **Secondary**: YAML linting for infrastructure changes
    - **Critical**: Add "ready-for-qa" label only when ALL quality checks pass
    
    ## PRIORITY TASKS
    
    ### 1. Merge Conflict Resolution (DO FIRST!)
    Check for merge conflicts and resolve them immediately:
    \\\`\\\`\\\`bash
    # Check if PR has conflicts
    gh pr view $PR_NUM --json mergeable,mergeStateStatus
    
    # If conflicts exist:
    git fetch origin main
    git merge origin/main
    # Resolve conflicts intelligently, preserving functionality
    git add -A
    git commit -m "fix: resolve merge conflicts with main"
    git push
    \\\`\\\`\\\`
    
    ### 2. CI/CD Failure Fixes (HIGH PRIORITY)
    Monitor CI status and fix any failures OR stuck jobs:
    \\\`\\\`\\\`bash
    # Check if repository has workflows before checking CI status
    if [ -d ".github/workflows" ] && [ "\\\$(ls .github/workflows/*.yml .github/workflows/*.yaml 2>/dev/null | wc -l)" -gt 0 ]; then
      # Check CI status - look for BOTH failures AND stuck jobs
      gh pr checks $PR_NUM
      # Get PR branch dynamically
      PR_BRANCH=\\\$(gh pr view $PR_NUM --json headRefName -q .headRefName)
      gh run list --branch="\\\$PR_BRANCH" --limit 5
    else
      echo "ℹ️  No GitHub Actions workflows found in repository"
      echo "   CI/CD checks will be skipped for this repository"
    fi
    
    # If jobs are stuck/not starting:
    # 1. Check workflow syntax:
    cat .github/workflows/*.yml | head -50
    # 2. Verify runner labels exist
    # 3. Check for workflow errors in GitHub UI
    
    # Common fixes for stuck jobs:
    # - Fix 'runs-on:' to use valid runner (ubuntu-latest, ubuntu-22.04, etc.)
    # - Fix action versions (e.g., actions/checkout@v4)
    # - Ensure workflow triggers match (push, pull_request)
    # - Remove or fix invalid workflow syntax
    
    # Common fixes for failed jobs:
    # - Fix linting errors (cargo fmt, black, eslint --fix)
    # - Fix type errors
    # - Update dependencies if needed
    # - Fix test failures
    # - Adjust CI configuration if needed
    \\\`\\\`\\\`
    
    ## Code Quality Requirements
    
    ### Change Detection Logic
    Analyze git diff to determine appropriate quality checks:
    \\\`\\\`\\\`bash
    RUST_CHANGES=\\\$(git diff --name-only origin/main...HEAD | grep -E '\\\.(rs|toml)\\\$' || true)
    YAML_CHANGES=\\\$(git diff --name-only origin/main...HEAD | grep -E '\\\.(yaml|yml)\\\$' || true)
    \\\`\\\`\\\`
    
    ### Quality Check Execution
    **For Rust Changes:**
    1. \\\`cargo clippy -- -D warnings -D clippy::pedantic\\\` (zero tolerance)
    2. \\\`cargo fmt\\\` (auto-fix formatting)
    3. \\\`cargo test\\\` (all tests must pass)
    
    **For YAML Changes:**
    1. YAML syntax validation with yamllint
    2. Auto-fix trailing spaces and formatting issues
    
    ### Error Handling
    - Automatically fix formatting and linting issues
    - Fix compilation errors if straightforward
    - Update outdated dependencies if causing CI failures
    - Never approve when quality checks fail after fixes
    
    ### GitHub Integration
    - Monitor PR for CI failures and merge conflicts
    - Fix issues proactively without waiting
    - Post PR comments about fixes made
    - Add "ready-for-qa" label only when CI is green
    - Use GitHub CLI for all PR operations
    
    ## Success Criteria
    - PR has no merge conflicts
    - All CI checks passing (green)
    - Zero clippy warnings at pedantic level
    - Perfect code formatting consistency
    - 100% test pass rate
    - Clean YAML syntax and structure
    EOF
    
        # Append base CLAUDE.md from ConfigMap if it exists
        if [ -f "/task-files/CLAUDE.md" ]; then
            echo "" >> "$CLAUDE_WORK_DIR/CLAUDE.md"
            cat "/task-files/CLAUDE.md" >> "$CLAUDE_WORK_DIR/CLAUDE.md"
            echo "✓ Appended base CLAUDE.md content from ConfigMap"
        fi
    fi
    
    # Copy guidelines files to working directory (match Rex pattern)
    if [ -f "/task-files/coding-guidelines.md" ]; then
      cp /task-files/coding-guidelines.md "$CLAUDE_WORK_DIR/"
      echo "✓ Copied coding-guidelines.md to working directory"
    fi
    
    if [ -f "/task-files/github-guidelines.md" ]; then
      cp /task-files/github-guidelines.md "$CLAUDE_WORK_DIR/"
      echo "✓ Copied github-guidelines.md to working directory"
    fi
    
    # Copy MCP configuration from ConfigMap to project root (project scope)
    if [ -f "/task-files/mcp.json" ]; then
      cp /task-files/mcp.json "$CLAUDE_WORK_DIR/.mcp.json"
      echo "✓ Copied mcp.json to .mcp.json (project scope)"
    else
      echo "⚠️ mcp.json template not found"
    fi
    
    # Setup hook scripts
    echo "🔧 Setting up Cleo-specific hook scripts..."
    mkdir -p "$CLAUDE_WORK_DIR/hooks"
    
    {{`{{`{{`}}`}}#each hook_scripts{{`}}`}}
    cat > "$CLAUDE_WORK_DIR/hooks/{{`{{`{{`}}`}}@key{{`}}`}}" << 'EOF'
    {{`{{`{{`}}`}}{this{{`}}`}}}
    EOF
    chmod +x "$CLAUDE_WORK_DIR/hooks/{{`{{`{{`}}`}}@key{{`}}`}}"
    {{`{{`{{`}}`}}/each{{`}}`}}
    
    # Export environment for Claude
    export CLAUDE_WORK_DIR
    export GITHUB_TOKEN
    export REPO_OWNER
    export REPO_NAME
    export TARGET_REPO_DIR
    
    echo "════════════════════════════════════════════════════════════════"
    echo "✅ CLEO CODE QUALITY AGENT READY"
    echo "════════════════════════════════════════════════════════════════"
    echo "📁 Working Directory: $CLAUDE_WORK_DIR"
    echo "📦 Repository: $REPO_OWNER/$REPO_NAME"
    echo "📋 Task: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "🎯 Focus: Rigorous code quality enforcement"
    echo "⚠️  CRITICAL: Must pass all quality checks before adding 'ready-for-qa' label"
    echo "════════════════════════════════════════════════════════════════"
    
    # Export necessary variables for Claude execution
    export SERVICE_NAME="{{`{{`{{`}}`}}service{{`}}`}}"
    export TASK_ID="{{`{{`{{`}}`}}task_id{{`}}`}}"
    export GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Start Claude with Cleo-specific configuration
    cd "$CLAUDE_WORK_DIR"
    
    # Build Claude command
    CLAUDE_CMD="claude -p --output-format stream-json --input-format stream-json --verbose"
    
    # Create Cleo's static prompt
    echo "✓ Creating Cleo's static code quality enforcement prompt"
    
    # Build static prompt with task context
    CLEO_PROMPT="# Code Quality Review Assignment
    
    You are Cleo, a rigorous code quality enforcement agent. Your mission is to ensure zero-tolerance quality standards for this pull request.
    
    ## Your Role
    - **Primary Focus**: Code quality enforcement AND CI/CD pipeline setup
    - **Quality Tools**: Clippy (pedantic), cargo fmt, cargo test, YAML linting
    - **DevOps Setup**: GitHub Actions workflows, Docker image building, CI verification
    - **Decision Authority**: Add 'ready-for-qa' label only when ALL quality checks AND CI builds pass
    - **Standards**: Zero warnings, perfect formatting, 100% test pass rate, working Docker builds
    
    ## Current Context
    
    ### Pull Request Information
    - **PR Number**: ${PR_NUMBER:-"Not specified"}
    - **PR URL**: ${PR_URL:-"Not specified"}
    - **Repository**: $REPO_OWNER/$REPO_NAME
    - **Working Directory**: $CLAUDE_WORK_DIR"
    
    # Add task context if available
    if [ -f "$CLAUDE_WORK_DIR/task/task.md" ]; then
        CLEO_PROMPT="$CLEO_PROMPT
    
    ### Task Information (for context)
    $(cat "$CLAUDE_WORK_DIR/task/task.md")
    
    ### Task Requirements (Rex was asked to implement)
    $(cat "$CLAUDE_WORK_DIR/task/prompt.md" 2>/dev/null || echo "No prompt.md found")
    
    ### Acceptance Criteria (what Rex needed to achieve)
    $(cat "$CLAUDE_WORK_DIR/task/acceptance-criteria.md" 2>/dev/null || echo "No acceptance-criteria.md found")
    
    ### Architecture Reference (if available)
    $(cat "$CLAUDE_WORK_DIR/task/architecture.md" 2>/dev/null || echo "No architecture.md found")"
    else
        CLEO_PROMPT="$CLEO_PROMPT
    
    ### Task Information
    No task files found in /task directory - proceeding with general code quality review."
    fi
    
    # Complete the prompt
    CLEO_PROMPT="$CLEO_PROMPT
    
    ## Your Instructions
    1. **Analyze the PR changes**: The repository has been automatically positioned at the PR branch with latest changes
    2. **Detect change types**: Identify Rust files (.rs, .toml) and YAML files (.yml, .yaml)
    3. **Run quality checks**:
       - For Rust: cargo clippy -- -D warnings -W clippy::pedantic
       - Run cargo fmt to fix any formatting issues
       - For YAML: YAML linting and validation
       - IMPORTANT: Commit and push ALL fixes immediately (don't wait until the end)
       - NOTE: Do NOT write tests - Tess handles all testing
    4. **Set up CI/CD Pipeline (CRITICAL - Use These EXACT Patterns)**:
       - Check if .github/workflows/ci.yml exists (or similar CI workflow)
       - If not, create using these PROVEN TEMPLATES:
    
       **a) Dockerfile (Runtime-only, expects pre-built binary):**
       \\\`\\\`\\\`dockerfile
       FROM debian:bookworm-slim
       RUN apt-get update && apt-get install -y \\\\
           ca-certificates libssl3 wget --no-install-recommends \\\\
           && rm -rf /var/lib/apt/lists/* && apt-get clean
       RUN useradd -r -u 1000 -m -d /app -s /bin/bash app
       WORKDIR /app
       COPY <binary-name> /app/<binary-name>
       RUN chmod +x /app/<binary-name> && chown -R app:app /app
       USER app
       EXPOSE 8080
       HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\\
           CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1
       CMD ["./<binary-name>"]
       \\\`\\\`\\\`
    
       **b) CI Workflow (.github/workflows/ci.yml):**
       \\\`\\\`\\\`yaml
       name: Continuous Integration
       on:
         push:
           branches: [main]
         pull_request:
           branches: [main]
    
       jobs:
         lint-rust:
           runs-on: ubuntu-22.04
           steps:
             - uses: actions/checkout@v4
             - uses: actions-rust-lang/setup-rust-toolchain@v1
               with:
                 toolchain: stable
                 components: rustfmt, clippy
             - uses: Swatinem/rust-cache@v2
               with:
                 workspaces: . -> target
                 shared-key: "rust-cache-ci"
             - name: Format check
               run: cargo fmt --all -- --check
             - name: Clippy
               run: cargo clippy --all-targets --all-features -- -D warnings -W clippy::pedantic
    
         test-rust:
           runs-on: ubuntu-22.04
           steps:
             - uses: actions/checkout@v4
             - uses: actions-rust-lang/setup-rust-toolchain@v1
               with:
                 toolchain: stable
             - uses: Swatinem/rust-cache@v2
               with:
                 workspaces: . -> target
                 shared-key: "rust-cache-ci"
             - name: Run tests
               run: cargo test --all-features --all-targets
       \\\`\\\`\\\`
    
       **c) Deploy Workflow (.github/workflows/deploy.yml) for k8s-runner:**
       \\\`\\\`\\\`yaml
       name: Deploy
       on:
         push:
           branches: [main, develop, feature/*, feat/*, fix/*]
    
       env:
         REGISTRY: ghcr.io
         IMAGE_BASE: ${{`{{`{{`}}`}} github.repository_owner {{`}}`}}
    
       jobs:
         build:
           runs-on: [k8s-runner]  # Use self-hosted runner for speed
           permissions:
             contents: read
             packages: write
           steps:
             - uses: actions/checkout@v4
             - name: Build binary
               env:
                 RUSTC_WRAPPER: "sccache"
                 CARGO_TARGET_DIR: "\$HOME/cache/target"
               run: |
                 cargo build --release
                 cp \$HOME/cache/target/release/<binary> ./<binary>
             - uses: docker/setup-buildx-action@v3
             - uses: docker/login-action@v3
               with:
                 registry: ghcr.io
                 username: ${{`{{`{{`}}`}} github.actor {{`}}`}}
                 password: ${{`{{`{{`}}`}} secrets.GITHUB_TOKEN {{`}}`}}
             - uses: docker/build-push-action@v5
               with:
                 context: .
                 file: ./Dockerfile
                 platforms: linux/amd64,linux/arm64
                 push: true
                 tags: |
                   ghcr.io/${{`{{`{{`}}`}} github.repository {{`}}`}}:latest
                   ghcr.io/${{`{{`{{`}}`}} github.repository {{`}}`}}:${{`{{`{{`}}`}} github.sha {{`}}`}}
                 cache-from: type=gha
                 cache-to: type=gha,mode=max
       \\\`\\\`\\\`
    
       - Commit and push the CI configuration
       - Push any code fixes you made locally
       - Use 'gh workflow run' to trigger the build if needed
       - Use 'gh run list' and 'gh run view' to monitor status
       - **WATCH FOR STUCK JOBS**: If jobs show "Waiting" > 2 min:
         * Check runner availability and labels
         * Verify workflow syntax is correct
         * Fix any workflow configuration issues
       - KEEP ITERATING: Fix issues, push, check CI, repeat until ALL JOBS RUN AND PASS
    5. **Verify CI Success (THE ONLY MEASURE OF SUCCESS)**:
       - **If repository has workflows**: Use 'gh pr checks {{`{{`{{`}}`}}pr_number{{`}}`}}' to confirm ALL checks are passing
       - **If no workflows**: Skip CI validation and proceed to code quality checks
       - **CRITICAL: Check for stuck/pending jobs** (only if workflows exist):
         * Look for jobs showing "Waiting" or "Pending" for > 2 minutes
         * Check 'gh run list --branch=$(gh pr view {{`{{`{{`}}`}}pr_number{{`}}`}} --json headRefName -q .headRefName)' for workflow status
         * If jobs aren't starting, investigate:
           - Missing runner labels? Check 'runs-on:' in workflow
           - Workflow syntax errors? Validate with 'actionlint' or GitHub UI
           - Missing workflow triggers? Check 'on:' section
           - Concurrency limits? Check workflow 'concurrency:' settings
       - **Common fixes for stuck jobs** (only if workflows exist):
         * Add/fix 'runs-on: ubuntu-latest' (or appropriate runner)
         * Remove invalid actions or fix version tags
         * Ensure workflow file is in .github/workflows/
         * Check if workflow needs to be enabled in Actions settings
       - Specifically verify 'cargo clippy -- -D warnings -W clippy::pedantic' passes in CI (when workflows exist)
       - SUCCESS = Code quality checks pass + CI passes (if workflows exist) OR code quality checks pass (if no workflows)
       - Do NOT proceed until quality standards are met
    6. **Review against task requirements**: Verify implementation matches acceptance criteria
    7. **Report results**: Provide detailed summary of checks performed, CI setup, and any fixes applied
    8. **Success criteria**: Quality checks must pass for approval. CI/CD validation required only when workflows exist.
    
    ## Quality Standards (MUST PASS IN GITHUB ACTIONS WHEN WORKFLOWS EXIST, OTHERWISE LOCALLY!)
    - **Zero tolerance** for clippy warnings at pedantic level (in CI if workflows exist, locally otherwise)
    - **Perfect formatting** required (cargo fmt --check must pass in CI if workflows exist, locally otherwise)
    - **All tests pass** (cargo test must succeed in CI if workflows exist, locally otherwise)
    - **Clean YAML** syntax and structure
    - **CI/CD Pipeline** SHOULD be working with successful Docker image build (when workflows exist)
    - **GitHub Actions** SHOULD show green checks for ALL quality gates (when workflows exist)
    - **Task compliance** (implementation should meet acceptance criteria)
    
    ## CRITICAL REMINDER
    Your success is measured by:
    - **If workflows exist**: GitHub Actions CI status, NOT local checks
      - You MUST push your changes to see them tested in CI
      - You MUST iterate: fix locally → push → check CI → repeat until green
      - Clippy pedantic MUST pass in GitHub Actions before you can add 'ready-for-qa' label
      - **ALL CI JOBS MUST ACTUALLY RUN** - stuck/pending jobs = FAILURE
    - **If no workflows**: Local quality checks and task compliance
      - Run quality checks locally: cargo clippy, cargo fmt, cargo test
      - Ensure code meets quality standards before approval
    
    ## TROUBLESHOOTING STUCK CI JOBS
    If CI jobs won't start (showing \"Waiting\" or \"Pending\" indefinitely):
    1. **Check runner labels**: Ensure 'runs-on:' uses valid runners
       - Common: ubuntu-latest, ubuntu-22.04, ubuntu-20.04
       - Self-hosted: [self-hosted], [k8s-runner]
    2. **Validate workflow syntax**: Run locally or check GitHub UI for errors
    3. **Check workflow triggers**: Ensure 'on:' section includes your event
    4. **Fix common issues**:
       - Missing or misspelled action names
       - Invalid YAML syntax (use yamllint)
       - Workflow file not in .github/workflows/
       - Workflow disabled in repo settings
    - The PR checks page on GitHub is your source of truth
    
    Begin your code quality review now."
    
    # Debug: Print the actual prompt and CLAUDE.md content
    echo "════════════════════════════════════════════════════════════════"
    echo "🔍 DEBUG: CLEO PROMPT CONTENT"
    echo "════════════════════════════════════════════════════════════════"
    echo "$CLEO_PROMPT"
    echo "════════════════════════════════════════════════════════════════"
    
    echo "════════════════════════════════════════════════════════════════"
    echo "🔍 DEBUG: CLAUDE.md MEMORY CONTENT"
    echo "════════════════════════════════════════════════════════════════"
    if [ -f "$CLAUDE_WORK_DIR/CLAUDE.md" ]; then
        cat "$CLAUDE_WORK_DIR/CLAUDE.md"
    else
        echo "❌ No CLAUDE.md found at $CLAUDE_WORK_DIR/CLAUDE.md"
    fi
    echo "════════════════════════════════════════════════════════════════"
    
    # Send the static prompt to Claude
    FIFO_PATH="/workspace/agent-input.jsonl"
    rm -f "$FIFO_PATH" 2>/dev/null || true
    mkfifo "$FIFO_PATH"
    chmod 666 "$FIFO_PATH" || true
    
    # Start Claude (reader) first in background
    $CLAUDE_CMD < "$FIFO_PATH" &
    CLAUDE_PID=$!
    
    # Start background token refresh for long-running jobs
    (
        while kill -0 $CLAUDE_PID 2>/dev/null; do
            sleep 2700  # Check every 45 minutes
    
            if [ -n "$TOKEN_GENERATED_AT" ] && [ -n "$GITHUB_APP_PRIVATE_KEY" ]; then
                NOW=$(date +%s)
                TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
    
                if [ $TOKEN_AGE -gt 2700 ]; then
                    echo "[Background] Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
                    refresh_github_token
                fi
            fi
        done
    ) &
    TOKEN_REFRESH_PID=$!
    echo "✓ Started background token refresh (PID: $TOKEN_REFRESH_PID)"
    
    # Compose initial user turn with the static prompt
    USER_COMBINED=$(printf "%s" "$CLEO_PROMPT" | jq -Rs .)
    
    # Send via sidecar HTTP endpoint
    if printf '{"text":%s}\n' "$USER_COMBINED" | \
         curl -fsS -X POST http://127.0.0.1:8080/input \
           -H 'Content-Type: application/json' \
           --data-binary @- >/dev/null 2>&1; then
      echo "✓ Static Cleo prompt sent via sidecar /input"
    else
      echo "⚠️ Sidecar /input failed, falling back to direct FIFO write"
      exec 9>"$FIFO_PATH"
      printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":%s}]{{`}}`}}\n' "$USER_COMBINED" >&9
      exec 9>&- 2>/dev/null || true  # Close immediately
    fi
    
    # Wait for Claude process to complete
    wait "$CLAUDE_PID"
    CLAUDE_EXIT_CODE=$?
    
    # Stop token refresh background process
    if [ -n "$TOKEN_REFRESH_PID" ]; then
        kill $TOKEN_REFRESH_PID 2>/dev/null || true
        echo "✓ Stopped token refresh process"
    fi
    
    # Always attempt to complete quality review - don't exit on Claude failures
    echo "🔄 Processing quality review results..."
    if [ $CLAUDE_EXIT_CODE -eq 0 ]; then
      echo "✅ Claude quality review completed successfully"
    fi
    
    # Always attempt to post PR comment and add label regardless of Claude exit status
    # Determine OWNER/REPO slug for gh -R
    REPO_INPUT="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    if echo "$REPO_INPUT" | grep -q "^https://github.com/"; then
      REPO_SLUG=$(echo "$REPO_INPUT" | sed -E 's|https://github.com/([^/]+/[^/.]+)(\.git)?$|\1|')
    else
      REPO_SLUG="$REPO_INPUT"
    fi
    
    # Post quality review comment to PR
    if [ -n "$PR_NUMBER" ] || [ -n "$PR_URL" ]; then
      echo "💬 Posting quality review comment to PR..."
    
      # Create comment body based on Claude exit status
      if [ $CLAUDE_EXIT_CODE -eq 0 ]; then
        COMMENT_BODY="## 🔍 Code Quality Review by Cleo
    
    ✅ **Quality checks completed successfully**
    
    ### Review Summary
    - Code has been reviewed for quality standards
    - All required checks have passed
    - Ready for QA testing
    
    ---
    *Reviewed by Cleo - 5DLabs Code Quality Agent*"
      else
        COMMENT_BODY="## 🔍 Code Quality Review by Cleo
    
    ⚠️ **Quality review encountered issues**
    
    ### Current Status
    - Quality checks are being processed
    - Some issues may need to be resolved
    - Review will continue until standards are met
    
    ### Next Steps
    - Monitor CI/CD pipeline status
    - Address any failing quality checks
    - Iterate until all standards are met
    
    ---
    *Reviewed by Cleo - 5DLabs Code Quality Agent*"
      fi
    
      # Post comment using PR number or URL
      if [ -n "$PR_NUMBER" ]; then
        if echo "$COMMENT_BODY" | gh pr comment "$PR_NUMBER" -R "$REPO_SLUG" --body-file - 2>/dev/null; then
          echo "✅ Successfully posted quality review comment"
        else
          echo "⚠️ Failed to post comment using PR number"
        fi
      elif [ -n "$PR_URL" ]; then
        if echo "$COMMENT_BODY" | gh pr comment "$PR_URL" --body-file - 2>/dev/null; then
          echo "✅ Successfully posted quality review comment"
        else
          echo "⚠️ Failed to post comment"
        fi
      fi
    fi
    
    # Always attempt to add the ready-for-qa label
    if [ -n "$PR_NUMBER" ]; then
      echo "🏷️ Adding 'ready-for-qa' label to PR #$PR_NUMBER..."
      echo "🔍 DEBUG: PR_NUMBER='$PR_NUMBER', REPO_SLUG='$REPO_SLUG'"
    
      # Capture error output for debugging
      LABEL_ERROR=$(gh pr edit "$PR_NUMBER" -R "$REPO_SLUG" --add-label "ready-for-qa" 2>&1)
      LABEL_EXIT=$?
    
      if [ $LABEL_EXIT -eq 0 ]; then
        echo "✅ Successfully added 'ready-for-qa' label"
      else
        echo "⚠️ Failed to add label using PR number (exit code: $LABEL_EXIT)"
        echo "🔍 DEBUG: Error: $LABEL_ERROR"
    
        # Check if the label exists
        echo "🔍 DEBUG: Checking if 'ready-for-qa' label exists..."
        if gh label list -R "$REPO_SLUG" --search "ready-for-qa" | grep -q "ready-for-qa"; then
          echo "   ✓ Label 'ready-for-qa' exists in repository"
        else
          echo "   ✗ Label 'ready-for-qa' does not exist - attempting to create it..."
          CREATE_ERROR=$(gh label create "ready-for-qa" -R "$REPO_SLUG" --color "0e8a16" --description "Ready for QA testing" 2>&1)
          CREATE_EXIT=$?
          if [ $CREATE_EXIT -eq 0 ]; then
            echo "   ✅ Created 'ready-for-qa' label"
            # Retry adding the label
            RETRY_ERROR=$(gh pr edit "$PR_NUMBER" -R "$REPO_SLUG" --add-label "ready-for-qa" 2>&1)
            RETRY_EXIT=$?
            if [ $RETRY_EXIT -eq 0 ]; then
              echo "   ✅ Successfully added label after creating it"
            else
              echo "   ❌ Still failed to add label: $RETRY_ERROR"
            fi
          else
            echo "   ❌ Failed to create label: $CREATE_ERROR"
          fi
        fi
    
        # Try with PR URL as fallback
        if [ -n "$PR_URL" ] && [ $LABEL_EXIT -ne 0 ]; then
          echo "⚠️ Attempting with PR URL as fallback..."
          URL_ERROR=$(gh pr edit "$PR_URL" --add-label "ready-for-qa" 2>&1)
          URL_EXIT=$?
          if [ $URL_EXIT -eq 0 ]; then
            echo "✅ Successfully added 'ready-for-qa' label using PR URL"
          else
            echo "❌ Failed to add 'ready-for-qa' label using PR URL: $URL_ERROR"
          fi
        fi
      fi
    elif [ -n "$PR_URL" ]; then
      echo "🏷️ Adding 'ready-for-qa' label using PR URL..."
      URL_ERROR=$(gh pr edit "$PR_URL" --add-label "ready-for-qa" 2>&1)
      URL_EXIT=$?
      if [ $URL_EXIT -eq 0 ]; then
        echo "✅ Successfully added 'ready-for-qa' label"
      else
        echo "❌ Failed to add 'ready-for-qa' label: $URL_ERROR"
      fi
    else
      echo "⚠️ No PR_NUMBER or PR_URL available, cannot add label"
    fi
    
    # Gracefully stop sidecar (with enhanced debugging and retries)
    echo "🔧 Attempting sidecar shutdown..."
    shutdown_attempts=0
    max_shutdown_attempts=3
    
    while [ $shutdown_attempts -lt $max_shutdown_attempts ]; do
      if curl -fsS -X POST http://127.0.0.1:8080/shutdown -m 5 2>/dev/null; then
        echo "✓ Sidecar shutdown request successful (attempt $((shutdown_attempts + 1)))"
        break
      else
        shutdown_attempts=$((shutdown_attempts + 1))
        echo "⚠️ Sidecar shutdown request failed (attempt $shutdown_attempts/$max_shutdown_attempts)"
        if [ $shutdown_attempts -lt $max_shutdown_attempts ]; then
          echo "Retrying in 2 seconds..."
          sleep 2
        fi
      fi
    done
    
    if [ $shutdown_attempts -eq $max_shutdown_attempts ]; then
      echo "❌ Failed to shutdown sidecar after $max_shutdown_attempts attempts"
      echo "🔧 Force terminating sidecar processes..."
      pkill -f "sidecar" || echo "No sidecar processes found to kill"
    fi
    
    # Wait for sidecar to actually terminate
    echo "⏳ Waiting for sidecar termination..."
    timeout=10
    while [ $timeout -gt 0 ]; do
      if ! pgrep -f "sidecar" > /dev/null 2>&1; then
        echo "✅ Sidecar terminated successfully"
        break
      fi
      sleep 1
      timeout=$((timeout - 1))
    done
    
    if [ $timeout -eq 0 ]; then
      echo "⚠️ Sidecar still running after wait period"
    fi
    
    # Cleanup and exit
    echo "════════════════════════════════════════════════════════════════"
    echo "║                  CLEO CODE QUALITY COMPLETE                  ║"
    echo "════════════════════════════════════════════════════════════════"
    echo "📋 Task: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "✅ Code quality checks completed"
    echo "════════════════════════════════════════════════════════════════"
    
    # Final termination sequence
    echo "════════════════════════════════════════════════════════════════"
    echo "🔚 TERMINATING CLEO CONTAINER"
    echo "════════════════════════════════════════════════════════════════"
    echo "Claude Exit Code: $CLAUDE_EXIT_CODE"
    echo "Container PID: $$"
    echo "Final Process Check:"
    ps aux | head -5
    
    # Write completion marker for workflow tracking
    echo "cleo-quality-completed:$(date -u +%Y-%m-%dT%H:%M:%SZ)" > /workspace/.cleo-complete
    
    # Cleanup FIFO
    rm -f "$FIFO_PATH" 2>/dev/null || true
    
    # Always exit successfully to keep workflow running
    echo "🔚 Force terminating container..."
    echo "📝 Note: Container always exits with code 0 to allow workflow continuation"
    exit 0  code_container-rex-remediation.sh.hbs: |
    #!/bin/sh
    
    # Ensure Rust environment is always properly set up
    echo "🔧 Setting up Rust environment..."
    
    # Source Rust environment if available (fixes cargo not found issues)
    if [ -f "$HOME/.cargo/env" ]; then
        . "$HOME/.cargo/env"
        echo "✓ Sourced Rust environment from $HOME/.cargo/env"
    fi
    
    # Also try root cargo env as fallback
    if [ -f "/root/.cargo/env" ]; then
        . "/root/.cargo/env"
        echo "✓ Sourced Rust environment from /root/.cargo/env"
    fi
    
    # Ensure rustup has a default toolchain set
    if command -v rustup >/dev/null 2>&1; then
        rustup default stable 2>/dev/null || true
        echo "✓ Ensured stable Rust toolchain is default"
    else
        echo "⚠️ rustup not found in PATH"
    fi
    
    # Verify Rust is available
    if command -v cargo >/dev/null 2>&1; then
        echo "✓ Cargo is available: $(cargo --version)"
    else
        echo "❌ Cargo not found in PATH"
        echo "Current PATH: $PATH"
        echo "Attempting to find cargo..."
        find /usr -name cargo 2>/dev/null | head -5 || echo "No cargo found in /usr"
        find /home -name cargo 2>/dev/null | head -5 || echo "No cargo found in /home"
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║               🔧 REX REMEDIATION WORKFLOW STARTING             ║'
    echo '║                  Remediation Agent Active                      ║'
    echo '║            ⚠️  FIXING FEEDBACK - NO NEW IMPLEMENTATION ⚠️         ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "🎯 Agent: {{`{{`{{`}}`}}github_app{{`}}`}}"
    echo "🔧 Mode: Remediation - Fix Only"
    echo "📋 Task ID: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "🚨 CRITICAL: ONLY fix the issues identified in feedback"
    
    # Disable interactive Git prompts globally
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # Repository URL
    REPO_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    
    # GitHub App authentication is configured via environment variables
    echo "Using GitHub App authentication"
    
    # Authenticate with GitHub App
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        echo "Authenticating with GitHub App..."
    
        # Create temporary private key file (support escaped newlines)
        TEMP_KEY_FILE="/tmp/github-app-key.pem"
        printf '%b' "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
        chmod 600 "$TEMP_KEY_FILE"
    
        # Generate JWT token for GitHub App (fixed JWT generation for Linux containers)
        # JWT header
        JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # JWT payload with current time and expiration (10 minutes)
        NOW=$(date +%s)
        EXP=$((NOW + 600))
        JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # Sign the JWT
        JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
        JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
    
        # Get installation ID for the repository (robust parsing of owner/repo)
        INPUT_REPO="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        REPO_OWNER=""
        REPO_NAME=""
    
        if echo "$INPUT_REPO" | grep -qE '^https://github.com/'; then
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
        elif echo "$INPUT_REPO" | grep -qE '^git@github.com:'; then
            # SSH format git@github.com:owner/repo(.git)
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:[^/]+/([^/]+)(\.git)?|\1|')
        else
            # Fallback: assume slug owner/repo (possibly with .git)
            SLUG=$(echo "$INPUT_REPO" | sed -E 's|\.git$||')
            REPO_OWNER=$(echo "$SLUG" | cut -d'/' -f1)
            REPO_NAME=$(echo "$SLUG" | cut -d'/' -f2)
        fi
    
        echo "DEBUG: Parsed repository - Owner: '$REPO_OWNER', Name: '$REPO_NAME'"
    
        echo "Getting installation ID for $REPO_OWNER/$REPO_NAME..."
    
        # Get the installation ID (retry and follow redirects). Fallback to org installation.
        INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
            --connect-timeout 5 --max-time 12 \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
        INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "⚠️ Repo installation not found, trying org installation..."
            ORG_INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/orgs/$REPO_OWNER/installation")
            INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
        fi
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "❌ Failed to get installation ID for $REPO_OWNER/$REPO_NAME"
            echo "Response (repo): $INSTALLATION_RESPONSE"
            echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "Installation ID: $INSTALLATION_ID"
    
        # Get installation access token
        TOKEN_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
        GITHUB_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
    
        if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ Failed to get installation access token"
            echo "Response: $TOKEN_RESPONSE"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        # Clean up temporary key file
        rm -f "$TEMP_KEY_FILE"
    
        # Export the token for git to use
        export GITHUB_TOKEN
    
        # Configure git to use the token (use --replace-all to handle multiple existing helpers)
        git config --global --replace-all credential.helper store
        echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
    
        # Also authenticate gh CLI with the token
        echo "$GITHUB_TOKEN" | gh auth login --with-token
    
        echo "✓ GitHub App authenticated successfully"
    
    else
        echo "❌ GITHUB_APP_PRIVATE_KEY or GITHUB_APP_ID not found"
        exit 1
    fi
    
    # Git configuration with proper GitHub App attribution
    git config --global --add safe.directory /workspace
    
    # Set GitHub App attribution - use generic format for all agents
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    # Generic attribution that works for any agent
    GIT_AUTHOR_NAME="${GITHUB_APP} Agent (Claude Code)"
    GIT_AUTHOR_EMAIL="${GITHUB_APP}[bot]@users.noreply.github.com"
    
    # Configure git with proper GitHub App attribution
    git config --global user.name "$GIT_AUTHOR_NAME"
    git config --global user.email "$GIT_AUTHOR_EMAIL"
    
    # Set environment variables for Claude Code to use
    export GIT_AUTHOR_NAME="$GIT_AUTHOR_NAME"
    export GIT_AUTHOR_EMAIL="$GIT_AUTHOR_EMAIL"
    export GIT_COMMITTER_NAME="$GIT_AUTHOR_NAME"
    export GIT_COMMITTER_EMAIL="$GIT_AUTHOR_EMAIL"
    echo "✓ Git configured"
    
    # =============================================================================
    # REMEDIATION MODE VALIDATION
    # =============================================================================
    
    # Validate remediation environment variables
    echo ""
    echo "🔧 REMEDIATION MODE VALIDATION"
    
    if [ -z "${FEEDBACK_COMMENT_ID:-}" ]; then
        echo "❌ ERROR: FEEDBACK_COMMENT_ID is required in remediation mode"
        exit 1
    fi
    
    if [ -z "${ITERATION_COUNT:-}" ]; then
        echo "❌ ERROR: ITERATION_COUNT is required in remediation mode"
        exit 1
    fi
    
    echo "🔧 Remediation Mode Configuration:"
    echo "   Task ID: ${TASK_ID:-"Not specified"}"
    echo "   PR Number: ${PR_NUMBER:-"Not specified"}"
    echo "   Feedback Comment ID: ${FEEDBACK_COMMENT_ID}"
    echo "   Iteration: ${ITERATION_COUNT}"
    echo "   Feedback Author: ${FEEDBACK_AUTHOR:-"Unknown"}"
    
    # Check iteration limits
    MAX_ITERATIONS=10
    if [ "${ITERATION_COUNT}" -gt "${MAX_ITERATIONS}" ]; then
        echo "❌ ERROR: Maximum iterations (${MAX_ITERATIONS}) exceeded (current: ${ITERATION_COUNT})"
        echo "🚨 Triggering escalation..."
    
        # Post escalation comment
        ESCALATION_BODY=$(cat <<EOF
    ## 🚨 Remediation Escalation Required
    
    **Iteration Limit Reached**: ${ITERATION_COUNT}/10
    
    The automated remediation process has reached its maximum iteration limit and requires human intervention.
    
    ### Next Steps:
    1. **Review the feedback history** in this PR for all attempted fixes
    2. **Manually address** the remaining issues identified in the feedback
    3. **Consider** if the original requirements need clarification or adjustment
    4. **Merge or close** this PR based on the remediation outcome
    
    ### Context:
    - **Task ID**: ${TASK_ID:-"Unknown"}
    - **PR**: #${PR_NUMBER:-"Unknown"}
    - **Last Attempt**: Iteration ${ITERATION_COUNT}
    - **Feedback Source**: Comment ID ${FEEDBACK_COMMENT_ID}
    
    @platform-team @cto - Manual intervention required for this remediation.
    
    ---
    *Posted by Rex Remediation Agent*
    EOF
        )
    
        if [ -n "${PR_NUMBER:-}" ] && [ -n "${GITHUB_TOKEN:-}" ]; then
            if gh pr comment "${PR_NUMBER}" --body "${ESCALATION_BODY}" 2>/dev/null; then
                echo "✅ Escalation comment posted successfully"
            else
                echo "⚠️ Failed to post escalation comment"
            fi
        fi
    
        exit 1
    fi
    
    if [ "${ITERATION_COUNT}" -eq "${MAX_ITERATIONS}" ]; then
        echo "⚠️ WARNING: Final iteration (${ITERATION_COUNT}/${MAX_ITERATIONS}) - this is the last attempt"
    fi
    
    echo "✅ Iteration check passed: ${ITERATION_COUNT}/${MAX_ITERATIONS}"
    
    # Fetch feedback comment
    echo ""
    echo "📥 Fetching feedback comment ${FEEDBACK_COMMENT_ID}..."
    MAX_RETRIES=3
    RETRY_COUNT=0
    FEEDBACK_COMMENT=""
    
    while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
        if FEEDBACK_COMMENT=$(gh api "/repos/{{`{{`{{`}}`}}repository_url{{`}}`}}/issues/comments/${FEEDBACK_COMMENT_ID}" --jq '.body' 2>/dev/null); then
            echo "✅ Feedback comment fetched successfully (${#FEEDBACK_COMMENT} characters)"
            break
        else
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "⚠️ Failed to fetch comment (attempt ${RETRY_COUNT}/${MAX_RETRIES})"
    
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                sleep $((2 ** RETRY_COUNT))  # Exponential backoff
            fi
        fi
    done
    
    if [ -z "${FEEDBACK_COMMENT}" ]; then
        echo "❌ Failed to fetch feedback comment after ${MAX_RETRIES} attempts"
        echo "Cannot proceed with remediation without feedback context"
        exit 1
    fi
    
    # Parse feedback metadata
    echo ""
    echo "🔍 Parsing feedback metadata..."
    SEVERITY="medium"
    ISSUE_TYPES=""
    
    if echo "${FEEDBACK_COMMENT}" | grep -q "🔴"; then
        SEVERITY="critical"
    elif echo "${FEEDBACK_COMMENT}" | grep -q "🟡"; then
        SEVERITY="high"
    elif echo "${FEEDBACK_COMMENT}" | grep -q "🟢"; then
        SEVERITY="low"
    fi
    
    if echo "${FEEDBACK_COMMENT}" | grep -qi "security\|vulnerability\|exploit"; then
        ISSUE_TYPES="${ISSUE_TYPES}security,"
    fi
    if echo "${FEEDBACK_COMMENT}" | grep -qi "performance\|slow\|optimization"; then
        ISSUE_TYPES="${ISSUE_TYPES}performance,"
    fi
    if echo "${FEEDBACK_COMMENT}" | grep -qi "bug\|error\|exception\|crash"; then
        ISSUE_TYPES="${ISSUE_TYPES}bug,"
    fi
    if echo "${FEEDBACK_COMMENT}" | grep -qi "test\|testing\|coverage"; then
        ISSUE_TYPES="${ISSUE_TYPES}testing,"
    fi
    if echo "${FEEDBACK_COMMENT}" | grep -qi "documentation\|docs\|readme"; then
        ISSUE_TYPES="${ISSUE_TYPES}documentation,"
    fi
    
    ISSUE_TYPES="${ISSUE_TYPES%,}"
    if [ -z "${ISSUE_TYPES}" ]; then
        ISSUE_TYPES="general"
    fi
    
    echo "📊 Detected severity: ${SEVERITY}"
    echo "🏷️ Detected issue types: ${ISSUE_TYPES}"
    
    # Fetch original task context for reference (not as main prompt)
    echo ""
    echo "📋 Fetching original task context..."
    TASK_CONTENT=""
    
    TASK_FILE="/tmp/docs-repo/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster/docs/task-${TASK_ID}/task.md"
    if [ -f "${TASK_FILE}" ]; then
        TASK_CONTENT=$(cat "${TASK_FILE}")
        echo "✅ Found task file: ${TASK_FILE}"
    else
        echo "⚠️ Task file not found, using default context"
        TASK_CONTENT="Task ${TASK_ID}: Implement the required functionality with proper error handling and testing."
    fi
    
    # Create remediation-specific CLAUDE.md
    echo ""
    echo "📝 Preparing remediation context for Claude..."
    
    cat > /workspace/CLAUDE.md << EOF
    # 🔧 REMEDIATION MODE - Fix Required Issues
    
    **Iteration ${ITERATION_COUNT}/10** | **Severity: ${SEVERITY^^}** | **Task: ${TASK_ID}**
    
    You are operating in **REX REMEDIATION MODE**. Your mission is to fix specific issues identified in QA feedback while preserving all working functionality. This is NOT a reimplementation - focus on surgical, targeted fixes.
    
    ---
    
    ## 🎯 ORIGINAL TASK REQUIREMENTS (Reference Only)
    
    ${TASK_CONTENT}
    
    ---
    
    ## 🚨 ISSUES TO FIX (Priority: ${SEVERITY^^})
    
    **Issue Categories:** ${ISSUE_TYPES}
    
    ${FEEDBACK_COMMENT}
    
    ---
    
    ## 📋 REMEDIATION INSTRUCTIONS
    
    ### Your Mission:
    1. **PRESERVE** all working functionality - do NOT break anything that currently works
    2. **FIX** only the specific issues mentioned in the feedback above
    3. **FOCUS** on surgical changes, not broad reimplementation
    4. **VERIFY** each fix addresses the exact problem described
    5. **TEST** that your changes solve the issues without introducing new problems
    
    ### Key Principles:
    - **Targeted Fixes**: Address specific problems, not general improvements
    - **Minimal Changes**: Make the smallest possible changes to fix issues
    - **Preserve Architecture**: Keep existing patterns and structures intact
    - **Risk Management**: Avoid changes that could break other features
    
    ### What to Avoid:
    - ❌ Reimplementing working features
    - ❌ Major refactoring unless specifically requested
    - ❌ Adding new features or capabilities
    - ❌ Changing established patterns or conventions
    
    ---
    
    ## 🔍 FEEDBACK ANALYSIS
    
    **PR Number:** ${PR_NUMBER:-"Unknown"}
    **Comment ID:** ${FEEDBACK_COMMENT_ID}
    **Author:** ${FEEDBACK_AUTHOR:-"Unknown"}
    **Iteration:** ${ITERATION_COUNT} of 10
    
    **Metadata:**
    - Severity: ${SEVERITY}
    - Categories: ${ISSUE_TYPES}
    - Source: GitHub PR Comment
    
    ---
    
    ## ✅ SUCCESS CRITERIA
    
    Your remediation is successful when:
    1. All issues mentioned in the feedback are resolved
    2. No existing functionality is broken
    3. Changes are minimal and targeted
    4. Code quality is maintained
    5. Tests (if present) continue to pass
    
    ---
    
    ## 🚨 ESCALATION WARNING
    
    If you cannot fix these issues within this iteration:
    - Be explicit about what cannot be fixed and why
    - Document any blockers or limitations encountered
    - Suggest alternative approaches for human review
    - This is iteration ${ITERATION_COUNT}/10 - use it wisely
    
    ---
    
    *Generated by Rex Remediation Agent v1.0.0*
    EOF
    
    echo "✅ Remediation context prepared at /workspace/CLAUDE.md"
    
    # =============================================================================
    # AUTHENTICATION VERIFICATION
    # =============================================================================
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "🔐 AUTHENTICATION VERIFICATION"
    echo "═══════════════════════════════════════════════════════════════"
    echo ""
    
    # Repository URLs - Handle both full URLs and org/repo format
    # Check if repository_url already contains https://github.com/
    if echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        REPO_HTTP_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "\.git$"; then
            REPO_HTTP_URL="${REPO_HTTP_URL}.git"
        fi
    else
        REPO_HTTP_URL="https://github.com/{{`{{`{{`}}`}}repository_url{{`}}`}}.git"
    fi
    
    # Same for docs repository
    if echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        DOCS_HTTP_URL="{{`{{`{{`}}`}}docs_repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "\.git$"; then
            DOCS_HTTP_URL="${DOCS_HTTP_URL}.git"
        fi
    else
        DOCS_HTTP_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}.git"
    fi
    
    # DEBUG: Show what URLs are being constructed
    echo "🔍 DEBUG: URL Construction & Parameters"
    echo "  Input repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  Input docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  Input docs_project_directory: '{{`{{`{{`}}`}}docs_project_directory{{`}}`}}'"
    echo "  Input working_directory: '{{`{{`{{`}}`}}working_directory{{`}}`}}'"
    echo "  Input docs_branch: '{{`{{`{{`}}`}}docs_branch{{`}}`}}'"
    echo "  Input github_app: '{{`{{`{{`}}`}}github_app{{`}}`}}'"
    echo "  Input task_id: '{{`{{`{{`}}`}}task_id{{`}}`}}'"
    echo "  Input service: '{{`{{`{{`}}`}}service{{`}}`}}'"
    echo "  Constructed REPO_HTTP_URL: '$REPO_HTTP_URL'"
    echo "  Constructed DOCS_HTTP_URL: '$DOCS_HTTP_URL'"
    echo "  Current working directory: $(pwd)"
    echo "  Available environment variables:"
    env | grep -E "(GITHUB|ANTHROPIC)" | sort
    
    # Test HTTPS access to repository
    echo "🔍 DEBUG: Testing HTTPS repository access..."
    echo "  Command: git ls-remote \"$REPO_HTTP_URL\" HEAD"
    if git ls-remote "$REPO_HTTP_URL" HEAD > /tmp/repo_test.out 2>&1; then
      echo "✓ HTTPS repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Output: $(cat /tmp/repo_test.out | head -1)"
    else
      echo "❌ HTTPS repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Error output: $(cat /tmp/repo_test.out)"
      echo "  Git credential helper status:"
      git config --list | grep credential || echo "  No credential helpers configured"
      echo ""
      echo "🚫 ABORTING: Cannot access repository via HTTPS"
      exit 1
    fi
    
    # Test docs repository access
    echo "🔍 DEBUG: Testing docs repository access..."
    echo "  Command: git ls-remote \"$DOCS_HTTP_URL\" HEAD"
    if git ls-remote "$DOCS_HTTP_URL" HEAD > /tmp/docs_test.out 2>&1; then
      echo "✓ Docs repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Output: $(cat /tmp/docs_test.out | head -1)"
    else
      echo "❌ Docs repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Error output: $(cat /tmp/docs_test.out)"
      echo ""
      echo "🚫 ABORTING: Cannot access docs repository via HTTPS"
      exit 1
    fi
    
    # Dual Repository Setup - Platform repo for docs, Target repo for implementation
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "║                 DUAL REPOSITORY SETUP                        ║"
    echo "═══════════════════════════════════════════════════════════════"
    
    # Repository Information
    DOCS_BRANCH="{{`{{`{{`}}`}}docs_branch{{`}}`}}"
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Helper: derive safe workspace directory name from repo input (URL, SSH, or slug)
    sanitize_repo_dir() {
        input="$1"
        if echo "$input" | grep -qE '^https://github.com/'; then
            owner=$(echo "$input" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            name=$(echo "$input" | sed -E 's|https://github.com/[^/]+/([^/]+)(\\.git)?|\1|')
            printf '%s-%s' "$owner" "$name"
        elif echo "$input" | grep -qE '^git@github.com:'; then
            owner=$(echo "$input" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            name=$(echo "$input" | sed -E 's|git@github.com:[^/]+/([^/]+)(\\.git)?|\1|')
            printf '%s-%s' "$owner" "$name"
        else
            # Assume owner/repo (optionally with .git)
            slug=$(echo "$input" | sed -E 's|\\.git$||')
            echo "$slug" | tr '/' '-'
        fi
    }
    
    # Derive workspace directory names (owner-repo)
    DOCS_REPO_DIR=$(sanitize_repo_dir "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}")
    TARGET_REPO_DIR=$(sanitize_repo_dir "{{`{{`{{`}}`}}repository_url{{`}}`}}")
    
    echo "=== REPOSITORY SETUP ==="
    echo "Docs repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
    echo "Target repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
    echo "Docs branch: $DOCS_BRANCH"
    echo "GitHub App: $GITHUB_APP"
    
    # Always use consistent workflow approach
    # Even if docs and target are the same repo, we clone them separately
    # This avoids complex branch switching and file preservation issues
    echo "=== UNIFIED WORKFLOW APPROACH ==="
    echo "  docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  └─ TaskMaster files will be copied from docs repo at: {{`{{`{{`}}`}}docs_project_directory{{`}}`}}"
    
    # Repository Setup - Always use consistent approach
    echo "=== REPOSITORY SETUP ==="
    
    # Step 1: Clone or update docs repository temporarily
    if [ -d "/tmp/docs-repo" ]; then
        echo "🔄 DOCS REPOSITORY: UPDATE - temporary directory exists"
        cd /tmp/docs-repo
        git fetch origin
        git checkout "$DOCS_BRANCH"
        git reset --hard "origin/$DOCS_BRANCH"
        cd /workspace
        echo "✓ Docs repository updated"
    else
        echo "📥 DOCS REPOSITORY: CLONING - extracting task files"
        if ! git clone "$DOCS_HTTP_URL" /tmp/docs-repo; then
            echo "❌ Failed to clone docs repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
            exit 1
        fi
        cd /tmp/docs-repo && git checkout "$DOCS_BRANCH" && cd /workspace
        echo "✓ Docs repository cloned to temporary location"
    fi
    
    # Step 2: Clone or update target repository
    if [ -d "$TARGET_REPO_DIR" ]; then
        echo "🔄 TARGET REPOSITORY: UPDATE - directory already exists"
        echo "📁 Found existing target repository '$TARGET_REPO_DIR', updating..."
        cd "$TARGET_REPO_DIR"
        git fetch origin main
        git reset --hard origin/main
        cd /workspace
        echo "✓ Target repository updated successfully"
    else
        echo "📥 TARGET REPOSITORY: CLONING - first time setup"
        if ! git clone "$REPO_HTTP_URL" "$TARGET_REPO_DIR"; then
            echo "❌ Failed to clone target repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
            exit 1
        fi
        echo "✓ Target repository cloned successfully"
    fi
    
    # Step 3: Copy task files from docs repo to target repo
    echo "📋 TASK FILES: COPYING from docs to target repository"
    mkdir -p "/workspace/$TARGET_REPO_DIR/task"
    
    # Determine docs project directory path
    {{`{{`{{`}}`}}#if docs_project_directory{{`}}`}}
    if [ "{{`{{`{{`}}`}}docs_project_directory{{`}}`}}" = "." ]; then
        DOCS_PATH="/tmp/docs-repo/.taskmaster"
    else
        DOCS_PATH="/tmp/docs-repo/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster"
    fi
    {{`{{`{{`}}`}}else{{`}}`}}
    DOCS_PATH="/tmp/docs-repo/.taskmaster"
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    # Copy specific task files
    TASK_DIR="$DOCS_PATH/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "🔍 DEBUG: Looking for task files at: $TASK_DIR"
    echo "🔍 DEBUG: Docs path is: $DOCS_PATH"
    echo "🔍 DEBUG: Contents of docs temp directory:"
    ls -la /tmp/docs-repo/.taskmaster/ || echo "No .taskmaster found"
    echo "🔍 DEBUG: Contents of docs directory:"
    ls -la /tmp/docs-repo/.taskmaster/docs/ || echo "No docs directory found"
    
    if [ -d "$TASK_DIR" ]; then
        echo "🔍 DEBUG: Task directory found, contents:"
        ls -la "$TASK_DIR"
    
        echo "✅ Copying task.md..."
        cp "$TASK_DIR/task.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ task.md copied" || echo "❌ task.md copy failed"
    
        echo "✅ Copying acceptance-criteria.md..."
        cp "$TASK_DIR/acceptance-criteria.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ acceptance-criteria.md copied" || echo "❌ acceptance-criteria.md copy failed"
    
        echo "✅ Copying prompt.md..."
        cp "$TASK_DIR/prompt.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ prompt.md copied" || echo "❌ prompt.md copy failed"
    
        echo "✅ Copying client-config.json..."
        if [ -f "$TASK_DIR/client-config.json" ]; then
            cp "$TASK_DIR/client-config.json" "$CLAUDE_WORK_DIR/client-config.json" && echo "✓ client-config.json copied to Claude working directory" || echo "❌ client-config.json copy failed"
        else
            echo "⚠️ client-config.json not found - MCP client may not be configured"
        fi
    
        echo "✅ Copying toolman-guide.md..."
        if [ -f "$TASK_DIR/toolman-guide.md" ]; then
            cp "$TASK_DIR/toolman-guide.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ toolman-guide.md copied" || echo "❌ toolman-guide.md copy failed"
        else
            echo "⚠️ toolman-guide.md not found - code agent won't have tool usage guidance"
        fi
    
        echo "✓ Task {{`{{`{{`}}`}}task_id{{`}}`}} files copied from $TASK_DIR"
    else
        echo "❌ CRITICAL: Task {{`{{`{{`}}`}}task_id{{`}}`}} directory not found at: $TASK_DIR"
        echo "🔍 DEBUG: Available directories in docs:"
        find /tmp/docs-repo -name "task-*" -type d || echo "No task directories found"
    fi
    
    # Copy architecture.md from docs root
    ARCH_FILE="$DOCS_PATH/docs/architecture.md"
    if [ -f "$ARCH_FILE" ]; then
        cp "$ARCH_FILE" "/workspace/$TARGET_REPO_DIR/task/"
        echo "✓ Architecture documentation copied"
    else
        echo "⚠️ architecture.md not found at: $ARCH_FILE"
    fi
    
    # Copy tasks.json if it exists
    if [ -f "$DOCS_PATH/tasks.json" ]; then
        cp "$DOCS_PATH/tasks.json" "/workspace/$TARGET_REPO_DIR/task/"
        echo "✓ tasks.json copied"
    fi
    
    echo "✓ Task files copied to target repository"
    
    # DEBUG: Verify files were copied successfully
    echo "🔍 DEBUG: Contents of target task directory after copy:"
    ls -la "/workspace/$TARGET_REPO_DIR/task/" || echo "Task directory not found"
    echo "🔍 DEBUG: Checking if prompt.md exists:"
    [ -f "/workspace/$TARGET_REPO_DIR/task/prompt.md" ] && echo "✅ prompt.md exists" || echo "❌ prompt.md missing"
    
    # Step 4: Clean up docs repository
    echo "🧹 CLEANUP: Removing temporary docs repository"
    rm -rf /tmp/docs-repo
    echo "✓ Docs repository cleaned up"
    
    # Set working directory to the target repository root
    REPO_NAME="$TARGET_REPO_DIR"
    echo "✓ Working directory: /workspace/$REPO_NAME"
    
    # Set Claude working directory early (needed for client-config.json copy)
    WORK_DIR="{{`{{`{{`}}`}}working_directory{{`}}`}}"
    if [ "$WORK_DIR" = "." ] || [ -z "$WORK_DIR" ]; then
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME"
    else
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME/$WORK_DIR"
    fi
    mkdir -p "$CLAUDE_WORK_DIR"
    echo "✓ Set Claude working directory: $CLAUDE_WORK_DIR"
    
    # Setup feature branch for implementation
    echo "=== BRANCH SETUP ==="
    cd "/workspace/$REPO_NAME"
    
    # Sync with latest main to prevent conflicts
    echo "🔄 Syncing with latest main to prevent conflicts..."
    git fetch origin main 2>/dev/null || git fetch origin master 2>/dev/null || echo "⚠️ Could not fetch main/master branch"
    
    # Create or checkout feature branch (with conflict-safe fallback)
    FEATURE_BRANCH="feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation"
    BRANCH_EXISTS="false"
    
    if git show-ref --verify --quiet refs/heads/$FEATURE_BRANCH; then
        BRANCH_EXISTS="true"
        echo "Feature branch '$FEATURE_BRANCH' exists, checking out..."
        git checkout $FEATURE_BRANCH
    
        echo "📥 Merging latest main into $FEATURE_BRANCH..."
        if git merge origin/main --no-edit; then
            echo "✓ Successfully merged latest main into feature branch"
        else
            echo "⚠️ MERGE CONFLICT: Cannot auto-merge main into $FEATURE_BRANCH"
            echo "🔄 Auto-aborting merge and creating a fresh branch from origin/main"
            # Abort merge if in progress
            git merge --abort 2>/dev/null || true
            # Create a unique fresh branch to avoid reuse conflicts
            NEW_BRANCH="${FEATURE_BRANCH}-$(date -u +%Y%m%d%H%M%S)"
            git checkout -B "$NEW_BRANCH" origin/main
            FEATURE_BRANCH="$NEW_BRANCH"
            echo "✓ Switched to fresh branch: $FEATURE_BRANCH"
        fi
    else
        # Create new feature branch from latest main
        echo "Creating new feature branch '$FEATURE_BRANCH' from latest main..."
        git checkout -b $FEATURE_BRANCH origin/main
        echo "✓ Created feature branch: $FEATURE_BRANCH"
    fi
    
    # 5. Change to Claude Working Directory (already set up earlier)
    cd "$CLAUDE_WORK_DIR"
    echo "✓ Changed to Claude working directory: $CLAUDE_WORK_DIR"
    echo "🔑 CRITICAL: Claude will be launched from this directory"
    
    # Working directory setup completed above
    
    # Configure git user after successful clone
    echo "=== POST-CLONE GIT CONFIGURATION ==="
    # Fix dubious ownership issues
    git config --global --add safe.directory "/workspace/$REPO_NAME"
    echo "✓ Added repository to safe directories"
    
    # Set git config locally in the working repository (persistent on PVC)
    if [ -d "/workspace/$REPO_NAME/.git" ]; then
        cd "/workspace/$REPO_NAME"
        git config --local user.name "$GIT_AUTHOR_NAME"
        git config --local user.email "$GIT_AUTHOR_EMAIL"
        # Set up automatic upstream for new branches
        git config --local push.autoSetupRemote true
        echo "✓ Configured git user in target repository: $GIT_AUTHOR_NAME"
        echo "✓ Enabled automatic upstream setup for new branches"
    fi
    
    cd /workspace
    
    # Copy ConfigMap files to working directory (AFTER repository clone)
    echo "=== CONFIGMAP FILE SETUP ==="
    
    # Claude working directory already set above during repository setup
    
    echo "Setting up files in Claude working directory: $CLAUDE_WORK_DIR"
    cd "$CLAUDE_WORK_DIR"
    
    # Copy all files from ConfigMap to working directory
    if [ -d "/task-files" ]; then
      echo "Copying ConfigMap files to working directory..."
    
      # CLAUDE.md Memory Persistence Logic (controlled by overwriteMemory CRD field)
            OVERWRITE_MEMORY="{{`{{`{{`}}`}}overwrite_memory{{`}}`}}"
    
      # Handle CLAUDE.md based on overwriteMemory setting
            if [ "$OVERWRITE_MEMORY" = "true" ]; then
              # Overwrite mode: Always replace CLAUDE.md with fresh template
        cp "/task-files/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
        cp "/task-files/CLAUDE.md" "/workspace/CLAUDE.md"
              echo "✓ Overwrote CLAUDE.md memory file (fresh start requested)"
              echo "✓ Copied CLAUDE.md to workspace root for easy access"
            else
              # Preserve mode (default): Only copy if doesn't exist
              if [ ! -f "$CLAUDE_WORK_DIR/CLAUDE.md" ]; then
          # Initial creation - copy from ConfigMap
          cp "/task-files/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
          cp "/task-files/CLAUDE.md" "/workspace/CLAUDE.md"
                echo "✓ Created initial CLAUDE.md memory file"
                echo "✓ Copied CLAUDE.md to workspace root for easy access"
              else
                echo "✓ Preserved existing CLAUDE.md memory file (maintaining accumulated context)"
                # Still copy to workspace root for consistency
                cp "$CLAUDE_WORK_DIR/CLAUDE.md" "/workspace/CLAUDE.md"
                echo "✓ Synced CLAUDE.md to workspace root"
              fi
            fi
    
      # Copy all other markdown files (excluding CLAUDE.md)
      for md_file in /task-files/*.md; do
        if [ -f "$md_file" ]; then
          basename_file=$(basename "$md_file")
          # Skip CLAUDE.md since we handled it above
          if [ "$basename_file" != "CLAUDE.md" ]; then
            cp "$md_file" "$CLAUDE_WORK_DIR/"
            echo "✓ Updated $basename_file"
          fi
        fi
      done
    
      # Verify enterprise settings (mounted directly from ConfigMap)
      if [ -f "/etc/claude-code/managed-settings.json" ]; then
        echo "✓ Enterprise settings verified"
        if ! jq empty /etc/claude-code/managed-settings.json 2>/dev/null; then
          echo "❌ Invalid enterprise settings JSON"
          exit 1
        fi
      else
        echo "❌ Enterprise settings not found"
        exit 1
      fi
    
      # Copy guidelines files to working directory
      if [ -f "/task-files/coding-guidelines.md" ]; then
        cp /task-files/coding-guidelines.md "$CLAUDE_WORK_DIR/"
        echo "✓ Copied coding-guidelines.md to working directory"
      fi
    
      if [ -f "/task-files/github-guidelines.md" ]; then
        cp /task-files/github-guidelines.md "$CLAUDE_WORK_DIR/"
        echo "✓ Copied github-guidelines.md to working directory"
      fi
    
      # System prompt will be rendered inline (no file copying needed)
      echo "✓ System prompt template will be rendered inline"
    
      # Hook copying disabled
      echo "! Hook scripts disabled - no hooks will be copied"
    
      # Set up MCP configuration
      echo "Setting up MCP configuration..."
    
      # Copy MCP configuration from ConfigMap to project root (project scope)
      if [ -f "/task-files/mcp.json" ]; then
        cp /task-files/mcp.json "$CLAUDE_WORK_DIR/.mcp.json"
        echo "✓ Copied mcp.json to .mcp.json (project scope)"
      else
        echo "⚠️  mcp.json template not found"
      fi
    
      # Enterprise managed settings are mounted directly from ConfigMap
      echo "=== ENTERPRISE MANAGED SETTINGS ==="
      echo "✓ Settings mounted directly from ConfigMap at: /etc/claude-code/managed-settings.json"
      echo "✓ No copying needed - mount automatically reflects latest ConfigMap changes"
    
      echo "✓ ConfigMap files copied to $CLAUDE_WORK_DIR"
    else
      echo "⚠️  Warning: /task-files directory not found (ConfigMap not mounted?)"
    fi
    
    
    # Move client-config.json if it exists in task directory
    if [ -f "$CLAUDE_WORK_DIR/task/client-config.json" ]; then
        mv "$CLAUDE_WORK_DIR/task/client-config.json" "$CLAUDE_WORK_DIR/client-config.json" && echo "✓ client-config.json moved to Claude working directory" || echo "❌ client-config.json move failed"
    fi
    
    # Verify client-config.json is available in Claude's working directory
    echo "=== TOOLMAN CONFIG SETUP ==="
    CLAUDE_CONFIG="$CLAUDE_WORK_DIR/client-config.json"
    
    if [ -f "$CLAUDE_CONFIG" ]; then
      echo "✓ client-config.json found in Claude working directory"
      # Set MCP_CLIENT_CONFIG environment variable for MCP server/bridge
      export MCP_CLIENT_CONFIG="$CLAUDE_CONFIG"
      echo "✓ MCP_CLIENT_CONFIG set to: $MCP_CLIENT_CONFIG"
    else
      echo "⚠️ client-config.json not found in Claude working directory - MCP client may not work correctly"
    fi
    
    echo '=== WORKSPACE VALIDATION ==='
    
    # Check for required files in Claude's working directory
    MISSING_FILES=""
    REQUIRED_FILES="CLAUDE.md"
    
    echo "Checking for required files..."
    for file in $REQUIRED_FILES; do
      if [ ! -f "$CLAUDE_WORK_DIR/$file" ]; then
        echo "ERROR: Missing required file: $CLAUDE_WORK_DIR/$file"
        MISSING_FILES="$MISSING_FILES $file"
      else
        echo "✓ Found: $CLAUDE_WORK_DIR/$file"
        # Show file size for verification
        size=$(wc -c < "$CLAUDE_WORK_DIR/$file" 2>/dev/null || echo "0")
        echo "  File size: $size bytes"
      fi
    done
    
    # Check git repository (REQUIRED for implementation tasks)
    if [ ! -d "/workspace/$REPO_NAME/.git" ]; then
      echo "✗ CRITICAL ERROR: No target git repository found!"
      MISSING_FILES="$MISSING_FILES git-repository"
    else
      echo "✓ Found: target git repository"
    fi
    
    # If any files are missing, abort
    if [ -n "$MISSING_FILES" ]; then
      echo ""
      echo "═══════════════════════════════════════════════════════════════"
      echo "║                 WORKSPACE VALIDATION FAILED                  ║"
      echo "═══════════════════════════════════════════════════════════════"
      echo ""
      echo "The following required files are missing:"
      for missing in $MISSING_FILES; do
        case "$missing" in
          "CLAUDE.md")
            echo "  ❌ $missing - Main task instructions for Claude"
            ;;
          "git-repository")
            echo "  ❌ $missing - Required for committing implementation changes"
            ;;
          *)
            echo "  ❌ $missing"
            ;;
        esac
      done
      echo ""
      echo "These files should have been created by the ConfigMap setup process."
      echo "Claude will NOT be started to avoid wasting API credits."
      echo ""
      exit 1
    fi
    
    echo "✓ All required files present. Workspace is valid."
    
    echo '=== IMPLEMENTATION TASK DIAGNOSTICS ==='
    echo "Project directory: $CLAUDE_WORK_DIR"
    echo "Project directory contents:"
    ls -la "$CLAUDE_WORK_DIR"
    echo ""
    
    # Show git status
    echo "Git status:"
    git status 2>/dev/null || echo "Git status unavailable"
    echo ""
    
    echo '=== CLAUDE EXECUTION ==='
    
    # Export necessary variables
    export SERVICE_NAME="{{`{{`{{`}}`}}service{{`}}`}}"
    export TASK_ID="{{`{{`{{`}}`}}task_id{{`}}`}}"
    export GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Change to project directory before running Claude
    cd "$CLAUDE_WORK_DIR"
    echo "Changed to directory: $(pwd)"
    
    # Verify we're in the correct directory and have required files
    echo "=== WORKING DIRECTORY VERIFICATION ==="
    echo "Current working directory: $(pwd)"
    echo "Expected directory: $CLAUDE_WORK_DIR"
    if [ "$(pwd)" != "$CLAUDE_WORK_DIR" ]; then
      echo "❌ ERROR: Failed to change to correct working directory!"
      echo "Attempting to change directory again..."
      cd "$CLAUDE_WORK_DIR" || exit 1
      echo "✓ Successfully changed to: $(pwd)"
    fi
    
    # Verify git repository is accessible from Claude working directory
    echo "=== GIT REPOSITORY VERIFICATION ==="
    if [ ! -d ".git" ]; then
      echo "❌ ERROR: No .git directory found in Claude working directory: $(pwd)"
      echo "📂 Checking parent directory structure:"
      echo "  Current: $(pwd)"
      echo "  Contents: $(ls -la . | head -5)"
      if [ -d "/workspace/$REPO_NAME/.git" ]; then
        echo "  Found .git at: /workspace/$REPO_NAME/"
        echo "🔧 This indicates a working directory path mismatch"
        echo "🔧 CLAUDE_WORK_DIR: $CLAUDE_WORK_DIR"
        echo "🔧 Expected git repo: /workspace/$REPO_NAME"
      fi
      exit 1
    else
      echo "✅ Git repository verified at: $(pwd)/.git"
      echo "✅ Repository status: $(git status --porcelain | wc -l) modified files"
      echo "✅ Current branch: $(git branch --show-current 2>/dev/null || echo 'detached')"
    fi
    
    # Verify setup
    echo "✓ Code implementation environment ready"
    
    # Build Claude command
    CLAUDE_CMD="claude -p --output-format stream-json --input-format stream-json --verbose"
    
    # Look for agent-specific system prompt file from agents ConfigMap
    # The system prompt should be in the agents ConfigMap if configured
    if [ -f "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        echo "✓ Found system prompt file for {{`{{`{{`}}`}}github_app{{`}}`}}, adding to Claude command"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    elif [ -f "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        # Fallback to task-files if included inline
        echo "✓ Found system prompt in task ConfigMap for {{`{{`{{`}}`}}github_app{{`}}`}}"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    else
        echo "ℹ️ No system prompt file found for agent {{`{{`{{`}}`}}github_app{{`}}`}}, using defaults"
    fi
    
    # Model is set via settings.json template, not CLI flag
    
    # Add continue flag if this is a retry attempt or user requested continuation
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    CLAUDE_CMD="$CLAUDE_CMD --continue"
    echo 'Adding --continue flag (attempt {{`{{`{{`}}`}}attempts{{`}}`}}{{`{{`{{`}}`}}#if user_requested{{`}}`}} - user requested{{`{{`{{`}}`}}/if{{`}}`}})'
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    echo "════════════════════════════════════════════════════════════════"
    echo "║                    STARTING CLAUDE EXECUTION                  ║"
    echo "════════════════════════════════════════════════════════════════"
    echo "Command: $CLAUDE_CMD"
    echo "Note: Claude will automatically read CLAUDE.md from the working directory"
    
    # Inline system prompt (static content)
    SYSTEM_PROMPT='## 🚨 CRITICAL SYSTEM REQUIREMENTS 🚨
    
    **⛔ OVERCONFIDENCE MITIGATION - MANDATORY VERIFICATION ⛔**
    
    You have a DANGEROUS tendency to declare task completion before actually verifying everything works. This is ABSOLUTELY UNACCEPTABLE.
    
    **MANDATORY VERIFICATION REQUIREMENTS:**
    - ✅ **MUST** actually run and test your code - never assume it works
    - ✅ **MUST** verify ALL acceptance criteria through actual testing
    - ✅ **MUST** confirm your changes don'\''t break existing functionality
    - ✅ **MUST** test end-to-end workflows and edge cases
    - ✅ **MUST** run all linters and build checks successfully
    - ✅ **CANNOT** claim completion based on code appearance alone
    
    **YOU ARE PROHIBITED FROM CLAIMING SUCCESS UNTIL:**
    1. You have executed and verified every piece of functionality
    2. You have tested integration with existing systems
    3. You have confirmed all acceptance criteria pass through testing
    4. All automated tests pass (linting, builds, unit tests)
    5. You have verified the solution works end-to-end in practice
    
    **IF YOU DECLARE SUCCESS WITHOUT VERIFICATION, YOU HAVE FAILED.**
    
    ## 🔧 ORCHESTRATOR EXECUTION CONTEXT
    
    - **Service**: {{`{{`{{`}}`}}service{{`}}`}}
    - **Task ID**: {{`{{`{{`}}`}}task_id{{`}}`}}
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Docs Repository**: {{`{{`{{`}}`}}docs_repository_url{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    - **GitHub App**: {{`{{`{{`}}`}}github_app{{`}}`}}
    
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    ## 🔄 CONTINUE SESSION - PR COMMENT RESOLUTION PRIORITY
    
    **⚠️ MANDATORY FIRST STEP: Before proceeding with any other work, you MUST:**
    
    1. **Check for unresolved PR comments**: Use `gh pr view --json reviews` or check the PR directly
    2. **Resolve ALL pending comments first**: Address reviewer feedback, fix issues, respond to questions
    3. **Push comment resolutions**: Commit and push any fixes for reviewer concerns
    4. **Only then proceed**: After ALL PR comments are resolved, continue with the main task
    
    **This ensures reviewer feedback takes priority and maintains collaborative workflow quality.**
    
    {{`{{`{{`}}`}}/if{{`}}`}}
    ## ⚠️ EXECUTION REQUIREMENTS
    
    - **Follow patterns**: Use @coding-guidelines.md and @github-guidelines.md
    - **Pre-PR quality gates (MANDATORY)**: Do NOT open a PR unless all of these pass locally:
      - `cargo fmt --all -- --check`
      - `cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic`
      - `cargo test --workspace --all-features` and high coverage (aim ≥95%, target ~100% on critical paths)
    - **GitHub workflow**: Read @github-guidelines.md for commit standards
    - **Verify continuously**: Run tests and checks after each significant change
    - **Commit incrementally**: Don'\''t save all changes for the end
    - **Test thoroughly**: Validate against acceptance criteria before completion
    
    ## 🚨 NON-NEGOTIABLE PULL REQUEST REQUIREMENT 🚨
    
    **⛔ CRITICAL: YOU MUST CREATE A PULL REQUEST - NO EXCEPTIONS ⛔**
    
    **MANDATORY FINAL STEP:**
    - **MUST** create a pull request using `gh pr create` command
    - **MUST** include proper labels (task-{{`{{`{{`}}`}}task_id{{`}}`}}, run-{{`{{`{{`}}`}}workflow.name{{`}}`}}, service-{{`{{`{{`}}`}}service{{`}}`}})
    - **MUST** verify PR creation succeeded before claiming task completion
    - **THE TASK IS INCOMPLETE AND FAILED IF NO PR IS CREATED**
    
    **YOU CANNOT COMPLETE THIS TASK WITHOUT CREATING A PULL REQUEST.**
    **IF YOU DO NOT CREATE A PR, YOU HAVE FAILED THE TASK COMPLETELY.**
    
    **Remember**: Focus on thorough implementation and verification.'
    
    echo "Starting Claude execution (stream-json via FIFO)..."
    echo "=========================="
    
    # Safe mode toggle for debugging (prevents token consumption)
    SAFE_MODE="false"  # Set to "false" for full task execution
    
    if [ "$SAFE_MODE" = "true" ]; then
        echo "🛡️ SAFE MODE ENABLED - Running simple test instead of full task"
        FIFO_PATH="/workspace/agent-input.jsonl"
        rm -f "$FIFO_PATH" 2>/dev/null || true
        mkfifo "$FIFO_PATH"
        chmod 666 "$FIFO_PATH" || true
        # Keep a persistent writer open and start Claude in background to avoid EOF race
        exec 9>"$FIFO_PATH"
        $CLAUDE_CMD < "$FIFO_PATH" &
        CLAUDE_PID=$!
        printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":"What time is it? Please answer this simple question and exit immediately."}]{{`}}`}}\n' >&9
        # Close writer so reader can exit cleanly
        exec 9>&-
        wait $CLAUDE_PID
    else
        # For remediation, we use the CLAUDE.md we created earlier
        # No need to read prompt.md - remediation context is already prepared
        echo "✓ Using remediation context from CLAUDE.md"
    
        echo "startingRemediation:{{`{{`{{`}}`}}task_id{{`}}`}}"
        echo ""
    
            # DEBUG: Print MCP_CLIENT_CONFIG for troubleshooting client config issues
            echo "🔍 DEBUG: MCP_CLIENT_CONFIG is set to: '$MCP_CLIENT_CONFIG'"
            if [ -f "$MCP_CLIENT_CONFIG" ]; then
                echo "🔍 DEBUG: MCP_CLIENT_CONFIG file exists and is readable"
                echo "🔍 DEBUG: First few lines of client config:"
                head -10 "$MCP_CLIENT_CONFIG" 2>/dev/null || echo "Could not read client config file"
            else
                echo "🔍 DEBUG: MCP_CLIENT_CONFIG file does NOT exist or is not readable"
            fi
            echo ""
    
            # For remediation, we don't need complex prompt composition
            # The CLAUDE.md file contains all the necessary context and instructions
            echo "🔧 Starting Claude with remediation context..."
    
    
    
    
            # Seed initial user turn via a FIFO (system prompts are set via CLI flags, not streamed)
            FIFO_PATH="/workspace/agent-input.jsonl"
            rm -f "$FIFO_PATH" 2>/dev/null || true
            mkfifo "$FIFO_PATH"
            chmod 666 "$FIFO_PATH" || true
    
            # Start Claude (reader) first in background to avoid writer-open blocking
            $CLAUDE_CMD < "$FIFO_PATH" &
            CLAUDE_PID=$!
    
            # For remediation, we send a simple start message since CLAUDE.md contains all context
            USER_MESSAGE="🔧 REMEDIATION MODE ACTIVATED
    
    Please review the CLAUDE.md file for complete context and instructions. You are in remediation mode - focus on fixing the specific issues identified in the feedback while preserving existing functionality."
    
            # Prefer sending via sidecar HTTP endpoint (opens-writes-closes per request)
            if printf '{"text":%s}\n' "$(printf '%s' "$USER_MESSAGE" | jq -Rs .)" | \
                 curl -fsS -X POST http://127.0.0.1:8080/input \
                   -H 'Content-Type: application/json' \
                   --data-binary @- >/dev/null 2>&1; then
              echo "✓ Remediation prompt sent via sidecar /input"
            else
              echo "⚠️ Sidecar /input failed, falling back to direct FIFO write"
              # Fallback: open FIFO writer, send prompt, and close immediately to send EOF
              exec 9>"$FIFO_PATH"
              printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":%s}]{{`}}`}}\n' "$(printf '%s' "$USER_MESSAGE" | jq -Rs .)" >&9
              exec 9>&-  # Close immediately to send EOF to Claude
            fi
    
            # Optional debug: dump FIFO holders if requested
            if [ "${DEBUG_FIFO:-false}" = "true" ]; then
              echo "[DEBUG] Dumping FIFO holders for $FIFO_PATH"
              for p in /proc/[0-9]*; do
                pid=${p##*/}
                [ -d "$p/fd" ] || continue
                for fd in "$p"/fd/*; do
                  tgt=$(readlink "$fd" 2>/dev/null || true)
                  case "$tgt" in *agent-input.jsonl*)
                    fdnum=${fd##*/}
                    comm=$(cat "$p/comm" 2>/dev/null || echo "?")
                    echo "  PID=$pid COMM=$comm FD=$fdnum -> $tgt"
                  ;;
                  esac
                done
              done
            fi
    
            # Optional hang diagnostics without enforcing a timeout
            if [ -n "${HANG_DIAG_SECONDS:-}" ] && [ "$HANG_DIAG_SECONDS" -gt 0 ] 2>/dev/null; then
              (
                sleep "$HANG_DIAG_SECONDS"
                if kill -0 "$CLAUDE_PID" 2>/dev/null; then
                  echo "[DEBUG] Hang diag after ${HANG_DIAG_SECONDS}s: dumping FIFO holders and ps"
                  for p in /proc/[0-9]*; do
                    pid=${p##*/}; [ -d "$p/fd" ] || continue
                    for fd in "$p"/fd/*; do tgt=$(readlink "$fd" 2>/dev/null || true); case "$tgt" in *agent-input.jsonl*) fdnum=${fd##*/}; comm=$(cat "$p/comm" 2>/dev/null || echo "?"); echo "  PID=$pid COMM=$comm FD=$fdnum -> $tgt";; esac; done
                  done
                  ps -eo pid,ppid,comm,args | head -200 || true
                fi
              ) & HANG_DIAG_PID=$!
            fi
    
            # Wait for Claude process to complete naturally
            echo "⏳ Waiting for Claude process (PID: $CLAUDE_PID) to complete..."
    
            # Simple wait - Claude should exit naturally when done
            wait "$CLAUDE_PID"
            CLAUDE_EXIT_CODE=$?
    
            if [ $CLAUDE_EXIT_CODE -eq 0 ]; then
              echo "✅ Claude process completed successfully"
            else
              echo "⚠️ Claude process exited with code: $CLAUDE_EXIT_CODE"
            fi
    
            # Stop diagnostics if running
            if [ -n "${HANG_DIAG_PID:-}" ]; then kill "$HANG_DIAG_PID" 2>/dev/null || true; fi
    
            # Ensure FIFO cleanup happens regardless of how Claude exited
            echo "🔧 Performing FIFO cleanup..."
    
            # Close FIFO writer if it was opened (in fallback)
            if [ "$FIFO_OPENED" = "true" ]; then
              echo "🔧 Closing FIFO file descriptor..."
              # Try multiple methods to ensure fd 9 gets closed
              exec 9>&- 2>/dev/null || {
                echo "⚠️ exec 9>&- failed, trying alternative close method"
                eval "exec 9>&-" 2>/dev/null || {
                  echo "⚠️ Alternative close failed, FIFO fd may remain open"
                }
              }
            else
              echo "ℹ️ FIFO was not opened via fallback, checking sidecar"
            fi
    
            # Clean up FIFO file to ensure no processes are blocked
            if [ -p "$FIFO_PATH" ]; then
              echo "🔧 Removing FIFO to ensure clean shutdown"
              rm -f "$FIFO_PATH" 2>/dev/null || echo "⚠️ Could not remove FIFO"
            fi
    
            # Gracefully stop sidecar to allow Job to complete (all containers must exit)
            echo "🔧 Attempting sidecar shutdown..."
            shutdown_attempts=0
            max_shutdown_attempts=3
    
            while [ $shutdown_attempts -lt $max_shutdown_attempts ]; do
              if timeout 5 curl -fsS -X POST http://127.0.0.1:8080/shutdown >/dev/null 2>&1; then
                echo "✓ Sidecar shutdown request successful (attempt $((shutdown_attempts + 1)))"
                break
              else
                shutdown_attempts=$((shutdown_attempts + 1))
                echo "⚠️ Sidecar shutdown request failed (attempt $shutdown_attempts/$max_shutdown_attempts)"
                if [ $shutdown_attempts -lt $max_shutdown_attempts ]; then
                  echo "Retrying in 2 seconds..."
                  sleep 2
                fi
              fi
            done
    
            if [ $shutdown_attempts -eq $max_shutdown_attempts ]; then
              echo "❌ Failed to shutdown sidecar after $max_shutdown_attempts attempts"
              echo "🔧 Force terminating sidecar processes..."
              pkill -f "sidecar" || echo "No sidecar processes found to kill"
            fi
    
            # Wait for sidecar to actually terminate
            echo "⏳ Waiting for sidecar termination..."
            timeout=10
            while [ $timeout -gt 0 ]; do
              if ! pgrep -f "sidecar" > /dev/null 2>&1; then
                echo "✅ Sidecar terminated successfully"
                break
              fi
              sleep 1
              timeout=$((timeout - 1))
            done
    
            if [ $timeout -eq 0 ]; then
              echo "⚠️ Sidecar still running after wait period"
            fi
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 REMEDIATION TASK COMPLETE                    ║'
    echo '════════════════════════════════════════════════════════════════'
    
    # Claude execution completed - no hooks configured
    echo "Claude has completed successfully."
    
    # =============================================================================
    # PR DETECTION AND LABELING
    # =============================================================================
    # After Claude completes, check if a PR was created and apply correlation labels
    if [ -n "${GITHUB_TOKEN:-}" ] && command -v gh >/dev/null 2>&1; then
      echo "🔍 Checking for PRs created by this task..."
    
      # First, try to find PR by task label (Claude should have added task-N label)
      TASK_LABEL="task-${TASK_ID}"
      PR_NUMBER=$(gh pr list -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --label "$TASK_LABEL" --json number --jq '.[0].number' 2>/dev/null || true)
    
      # If not found by label, try by branch name (current branch)
      if [ -z "$PR_NUMBER" ]; then
        CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || true)
        if [ -n "$CURRENT_BRANCH" ] && [ "$CURRENT_BRANCH" != "main" ]; then
          PR_NUMBER=$(gh pr list -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --head "$CURRENT_BRANCH" --json number --jq '.[0].number' 2>/dev/null || true)
        fi
      fi
    
      if [ -n "$PR_NUMBER" ]; then
        echo "✅ Found PR #${PR_NUMBER}"
    
        # Get the PR URL
        PR_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}/pull/${PR_NUMBER}"
        echo "📝 PR URL: $PR_URL"
    
        # Update CodeRun status with PR URL via Kubernetes API
        echo "🔄 Updating CodeRun status with PR URL..."
        if command -v kubectl >/dev/null 2>&1; then
          # Create a patch to update the CodeRun status
          PATCH_JSON=$(cat <<EOF
    {
      "status": {
        "pullRequestUrl": "$PR_URL",
        "lastUpdate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
      }
    }
    EOF
    )
    
          # Apply the patch to update CodeRun status
          if kubectl patch coderun "$CODERUN_NAME" -n "$NAMESPACE" --type=merge --subresource=status -p "$PATCH_JSON" 2>/dev/null; then
            echo "✅ Updated CodeRun status with PR URL"
          else
            echo "⚠️ Failed to update CodeRun status (kubectl patch failed)"
          fi
        else
          echo "⚠️ kubectl not available, cannot update CodeRun status"
        fi
    
        # Apply correlation labels with comprehensive debugging
        echo "🏷️ Adding correlation labels to PR #${PR_NUMBER}..."
    
        # Debug: Check environment variables
        echo "🔍 DEBUG: Environment check for label creation:"
        echo "   TASK_ID: '${TASK_ID}'"
        echo "   WORKFLOW_NAME: '${WORKFLOW_NAME}'"
        echo "   SERVICE_NAME: '${SERVICE_NAME}'"
        echo "   CODERUN_NAME: '${CODERUN_NAME}'"
        echo "   GitHub Token: $([ -n "$GITHUB_TOKEN" ] && echo 'Present' || echo 'Missing')"
    
        # Validate required variables
        if [ -z "$WORKFLOW_NAME" ]; then
          echo "❌ ERROR: WORKFLOW_NAME is not set!"
          echo "🔍 DEBUG: Attempting to extract from CODERUN_NAME..."
          # Try to extract workflow name from CodeRun name pattern
          if [ -n "$CODERUN_NAME" ]; then
            # Pattern: service-t{task}-stage-{hash} created by workflow
            echo "   CODERUN_NAME format: $CODERUN_NAME"
          fi
    
          # Check if we can get it from Kubernetes labels
          if command -v kubectl >/dev/null 2>&1 && [ -n "$CODERUN_NAME" ] && [ -n "$NAMESPACE" ]; then
            echo "🔍 DEBUG: Trying to get workflow name from CodeRun labels..."
            WORKFLOW_FROM_LABELS=$(kubectl get coderun "$CODERUN_NAME" -n "$NAMESPACE" -o jsonpath='{.metadata.labels.workflow-name}' 2>/dev/null || echo "")
            if [ -n "$WORKFLOW_FROM_LABELS" ]; then
              echo "✅ Found workflow name from CodeRun labels: $WORKFLOW_FROM_LABELS"
              WORKFLOW_NAME="$WORKFLOW_FROM_LABELS"
            else
              echo "❌ Could not retrieve workflow name from CodeRun labels"
            fi
          fi
    
          # Final check - if still no workflow name, fail loudly
          if [ -z "$WORKFLOW_NAME" ]; then
            echo "❌ CRITICAL: Cannot determine WORKFLOW_NAME - this will cause correlation issues!"
            echo "🔍 DEBUG: Available environment variables:"
            env | grep -E "WORKFLOW|CODERUN|TASK|SERVICE" | sort
            # DO NOT use 'unknown' - exit with error instead
            echo "❌ Refusing to use 'unknown' label - failing task"
            exit 1
          fi
        fi
    
        TASK_LABEL="task-${TASK_ID}"
        RUN_LABEL="run-${WORKFLOW_NAME}"
        SERVICE_LABEL="service-${SERVICE_NAME}"
    
        echo "📋 Labels to apply:"
        echo "   Task: $TASK_LABEL"
        echo "   Run: $RUN_LABEL"
        echo "   Service: $SERVICE_LABEL"
    
        # Try to add labels with detailed error capture
        echo "🔍 DEBUG: Attempting to add labels to PR..."
        LABEL_ERROR=$(gh pr edit "$PR_NUMBER" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --add-label "${TASK_LABEL},${RUN_LABEL},${SERVICE_LABEL}" 2>&1)
        LABEL_EXIT_CODE=$?
    
        if [ $LABEL_EXIT_CODE -eq 0 ]; then
          echo "✅ Added correlation labels successfully"
        else
          echo "⚠️ Failed to add labels (exit code: $LABEL_EXIT_CODE)"
          echo "🔍 DEBUG: Error output: $LABEL_ERROR"
    
          # Check if labels exist
          echo "🔍 DEBUG: Checking which labels exist..."
          for label in "$TASK_LABEL" "$RUN_LABEL" "$SERVICE_LABEL"; do
            if gh label list -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --search "$label" | grep -q "^$label"; then
              echo "   ✓ Label '$label' exists"
            else
              echo "   ✗ Label '$label' does not exist"
              # Create the missing label
              echo "   📝 Creating label '$label'..."
              case "$label" in
                task-*) COLOR="f29513"; DESC="Task correlation" ;;
                run-*) COLOR="0366d6"; DESC="Workflow run correlation" ;;
                service-*) COLOR="0e8a16"; DESC="Service correlation" ;;
                *) COLOR="ededed"; DESC="Unknown label type" ;;
              esac
    
              CREATE_ERROR=$(gh label create "$label" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --color "$COLOR" --description "$DESC" 2>&1)
              CREATE_EXIT=$?
              if [ $CREATE_EXIT -eq 0 ]; then
                echo "   ✅ Created label '$label'"
              else
                echo "   ❌ Failed to create label '$label': $CREATE_ERROR"
              fi
            fi
          done
    
          # Retry adding labels with individual attempts
          echo "🔍 DEBUG: Retrying label addition individually..."
          LABELS_ADDED=0
          for label in "$TASK_LABEL" "$RUN_LABEL" "$SERVICE_LABEL"; do
            RETRY_ERROR=$(gh pr edit "$PR_NUMBER" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --add-label "$label" 2>&1)
            RETRY_EXIT=$?
            if [ $RETRY_EXIT -eq 0 ]; then
              echo "   ✅ Added label '$label'"
              LABELS_ADDED=$((LABELS_ADDED + 1))
            else
              echo "   ❌ Failed to add label '$label': $RETRY_ERROR"
            fi
          done
    
          if [ $LABELS_ADDED -eq 3 ]; then
            echo "✅ All labels added successfully after retry"
          elif [ $LABELS_ADDED -gt 0 ]; then
            echo "⚠️ Partial success: $LABELS_ADDED/3 labels added"
          else
            echo "❌ CRITICAL: Could not add any labels to PR"
            echo "🔍 DEBUG: Checking PR state..."
            PR_STATE=$(gh pr view "$PR_NUMBER" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --json state -q .state 2>/dev/null || echo "UNKNOWN")
            echo "   PR State: $PR_STATE"
            if [ "$PR_STATE" = "CLOSED" ] || [ "$PR_STATE" = "MERGED" ]; then
              echo "❌ PR is $PR_STATE - cannot add labels to closed/merged PRs"
            fi
          fi
        fi
      else
        echo "ℹ️ No PR found for this task (Claude may not have created one)"
      fi
    else
      echo "ℹ️ Skipping PR labeling: missing GITHUB_TOKEN or gh CLI"
    fi
    
    # Write sentinel file to signal sidecar to stop (Kubernetes-native file watch)
    touch /workspace/.agent_done 2>/dev/null || true
    
    # Final termination sequence
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 REX CONTAINER TERMINATION                    ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "Container PID: $$"
    echo "Final Process Check:"
    ps aux | head -5
    
    # Write completion marker for workflow tracking
    echo "rex-remediation-completed:$(date -u +%Y-%m-%dT%H:%M:%SZ)" > /workspace/.rex-complete
    
    # Force exit to terminate the pod
    echo "🔚 Force terminating container..."
    exit 0  code_container-rex.sh.hbs: |
    #!/bin/sh
    
    # Ensure Rust environment is always properly set up
    echo "🔧 Setting up Rust environment..."
    
    # Source Rust environment if available (fixes cargo not found issues)
    if [ -f "$HOME/.cargo/env" ]; then
        . "$HOME/.cargo/env"
        echo "✓ Sourced Rust environment from $HOME/.cargo/env"
    fi
    
    # Also try root cargo env as fallback
    if [ -f "/root/.cargo/env" ]; then
        . "/root/.cargo/env"
        echo "✓ Sourced Rust environment from /root/.cargo/env"
    fi
    
    # Ensure rustup has a default toolchain set
    if command -v rustup >/dev/null 2>&1; then
        rustup default stable 2>/dev/null || true
        echo "✓ Ensured stable Rust toolchain is default"
    else
        echo "⚠️ rustup not found in PATH"
    fi
    
    # Verify Rust is available
    if command -v cargo >/dev/null 2>&1; then
        echo "✓ Cargo is available: $(cargo --version)"
    else
        echo "❌ Cargo not found in PATH"
        echo "Current PATH: $PATH"
        echo "Attempting to find cargo..."
        find /usr -name cargo 2>/dev/null | head -5 || echo "No cargo found in /usr"
        find /home -name cargo 2>/dev/null | head -5 || echo "No cargo found in /home"
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║           REX/BLAZE DOCUMENTATION WORKFLOW STARTING          ║'
    echo '║                  Implementation Agent Active                  ║'
    echo '║            ⚠️  TASK {{`{{`{{`}}`}}task_id{{`}}`}} ONLY - NO OTHER TASKS ⚠️             ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "🎯 Agent: {{`{{`{{`}}`}}github_app{{`}}`}}"
    echo "📚 Focus: Documentation-first implementation approach"
    echo "📋 Task ID: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "⛔ CRITICAL: You must ONLY work on Task {{`{{`{{`}}`}}task_id{{`}}`}} - ignore ALL other tasks"
    
    # Clean up any leftover sentinel file from previous runs
    # This prevents premature sidecar shutdown on sequential task executions
    if [ -f /workspace/.agent_done ]; then
        echo "🧹 Cleaning up sentinel file from previous run"
        rm -f /workspace/.agent_done
    fi
    
    # Disable interactive Git prompts globally
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # Repository URL
    REPO_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    
    # GitHub App authentication is configured via environment variables
    echo "Using GitHub App authentication"
    
    # Authenticate with GitHub App
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        echo "Authenticating with GitHub App..."
    
        # Create temporary private key file (support escaped newlines)
        TEMP_KEY_FILE="/tmp/github-app-key.pem"
        printf '%b' "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
        chmod 600 "$TEMP_KEY_FILE"
    
        # Generate JWT token for GitHub App (fixed JWT generation for Linux containers)
        # JWT header
        JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # JWT payload with current time and expiration (10 minutes)
        NOW=$(date +%s)
        EXP=$((NOW + 600))
        JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # Sign the JWT
        JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
        JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
    
        # Get installation ID for the repository (robust parsing of owner/repo)
        INPUT_REPO="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        REPO_OWNER=""
        REPO_NAME=""
    
        if echo "$INPUT_REPO" | grep -qE '^https://github.com/'; then
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
        elif echo "$INPUT_REPO" | grep -qE '^git@github.com:'; then
            # SSH format git@github.com:owner/repo(.git)
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:[^/]+/([^/]+)(\.git)?|\1|')
        else
            # Fallback: assume slug owner/repo (possibly with .git)
            SLUG=$(echo "$INPUT_REPO" | sed -E 's|\.git$||')
            REPO_OWNER=$(echo "$SLUG" | cut -d'/' -f1)
            REPO_NAME=$(echo "$SLUG" | cut -d'/' -f2)
        fi
    
        echo "DEBUG: Parsed repository - Owner: '$REPO_OWNER', Name: '$REPO_NAME'"
    
        echo "Getting installation ID for $REPO_OWNER/$REPO_NAME..."
    
        # Get the installation ID (retry and follow redirects). Fallback to org installation.
        INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
            --connect-timeout 5 --max-time 12 \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
        INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "⚠️ Repo installation not found, trying org installation..."
            ORG_INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/orgs/$REPO_OWNER/installation")
            INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
        fi
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "❌ Failed to get installation ID for $REPO_OWNER/$REPO_NAME"
            echo "Response (repo): $INSTALLATION_RESPONSE"
            echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "Installation ID: $INSTALLATION_ID"
    
        # Get installation access token
        TOKEN_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
        GITHUB_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
        TOKEN_GENERATED_AT=$(date +%s)  # Track when token was generated for refresh logic
    
        if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ Failed to get installation access token"
            echo "Response: $TOKEN_RESPONSE"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        # Clean up temporary key file
        rm -f "$TEMP_KEY_FILE"
    
        # Export the token for git to use
        export GITHUB_TOKEN
    
        # Configure git to use the token (use --replace-all to handle multiple existing helpers)
        git config --global --replace-all credential.helper store
        echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
    
        # Also authenticate gh CLI with the token
        echo "$GITHUB_TOKEN" | gh auth login --with-token
    
        echo "✓ GitHub App authenticated successfully"
    
        # Token refresh functions for long-running jobs
        refresh_github_token() {
            echo "🔄 Refreshing GitHub App token..."
    
            # Create temporary key file
            TEMP_KEY_FILE="/tmp/github-app-key-$$"
            echo "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
            chmod 600 "$TEMP_KEY_FILE"
    
            # Generate new JWT
            JWT_TOKEN=$(ruby -r openssl -r json -r base64 -e "
            key = OpenSSL::PKey::RSA.new(File.read('$TEMP_KEY_FILE'))
            payload = {
                iat: Time.now.to_i - 60,
                exp: Time.now.to_i + (10 * 60),
                iss: '$GITHUB_APP_ID'
            }
            header = { alg: 'RS256', typ: 'JWT' }
    
            header_enc = Base64.urlsafe_encode64(header.to_json).gsub('=', '')
            payload_enc = Base64.urlsafe_encode64(payload.to_json).gsub('=', '')
            signature = Base64.urlsafe_encode64(key.sign(OpenSSL::Digest::SHA256.new, \"#{header_enc}.#{payload_enc}\")).gsub('=', '')
    
            puts \"#{header_enc}.#{payload_enc}.#{signature}\"
            ")
    
            # Get installation ID (reuse logic from initial auth)
            INSTALLATION_ID=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation" | jq -r '.id')
    
            if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
                INSTALLATION_ID=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" \
                    -H "Accept: application/vnd.github+json" \
                    "https://api.github.com/orgs/$REPO_OWNER/installation" | jq -r '.id')
            fi
    
            # Get new installation token
            TOKEN_RESPONSE=$(curl -s -X POST \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
            NEW_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
    
            if [ "$NEW_TOKEN" != "null" ] && [ -n "$NEW_TOKEN" ]; then
                export GITHUB_TOKEN="$NEW_TOKEN"
                export TOKEN_GENERATED_AT=$(date +%s)
    
                # Update git credentials
                echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
                echo "$GITHUB_TOKEN" | gh auth login --with-token 2>/dev/null
    
                echo "✅ Token refreshed successfully"
                rm -f "$TEMP_KEY_FILE"
                return 0
            else
                echo "❌ Failed to refresh token: $TOKEN_RESPONSE"
                rm -f "$TEMP_KEY_FILE"
                return 1
            fi
        }
    
        # Check if token needs refresh (call before git operations)
        refresh_token_if_needed() {
            if [ -z "$TOKEN_GENERATED_AT" ]; then
                echo "⚠️ No token timestamp found, refreshing token..."
                refresh_github_token
                return
            fi
    
            NOW=$(date +%s)
            TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
    
            # Refresh if token is older than 50 minutes (tokens last 1 hour, refresh at 50 min to be safe)
            if [ $TOKEN_AGE -gt 3000 ]; then
                echo "🔄 Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
                refresh_github_token
            fi
        }
    
    else
        echo "❌ GITHUB_APP_PRIVATE_KEY or GITHUB_APP_ID not found"
        exit 1
    fi
    
    # Git configuration with proper GitHub App attribution
    git config --global --add safe.directory /workspace
    
    # Set GitHub App attribution - use generic format for all agents
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    # Generic attribution that works for any agent
    GIT_AUTHOR_NAME="${GITHUB_APP} Agent (Claude Code)"
    GIT_AUTHOR_EMAIL="${GITHUB_APP}[bot]@users.noreply.github.com"
    
    # Configure git with proper GitHub App attribution
    git config --global user.name "$GIT_AUTHOR_NAME"
    git config --global user.email "$GIT_AUTHOR_EMAIL"
    
    # Set environment variables for Claude Code to use
    export GIT_AUTHOR_NAME="$GIT_AUTHOR_NAME"
    export GIT_AUTHOR_EMAIL="$GIT_AUTHOR_EMAIL"
    export GIT_COMMITTER_NAME="$GIT_AUTHOR_NAME"
    export GIT_COMMITTER_EMAIL="$GIT_AUTHOR_EMAIL"
    echo "✓ Git configured"
    
    # =============================================================================
    # AUTHENTICATION VERIFICATION
    # =============================================================================
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "🔐 AUTHENTICATION VERIFICATION"
    echo "═══════════════════════════════════════════════════════════════"
    echo ""
    
    # Repository URLs - Handle both full URLs and org/repo format
    # Check if repository_url already contains https://github.com/
    if echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        REPO_HTTP_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "\.git$"; then
            REPO_HTTP_URL="${REPO_HTTP_URL}.git"
        fi
    else
        REPO_HTTP_URL="https://github.com/{{`{{`{{`}}`}}repository_url{{`}}`}}.git"
    fi
    
    # Same for docs repository
    if echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        DOCS_HTTP_URL="{{`{{`{{`}}`}}docs_repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "\.git$"; then
            DOCS_HTTP_URL="${DOCS_HTTP_URL}.git"
        fi
    else
        DOCS_HTTP_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}.git"
    fi
    
    # DEBUG: Show what URLs are being constructed
    echo "🔍 DEBUG: URL Construction & Parameters"
    echo "  Input repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  Input docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  Input docs_project_directory: '{{`{{`{{`}}`}}docs_project_directory{{`}}`}}'"
    echo "  Input working_directory: '{{`{{`{{`}}`}}working_directory{{`}}`}}'"
    echo "  Input docs_branch: '{{`{{`{{`}}`}}docs_branch{{`}}`}}'"
    echo "  Input github_app: '{{`{{`{{`}}`}}github_app{{`}}`}}'"
    echo "  Input task_id: '{{`{{`{{`}}`}}task_id{{`}}`}}'"
    echo "  Input service: '{{`{{`{{`}}`}}service{{`}}`}}'"
    echo "  Constructed REPO_HTTP_URL: '$REPO_HTTP_URL'"
    echo "  Constructed DOCS_HTTP_URL: '$DOCS_HTTP_URL'"
    echo "  Current working directory: $(pwd)"
    echo "  Available environment variables:"
    env | grep -E "(GITHUB|ANTHROPIC)" | sort
    
    # Test HTTPS access to repository
    echo "🔍 DEBUG: Testing HTTPS repository access..."
    echo "  Command: git ls-remote \"$REPO_HTTP_URL\" HEAD"
    if git ls-remote "$REPO_HTTP_URL" HEAD > /tmp/repo_test.out 2>&1; then
      echo "✓ HTTPS repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Output: $(cat /tmp/repo_test.out | head -1)"
    else
      echo "❌ HTTPS repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Error output: $(cat /tmp/repo_test.out)"
      echo "  Git credential helper status:"
      git config --list | grep credential || echo "  No credential helpers configured"
      echo ""
      echo "🚫 ABORTING: Cannot access repository via HTTPS"
      exit 1
    fi
    
    # Test docs repository access
    echo "🔍 DEBUG: Testing docs repository access..."
    echo "  Command: git ls-remote \"$DOCS_HTTP_URL\" HEAD"
    if git ls-remote "$DOCS_HTTP_URL" HEAD > /tmp/docs_test.out 2>&1; then
      echo "✓ Docs repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Output: $(cat /tmp/docs_test.out | head -1)"
    else
      echo "❌ Docs repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Error output: $(cat /tmp/docs_test.out)"
      echo ""
      echo "🚫 ABORTING: Cannot access docs repository via HTTPS"
      exit 1
    fi
    
    # Dual Repository Setup - Platform repo for docs, Target repo for implementation
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "║                 DUAL REPOSITORY SETUP                        ║"
    echo "═══════════════════════════════════════════════════════════════"
    
    # Repository Information
    DOCS_BRANCH="{{`{{`{{`}}`}}docs_branch{{`}}`}}"
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Helper: derive safe workspace directory name from repo input (URL, SSH, or slug)
    sanitize_repo_dir() {
        input="$1"
        if echo "$input" | grep -qE '^https://github.com/'; then
            owner=$(echo "$input" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            name=$(echo "$input" | sed -E 's|https://github.com/[^/]+/([^/]+)(\\.git)?|\1|')
            printf '%s-%s' "$owner" "$name"
        elif echo "$input" | grep -qE '^git@github.com:'; then
            owner=$(echo "$input" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            name=$(echo "$input" | sed -E 's|git@github.com:[^/]+/([^/]+)(\\.git)?|\1|')
            printf '%s-%s' "$owner" "$name"
        else
            # Assume owner/repo (optionally with .git)
            slug=$(echo "$input" | sed -E 's|\\.git$||')
            echo "$slug" | tr '/' '-'
        fi
    }
    
    # Derive workspace directory names (owner-repo)
    DOCS_REPO_DIR=$(sanitize_repo_dir "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}")
    TARGET_REPO_DIR=$(sanitize_repo_dir "{{`{{`{{`}}`}}repository_url{{`}}`}}")
    
    echo "=== REPOSITORY SETUP ==="
    echo "Docs repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
    echo "Target repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
    echo "Docs branch: $DOCS_BRANCH"
    echo "GitHub App: $GITHUB_APP"
    
    # Always use consistent workflow approach
    # Even if docs and target are the same repo, we clone them separately
    # This avoids complex branch switching and file preservation issues
    echo "=== UNIFIED WORKFLOW APPROACH ==="
    echo "  docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  └─ TaskMaster files will be copied from docs repo at: {{`{{`{{`}}`}}docs_project_directory{{`}}`}}"
    
    # Repository Setup - Always use consistent approach
    echo "=== REPOSITORY SETUP ==="
    
    # Step 1: Clone or update docs repository temporarily
    if [ -d "/tmp/docs-repo" ]; then
        echo "🔄 DOCS REPOSITORY: UPDATE - temporary directory exists"
        cd /tmp/docs-repo
        git fetch origin
        git checkout "$DOCS_BRANCH"
        git reset --hard "origin/$DOCS_BRANCH"
        cd /workspace
        echo "✓ Docs repository updated"
    else
        echo "📥 DOCS REPOSITORY: CLONING - extracting task files"
        if ! git clone "$DOCS_HTTP_URL" /tmp/docs-repo; then
            echo "❌ Failed to clone docs repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
            exit 1
        fi
        cd /tmp/docs-repo && git checkout "$DOCS_BRANCH" && cd /workspace
        echo "✓ Docs repository cloned to temporary location"
    fi
    
    # Step 2: Clone or update target repository
    if [ -d "$TARGET_REPO_DIR" ]; then
        echo "🔄 TARGET REPOSITORY: UPDATE - directory already exists"
        echo "📁 Found existing target repository '$TARGET_REPO_DIR', updating..."
        cd "$TARGET_REPO_DIR"
        git fetch origin main
        git reset --hard origin/main
        cd /workspace
        echo "✓ Target repository updated successfully"
    else
        echo "📥 TARGET REPOSITORY: CLONING - first time setup"
        if ! git clone "$REPO_HTTP_URL" "$TARGET_REPO_DIR"; then
            echo "❌ Failed to clone target repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
            exit 1
        fi
        echo "✓ Target repository cloned successfully"
    fi
    
    # Step 3: Copy task files from docs repo to target repo
    echo "📋 TASK FILES: COPYING from docs to target repository"
    mkdir -p "/workspace/$TARGET_REPO_DIR/task"
    
    # Determine docs project directory path
    {{`{{`{{`}}`}}#if docs_project_directory{{`}}`}}
    if [ "{{`{{`{{`}}`}}docs_project_directory{{`}}`}}" = "." ]; then
        DOCS_PATH="/tmp/docs-repo/.taskmaster"
    else
        DOCS_PATH="/tmp/docs-repo/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster"
    fi
    {{`{{`{{`}}`}}else{{`}}`}}
    DOCS_PATH="/tmp/docs-repo/.taskmaster"
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    # Copy specific task files
    TASK_DIR="$DOCS_PATH/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "🔍 DEBUG: Looking for task files at: $TASK_DIR"
    echo "🔍 DEBUG: Docs path is: $DOCS_PATH"
    echo "🔍 DEBUG: Contents of docs temp directory:"
    ls -la /tmp/docs-repo/.taskmaster/ || echo "No .taskmaster found"
    echo "🔍 DEBUG: Contents of docs directory:"
    ls -la /tmp/docs-repo/.taskmaster/docs/ || echo "No docs directory found"
    
    if [ -d "$TASK_DIR" ]; then
        echo "🔍 DEBUG: Task directory found, contents:"
        ls -la "$TASK_DIR"
    
        echo "✅ Copying task.md..."
        cp "$TASK_DIR/task.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ task.md copied" || echo "❌ task.md copy failed"
    
        echo "✅ Copying acceptance-criteria.md..."
        cp "$TASK_DIR/acceptance-criteria.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ acceptance-criteria.md copied" || echo "❌ acceptance-criteria.md copy failed"
    
        echo "✅ Copying prompt.md..."
        cp "$TASK_DIR/prompt.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ prompt.md copied" || echo "❌ prompt.md copy failed"
    
        echo "✅ Copying client-config.json..."
        if [ -f "$TASK_DIR/client-config.json" ]; then
            cp "$TASK_DIR/client-config.json" "$CLAUDE_WORK_DIR/client-config.json" && echo "✓ client-config.json copied to Claude working directory" || echo "❌ client-config.json copy failed"
        else
            echo "⚠️ client-config.json not found - MCP client may not be configured"
        fi
    
        echo "✅ Copying toolman-guide.md..."
        if [ -f "$TASK_DIR/toolman-guide.md" ]; then
            cp "$TASK_DIR/toolman-guide.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ toolman-guide.md copied" || echo "❌ toolman-guide.md copy failed"
        else
            echo "⚠️ toolman-guide.md not found - code agent won't have tool usage guidance"
        fi
    
        echo "✓ Task {{`{{`{{`}}`}}task_id{{`}}`}} files copied from $TASK_DIR"
    else
        echo "❌ CRITICAL: Task {{`{{`{{`}}`}}task_id{{`}}`}} directory not found at: $TASK_DIR"
        echo "🔍 DEBUG: Available directories in docs:"
        find /tmp/docs-repo -name "task-*" -type d || echo "No task directories found"
    fi
    
    # Copy architecture.md from docs root
    ARCH_FILE="$DOCS_PATH/docs/architecture.md"
    if [ -f "$ARCH_FILE" ]; then
        cp "$ARCH_FILE" "/workspace/$TARGET_REPO_DIR/task/"
        echo "✓ Architecture documentation copied"
    else
        echo "⚠️ architecture.md not found at: $ARCH_FILE"
    fi
    
    # Copy tasks.json if it exists
    if [ -f "$DOCS_PATH/tasks.json" ]; then
        cp "$DOCS_PATH/tasks.json" "/workspace/$TARGET_REPO_DIR/task/"
        echo "✓ tasks.json copied"
    fi
    
    echo "✓ Task files copied to target repository"
    
    # DEBUG: Verify files were copied successfully
    echo "🔍 DEBUG: Contents of target task directory after copy:"
    ls -la "/workspace/$TARGET_REPO_DIR/task/" || echo "Task directory not found"
    echo "🔍 DEBUG: Checking if prompt.md exists:"
    [ -f "/workspace/$TARGET_REPO_DIR/task/prompt.md" ] && echo "✅ prompt.md exists" || echo "❌ prompt.md missing"
    
    # Step 4: Clean up docs repository
    echo "🧹 CLEANUP: Removing temporary docs repository"
    rm -rf /tmp/docs-repo
    echo "✓ Docs repository cleaned up"
    
    # Set working directory to the target repository root
    REPO_NAME="$TARGET_REPO_DIR"
    echo "✓ Working directory: /workspace/$REPO_NAME"
    
    # Set Claude working directory early (needed for client-config.json copy)
    WORK_DIR="{{`{{`{{`}}`}}working_directory{{`}}`}}"
    if [ "$WORK_DIR" = "." ] || [ -z "$WORK_DIR" ]; then
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME"
    else
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME/$WORK_DIR"
    fi
    mkdir -p "$CLAUDE_WORK_DIR"
    echo "✓ Set Claude working directory: $CLAUDE_WORK_DIR"
    
    # Setup feature branch for implementation
    echo "=== BRANCH SETUP ==="
    cd "/workspace/$REPO_NAME"
    
    # Sync with latest main to prevent conflicts
    echo "🔄 Syncing with latest main to prevent conflicts..."
    git fetch origin main 2>/dev/null || git fetch origin master 2>/dev/null || echo "⚠️ Could not fetch main/master branch"
    
    # Create or checkout feature branch (with conflict-safe fallback)
    FEATURE_BRANCH="feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation"
    BRANCH_EXISTS="false"
    
    if git show-ref --verify --quiet refs/heads/$FEATURE_BRANCH; then
        BRANCH_EXISTS="true"
        echo "Feature branch '$FEATURE_BRANCH' exists, checking out..."
        git checkout $FEATURE_BRANCH
    
        echo "📥 Merging latest main into $FEATURE_BRANCH..."
        if git merge origin/main --no-edit; then
            echo "✓ Successfully merged latest main into feature branch"
        else
            echo "⚠️ MERGE CONFLICT: Cannot auto-merge main into $FEATURE_BRANCH"
            echo "🔄 Auto-aborting merge and creating a fresh branch from origin/main"
            # Abort merge if in progress
            git merge --abort 2>/dev/null || true
            # Create a unique fresh branch to avoid reuse conflicts
            NEW_BRANCH="${FEATURE_BRANCH}-$(date -u +%Y%m%d%H%M%S)"
            git checkout -B "$NEW_BRANCH" origin/main
            FEATURE_BRANCH="$NEW_BRANCH"
            echo "✓ Switched to fresh branch: $FEATURE_BRANCH"
        fi
    else
        # Create new feature branch from latest main
        echo "Creating new feature branch '$FEATURE_BRANCH' from latest main..."
        git checkout -b $FEATURE_BRANCH origin/main
        echo "✓ Created feature branch: $FEATURE_BRANCH"
    fi
    
    # 5. Change to Claude Working Directory (already set up earlier)
    cd "$CLAUDE_WORK_DIR"
    echo "✓ Changed to Claude working directory: $CLAUDE_WORK_DIR"
    echo "🔑 CRITICAL: Claude will be launched from this directory"
    
    # Working directory setup completed above
    
    # Configure git user after successful clone
    echo "=== POST-CLONE GIT CONFIGURATION ==="
    # Fix dubious ownership issues
    git config --global --add safe.directory "/workspace/$REPO_NAME"
    echo "✓ Added repository to safe directories"
    
    # Set git config locally in the working repository (persistent on PVC)
    if [ -d "/workspace/$REPO_NAME/.git" ]; then
        cd "/workspace/$REPO_NAME"
        git config --local user.name "$GIT_AUTHOR_NAME"
        git config --local user.email "$GIT_AUTHOR_EMAIL"
        # Set up automatic upstream for new branches
        git config --local push.autoSetupRemote true
        echo "✓ Configured git user in target repository: $GIT_AUTHOR_NAME"
        echo "✓ Enabled automatic upstream setup for new branches"
    fi
    
    cd /workspace
    
    # Copy ConfigMap files to working directory (AFTER repository clone)
    echo "=== CONFIGMAP FILE SETUP ==="
    
    # Claude working directory already set above during repository setup
    
    echo "Setting up files in Claude working directory: $CLAUDE_WORK_DIR"
    cd "$CLAUDE_WORK_DIR"
    
    # Copy all files from ConfigMap to working directory
    if [ -d "/task-files" ]; then
      echo "Copying ConfigMap files to working directory..."
    
      # CLAUDE.md Memory Persistence Logic (controlled by overwriteMemory CRD field)
            OVERWRITE_MEMORY="{{`{{`{{`}}`}}overwrite_memory{{`}}`}}"
    
      # Handle CLAUDE.md based on overwriteMemory setting
            if [ "$OVERWRITE_MEMORY" = "true" ]; then
              # Overwrite mode: Always replace CLAUDE.md with fresh template
        cp "/task-files/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
        cp "/task-files/CLAUDE.md" "/workspace/CLAUDE.md"
              echo "✓ Overwrote CLAUDE.md memory file (fresh start requested)"
              echo "✓ Copied CLAUDE.md to workspace root for easy access"
            else
              # Preserve mode (default): Only copy if doesn't exist
              if [ ! -f "$CLAUDE_WORK_DIR/CLAUDE.md" ]; then
          # Initial creation - copy from ConfigMap
          cp "/task-files/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
          cp "/task-files/CLAUDE.md" "/workspace/CLAUDE.md"
                echo "✓ Created initial CLAUDE.md memory file"
                echo "✓ Copied CLAUDE.md to workspace root for easy access"
              else
                echo "✓ Preserved existing CLAUDE.md memory file (maintaining accumulated context)"
                # Still copy to workspace root for consistency
                cp "$CLAUDE_WORK_DIR/CLAUDE.md" "/workspace/CLAUDE.md"
                echo "✓ Synced CLAUDE.md to workspace root"
              fi
            fi
    
      # Copy all other markdown files (excluding CLAUDE.md)
      for md_file in /task-files/*.md; do
        if [ -f "$md_file" ]; then
          basename_file=$(basename "$md_file")
          # Skip CLAUDE.md since we handled it above
          if [ "$basename_file" != "CLAUDE.md" ]; then
            cp "$md_file" "$CLAUDE_WORK_DIR/"
            echo "✓ Updated $basename_file"
          fi
        fi
      done
    
      # Verify enterprise settings (mounted directly from ConfigMap)
      if [ -f "/etc/claude-code/managed-settings.json" ]; then
        echo "✓ Enterprise settings verified"
        if ! jq empty /etc/claude-code/managed-settings.json 2>/dev/null; then
          echo "❌ Invalid enterprise settings JSON"
          exit 1
        fi
      else
        echo "❌ Enterprise settings not found"
        exit 1
      fi
    
      # Copy guidelines files to working directory
      if [ -f "/task-files/coding-guidelines.md" ]; then
        cp /task-files/coding-guidelines.md "$CLAUDE_WORK_DIR/"
        echo "✓ Copied coding-guidelines.md to working directory"
      fi
    
      if [ -f "/task-files/github-guidelines.md" ]; then
        cp /task-files/github-guidelines.md "$CLAUDE_WORK_DIR/"
        echo "✓ Copied github-guidelines.md to working directory"
      fi
    
      # System prompt will be rendered inline (no file copying needed)
      echo "✓ System prompt template will be rendered inline"
    
      # Hook copying disabled
      echo "! Hook scripts disabled - no hooks will be copied"
    
      # Set up MCP configuration
      echo "Setting up MCP configuration..."
    
      # Copy MCP configuration from ConfigMap to project root (project scope)
      if [ -f "/task-files/mcp.json" ]; then
        cp /task-files/mcp.json "$CLAUDE_WORK_DIR/.mcp.json"
        echo "✓ Copied mcp.json to .mcp.json (project scope)"
      else
        echo "⚠️  mcp.json template not found"
      fi
    
      # Enterprise managed settings are mounted directly from ConfigMap
      echo "=== ENTERPRISE MANAGED SETTINGS ==="
      echo "✓ Settings mounted directly from ConfigMap at: /etc/claude-code/managed-settings.json"
      echo "✓ No copying needed - mount automatically reflects latest ConfigMap changes"
    
      echo "✓ ConfigMap files copied to $CLAUDE_WORK_DIR"
    else
      echo "⚠️  Warning: /task-files directory not found (ConfigMap not mounted?)"
    fi
    
    
    # Copy Current Task Documentation to Working Directory
    echo "=== TASK DOCUMENTATION SETUP ==="
    echo "🔍 DEBUG: REPO_NAME is: $REPO_NAME"
    echo "🔍 DEBUG: CLAUDE_WORK_DIR is: $CLAUDE_WORK_DIR"
    echo "🔍 DEBUG: Task ID is: {{`{{`{{`}}`}}task_id{{`}}`}}"
    
    # Task directory should already exist from multi-repo workflow or be created as needed
    mkdir -p "$CLAUDE_WORK_DIR/task"
    echo "✓ Created task directory at: $CLAUDE_WORK_DIR/task"
    
    # Task documentation was copied from docs repository during repository setup
    echo "✓ Task documentation available in task/ directory"
    
    # Move client-config.json if it's in the task directory
    if [ -f "$CLAUDE_WORK_DIR/task/client-config.json" ]; then
        mv "$CLAUDE_WORK_DIR/task/client-config.json" "$CLAUDE_WORK_DIR/client-config.json" && echo "✓ client-config.json moved to Claude working directory" || echo "❌ client-config.json move failed"
    fi
    
    # DEBUG: Verify files were copied successfully
    echo "🔍 DEBUG: Contents of target task directory:"
    ls -la "$CLAUDE_WORK_DIR/task/" || echo "Task directory not found"
    echo "🔍 DEBUG: Checking if prompt.md exists:"
    [ -f "$CLAUDE_WORK_DIR/task/prompt.md" ] && echo "✅ prompt.md exists" || echo "❌ prompt.md missing"
    
    # Verify client-config.json is available in Claude's working directory
    echo "=== TOOLMAN CONFIG SETUP ==="
    CLAUDE_CONFIG="$CLAUDE_WORK_DIR/client-config.json"
    
    if [ -f "$CLAUDE_CONFIG" ]; then
      echo "✓ client-config.json found in Claude working directory"
      # Set MCP_CLIENT_CONFIG environment variable for MCP server/bridge
      export MCP_CLIENT_CONFIG="$CLAUDE_CONFIG"
      echo "✓ MCP_CLIENT_CONFIG set to: $MCP_CLIENT_CONFIG"
    else
      echo "⚠️ client-config.json not found in Claude working directory - MCP client may not work correctly"
    fi
    
    echo '=== WORKSPACE VALIDATION ==='
    
    # Check for required files in Claude's working directory
    MISSING_FILES=""
    REQUIRED_FILES="CLAUDE.md"
    
    echo "Checking for required files..."
    for file in $REQUIRED_FILES; do
      if [ ! -f "$CLAUDE_WORK_DIR/$file" ]; then
        echo "ERROR: Missing required file: $CLAUDE_WORK_DIR/$file"
        MISSING_FILES="$MISSING_FILES $file"
      else
        echo "✓ Found: $CLAUDE_WORK_DIR/$file"
        # Show file size for verification
        size=$(wc -c < "$CLAUDE_WORK_DIR/$file" 2>/dev/null || echo "0")
        echo "  File size: $size bytes"
      fi
    done
    
    # Check git repository (REQUIRED for implementation tasks)
    if [ ! -d "/workspace/$REPO_NAME/.git" ]; then
      echo "✗ CRITICAL ERROR: No target git repository found!"
      MISSING_FILES="$MISSING_FILES git-repository"
    else
      echo "✓ Found: target git repository"
    fi
    
    # If any files are missing, abort
    if [ -n "$MISSING_FILES" ]; then
      echo ""
      echo "═══════════════════════════════════════════════════════════════"
      echo "║                 WORKSPACE VALIDATION FAILED                  ║"
      echo "═══════════════════════════════════════════════════════════════"
      echo ""
      echo "The following required files are missing:"
      for missing in $MISSING_FILES; do
        case "$missing" in
          "CLAUDE.md")
            echo "  ❌ $missing - Main task instructions for Claude"
            ;;
          "git-repository")
            echo "  ❌ $missing - Required for committing implementation changes"
            ;;
          *)
            echo "  ❌ $missing"
            ;;
        esac
      done
      echo ""
      echo "These files should have been created by the ConfigMap setup process."
      echo "Claude will NOT be started to avoid wasting API credits."
      echo ""
      exit 1
    fi
    
    echo "✓ All required files present. Workspace is valid."
    
    echo '=== IMPLEMENTATION TASK DIAGNOSTICS ==='
    echo "Project directory: $CLAUDE_WORK_DIR"
    echo "Project directory contents:"
    ls -la "$CLAUDE_WORK_DIR"
    echo ""
    
    # Show git status
    echo "Git status:"
    git status 2>/dev/null || echo "Git status unavailable"
    echo ""
    
    echo '=== CLAUDE EXECUTION ==='
    
    # Export necessary variables
    export SERVICE_NAME="{{`{{`{{`}}`}}service{{`}}`}}"
    export TASK_ID="{{`{{`{{`}}`}}task_id{{`}}`}}"
    export GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Change to project directory before running Claude
    cd "$CLAUDE_WORK_DIR"
    echo "Changed to directory: $(pwd)"
    
    # Verify we're in the correct directory and have required files
    echo "=== WORKING DIRECTORY VERIFICATION ==="
    echo "Current working directory: $(pwd)"
    echo "Expected directory: $CLAUDE_WORK_DIR"
    if [ "$(pwd)" != "$CLAUDE_WORK_DIR" ]; then
      echo "❌ ERROR: Failed to change to correct working directory!"
      echo "Attempting to change directory again..."
      cd "$CLAUDE_WORK_DIR" || exit 1
      echo "✓ Successfully changed to: $(pwd)"
    fi
    
    # Verify git repository is accessible from Claude working directory
    echo "=== GIT REPOSITORY VERIFICATION ==="
    if [ ! -d ".git" ]; then
      echo "❌ ERROR: No .git directory found in Claude working directory: $(pwd)"
      echo "📂 Checking parent directory structure:"
      echo "  Current: $(pwd)"
      echo "  Contents: $(ls -la . | head -5)"
      if [ -d "/workspace/$REPO_NAME/.git" ]; then
        echo "  Found .git at: /workspace/$REPO_NAME/"
        echo "🔧 This indicates a working directory path mismatch"
        echo "🔧 CLAUDE_WORK_DIR: $CLAUDE_WORK_DIR"
        echo "🔧 Expected git repo: /workspace/$REPO_NAME"
      fi
      exit 1
    else
      echo "✅ Git repository verified at: $(pwd)/.git"
      echo "✅ Repository status: $(git status --porcelain | wc -l) modified files"
      echo "✅ Current branch: $(git branch --show-current 2>/dev/null || echo 'detached')"
    fi
    
    # Verify setup
    echo "✓ Code implementation environment ready"
    
    # Build Claude command
    CLAUDE_CMD="claude -p --output-format stream-json --input-format stream-json --verbose"
    
    # Look for agent-specific system prompt file from agents ConfigMap
    # The system prompt should be in the agents ConfigMap if configured
    if [ -f "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        echo "✓ Found system prompt file for {{`{{`{{`}}`}}github_app{{`}}`}}, adding to Claude command"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    elif [ -f "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        # Fallback to task-files if included inline
        echo "✓ Found system prompt in task ConfigMap for {{`{{`{{`}}`}}github_app{{`}}`}}"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    else
        echo "ℹ️ No system prompt file found for agent {{`{{`{{`}}`}}github_app{{`}}`}}, using defaults"
    fi
    
    # Model is set via settings.json template, not CLI flag
    
    # Add continue flag if this is a retry attempt or user requested continuation
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    CLAUDE_CMD="$CLAUDE_CMD --continue"
    echo 'Adding --continue flag (attempt {{`{{`{{`}}`}}attempts{{`}}`}}{{`{{`{{`}}`}}#if user_requested{{`}}`}} - user requested{{`{{`{{`}}`}}/if{{`}}`}})'
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    echo "════════════════════════════════════════════════════════════════"
    echo "║                    STARTING CLAUDE EXECUTION                  ║"
    echo "════════════════════════════════════════════════════════════════"
    echo "Command: $CLAUDE_CMD"
    echo "Note: Claude will automatically read CLAUDE.md from the working directory"
    
    # Inline system prompt (static content)
    SYSTEM_PROMPT='## 🚨 CRITICAL SYSTEM REQUIREMENTS 🚨
    
    **⛔ OVERCONFIDENCE MITIGATION - MANDATORY VERIFICATION ⛔**
    
    You have a DANGEROUS tendency to declare task completion before actually verifying everything works. This is ABSOLUTELY UNACCEPTABLE.
    
    **MANDATORY VERIFICATION REQUIREMENTS:**
    - ✅ **MUST** actually run and test your code - never assume it works
    - ✅ **MUST** verify ALL acceptance criteria through actual testing
    - ✅ **MUST** confirm your changes don'\''t break existing functionality
    - ✅ **MUST** test end-to-end workflows and edge cases
    - ✅ **MUST** run all linters and build checks successfully
    - ✅ **CANNOT** claim completion based on code appearance alone
    
    **YOU ARE PROHIBITED FROM CLAIMING SUCCESS UNTIL:**
    1. You have executed and verified every piece of functionality
    2. You have tested integration with existing systems
    3. You have confirmed all acceptance criteria pass through testing
    4. All automated tests pass (linting, builds, unit tests)
    5. You have verified the solution works end-to-end in practice
    
    **IF YOU DECLARE SUCCESS WITHOUT VERIFICATION, YOU HAVE FAILED.**
    
    ## 🔧 ORCHESTRATOR EXECUTION CONTEXT
    
    - **Service**: {{`{{`{{`}}`}}service{{`}}`}}
    - **Task ID**: {{`{{`{{`}}`}}task_id{{`}}`}}
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Docs Repository**: {{`{{`{{`}}`}}docs_repository_url{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    - **GitHub App**: {{`{{`{{`}}`}}github_app{{`}}`}}
    
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    ## 🔄 CONTINUE SESSION - PR COMMENT RESOLUTION PRIORITY
    
    **⚠️ MANDATORY FIRST STEP: Before proceeding with any other work, you MUST:**
    
    1. **Check for unresolved PR comments**: Use `gh pr view --json reviews` or check the PR directly
    2. **Resolve ALL pending comments first**: Address reviewer feedback, fix issues, respond to questions
    3. **Push comment resolutions**: Commit and push any fixes for reviewer concerns
    4. **Only then proceed**: After ALL PR comments are resolved, continue with the main task
    
    **This ensures reviewer feedback takes priority and maintains collaborative workflow quality.**
    
    {{`{{`{{`}}`}}/if{{`}}`}}
    ## ⚠️ EXECUTION REQUIREMENTS
    
    - **Follow patterns**: Use @coding-guidelines.md and @github-guidelines.md
    - **Pre-PR quality gates (MANDATORY)**: Do NOT open a PR unless all of these pass locally:
      - `cargo fmt --all -- --check`
      - `cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic`
      - `cargo test --workspace --all-features` and high coverage (aim ≥95%, target ~100% on critical paths)
    - **GitHub workflow**: Read @github-guidelines.md for commit standards
    - **Verify continuously**: Run tests and checks after each significant change
    - **Commit incrementally**: Don'\''t save all changes for the end
    - **Test thoroughly**: Validate against acceptance criteria before completion
    
    ## 🚨 NON-NEGOTIABLE PULL REQUEST REQUIREMENT 🚨
    
    **⛔ CRITICAL: YOU MUST CREATE A PULL REQUEST - NO EXCEPTIONS ⛔**
    
    **MANDATORY FINAL STEP:**
    - **MUST** create a pull request using `gh pr create` command
    - **MUST** include proper labels (task-{{`{{`{{`}}`}}task_id{{`}}`}}, run-{{`{{`{{`}}`}}workflow.name{{`}}`}}, service-{{`{{`{{`}}`}}service{{`}}`}})
    - **MUST** verify PR creation succeeded before claiming task completion
    - **THE TASK IS INCOMPLETE AND FAILED IF NO PR IS CREATED**
    
    **YOU CANNOT COMPLETE THIS TASK WITHOUT CREATING A PULL REQUEST.**
    **IF YOU DO NOT CREATE A PR, YOU HAVE FAILED THE TASK COMPLETELY.**
    
    **Remember**: Focus on thorough implementation and verification.'
    
    echo "Starting Claude execution (stream-json via FIFO)..."
    echo "=========================="
    
    # Safe mode toggle for debugging (prevents token consumption)
    SAFE_MODE="false"  # Set to "false" for full task execution
    
    if [ "$SAFE_MODE" = "true" ]; then
        echo "🛡️ SAFE MODE ENABLED - Running simple test instead of full task"
        FIFO_PATH="/workspace/agent-input.jsonl"
        rm -f "$FIFO_PATH" 2>/dev/null || true
        mkfifo "$FIFO_PATH"
        chmod 666 "$FIFO_PATH" || true
        # Keep a persistent writer open and start Claude in background to avoid EOF race
        exec 9>"$FIFO_PATH"
        $CLAUDE_CMD < "$FIFO_PATH" &
        CLAUDE_PID=$!
        printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":"What time is it? Please answer this simple question and exit immediately."}]{{`}}`}}\n' >&9
        # Close writer so reader can exit cleanly
        exec 9>&-
        wait $CLAUDE_PID
    else
        # Debug: Show what's actually in the task directory before checking for prompt.md
        echo "🔍 DEBUG: About to check for prompt.md at: $CLAUDE_WORK_DIR/task/prompt.md"
        echo "🔍 DEBUG: Contents of task directory:"
        ls -la "$CLAUDE_WORK_DIR/task/" || echo "Task directory not found or empty"
        echo "🔍 DEBUG: Current working directory contents:"
        ls -la "$CLAUDE_WORK_DIR/" || echo "Working directory not accessible"
    
        # Check if prompt.md exists and use it as main prompt
        if [ -f "$CLAUDE_WORK_DIR/task/prompt.md" ]; then
            echo "✓ Using task-specific prompt from docs service: task/prompt.md"
    
            echo "startingTask:{{`{{`{{`}}`}}task_id{{`}}`}}"
            echo ""
    
            # DEBUG: Print MCP_CLIENT_CONFIG for troubleshooting client config issues
            echo "🔍 DEBUG: MCP_CLIENT_CONFIG is set to: '$MCP_CLIENT_CONFIG'"
            if [ -f "$MCP_CLIENT_CONFIG" ]; then
                echo "🔍 DEBUG: MCP_CLIENT_CONFIG file exists and is readable"
                echo "🔍 DEBUG: First few lines of client config:"
                head -10 "$MCP_CLIENT_CONFIG" 2>/dev/null || echo "Could not read client config file"
            else
                echo "🔍 DEBUG: MCP_CLIENT_CONFIG file does NOT exist or is not readable"
            fi
            echo ""
    
            # Prepare prompt prefix with CRITICAL task isolation instruction
            PROMPT_PREFIX="⛔ **CRITICAL TASK ISOLATION REQUIREMENT** ⛔
    
    You are assigned to work on **TASK {{`{{`{{`}}`}}task_id{{`}}`}} ONLY**.
    
    **STRICT RULES:**
    1. You MUST ONLY implement Task {{`{{`{{`}}`}}task_id{{`}}`}} - ignore ALL other tasks
    2. DO NOT skip ahead to other tasks, even if you see evidence of previous work
    3. DO NOT implement task-2, task-3, task-4, etc. - ONLY Task {{`{{`{{`}}`}}task_id{{`}}`}}
    4. If you see existing code from other tasks, IGNORE IT
    5. If your memory (CLAUDE.md) mentions other tasks, IGNORE those parts
    6. Focus SOLELY on the requirements in task/prompt.md for Task {{`{{`{{`}}`}}task_id{{`}}`}}
    
    **TASK VERIFICATION:** Before starting, confirm you are working on Task {{`{{`{{`}}`}}task_id{{`}}`}} by stating: \"Starting implementation of Task {{`{{`{{`}}`}}task_id{{`}}`}} only.\"
    
    ---
    
    "
    
            # Add toolman guidance if available
            if [ -f "$CLAUDE_WORK_DIR/task/toolman-guide.md" ]; then
                PROMPT_PREFIX="${PROMPT_PREFIX}🔧 **Tool Usage Reference**
    
    Before starting implementation, you MUST read and follow the task-specific tool guidance in the file \`task/toolman-guide.md\`. This file contains:
    - Selected tools for this specific task
    - When and how to use each tool
    - Tool arguments, parameters, and configuration options
    - Implementation workflow and best practices
    - Tool relationships and sequencing
    
    **The toolman-guide.md is your authoritative reference for tool usage in this task.**
    
    ---
    
    "
                echo "✓ Including task isolation instructions and toolman guidance"
            else
                echo "✓ Including task isolation instructions (no toolman guide found)"
            fi
    
            # Seed initial user turn via a FIFO (system prompts are set via CLI flags, not streamed)
            FIFO_PATH="/workspace/agent-input.jsonl"
            rm -f "$FIFO_PATH" 2>/dev/null || true
            mkfifo "$FIFO_PATH"
            chmod 666 "$FIFO_PATH" || true
    
            # Start Claude (reader) first in background to avoid writer-open blocking
            $CLAUDE_CMD < "$FIFO_PATH" &
            CLAUDE_PID=$!
    
            # Start background token refresh for long-running jobs
            (
                while kill -0 $CLAUDE_PID 2>/dev/null; do
                    sleep 2700  # Check every 45 minutes
    
                    if [ -n "$TOKEN_GENERATED_AT" ] && [ -n "$GITHUB_APP_PRIVATE_KEY" ]; then
                        NOW=$(date +%s)
                        TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
    
                        if [ $TOKEN_AGE -gt 2700 ]; then
                            echo "[Background] Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
                            refresh_github_token
                        fi
                    fi
                done
            ) &
            TOKEN_REFRESH_PID=$!
            echo "✓ Started background token refresh (PID: $TOKEN_REFRESH_PID)"
    
            # Compose initial user turn
            USER_COMBINED=$(printf "%s" "${PROMPT_PREFIX}$(cat "$CLAUDE_WORK_DIR/task/prompt.md")" | jq -Rs .)
    
            # Prefer sending via sidecar HTTP endpoint (opens-writes-closes per request)
            FIFO_OPENED=false
            if printf '{"text":%s}\n' "$USER_COMBINED" | \
                 curl -fsS -X POST http://127.0.0.1:8080/input \
                   -H 'Content-Type: application/json' \
                   --data-binary @- >/dev/null 2>&1; then
              echo "✓ Initial prompt sent via sidecar /input"
            else
              echo "⚠️ Sidecar /input failed, falling back to direct FIFO write"
              # Fallback: open FIFO writer, send prompt, and close immediately to send EOF
              exec 9>"$FIFO_PATH"
              printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":%s}]{{`}}`}}\n' "$USER_COMBINED" >&9
              exec 9>&-  # Close immediately to send EOF to Claude
              FIFO_OPENED=false  # Mark as already closed
            fi
    
            # Optional debug: dump FIFO holders if requested
            if [ "${DEBUG_FIFO:-false}" = "true" ]; then
              echo "[DEBUG] Dumping FIFO holders for $FIFO_PATH"
              for p in /proc/[0-9]*; do
                pid=${p##*/}
                [ -d "$p/fd" ] || continue
                for fd in "$p"/fd/*; do
                  tgt=$(readlink "$fd" 2>/dev/null || true)
                  case "$tgt" in *agent-input.jsonl*)
                    fdnum=${fd##*/}
                    comm=$(cat "$p/comm" 2>/dev/null || echo "?")
                    echo "  PID=$pid COMM=$comm FD=$fdnum -> $tgt"
                  ;;
                  esac
                done
              done
            fi
    
            # Optional hang diagnostics without enforcing a timeout
            if [ -n "${HANG_DIAG_SECONDS:-}" ] && [ "$HANG_DIAG_SECONDS" -gt 0 ] 2>/dev/null; then
              (
                sleep "$HANG_DIAG_SECONDS"
                if kill -0 "$CLAUDE_PID" 2>/dev/null; then
                  echo "[DEBUG] Hang diag after ${HANG_DIAG_SECONDS}s: dumping FIFO holders and ps"
                  for p in /proc/[0-9]*; do
                    pid=${p##*/}; [ -d "$p/fd" ] || continue
                    for fd in "$p"/fd/*; do tgt=$(readlink "$fd" 2>/dev/null || true); case "$tgt" in *agent-input.jsonl*) fdnum=${fd##*/}; comm=$(cat "$p/comm" 2>/dev/null || echo "?"); echo "  PID=$pid COMM=$comm FD=$fdnum -> $tgt";; esac; done
                  done
                  ps -eo pid,ppid,comm,args | head -200 || true
                fi
              ) & HANG_DIAG_PID=$!
            fi
    
            # Wait for Claude process to complete naturally
            echo "⏳ Waiting for Claude process (PID: $CLAUDE_PID) to complete..."
    
            # Simple wait - Claude should exit naturally when done
            wait "$CLAUDE_PID"
            CLAUDE_EXIT_CODE=$?
    
            # Stop token refresh background process
            if [ -n "$TOKEN_REFRESH_PID" ]; then
                kill $TOKEN_REFRESH_PID 2>/dev/null || true
                echo "✓ Stopped token refresh process"
            fi
    
            if [ $CLAUDE_EXIT_CODE -eq 0 ]; then
              echo "✅ Claude process completed successfully"
            else
              echo "⚠️ Claude process exited with code: $CLAUDE_EXIT_CODE"
            fi
    
            # Stop diagnostics if running
            if [ -n "${HANG_DIAG_PID:-}" ]; then kill "$HANG_DIAG_PID" 2>/dev/null || true; fi
    
            # Ensure FIFO cleanup happens regardless of how Claude exited
            echo "🔧 Performing FIFO cleanup..."
    
            # Close FIFO writer if it was opened (in fallback)
            if [ "$FIFO_OPENED" = "true" ]; then
              echo "🔧 Closing FIFO file descriptor..."
              # Try multiple methods to ensure fd 9 gets closed
              exec 9>&- 2>/dev/null || {
                echo "⚠️ exec 9>&- failed, trying alternative close method"
                eval "exec 9>&-" 2>/dev/null || {
                  echo "⚠️ Alternative close failed, FIFO fd may remain open"
                }
              }
            else
              echo "ℹ️ FIFO was not opened via fallback, checking sidecar"
            fi
    
            # Clean up FIFO file to ensure no processes are blocked
            if [ -p "$FIFO_PATH" ]; then
              echo "🔧 Removing FIFO to ensure clean shutdown"
              rm -f "$FIFO_PATH" 2>/dev/null || echo "⚠️ Could not remove FIFO"
            fi
    
            # Gracefully stop sidecar to allow Job to complete (all containers must exit)
            echo "🔧 Attempting sidecar shutdown..."
            shutdown_attempts=0
            max_shutdown_attempts=3
    
            while [ $shutdown_attempts -lt $max_shutdown_attempts ]; do
              if timeout 5 curl -fsS -X POST http://127.0.0.1:8080/shutdown >/dev/null 2>&1; then
                echo "✓ Sidecar shutdown request successful (attempt $((shutdown_attempts + 1)))"
                break
              else
                shutdown_attempts=$((shutdown_attempts + 1))
                echo "⚠️ Sidecar shutdown request failed (attempt $shutdown_attempts/$max_shutdown_attempts)"
                if [ $shutdown_attempts -lt $max_shutdown_attempts ]; then
                  echo "Retrying in 2 seconds..."
                  sleep 2
                fi
              fi
            done
    
            if [ $shutdown_attempts -eq $max_shutdown_attempts ]; then
              echo "❌ Failed to shutdown sidecar after $max_shutdown_attempts attempts"
              echo "🔧 Force terminating sidecar processes..."
              pkill -f "sidecar" || echo "No sidecar processes found to kill"
            fi
    
            # Wait for sidecar to actually terminate
            echo "⏳ Waiting for sidecar termination..."
            timeout=10
            while [ $timeout -gt 0 ]; do
              if ! pgrep -f "sidecar" > /dev/null 2>&1; then
                echo "✅ Sidecar terminated successfully"
                break
              fi
              sleep 1
              timeout=$((timeout - 1))
            done
    
            if [ $timeout -eq 0 ]; then
              echo "⚠️ Sidecar still running after wait period"
            fi
        else
            echo "❌ ERROR: No prompt.md found from docs service"
            echo "The docs service should always provide task/prompt.md"
            echo "Check docs repository and task configuration"
            exit 1
        fi
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 IMPLEMENTATION TASK COMPLETE                 ║'
    echo '════════════════════════════════════════════════════════════════'
    
    # Claude execution completed - no hooks configured
    echo "Claude has completed successfully."
    
    # =============================================================================
    # PR DETECTION AND LABELING
    # =============================================================================
    # After Claude completes, check if a PR was created and apply correlation labels
    if [ -n "${GITHUB_TOKEN:-}" ] && command -v gh >/dev/null 2>&1; then
      echo "🔍 Checking for PRs created by this task..."
    
      # First, try to find PR by task label (Claude should have added task-N label)
      TASK_LABEL="task-${TASK_ID}"
      PR_NUMBER=$(gh pr list -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --label "$TASK_LABEL" --json number --jq '.[0].number' 2>/dev/null || true)
    
      # If not found by label, try by branch name (current branch)
      if [ -z "$PR_NUMBER" ]; then
        CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || true)
        if [ -n "$CURRENT_BRANCH" ] && [ "$CURRENT_BRANCH" != "main" ]; then
          PR_NUMBER=$(gh pr list -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --head "$CURRENT_BRANCH" --json number --jq '.[0].number' 2>/dev/null || true)
        fi
      fi
    
      if [ -n "$PR_NUMBER" ]; then
        echo "✅ Found PR #${PR_NUMBER}"
    
        # Get the PR URL
        PR_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}/pull/${PR_NUMBER}"
        echo "📝 PR URL: $PR_URL"
    
        # Update CodeRun status with PR URL via Kubernetes API
        echo "🔄 Updating CodeRun status with PR URL..."
        if command -v kubectl >/dev/null 2>&1; then
          # Create a patch to update the CodeRun status
          PATCH_JSON=$(cat <<EOF
    {
      "status": {
        "pullRequestUrl": "$PR_URL",
        "lastUpdate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
      }
    }
    EOF
    )
    
          # Apply the patch to update CodeRun status
          if kubectl patch coderun "$CODERUN_NAME" -n "$NAMESPACE" --type=merge --subresource=status -p "$PATCH_JSON" 2>/dev/null; then
            echo "✅ Updated CodeRun status with PR URL"
          else
            echo "⚠️ Failed to update CodeRun status (kubectl patch failed)"
          fi
        else
          echo "⚠️ kubectl not available, cannot update CodeRun status"
        fi
    
        # Apply correlation labels with comprehensive debugging
        echo "🏷️ Adding correlation labels to PR #${PR_NUMBER}..."
    
        # Debug: Check environment variables
        echo "🔍 DEBUG: Environment check for label creation:"
        echo "   TASK_ID: '${TASK_ID}'"
        echo "   WORKFLOW_NAME: '${WORKFLOW_NAME}'"
        echo "   SERVICE_NAME: '${SERVICE_NAME}'"
        echo "   CODERUN_NAME: '${CODERUN_NAME}'"
        echo "   GitHub Token: $([ -n "$GITHUB_TOKEN" ] && echo 'Present' || echo 'Missing')"
    
        # Validate required variables
        if [ -z "$WORKFLOW_NAME" ]; then
          echo "❌ ERROR: WORKFLOW_NAME is not set!"
          echo "🔍 DEBUG: Attempting to extract from CODERUN_NAME..."
          # Try to extract workflow name from CodeRun name pattern
          if [ -n "$CODERUN_NAME" ]; then
            # Pattern: service-t{task}-stage-{hash} created by workflow
            echo "   CODERUN_NAME format: $CODERUN_NAME"
          fi
    
          # Check if we can get it from Kubernetes labels
          if command -v kubectl >/dev/null 2>&1 && [ -n "$CODERUN_NAME" ] && [ -n "$NAMESPACE" ]; then
            echo "🔍 DEBUG: Trying to get workflow name from CodeRun labels..."
            WORKFLOW_FROM_LABELS=$(kubectl get coderun "$CODERUN_NAME" -n "$NAMESPACE" -o jsonpath='{.metadata.labels.workflow-name}' 2>/dev/null || echo "")
            if [ -n "$WORKFLOW_FROM_LABELS" ]; then
              echo "✅ Found workflow name from CodeRun labels: $WORKFLOW_FROM_LABELS"
              WORKFLOW_NAME="$WORKFLOW_FROM_LABELS"
            else
              echo "❌ Could not retrieve workflow name from CodeRun labels"
            fi
          fi
    
          # Final check - if still no workflow name, fail loudly
          if [ -z "$WORKFLOW_NAME" ]; then
            echo "❌ CRITICAL: Cannot determine WORKFLOW_NAME - this will cause correlation issues!"
            echo "🔍 DEBUG: Available environment variables:"
            env | grep -E "WORKFLOW|CODERUN|TASK|SERVICE" | sort
            # DO NOT use 'unknown' - exit with error instead
            echo "❌ Refusing to use 'unknown' label - failing task"
            exit 1
          fi
        fi
    
        TASK_LABEL="task-${TASK_ID}"
        RUN_LABEL="run-${WORKFLOW_NAME}"
        SERVICE_LABEL="service-${SERVICE_NAME}"
    
        echo "📋 Labels to apply:"
        echo "   Task: $TASK_LABEL"
        echo "   Run: $RUN_LABEL"
        echo "   Service: $SERVICE_LABEL"
    
        # Try to add labels with detailed error capture
        echo "🔍 DEBUG: Attempting to add labels to PR..."
        LABEL_ERROR=$(gh pr edit "$PR_NUMBER" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --add-label "${TASK_LABEL},${RUN_LABEL},${SERVICE_LABEL}" 2>&1)
        LABEL_EXIT_CODE=$?
    
        if [ $LABEL_EXIT_CODE -eq 0 ]; then
          echo "✅ Added correlation labels successfully"
        else
          echo "⚠️ Failed to add labels (exit code: $LABEL_EXIT_CODE)"
          echo "🔍 DEBUG: Error output: $LABEL_ERROR"
    
          # Check if labels exist
          echo "🔍 DEBUG: Checking which labels exist..."
          for label in "$TASK_LABEL" "$RUN_LABEL" "$SERVICE_LABEL"; do
            if gh label list -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --search "$label" | grep -q "^$label"; then
              echo "   ✓ Label '$label' exists"
            else
              echo "   ✗ Label '$label' does not exist"
              # Create the missing label
              echo "   📝 Creating label '$label'..."
              case "$label" in
                task-*) COLOR="f29513"; DESC="Task correlation" ;;
                run-*) COLOR="0366d6"; DESC="Workflow run correlation" ;;
                service-*) COLOR="0e8a16"; DESC="Service correlation" ;;
                *) COLOR="ededed"; DESC="Unknown label type" ;;
              esac
    
              CREATE_ERROR=$(gh label create "$label" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --color "$COLOR" --description "$DESC" 2>&1)
              CREATE_EXIT=$?
              if [ $CREATE_EXIT -eq 0 ]; then
                echo "   ✅ Created label '$label'"
              else
                echo "   ❌ Failed to create label '$label': $CREATE_ERROR"
              fi
            fi
          done
    
          # Retry adding labels with individual attempts
          echo "🔍 DEBUG: Retrying label addition individually..."
          LABELS_ADDED=0
          for label in "$TASK_LABEL" "$RUN_LABEL" "$SERVICE_LABEL"; do
            RETRY_ERROR=$(gh pr edit "$PR_NUMBER" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --add-label "$label" 2>&1)
            RETRY_EXIT=$?
            if [ $RETRY_EXIT -eq 0 ]; then
              echo "   ✅ Added label '$label'"
              LABELS_ADDED=$((LABELS_ADDED + 1))
            else
              echo "   ❌ Failed to add label '$label': $RETRY_ERROR"
            fi
          done
    
          if [ $LABELS_ADDED -eq 3 ]; then
            echo "✅ All labels added successfully after retry"
          elif [ $LABELS_ADDED -gt 0 ]; then
            echo "⚠️ Partial success: $LABELS_ADDED/3 labels added"
          else
            echo "❌ CRITICAL: Could not add any labels to PR"
            echo "🔍 DEBUG: Checking PR state..."
            PR_STATE=$(gh pr view "$PR_NUMBER" -R "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" --json state -q .state 2>/dev/null || echo "UNKNOWN")
            echo "   PR State: $PR_STATE"
            if [ "$PR_STATE" = "CLOSED" ] || [ "$PR_STATE" = "MERGED" ]; then
              echo "❌ PR is $PR_STATE - cannot add labels to closed/merged PRs"
            fi
          fi
        fi
      else
        echo "ℹ️ No PR found for this task (Claude may not have created one)"
      fi
    else
      echo "ℹ️ Skipping PR labeling: missing GITHUB_TOKEN or gh CLI"
    fi
    
    # Write sentinel file to signal sidecar to stop (Kubernetes-native file watch)
    touch /workspace/.agent_done 2>/dev/null || true
    
    # Final termination sequence
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 REX CONTAINER TERMINATION                    ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "Container PID: $$"
    echo "Final Process Check:"
    ps aux | head -5
    
    # Write completion marker for workflow tracking
    echo "rex-implementation-completed:$(date -u +%Y-%m-%dT%H:%M:%SZ)" > /workspace/.rex-complete
    
    # Force exit to terminate the pod
    echo "🔚 Force terminating container..."
    exit 0  code_container-tess.sh.hbs: |
    #!/bin/sh
    
    # CRITICAL: Clean up sentinel file IMMEDIATELY to prevent sidecar from shutting down
    # This MUST happen before anything else, as the sidecar starts before our script
    if [ -f /workspace/.agent_done ]; then
        echo "🧹 URGENT: Removing leftover sentinel file from previous run"
        rm -f /workspace/.agent_done
    fi
    
    # Also clean up Tess completion marker if present
    if [ -f /workspace/.tess-complete ]; then
        echo "🧹 Removing Tess completion marker from previous run"
        rm -f /workspace/.tess-complete
    fi
    
    # Ensure Rust environment is always properly set up
    echo "🔧 Setting up Rust environment..."
    
    # Source Rust environment if available (fixes cargo not found issues)
    # Try multiple possible locations for Rust environment
    RUST_ENV_SOURCES=(
        "$HOME/.cargo/env"
        "/root/.cargo/env"
        "/usr/local/cargo/env"
        "/home/ubuntu/.cargo/env"
        "/home/user/.cargo/env"
    )
    
    for env_file in "${RUST_ENV_SOURCES[@]}"; do
        if [ -f "$env_file" ]; then
            echo "✓ Sourcing Rust environment from $env_file"
            . "$env_file"
            # Export PATH explicitly after sourcing
            export PATH="$HOME/.cargo/bin:/usr/local/cargo/bin:$PATH"
            break
        fi
    done
    
    # Ensure rustup has a default toolchain set
    if command -v rustup >/dev/null 2>&1; then
        echo "✓ Rustup found, ensuring stable toolchain is default..."
        rustup default stable 2>/dev/null || true
        # Re-source environment after setting default
        if [ -f "$HOME/.cargo/env" ]; then
            . "$HOME/.cargo/env"
        elif [ -f "/root/.cargo/env" ]; then
            . "/root/.cargo/env"
        fi
        export PATH="$HOME/.cargo/bin:/usr/local/cargo/bin:$PATH"
        echo "✓ Ensured stable Rust toolchain is default"
    else
        echo "⚠️ rustup not found in PATH"
    fi
    
    # Verify Rust is available with multiple fallback attempts
    if command -v cargo >/dev/null 2>&1; then
        echo "✓ Cargo is available: $(cargo --version)"
    elif [ -f "/usr/local/cargo/bin/cargo" ]; then
        echo "✓ Found cargo at /usr/local/cargo/bin/cargo"
        export PATH="/usr/local/cargo/bin:$PATH"
        echo "✓ Cargo is available: $(cargo --version)"
    elif [ -f "$HOME/.cargo/bin/cargo" ]; then
        echo "✓ Found cargo at $HOME/.cargo/bin/cargo"
        export PATH="$HOME/.cargo/bin:$PATH"
        echo "✓ Cargo is available: $(cargo --version)"
    else
        echo "❌ Cargo not found in PATH"
        echo "Current PATH: $PATH"
        echo "Attempting to find cargo..."
        find /usr -name cargo 2>/dev/null | head -5 || echo "No cargo found in /usr"
        find /home -name cargo 2>/dev/null | head -5 || echo "No cargo found in /home"
        find /root -name cargo 2>/dev/null | head -5 || echo "No cargo found in /root"
        # Try to install Rust as last resort
        echo "🔧 Attempting to install Rust via rustup..."
        curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y || true
        . "$HOME/.cargo/env" || true
        export PATH="$HOME/.cargo/bin:$PATH"
        if command -v cargo >/dev/null 2>&1; then
            echo "✓ Cargo installed and available: $(cargo --version)"
        else
            echo "❌ Failed to install Rust, continuing without cargo..."
        fi
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║              TESS TESTING WORKFLOW STARTING                  ║'
    echo '║         Quality Assurance & Deployment Testing Agent         ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "🎯 Agent: {{`{{`{{`}}`}}github_app{{`}}`}}"
    echo "🧪 Focus: Comprehensive testing, deployment validation, test coverage"
    echo "📋 Task ID: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "✅ Mission: 120% satisfaction through exhaustive testing"
    echo "🔍 Debug Session: $(date '+%Y-%m-%d %H:%M:%S') - PID: $$"
    echo "📊 Log Level: DEBUG (showing JSON construction details)"
    
    # Disable interactive Git prompts globally
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # Repository URL
    REPO_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    
    # GitHub App authentication is configured via environment variables
    echo "Using GitHub App authentication for testing workflow"
    
    # Function to ensure sidecar shutdown
    shutdown_sidecar() {
      echo "🔧 Signaling sidecar to shutdown..."
      touch /workspace/.agent_done 2>/dev/null || true
    
      echo "🔧 Attempting sidecar shutdown..."
      local shutdown_attempts=0
      local max_shutdown_attempts=3
    
      while [ $shutdown_attempts -lt $max_shutdown_attempts ]; do
        if timeout 5 curl -fsS -X POST http://127.0.0.1:8080/shutdown >/dev/null 2>&1; then
          echo "✓ Sidecar shutdown request successful (attempt $((shutdown_attempts + 1)))"
          break
        else
          shutdown_attempts=$((shutdown_attempts + 1))
          echo "⚠️ Sidecar shutdown request failed (attempt $shutdown_attempts/$max_shutdown_attempts)"
          if [ $shutdown_attempts -lt $max_shutdown_attempts ]; then
            echo "Retrying in 2 seconds..."
            sleep 2
          fi
        fi
      done
    
      if [ $shutdown_attempts -eq $max_shutdown_attempts ]; then
        echo "❌ Failed to shutdown sidecar after $max_shutdown_attempts attempts"
        echo "⚠️ Cannot force terminate sidecar from this container (PID namespace isolation)"
        echo "📝 Sidecar may still be running - Kubernetes will handle cleanup on pod termination"
      fi
    }
    
    # Authenticate with GitHub App
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        echo "Authenticating with GitHub App..."
    
        # Create temporary private key file (support escaped newlines)
        TEMP_KEY_FILE="/tmp/github-app-key.pem"
        printf '%b' "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
        chmod 600 "$TEMP_KEY_FILE"
    
        # Generate JWT token for GitHub App (fixed JWT generation for Linux containers)
        # JWT header
        JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # JWT payload with current time and expiration (10 minutes)
        NOW=$(date +%s)
        EXP=$((NOW + 600))
        JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # Sign the JWT
        JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
        JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
    
        # Get installation ID for the repository (robust parsing of owner/repo)
        INPUT_REPO="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        REPO_OWNER=""
        REPO_NAME=""
    
        if echo "$INPUT_REPO" | grep -qE '^https://github.com/'; then
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
        elif echo "$INPUT_REPO" | grep -qE '^git@github.com:'; then
            # SSH format git@github.com:owner/repo(.git)
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:[^/]+/([^/]+)(\.git)?|\1|')
        else
            # Fallback: assume slug owner/repo (possibly with .git)
            SLUG=$(echo "$INPUT_REPO" | sed -E 's|\.git$||')
            REPO_OWNER=$(echo "$SLUG" | cut -d'/' -f1)
            REPO_NAME=$(echo "$SLUG" | cut -d'/' -f2)
        fi
    
        echo "DEBUG: Parsed repository - Owner: '$REPO_OWNER', Name: '$REPO_NAME'"
    
        echo "Getting installation ID for $REPO_OWNER/$REPO_NAME..."
    
        # Get the installation ID (retry and follow redirects). Fallback to org installation.
        INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
            --connect-timeout 5 --max-time 12 \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
        INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "⚠️ Repo installation not found, trying org installation..."
            ORG_INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/orgs/$REPO_OWNER/installation")
            INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
        fi
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "❌ Failed to get installation ID for $REPO_OWNER/$REPO_NAME"
            echo "Response (repo): $INSTALLATION_RESPONSE"
            echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "Installation ID: $INSTALLATION_ID"
    
        # Get installation access token
        TOKEN_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
        GITHUB_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
        TOKEN_GENERATED_AT=$(date +%s)  # Track when token was generated for refresh logic
    
        if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ Failed to get installation access token"
            echo "Response: $TOKEN_RESPONSE"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "✅ Successfully authenticated with GitHub App"
    
        # Clean up temporary key file
        rm -f "$TEMP_KEY_FILE"
    
        # Export the token for git to use
        export GITHUB_TOKEN
    
        # Configure git to use the token (use --replace-all to handle multiple existing helpers)
        git config --global --replace-all credential.helper store
        echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
    
        # Also authenticate gh CLI with the token
        echo "$GITHUB_TOKEN" | gh auth login --with-token
    
        # Token refresh functions for long-running jobs
        refresh_github_token() {
            echo "🔄 Refreshing GitHub App token..."
    
            # Create temporary key file
            TEMP_KEY_FILE="/tmp/github-app-key-$$"
            echo "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
            chmod 600 "$TEMP_KEY_FILE"
    
            # Generate new JWT
            JWT_TOKEN=$(ruby -r openssl -r json -r base64 -e "
            key = OpenSSL::PKey::RSA.new(File.read('$TEMP_KEY_FILE'))
            payload = {
                iat: Time.now.to_i - 60,
                exp: Time.now.to_i + (10 * 60),
                iss: '$GITHUB_APP_ID'
            }
            header = { alg: 'RS256', typ: 'JWT' }
    
            header_enc = Base64.urlsafe_encode64(header.to_json).gsub('=', '')
            payload_enc = Base64.urlsafe_encode64(payload.to_json).gsub('=', '')
            signature = Base64.urlsafe_encode64(key.sign(OpenSSL::Digest::SHA256.new, \"#{header_enc}.#{payload_enc}\")).gsub('=', '')
    
            puts \"#{header_enc}.#{payload_enc}.#{signature}\"
            ")
    
            # Get installation ID (reuse logic from initial auth)
            INSTALLATION_ID=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation" | jq -r '.id')
    
            if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
                INSTALLATION_ID=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" \
                    -H "Accept: application/vnd.github+json" \
                    "https://api.github.com/orgs/$REPO_OWNER/installation" | jq -r '.id')
            fi
    
            # Get new installation token
            TOKEN_RESPONSE=$(curl -s -X POST \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
            NEW_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
    
            if [ "$NEW_TOKEN" != "null" ] && [ -n "$NEW_TOKEN" ]; then
                export GITHUB_TOKEN="$NEW_TOKEN"
                export TOKEN_GENERATED_AT=$(date +%s)
    
                # Update git credentials
                echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
                echo "$GITHUB_TOKEN" | gh auth login --with-token 2>/dev/null
    
                echo "✅ Token refreshed successfully"
                rm -f "$TEMP_KEY_FILE"
                return 0
            else
                echo "❌ Failed to refresh token: $TOKEN_RESPONSE"
                rm -f "$TEMP_KEY_FILE"
                return 1
            fi
        }
    
        # Check if token needs refresh (call before git operations)
        refresh_token_if_needed() {
            if [ -z "$TOKEN_GENERATED_AT" ]; then
                echo "⚠️ No token timestamp found, refreshing token..."
                refresh_github_token
                return
            fi
    
            NOW=$(date +%s)
            TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
    
            # Refresh if token is older than 50 minutes (tokens last 1 hour, refresh at 50 min to be safe)
            if [ $TOKEN_AGE -gt 3000 ]; then
                echo "🔄 Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
                refresh_github_token
            fi
        }
    
    else
        echo "❌ GitHub App credentials not found"
        exit 1
    fi
    
    # Set working directory for the agent
    # Set Working Directory (Critical for Claude Execution) - Match Rex pattern
    WORK_DIR="{{`{{`{{`}}`}}working_directory{{`}}`}}"
    if [ "$WORK_DIR" = "." ] || [ -z "$WORK_DIR" ]; then
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME"
    else
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME/$WORK_DIR"
    fi
    mkdir -p "$CLAUDE_WORK_DIR"
    cd "$CLAUDE_WORK_DIR"
    
    # Prepare environment for testing
    echo "════════════════════════════════════════════════════════════════"
    echo "🧪 PREPARING TESTING ENVIRONMENT"
    echo "════════════════════════════════════════════════════════════════"
    
    # Git configuration with proper GitHub App attribution
    git config --global --add safe.directory /workspace
    
    # Set GitHub App attribution - use generic format for all agents
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    # Generic attribution that works for any agent
    GIT_AUTHOR_NAME="${GITHUB_APP} Agent (Claude Code)"
    GIT_AUTHOR_EMAIL="${GITHUB_APP}[bot]@users.noreply.github.com"
    
    # Configure git with proper GitHub App attribution
    git config --global user.name "$GIT_AUTHOR_NAME"
    git config --global user.email "$GIT_AUTHOR_EMAIL"
    
    # Set environment variables for Claude Code to use
    export GIT_AUTHOR_NAME="$GIT_AUTHOR_NAME"
    export GIT_AUTHOR_EMAIL="$GIT_AUTHOR_EMAIL"
    export GIT_COMMITTER_NAME="$GIT_AUTHOR_NAME"
    export GIT_COMMITTER_EMAIL="$GIT_AUTHOR_EMAIL"
    echo "✓ Git configured"
    
    # =============================================================================
    # AUTHENTICATION VERIFICATION
    # =============================================================================
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "🔐 AUTHENTICATION VERIFICATION"
    echo "═══════════════════════════════════════════════════════════════"
    echo ""
    
    # Repository URLs - Handle both full URLs and org/repo format
    # Check if repository_url already contains https://github.com/
    if echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        REPO_HTTP_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "\.git$"; then
            REPO_HTTP_URL="${REPO_HTTP_URL}.git"
        fi
    else
        REPO_HTTP_URL="https://github.com/{{`{{`{{`}}`}}repository_url{{`}}`}}.git"
    fi
    
    # Same for docs repository
    if echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        DOCS_HTTP_URL="{{`{{`{{`}}`}}docs_repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "\.git$"; then
            DOCS_HTTP_URL="${DOCS_HTTP_URL}.git"
        fi
    else
        DOCS_HTTP_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}.git"
    fi
    
    # DEBUG: Show what URLs are being constructed
    echo "🔍 DEBUG: URL Construction & Parameters"
    echo "  Input repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  Input docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  Input docs_project_directory: '{{`{{`{{`}}`}}docs_project_directory{{`}}`}}'"
    echo "  Input working_directory: '{{`{{`{{`}}`}}working_directory{{`}}`}}'"
    echo "  Input docs_branch: '{{`{{`{{`}}`}}docs_branch{{`}}`}}'"
    echo "  Input github_app: '{{`{{`{{`}}`}}github_app{{`}}`}}'"
    echo "  Input task_id: '{{`{{`{{`}}`}}task_id{{`}}`}}'"
    echo "  Input service: '{{`{{`{{`}}`}}service{{`}}`}}'"
    echo "  Constructed REPO_HTTP_URL: '$REPO_HTTP_URL'"
    echo "  Constructed DOCS_HTTP_URL: '$DOCS_HTTP_URL'"
    echo "  Current working directory: $(pwd)"
    echo "  Available environment variables:"
    env | grep -E "(GITHUB|ANTHROPIC)" | sort
    
    # Test HTTPS access to repository
    echo "🔍 DEBUG: Testing HTTPS repository access..."
    echo "  Command: git ls-remote \"$REPO_HTTP_URL\" HEAD"
    if git ls-remote "$REPO_HTTP_URL" HEAD > /tmp/repo_test.out 2>&1; then
      echo "✓ HTTPS repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Output: $(cat /tmp/repo_test.out | head -1)"
    else
      echo "❌ HTTPS repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Error output: $(cat /tmp/repo_test.out)"
      echo "  Git credential helper status:"
      git config --list | grep credential || echo "  No credential helpers configured"
      echo ""
      echo "🚫 ABORTING: Cannot access repository via HTTPS"
      exit 1
    fi
    
    # Test docs repository access
    echo "🔍 DEBUG: Testing docs repository access..."
    echo "  Command: git ls-remote \"$DOCS_HTTP_URL\" HEAD"
    if git ls-remote "$DOCS_HTTP_URL" HEAD > /tmp/docs_test.out 2>&1; then
      echo "✓ Docs repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Output: $(cat /tmp/docs_test.out | head -1)"
    else
      echo "❌ Docs repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Error output: $(cat /tmp/docs_test.out)"
      echo ""
      echo "🚫 ABORTING: Cannot access docs repository via HTTPS"
      exit 1
    fi
    
    # Clone or update repository (directly to Claude working directory)
    if [ -d "$CLAUDE_WORK_DIR/.git" ]; then
        echo "📁 Found existing repository at working directory, updating..."
        cd "$CLAUDE_WORK_DIR"
        git fetch origin --prune
    else
        # Ensure parent directories exist
        mkdir -p "$(dirname "$CLAUDE_WORK_DIR")"
    
        # If directory exists but isn't a git repo, remove it first
        if [ -d "$CLAUDE_WORK_DIR" ] && [ ! -d "$CLAUDE_WORK_DIR/.git" ]; then
            echo "🧹 Removing non-git directory to prepare for clone..."
            rm -rf "$CLAUDE_WORK_DIR"
        fi
    
        echo "📥 Cloning repository to working directory..."
        # Make sure parent directory exists and we're in a valid location
        PARENT_DIR="$(dirname "$CLAUDE_WORK_DIR")"
        mkdir -p "$PARENT_DIR"
        cd "$PARENT_DIR"
    
        # Use the REPO_HTTP_URL constructed in authentication verification section
        if ! git clone "$REPO_HTTP_URL" "$(basename "$CLAUDE_WORK_DIR")"; then
            echo "❌ Failed to clone repository"
            echo "Debug: CLAUDE_WORK_DIR=$CLAUDE_WORK_DIR"
            echo "Debug: Parent directory exists: $(ls -la "$PARENT_DIR" 2>/dev/null || echo 'No')"
            exit 1
        fi
        cd "$(basename "$CLAUDE_WORK_DIR")"
    fi
    
    # Utility function for safe Git operations
    safe_git_pull() {
        local remote="$1"
        local branch="$2"
    
        echo "📥 Attempting to pull from $remote/$branch..."
    
        # Try rebase first (cleaner history)
        if git pull --rebase "$remote" "$branch" 2>/dev/null; then
            echo "✓ Successfully pulled with rebase"
            return 0
        fi
    
        # Try merge if rebase fails
        if git pull --no-rebase "$remote" "$branch" 2>/dev/null; then
            echo "✓ Successfully pulled with merge"
            return 0
        fi
    
        # If both fail, show current status and continue
        echo "⚠️ Could not pull due to divergent branches or conflicts"
        echo "📍 Current commit: $(git rev-parse --short HEAD 2>/dev/null || echo 'unknown')"
        echo "📍 Local changes: $(git status --porcelain | wc -l) files modified"
        echo "📍 Continuing with current branch state"
        return 1
    }
    
    # Checkout PR branch for testing review
    if [ -n "$PR_NUMBER" ] && [ -n "$PR_URL" ]; then
        echo "🔄 Checking out PR #$PR_NUMBER for QA testing..."
        cd "$CLAUDE_WORK_DIR"
        git fetch origin --prune
        PR_BRANCH=$(gh pr view "$PR_NUMBER" --json headRefName --jq '.headRefName' 2>/dev/null || echo "")
        if [ -n "$PR_BRANCH" ]; then
            # Try to checkout/create the branch
            if git checkout "$PR_BRANCH" 2>/dev/null; then
                echo "✓ Checked out existing branch: $PR_BRANCH"
            else
                echo "📝 Creating new local branch from remote: $PR_BRANCH"
                if git checkout -b "$PR_BRANCH" "origin/$PR_BRANCH" 2>/dev/null; then
                    echo "✓ Created new branch: $PR_BRANCH"
                else
                    echo "⚠️ Could not create branch $PR_BRANCH, staying on current branch"
                    # Skip to the next part without the continue
                fi
            fi
    
            # Only attempt pull if we successfully checked out/created the branch
            if [ "$(git rev-parse --abbrev-ref HEAD 2>/dev/null)" = "$PR_BRANCH" ]; then
                # Handle divergent branches gracefully using utility function
                if ! safe_git_pull origin "$PR_BRANCH"; then
                    echo "📍 Continuing with current branch state for testing"
                fi
            fi
            echo "✓ Checked out PR branch: $PR_BRANCH"
        else
            echo "⚠️ Could not determine PR branch name, staying on default branch"
        fi
    
        # Add PR context to CLAUDE.md for reference
        echo "" >> "$CLAUDE_WORK_DIR/CLAUDE.md" || true
        echo "# PR Context for Testing" >> "$CLAUDE_WORK_DIR/CLAUDE.md" || true
        echo "- **PR Number**: $PR_NUMBER" >> "$CLAUDE_WORK_DIR/CLAUDE.md" || true
        echo "- **PR URL**: $PR_URL" >> "$CLAUDE_WORK_DIR/CLAUDE.md" || true
        echo "- **Branch**: $PR_BRANCH" >> "$CLAUDE_WORK_DIR/CLAUDE.md" || true
        echo "" >> "$CLAUDE_WORK_DIR/CLAUDE.md" || true
    else
        echo "ℹ️ No PR context provided - working on default branch"
    fi
    
    echo "════════════════════════════════════════════════════════════════"
    echo "🔧 TESTING INFRASTRUCTURE SETUP"
    echo "════════════════════════════════════════════════════════════════"
    
    # Setup Kubernetes admin access if available
    if [ -f "/etc/kube/config" ]; then
        export KUBECONFIG=/etc/kube/config
        echo "✅ Kubernetes admin access configured"
        kubectl version --client 2>/dev/null || echo "⚠️ kubectl not available"
    fi
    
    # Setup database admin credentials if available
    if [ -n "$POSTGRES_ADMIN_PASSWORD" ]; then
        export PGPASSWORD="$POSTGRES_ADMIN_PASSWORD"
        echo "✅ PostgreSQL admin credentials configured"
    fi
    
    if [ -n "$REDIS_ADMIN_PASSWORD" ]; then
        export REDIS_PASSWORD="$REDIS_ADMIN_PASSWORD"
        echo "✅ Redis admin credentials configured"
    fi
    
    # Setup Argo CD admin access if available
    if [ -n "$ARGOCD_ADMIN_TOKEN" ]; then
        export ARGOCD_AUTH_TOKEN="$ARGOCD_ADMIN_TOKEN"
        echo "✅ Argo CD admin access configured"
    fi
    
    echo "════════════════════════════════════════════════════════════════"
    echo "📋 TESTING WORKFLOW REQUIREMENTS"
    echo "════════════════════════════════════════════════════════════════"
    echo ""
    echo "PHASE 0: CI/CD Setup (IMMEDIATE PRIORITY)"
    echo "- Set up GitHub Actions CI pipeline if not exists"
    echo "- Add test running and coverage reporting to CI"
    echo "- Configure branch protection rules with test gates"
    echo "- Ensure tests must pass before merge"
    echo "- Do this AS SOON as there's enough code to test"
    echo ""
    echo "PHASE 1: Acceptance Criteria Validation"
    echo "- Review implementation against acceptance criteria (NOT architecture)"
    echo "- Verify ALL acceptance criteria are fully met"
    echo "- Focus on task/acceptance-criteria.md requirements"
    echo "- Add PR comments for any missing acceptance criteria"
    echo ""
    echo "PHASE 2: Test Writing (PRIMARY RESPONSIBILITY)"
    echo "- Write comprehensive unit tests for all code"
    echo "- Write integration tests for all features"
    echo "- AIM FOR 100% TEST COVERAGE - this is critical!"
    echo "- Ensure all tests pass before approval"
    echo "- Push test files to the PR branch"
    echo "- ONLY write test files (*_test.*, *.test.*, etc.)"
    echo "- NEVER modify implementation/business logic code"
    echo ""
    echo "PHASE 3: Manual Testing & Validation"
    echo "- Run the test suite and verify coverage"
    echo "- Test application functionality manually"
    echo "- Verify no regressions introduced"
    echo "- Document findings in PR comments"
    echo ""
    echo "CRITICAL: Set up CI gates early & achieve 100% coverage!"
    echo "════════════════════════════════════════════════════════════════"
    
    # Copy task files if docs repository is specified
    {{`{{`{{`}}`}}#if docs_repository_url{{`}}`}}
    echo "📋 Copying task files from documentation repository..."
    DOCS_REPO_URL="{{`{{`{{`}}`}}docs_repository_url{{`}}`}}"
    DOCS_BRANCH="{{`{{`{{`}}`}}#if docs_branch{{`}}`}}{{`{{`{{`}}`}}docs_branch{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}main{{`{{`{{`}}`}}/if{{`}}`}}"
    DOCS_HTTP_URL=$(echo "$DOCS_REPO_URL" | sed "s|https://github.com/|https://x-access-token:${GITHUB_TOKEN}@github.com/|")
    
    if ! git clone "$DOCS_HTTP_URL" /tmp/docs-repo 2>/dev/null; then
        echo "❌ Failed to clone docs repository from $DOCS_REPO_URL"
        echo "📍 This may be due to authentication or network issues"
        echo "📍 Continuing without task files from docs repository"
    else
        cd /tmp/docs-repo || {
            echo "⚠️ Could not change to docs repository directory"
            cd "$CLAUDE_WORK_DIR"
        }
    
        # Try to checkout the docs branch with error handling
        if git checkout "$DOCS_BRANCH" 2>/dev/null; then
            echo "✓ Checked out docs branch: $DOCS_BRANCH"
            cd "$CLAUDE_WORK_DIR"
        else
            echo "⚠️ Could not checkout docs branch $DOCS_BRANCH"
            echo "📍 Available branches: $(git branch -r 2>/dev/null | head -5 || echo 'unknown')"
            cd "$CLAUDE_WORK_DIR"
        fi
    fi
    
    # Copy task files
    mkdir -p "$CLAUDE_WORK_DIR/task"
    {{`{{`{{`}}`}}#if docs_project_directory{{`}}`}}
    if [ "{{`{{`{{`}}`}}docs_project_directory{{`}}`}}" = "." ]; then
        DOCS_PATH="/tmp/docs-repo/.taskmaster"
    else
        DOCS_PATH="/tmp/docs-repo/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster"
    fi
    {{`{{`{{`}}`}}else{{`}}`}}
    DOCS_PATH="/tmp/docs-repo/.taskmaster"
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    TASK_DIR="$DOCS_PATH/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
    if [ -d "$TASK_DIR" ]; then
        cp "$TASK_DIR/task.md" "$CLAUDE_WORK_DIR/task/" 2>/dev/null || true
        cp "$TASK_DIR/acceptance-criteria.md" "$CLAUDE_WORK_DIR/task/" 2>/dev/null || true
        cp "$TASK_DIR/prompt.md" "$CLAUDE_WORK_DIR/task/" 2>/dev/null || true
        cp "$TASK_DIR/toolman-guide.md" "$CLAUDE_WORK_DIR/task/" 2>/dev/null || true
        echo "✓ Task {{`{{`{{`}}`}}task_id{{`}}`}} files copied"
    fi
    
    # Copy architecture.md
    if [ -f "$DOCS_PATH/docs/architecture.md" ]; then
        cp "$DOCS_PATH/docs/architecture.md" "$CLAUDE_WORK_DIR/task/"
    fi
    
    # Clean up docs repo
    rm -rf /tmp/docs-repo
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    # Repository is now cloned directly to Claude working directory - no copy needed
    echo "✓ Repository cloned directly to working directory"
    
    # Check if we should continue previous session
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    echo "📂 Continuing from previous session..."
    # Preserve existing CLAUDE.md if it exists
    if [ -f "/workspace/CLAUDE.md" ]; then
        echo "✓ Found existing CLAUDE.md, preserving session memory"
    fi
    {{`{{`{{`}}`}}else{{`}}`}}
    {{`{{`{{`}}`}}#if overwrite_memory{{`}}`}}
    echo "🔄 Overwriting session memory as requested..."
    rm -f /workspace/CLAUDE.md
    {{`{{`{{`}}`}}/if{{`}}`}}
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    # Generate configuration files from templates
    echo "🔧 Generating Tess-specific configuration files..."
    
    # Enterprise managed settings are mounted directly from ConfigMap
    echo "=== ENTERPRISE MANAGED SETTINGS ==="
    echo "✓ Settings mounted directly from ConfigMap at: /etc/claude-code/managed-settings.json"
    echo "✓ No copying needed - mount automatically reflects latest ConfigMap changes"
    
    # Copy MCP client configuration from task files
    if [ -f "/task-files/client-config.json" ]; then
      cp /task-files/client-config.json "$CLAUDE_WORK_DIR/client-config.json"
      echo "✓ client-config.json copied from ConfigMap"
      export MCP_CLIENT_CONFIG="$CLAUDE_WORK_DIR/client-config.json"
      echo "✓ MCP_CLIENT_CONFIG set to: $MCP_CLIENT_CONFIG"
    else
      echo "⚠️ client-config.json not found in task-files - MCP client may not work correctly"
    fi
    
    # Create initial CLAUDE.md if needed
    if [ ! -f "/workspace/CLAUDE.md" ] || [ "{{`{{`{{`}}`}}overwrite_memory{{`}}`}}" = "true" ]; then
        # Use PR_NUMBER from environment if available, otherwise use template value
        PR_NUM="${PR_NUMBER:-{{`{{`{{`}}`}}pr_number{{`}}`}}}"
        # Extract template variables for use in heredoc
        TASK_ID="{{`{{`{{`}}`}}task_id{{`}}`}}"
        cat > /workspace/CLAUDE.md << EOF
    # TESS - ULTRA-STRICT Quality Assurance Agent
    
    ## Agent Role & Philosophy
    - **Primary**: Find EVERY defect, no matter how minor - be EXTREMELY CRITICAL
    - **Mindset**: "This code is guilty until proven innocent"
    - **Philosophy**: "If it CAN fail, it WILL fail in production"
    - **Standards**: NOTHING less than perfection is acceptable
    - **Approach**: Be pedantic, nitpicky, and relentless - better to reject good code than approve bad code
    
    ## Testing Workflow Phases
    
    ### Phase 0: CI/CD Setup (MOVED TO CLIO)
    - ⚠️ **CI/CD setup is now handled by Clio agent**
    - Clio will create and manage `.github/workflows/` files
    - Focus on testing the code that exists
    - If CI is missing, request it from Clio rather than creating it yourself
    - Validate existing CI/CD if present, but don't create new workflows
    
    ### Phase 1: Task-Specific Acceptance Criteria Verification
    - Review implementation against **THIS SPECIFIC TASK'S** acceptance criteria ONLY
    - IMPORTANT: You are testing Task $TASK_ID ONLY, not the entire project
    - The project may be incomplete (e.g., task-1 won't have a working app yet)
    - Verify ALL acceptance criteria for **Task $TASK_ID** are fully met
    - Focus ONLY on what's defined for THIS SPECIFIC TASK
    - IGNORE missing features that belong to other tasks
    - Post PR comments for any missing items FROM THIS TASK ONLY
    
    ### Phase 2: Test Writing FOR THIS TASK (YOUR MAIN JOB!)
    - Write tests for the code implemented in **Task $TASK_ID** ONLY
    - Don't write tests for features from other tasks (they don't exist yet)
    - Write unit tests for ALL code FROM THIS TASK
    - Write integration tests for features IMPLEMENTED IN THIS TASK
    - **TARGET: 100% coverage of THIS TASK'S code** - not the whole project!
    - Use appropriate testing frameworks for the language:
      - Python: pytest with coverage
      - JavaScript/TypeScript: jest with coverage
      - Go: go test with coverage
      - Rust: cargo test with tarpaulin
    - Commit and push test files to the PR branch
    - Run coverage reports for THIS TASK'S code in PR comments
    
    ### Phase 3: Test Execution & Validation
    - Run the complete test suite with coverage reporting
    - Verify coverage meets or exceeds 95% (target 100%)
    - Ensure all tests pass successfully
    - Test application functionality manually if needed
    - Document coverage percentages in PR comments
    
    ## CRITICAL RULES
    - **CAN** write and push test files (*_test.*, *.test.*, spec.*, etc.)
    - **CANNOT** create CI/CD workflows - that's Clio's job
    - **CAN** modify test configuration files (jest.config.js, pytest.ini, etc.)
    - **CANNOT** modify implementation/business logic code
    - **CANNOT** modify non-test files (except test configs and CI/CD)
    - **MUST** write comprehensive tests for ALL functionality
    - **MUST** set up CI gates as early as possible
    - **MUST** achieve highest possible test coverage (target 100%)
    - **MUST** validate against THIS TASK'S acceptance criteria ONLY
    - **MUST** remember you're testing Task $TASK_ID, not the entire project
    - **MUST** verify Kubernetes cluster access and report if unavailable
    
    ## Admin Access Capabilities
    - Kubernetes cluster admin
    - PostgreSQL admin access
    - Redis admin access
    - Argo CD admin access
    - GitHub Actions access
    
    ## Success Criteria (BE EXTREMELY STRICT!)
    - **Coverage**: MINIMUM 95%, target 100% (reject if under 95%)
    - **Edge Cases**: EVERY conceivable edge case must have a test
    - **Error Handling**: ALL error paths must be tested thoroughly
    - **Performance**: Must be OPTIMAL (not just "acceptable")
    - **Security**: Look for ANY potential vulnerability
    - **Code Quality**: Even minor issues are grounds for rejection
    - **Documentation**: Missing or unclear docs = automatic rejection
    - **Acceptance Criteria**: 100% met (not 99%)
    - **Your Confidence**: Must be 200% certain (not just "pretty sure")
    
    ## CRITICAL REMINDERS
    - **BE HARSH**: Your job is to find problems, not be nice
    - **NO COMPROMISE**: Don't approve "good enough" code
    - **ASSUME THE WORST**: If something seems off, it probably is
    - **TEST EVERYTHING**: Including the tests themselves
    - **REJECT FIRST**: When in doubt, request changes
    
    ## Important Notes
    - Only start work when PR has "ready-for-qa" label
    - Do NOT merge PR - only approve
    - Human (CTO) performs final merge
    
    EOF
    
        # Copy base CLAUDE.md from ConfigMap if it exists (match Rex pattern)
        if [ -f "/task-files/CLAUDE.md" ]; then
            cat /task-files/CLAUDE.md >> "/workspace/CLAUDE.md"
            echo "✓ Appended base CLAUDE.md content from ConfigMap"
        fi
    
        # Copy to working directory for consistency with Rex pattern
        cp "/workspace/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
        echo "✓ Created Tess-specific CLAUDE.md memory"
    fi  # End of CLAUDE.md creation if block
    
    # Copy guidelines files to working directory (match Rex pattern)
    if [ -f "/task-files/coding-guidelines.md" ]; then
      cp /task-files/coding-guidelines.md "$CLAUDE_WORK_DIR/"
      echo "✓ Copied coding-guidelines.md to working directory"
    fi
    
    if [ -f "/task-files/github-guidelines.md" ]; then
      cp /task-files/github-guidelines.md "$CLAUDE_WORK_DIR/"
      echo "✓ Copied github-guidelines.md to working directory"
    fi
    
    # Copy MCP configuration from ConfigMap to project root (project scope)
    if [ -f "/task-files/mcp.json" ]; then
      cp /task-files/mcp.json "$CLAUDE_WORK_DIR/.mcp.json"
      echo "✓ Copied mcp.json to .mcp.json (project scope)"
    else
      echo "⚠️ mcp.json template not found"
    fi
    
    # Setup hook scripts
    echo "🔧 Setting up Tess-specific hook scripts..."
    mkdir -p "$CLAUDE_WORK_DIR/hooks"
    
    {{`{{`{{`}}`}}#each hook_scripts{{`}}`}}
    cat > "$CLAUDE_WORK_DIR/hooks/{{`{{`{{`}}`}}@key{{`}}`}}" << 'EOF'
    {{`{{`{{`}}`}}{this{{`}}`}}}
    EOF
    chmod +x "$CLAUDE_WORK_DIR/hooks/{{`{{`{{`}}`}}@key{{`}}`}}"
    {{`{{`{{`}}`}}/each{{`}}`}}
    
    # Export environment for Claude
    export CLAUDE_WORK_DIR
    export GITHUB_TOKEN
    export REPO_OWNER
    export REPO_NAME
    # TARGET_REPO_DIR no longer needed - repository cloned directly to CLAUDE_WORK_DIR
    
    echo "════════════════════════════════════════════════════════════════"
    echo "✅ TESS TESTING AGENT READY"
    echo "════════════════════════════════════════════════════════════════"
    echo "📁 Working Directory: $CLAUDE_WORK_DIR"
    echo "📦 Repository: $REPO_OWNER/$REPO_NAME"
    echo "📋 Task: {{`{{`{{`}}`}}task_id{{`}}`}}"
    echo "🧪 Focus: Comprehensive testing & deployment validation"
    echo "⚠️  CRITICAL: Must be 120% satisfied before approval"
    echo "════════════════════════════════════════════════════════════════"
    
    # Start Claude with Tess-specific configuration
    cd "$CLAUDE_WORK_DIR"
    
    # Build Claude command (continue flag disabled due to cache_control API bug)
    CLAUDE_CMD="claude -p --output-format stream-json --input-format stream-json --verbose"
    
    # Look for agent-specific system prompt file from agents ConfigMap
    if [ -f "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        echo "✓ Found system prompt file for {{`{{`{{`}}`}}github_app{{`}}`}}, adding to Claude command"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
    else
        echo "ℹ️ No system prompt file found for agent {{`{{`{{`}}`}}github_app{{`}}`}}, using defaults"
    fi
    
    # Continue flag disabled due to cache_control API bug - removed conditional logic
    
    echo "════════════════════════════════════════════════════════════════"
    echo "║                    STARTING CLAUDE EXECUTION                  ║"
    echo "════════════════════════════════════════════════════════════════"
    echo "Command: $CLAUDE_CMD"
    echo "Note: Claude will automatically read CLAUDE.md from the working directory"
    
    # Tess uses her own system prompt and focuses on acceptance criteria
    echo "✓ Starting Tess with specialized QA system prompt"
    echo "✓ Tess will focus on acceptance criteria and comprehensive testing"
    
    if [ -f "$CLAUDE_WORK_DIR/task/acceptance-criteria.md" ]; then
        echo "✓ Found acceptance-criteria.md - this is Tess's primary focus"
    else
        echo "⚠️ No acceptance-criteria.md found - Tess may need to work with available task files"
    fi
    
    # Prepare initial guidance for Tess
    INITIAL_GUIDANCE=$(cat <<TESS_EOF
    🧪 **TESS ULTRA-STRICT QA TESTING WORKFLOW**
    
    You are Tess - the quality gatekeeper for **Task $TASK_ID ONLY**. Your job is to validate THIS SPECIFIC TASK, not the entire project.
    
    **YOUR MINDSET - BE EXTREMELY HARSH BUT PERSISTENT**:
    - This code is GUILTY until proven innocent
    - If something CAN go wrong, it WILL in production
    - \"Good enough\" is NEVER good enough
    - Every minor issue is a potential disaster
    - Be pedantic, nitpicky, and relentless
    - It's better to reject good code than approve bad code
    - BUT: You MUST fix all issues yourself - don't just complain
    - Your job is NOT DONE until you achieve APPROVED status
    
    **CRITICAL INSTRUCTIONS**:
    - DO write and push comprehensive test files
    - DO NOT modify implementation/business logic code
    - Create proper PR reviews with your testing results
    - BE BRUTALLY HONEST - don't spare feelings
    
    **YOUR WORKFLOW LOOP (MUST COMPLETE)**:
    1. Check CI Status
    2. If CI fails: Write/Fix Tests and retry
    3. Write comprehensive tests
    4. Check test coverage (must be >= 95%)
    5. Deploy to Kubernetes (if access available)
    6. Verify all acceptance criteria met
    7. If issues found: Fix them and retry
    8. Post APPROVE review (only when everything passes)
    
    **Your STRICT testing requirements:**
    
    1. **CRITICAL: Verify CI Status FIRST (ABSOLUTE BLOCKER)**:
       - **If repository has workflows**: Run \`gh pr checks $PR_NUM\` to see CI status
       - **If no workflows**: Skip CI validation and proceed to testing requirements
       - If ANY CI check is failing: DO NOT EXIT
       - Instead: Write tests to fix the failures
       - Format Rust code: \`cargo fmt --all\` (if Rust project)
       - Push your changes: \`git add . && git commit -m "test: fix failing tests" && git push\`
       - Wait for CI (when workflows exist): \`sleep 60\` then check again
       - KEEP ITERATING until CI is GREEN (when workflows exist)
       - You CANNOT proceed OR exit until requirements are met
    
    2. **Write Comprehensive Tests (After CI passes)**:
       - Write unit tests for ALL new functionality
       - Write integration tests for API endpoints and workflows
       - Write edge case tests for boundary conditions
       - Ensure test coverage reaches 95% minimum
       - Push all test files to the repository
    
    3. **Deploy to Kubernetes (MANDATORY IF ACCESS EXISTS)**:
       - Test kubectl access: \`kubectl get nodes\` and \`kubectl get ns\`
       - If no access: Comment \"⚠️ Unable to verify K8s deployment - no cluster access\"
       - If access exists, YOU MUST:
         a) Create test namespace: \`kubectl create ns test-$TASK_ID\`
         b) Deploy using universal chart (see deployment instructions below)
         c) Verify pods are running: \`kubectl get pods -n test-$TASK_ID\`
         d) Test the service endpoints
         e) Cleanup: \`kubectl delete ns test-$TASK_ID\`
       - Report deployment results in PR review
    
    4. **Task $TASK_ID Acceptance Criteria (100% or REJECT)**:
       - EVERY requirement FOR THIS TASK must be PERFECTLY met
       - Remember: Task 1 won't have a complete app, that's EXPECTED
       - Only check criteria listed for Task $TASK_ID
       - 99% compliance = FAILURE
       - Any ambiguity = request clarification before approval
    
    5. **Test Coverage (95% MINIMUM or REJECT)**:
       - Check actual coverage numbers with tools
       - EVERY edge case must have a test
       - EVERY error path must be tested
       - Missing tests = automatic rejection
    
    6. **Manual Testing (EXHAUSTIVE)**:
       - Test EVERY possible input combination
       - Test invalid inputs, edge cases, boundary conditions
       - Test performance under load
       - Test memory usage and leaks
       - Test security vulnerabilities
       - If it crashes under ANY condition = REJECT
    
    7. **Code Quality (PRISTINE or REJECT)**:
       - ANY clippy warning = REJECT
       - ANY TODO or FIXME = REJECT
       - ANY commented out code = REJECT
       - ANY unclear variable names = REJECT
       - Missing documentation = REJECT
    
    8. **PR Review (BE HARSH)**:
       - List EVERY issue, no matter how minor
       - Demand fixes for EVERYTHING
       - Only approve when code is PERFECT
       - When in doubt, REQUEST CHANGES
    
    9. **ITERATE UNTIL APPROVED**:
       - After posting REQUEST CHANGES, DO NOT STOP
       - Fix the issues yourself by writing tests
       - Format Rust code if needed: \`cargo fmt --all\` (for Rust projects)
       - Push your fixes and wait for CI
       - **If workflows exist**: Check \`gh pr checks $PR_NUM\` again
       - If still failing, keep fixing and pushing
       - REPEAT until you can post APPROVE
       - You are NOT ALLOWED to finish without APPROVE status
    
    10. **MANDATORY PRE-APPROVAL CHECKLIST**:
        Before you can APPROVE, ALL of these MUST be true:
        □ CI Status: **If workflows exist** - Run \`gh pr checks $PR_NUM --json name,status\` - ALL must show "completed" with "success"
        □ Test Coverage: Must be >= 95% (verify with coverage tools)
        □ All Tests Pass: 100% of tests must pass, no skipped tests
        □ Acceptance Criteria: 100% of Task $TASK_ID criteria met
        □ No TODO/FIXME: Zero TODOs or FIXMEs in code
        □ No Warnings: Zero clippy warnings, zero compiler warnings
        □ K8s Deployment: If you have access, deployment must succeed
    
        **VERIFICATION COMMANDS TO RUN BEFORE APPROVING**:
        \`\`\`bash
        # 1. Verify CI is completely green - NO FAILURES ALLOWED
        # Check CI status (only if workflows exist)
       if [ -d ".github/workflows" ] && [ -n "$(find .github/workflows -name "*.yml" -o -name "*.yaml" 2>/dev/null | head -1)" ]; then
           gh pr checks $PR_NUM
       else
           echo "ℹ️  No GitHub Actions workflows found - skipping CI validation"
       fi
        # EVERY check must show "pass" or ✓
        # If you see ANY "fail", "pending", or "skipping" - CANNOT APPROVE
    
        # 2. Verify all checks are passing using tab-separated status field
        # gh pr checks output format: NAME<TAB>STATUS<TAB>CONCLUSION<TAB>URL
        CI_OUTPUT=\$(gh pr checks $PR_NUM)
        if [ -z "\$CI_OUTPUT" ]; then
            echo "⚠️ No CI checks found - continuing without CI verification"
            # Don't exit, just continue with testing
        fi
    
        # Count checks by looking at the status field (2nd column)
        TOTAL_CHECKS=\$(echo "\$CI_OUTPUT" | wc -l)
        # Look for pass/✓ only in the status column (tab-delimited field 2)
        PASSING_CHECKS=\$(echo "\$CI_OUTPUT" | awk -F'\t' '\$2 ~ /pass|✓/' | wc -l)
    
        if [ "\$TOTAL_CHECKS" != "\$PASSING_CHECKS" ]; then
            echo "⚠️ NOT ALL CHECKS PASSING - continuing with testing"
            echo "Total: \$TOTAL_CHECKS, Passing: \$PASSING_CHECKS"
            echo "Failed/pending checks:"
            echo "\$CI_OUTPUT" | awk -F'\t' '\$2 !~ /pass|✓/ {print \$1 " - " \$2}'
            echo "📝 Note: Will continue testing despite CI issues"
            # Don't exit, just continue with testing
        fi
    
        # 3. Only if ALL checks show "pass" can you approve
        \`\`\`
    
        IF ANY ITEM IS UNCHECKED, YOU CANNOT APPROVE!
    
    **KUBERNETES DEPLOYMENT INSTRUCTIONS**:
    If you have kubectl access, deploy the application to verify it works:
    \`\`\`bash
    # 1. Check if we can actually deploy (skip Docker build/push - image should exist)
    if ! kubectl version --short 2>/dev/null; then
      echo "⚠️ No kubectl access - skipping Kubernetes deployment"
      # Don't exit - continue with other tests
    fi
    
    # 2. Create or use test namespace (idempotent)
    kubectl create namespace test-$TASK_ID --dry-run=client -o yaml | kubectl apply -f -
    
    # 3. Check if universal-app chart exists locally
    CHART_PATH="/workspace/infra/charts/universal-app"
    if [ ! -d "$CHART_PATH" ]; then
      # Try alternate locations
      CHART_PATH="./infra/charts/universal-app"
      if [ ! -d "$CHART_PATH" ]; then
        echo "⚠️ Universal app chart not found - skipping deployment"
        # Don't exit - continue with other tests
        SKIP_K8S_DEPLOY=true
      fi
    fi
    
    # 4. Deploy using universal-app chart (assuming image already exists)
    if [ "$SKIP_K8S_DEPLOY" != "true" ] && kubectl version --short 2>/dev/null; then
      RELEASE_NAME="task-$TASK_ID"
      helm upgrade --install "$RELEASE_NAME" "$CHART_PATH" \
      --namespace test-$TASK_ID \
      --set fullnameOverride="$RELEASE_NAME" \
      --set image.repository=ghcr.io/5dlabs/task-$TASK_ID \
      --set image.tag=latest \
      --set ingress.enabled=false \
      --set service.port=8080 \
      --set resources.limits.cpu=500m \
      --set resources.limits.memory=512Mi \
      --timeout 5m \
      --wait || {
        echo "⚠️ Helm install failed - checking status"
        kubectl get all -n test-$TASK_ID
        helm uninstall "$RELEASE_NAME" -n test-$TASK_ID 2>/dev/null || true
        # Don't exit - continue with other tests
      }
    
      # 5. Get actual deployment and service names (helm may add suffixes)
      DEPLOYMENT_NAME=$(kubectl get deployment -n test-$TASK_ID -o name | head -1)
      SVC_NAME=$(kubectl get svc -n test-$TASK_ID -o name | head -1)
    
      # 6. Check pod status
      kubectl get pods -n test-$TASK_ID
    
      # 7. Port-forward with retry logic and better timing
      if [ -n "$SVC_NAME" ]; then
        PF_SUCCESS=false
        for i in 1 2 3; do
          # Kill any existing port-forward process before retry
          if [ -n "$PF_PID" ]; then
            kill $PF_PID 2>/dev/null || true
            wait $PF_PID 2>/dev/null || true
          fi
    
          kubectl port-forward -n test-$TASK_ID "$SVC_NAME" 8080:8080 &
          PF_PID=$!
          sleep 5  # Give port-forward time to establish
    
          # Test if port-forward is actually working, not just if process exists
          if curl -f -s --connect-timeout 2 http://localhost:8080/ >/dev/null 2>&1; then
            echo "✓ Port-forward established and responding"
            PF_SUCCESS=true
            break
          elif kill -0 $PF_PID 2>/dev/null; then
            echo "Port-forward process running but not responding yet"
          else
            echo "Retry $i: Port-forward failed, retrying..."
          fi
        done
    
        # Test endpoints if port-forward succeeded
        if [ "$PF_SUCCESS" = "true" ] && [ -n "$PF_PID" ]; then
          curl -f http://localhost:8080/health || echo "⚠️ Health check failed or not implemented"
          curl -f http://localhost:8080/ready || echo "⚠️ Ready check failed or not implemented"
          kill $PF_PID 2>/dev/null || true
          wait $PF_PID 2>/dev/null || true
        else
          echo "⚠️ Port-forward could not be established after 3 attempts"
          # Clean up any remaining process
          [ -n "$PF_PID" ] && kill $PF_PID 2>/dev/null || true
        fi
      fi
    
      # 8. Check logs for errors
      kubectl logs -n test-$TASK_ID -l app.kubernetes.io/instance="$RELEASE_NAME" --tail=50 || true
    
      # 9. Cleanup
      helm uninstall "$RELEASE_NAME" -n test-$TASK_ID --wait || true
      kubectl delete namespace test-$TASK_ID --wait=false || true
    else
      echo "ℹ️ Kubernetes deployment skipped - no access or chart missing"
    fi
    \`\`\`
    
    **HOW TO POST PR REVIEW (CRITICAL: Use proper review, NOT regular comments!)**:
    Use GitHub CLI to create a PROPER REVIEW with formal review status:
    \`\`\`bash
    # WRONG - Don't do this (creates regular comments, not a review):
    # gh pr review {{`{{`{{`}}`}}pr_number{{`}}`}} --comment --body \"Some feedback\"
    
    # CORRECT - Submit a proper REQUEST CHANGES review:
    gh pr review $PR_NUM --request-changes --body \"### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ✅ **GitHub Actions CI**: All checks passing
    
    ## Task $TASK_ID Acceptance Criteria Status
    ❌ **Criterion 1**: Not fully implemented (missing X)
    ✅ **Criterion 2**: Properly implemented
    ❌ **Criterion 3**: Partially complete (Y not working)
    
    ## Task $TASK_ID Test Coverage
    ❌ **Test Coverage**: 78% for task code (minimum: 95%)
    ❌ **Missing Tests**: Error handling in task-specific functions
    ✅ **Unit Tests**: 42/42 passing for this task's code
    
    ## Kubernetes Deployment
    ✅ **Deployment**: Successfully deployed to test-{{`{{`{{`}}`}}task_id{{`}}`}} namespace
    ✅ **Pods**: All pods running (1/1 ready)
    ❌ **Health Check**: /health endpoint returning 404
    
    ## Issues Found IN TASK {{`{{`{{`}}`}}task_id{{`}}`}}
    1. **Critical**: Health endpoint not implemented
    2. **Critical**: Task acceptance criterion #1 not met
    3. **Major**: Test coverage below 95% requirement
    
    ## Required Actions FOR TASK {{`{{`{{`}}`}}task_id{{`}}`}}
    - [ ] Implement /health and /ready endpoints
    - [ ] Complete acceptance criterion #1
    - [ ] Add tests to reach 95% coverage
    - [ ] Fix health check endpoints for K8s deployment
    
    Note: Only reviewing Task {{`{{`{{`}}`}}task_id{{`}}`}} implementation, not the entire project.\"
    
    # CORRECT - Submit an APPROVE review ONLY when ALL checks pass:
    # FIRST: Verify you can approve
    CI_OUTPUT=\$(gh pr checks ${PR_NUMBER:-$PR_NUM})
    if [ -z "\$CI_OUTPUT" ]; then
      echo "⚠️ No CI checks found - will continue working on testing requirements"
      # Don't exit, continue with testing
    fi
    
    # Check for non-passing statuses in the status column (2nd field)
    CI_FAILED=\$(echo "\$CI_OUTPUT" | awk -F'\t' '\$2 !~ /pass|✓/' | wc -l)
    if [ "\$CI_FAILED" -gt 0 ]; then
      echo "⚠️ CI HAS FAILURES OR IS INCOMPLETE - will continue working on fixes"
      echo "Failed/pending checks:"
      echo "\$CI_OUTPUT" | awk -F'\t' '\$2 !~ /pass|✓/ {print \$1 " - " \$2}'
      echo "📝 Note: Will continue testing and working on CI fixes"
      # Don't exit, continue working
    fi
    
    # ONLY IF ALL CHECKS PASS:
    gh pr review $PR_NUM --approve --body \"### ✅ QA Review for Task $TASK_ID - APPROVED
    
    ## Pre-Approval Verification
    ✅ **ALL CI checks verified**: Ran 'gh pr checks' - all showing success
    ✅ **No failures found**: Zero failing checks confirmed
    
    ## CI Status
    ✅ **GitHub Actions CI**: All checks passing (verified with gh CLI)
    ✅ **All workflows**: Green across the board
    
    ## Task $TASK_ID Acceptance Criteria
    ✅ **All criteria for Task $TASK_ID are fully met**
    ✅ **Criterion 1**: Implemented correctly
    ✅ **Criterion 2**: Working as specified
    ✅ **Criterion 3**: Validated and tested
    
    ## Task $TASK_ID Test Results
    ✅ **Test Coverage**: 98.5% for task-specific code
    ✅ **Unit Tests**: All passing for this task
    ✅ **Integration Tests**: Task features tested
    ✅ **CI/CD Pipeline**: All checks green
    
    ## Kubernetes Deployment
    ✅ **Deployment**: Successfully deployed to test-$TASK_ID namespace
    ✅ **Pods**: All pods running and healthy (1/1 ready)
    ✅ **Health Checks**: /health and /ready endpoints responding correctly
    ✅ **Service**: Verified functionality via port-forward testing
    ✅ **Cleanup**: Test namespace removed successfully
    
    ## Task $TASK_ID Quality Assessment
    - All acceptance criteria met for this specific task
    - Tests comprehensively cover task implementation
    - Successfully deployed and tested in Kubernetes
    - Code quality meets all standards
    
    ## Conclusion
    Task {{`{{`{{`}}`}}task_id{{`}}`}} implementation meets all requirements and is ready for the next task in the sequence.\"
    \`\`\`
    
    **IMPORTANT RULES**:
    1. NEVER use \`--comment\` flag - it creates regular comments, not reviews
    2. ALWAYS use \`--request-changes\` when issues are found
    3. ONLY use \`--approve\` when ALL tests pass and quality is perfect
    4. Include detailed feedback in the review body
    5. Format your review with clear sections and checkboxes
    
    Remember: Your job is to WRITE TESTS, VALIDATE functionality, and provide FEEDBACK via PR review comments. You handle all testing code while Rex handles implementation changes.
    
    **CRITICAL ITERATION REQUIREMENT**:
    - DO NOT EXIT until ALL of the following are true:
      1. CI is GREEN (all checks passing) - VERIFY WITH: gh pr checks ${PR_NUMBER:-$PR_NUM}
      2. Test coverage is >= 95%
      3. All acceptance criteria for Task $TASK_ID are met
      4. Kubernetes deployment succeeds (if you have access)
      5. You have posted an APPROVE review
    
    - If ANY of these are not met:
      1. Write/fix tests as needed
      2. Format Rust code: \`cargo fmt --all\` (if Rust project)
      3. Push your changes
      4. Wait for CI to run (use: sleep 120 && gh pr checks ${PR_NUMBER:-$PR_NUM})
      5. Check status again
      6. KEEP ITERATING until everything passes
    
    - **APPROVAL GATES** (You CANNOT approve if ANY of these are true):
      * Any CI check is failing or pending
      * Test coverage < 95%
      * Any acceptance criteria unmet
      * Any TODOs or FIXMEs in code
      * Any compiler/linter warnings
    
    - You are NOT DONE until you can post an APPROVE review
    - NEVER exit with a REQUEST CHANGES review - keep working until it's fixed
    - Your success is measured by getting to APPROVED status
    - **IF YOU APPROVE WITH FAILING CI, YOU HAVE FAILED YOUR MISSION**
    TESS_EOF
    )
    
    # Set trap to ensure sidecar shutdown on exit (set here after all functions are defined)
    # Using explicit function call for compatibility with /bin/sh
    trap 'echo "🚨 EXIT TRAP TRIGGERED - Shutting down sidecar..."; shutdown_sidecar' EXIT INT TERM
    echo "✅ EXIT trap set for sidecar shutdown"
    
    # Start Claude with initial guidance
    echo "════════════════════════════════════════════════════════════════"
    echo "║                    STARTING TESS QA EXECUTION                 ║"
    echo "════════════════════════════════════════════════════════════════"
    
    # Sentinel and completion marker cleanup already done at script start
    
    # Seed initial user turn via a FIFO with timeout protection
    FIFO_PATH="/workspace/agent-input.jsonl"
    rm -f "$FIFO_PATH" 2>/dev/null || true
    
    # Create FIFO with error handling
    if ! mkfifo "$FIFO_PATH" 2>/dev/null; then
        echo "❌ Failed to create FIFO at $FIFO_PATH"
        exit 1
    fi
    chmod 666 "$FIFO_PATH" || true
    
    # Start Claude (simple approach like Cleo)
    $CLAUDE_CMD < "$FIFO_PATH" &
    CLAUDE_PID=$!
    
    # Start background token refresh for long-running jobs
    (
        while kill -0 $CLAUDE_PID 2>/dev/null; do
            sleep 2700  # Check every 45 minutes
    
            if [ -n "$TOKEN_GENERATED_AT" ] && [ -n "$GITHUB_APP_PRIVATE_KEY" ]; then
                NOW=$(date +%s)
                TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
    
                if [ $TOKEN_AGE -gt 2700 ]; then
                    echo "[Background] Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
                    refresh_github_token
                fi
            fi
        done
    ) &
    TOKEN_REFRESH_PID=$!
    echo "✓ Started background token refresh (PID: $TOKEN_REFRESH_PID)"
    
    # Add timeout protection - if Claude doesn't start within 30 seconds, fail gracefully
    TIMEOUT=30
    COUNT=0
    while [ $COUNT -lt $TIMEOUT ]; do
        if kill -0 "$CLAUDE_PID" 2>/dev/null; then
            break
        fi
        sleep 1
        COUNT=$((COUNT + 1))
    done
    
    if [ $COUNT -ge $TIMEOUT ]; then
        echo "❌ Claude process failed to start within $TIMEOUT seconds"
        kill "$CLAUDE_PID" 2>/dev/null || true
        exit 1
    fi
    
    # =============================================================================
    # DEBUG LOGGING: JSON CONSTRUCTION PROCESS
    # =============================================================================
    echo "🔍 DEBUG: Starting JSON construction process..."
    echo "📝 Original INITIAL_GUIDANCE length: ${#INITIAL_GUIDANCE} characters"
    echo "📝 Original INITIAL_GUIDANCE preview: ${INITIAL_GUIDANCE:0:100}..."
    
    # Clean up initial guidance and send via sidecar - simplified approach
    echo "🧹 Cleaning INITIAL_GUIDANCE (removing empty lines and trailing spaces)..."
    INITIAL_GUIDANCE_CLEAN=$(printf "%s" "$INITIAL_GUIDANCE" | sed '/^[[:space:]]*$/d' | sed 's/[[:space:]]*$//')
    echo "✅ Cleaned INITIAL_GUIDANCE length: ${#INITIAL_GUIDANCE_CLEAN} characters"
    echo "✅ Cleaned INITIAL_GUIDANCE preview: ${INITIAL_GUIDANCE_CLEAN:0:100}..."
    
    # Wait for sidecar to be ready (simple check like Cleo)
    echo "⏳ Waiting for sidecar to be ready..."
    MAX_RETRIES=10
    RETRY_COUNT=0
    while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
        if curl -fsS http://127.0.0.1:8080/health >/dev/null 2>&1; then
            echo "✓ Sidecar is ready"
            break
        fi
        sleep 1
        RETRY_COUNT=$((RETRY_COUNT + 1))
    done
    
    if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
        echo "⚠️ Sidecar not ready after ${MAX_RETRIES}s, proceeding with fallback"
    fi
    
    # =============================================================================
    # DEBUG LOGGING: SIDECAR JSON CONSTRUCTION
    # =============================================================================
    echo "🔧 Constructing JSON for sidecar transmission..."
    
    # Create the JSON payload for sidecar
    SIDECAR_JSON=$(printf '{"text":%s}' "$(jq -Rs . <<< "$INITIAL_GUIDANCE_CLEAN")")
    echo "📤 Sidecar JSON payload length: ${#SIDECAR_JSON} characters"
    echo "📤 Sidecar JSON payload preview: ${SIDECAR_JSON:0:200}..."
    echo "🔍 Full sidecar JSON structure:"
    echo "$SIDECAR_JSON" | jq . 2>/dev/null || echo "❌ Sidecar JSON parsing failed: $SIDECAR_JSON"
    
    # Send via sidecar HTTP endpoint - use raw text to avoid JSON formatting issues
    echo "📡 Sending to sidecar /input endpoint..."
    if printf '%s\n' "$SIDECAR_JSON" | \
         curl -fsS -X POST http://127.0.0.1:8080/input \
           -H 'Content-Type: application/json' \
           --data-binary @- >/dev/null 2>&1; then
      echo "✅ Initial QA guidance sent via sidecar /input"
    else
      echo "⚠️ Sidecar /input failed, falling back to direct FIFO write"
      # Fallback: construct JSON properly to avoid cache_control errors
      echo "🔧 Constructing FIFO JSON payload..."
      FIFO_JSON=$(printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":%s}]{{`}}`}}' \
                  "$(jq -Rs . <<< "$INITIAL_GUIDANCE_CLEAN")")
      echo "📤 FIFO JSON payload length: ${#FIFO_JSON} characters"
      echo "📤 FIFO JSON payload preview: ${FIFO_JSON:0:200}..."
      echo "🔍 Full FIFO JSON structure:"
      echo "$FIFO_JSON" | jq . 2>/dev/null || echo "❌ FIFO JSON parsing failed: $FIFO_JSON"
    
      exec 9>"$FIFO_PATH"
      printf '%s\n' "$FIFO_JSON" >&9
      exec 9>&-  # Close immediately to send EOF to Claude
      echo "✅ Initial QA guidance sent via FIFO fallback"
    fi
    
    # Simple wait like Cleo - no complex monitoring
    
    # =============================================================================
    # DEBUG LOGGING: CLAUDE EXECUTION MONITORING
    # =============================================================================
    echo "🤖 Monitoring Claude execution..."
    echo "🔍 Claude PID: $CLAUDE_PID"
    
    # Wait for Claude process to complete
    echo "⏳ Waiting for Claude process to complete..."
    wait "$CLAUDE_PID" 2>/dev/null || true
    CLAUDE_EXIT_CODE=$?
    
    # Stop token refresh background process
    if [ -n "$TOKEN_REFRESH_PID" ]; then
        kill $TOKEN_REFRESH_PID 2>/dev/null || true
        echo "✓ Stopped token refresh process"
    fi
    
    echo "🔚 Claude process completed with exit code: $CLAUDE_EXIT_CODE"
    
    # Safety check: Ensure we don't have any syntax errors that could cause command interpretation issues
    echo "🔍 DEBUG: Performing safety checks..."
    if [ -n "$(echo "$INITIAL_GUIDANCE" | grep '^fix:')" ]; then
      echo "⚠️ WARNING: Found lines starting with 'fix:' in INITIAL_GUIDANCE - this could cause command interpretation errors"
    fi
    
    # Close FIFO writer if it was opened
    exec 9>&- 2>/dev/null || true
    
    # =============================================================================
    # PR REVIEW POSTING - Execute the actual GitHub commands
    # =============================================================================
    echo "🔍 Posting PR review based on testing results..."
    
    # Use PR_NUMBER from environment if available, otherwise use template value
    PR_NUM="${PR_NUMBER:-{{`{{`{{`}}`}}pr_number{{`}}`}}}"
    TASK_ID="{{`{{`{{`}}`}}task_id{{`}}`}}"
    
    # Debug: Show what we got for PR_NUM
    echo "🔍 DEBUG: PR_NUMBER='${PR_NUMBER:-<not_set>}', pr_number template='{{`{{`{{`}}`}}pr_number{{`}}`}}'"
    echo "🔍 DEBUG: Resolved PR_NUM='$PR_NUM'"
    
    # Handle case where PR_NUM is empty - skip PR review entirely
    if [ -z "$PR_NUM" ] || [ "$PR_NUM" = "{{`{{`{{`}}`}}pr_number{{`}}`}}" ]; then
      echo "ℹ️ No PR number available - skipping PR review posting"
      echo "🔍 This is normal for non-PR workflows or when PR context is not provided"
      echo "✅ Tess QA workflow completed successfully"
      exit 0
    fi
    
    # Check CI status to determine review type
    echo "📊 Checking CI status for PR #$PR_NUM..."
    
    # Pre-flight check: Verify GitHub CLI is available and working
    echo "🔍 Pre-flight check: GitHub CLI availability..."
    
    # Check if GitHub CLI is available (should be pre-installed in base image)
    GH_AVAILABLE=true
    if ! command -v gh >/dev/null 2>&1; then
      echo "❌ GitHub CLI not found in PATH"
      echo "⚠️ GitHub CLI should be pre-installed in the base image"
      echo "📝 Will skip PR review posting (GitHub CLI unavailable)"
      GH_AVAILABLE=false
    else
      echo "✅ GitHub CLI available"
    
      # Check authentication
      if ! gh auth status >/dev/null 2>&1; then
        echo "❌ GitHub CLI not authenticated"
        echo "⚠️ Cannot perform CI checks or PR reviews without authentication"
        echo "📝 Will skip PR review posting (GitHub authentication unavailable)"
        GH_AVAILABLE=false
      else
        echo "✅ GitHub CLI is available and authenticated"
      fi
    fi
    
    # Function to safely execute gh command with error handling
    check_ci_status() {
      local pr_num="$1"
      local temp_file
      temp_file=$(mktemp)
    
      # Check if gh is available and authenticated
      if ! command -v gh >/dev/null 2>&1; then
        echo "❌ Error: gh CLI is not installed"
        echo "ℹ️ Cannot perform CI checks or PR reviews without GitHub CLI"
        rm -f "$temp_file"
        return 1
      fi
    
      # Test gh authentication
      if ! gh auth status >/dev/null 2>&1; then
        echo "❌ Error: gh CLI is not authenticated"
        echo "ℹ️ Cannot perform CI checks or PR reviews without authentication"
        rm -f "$temp_file"
        return 1
      fi
    
      # Get CI checks in JSON format with proper error handling (with timeout)
      if ! timeout 30 gh pr checks "$pr_num" --json name,status,conclusion,url 2>"$temp_file"; then
        local error_output
        error_output=$(cat "$temp_file" 2>/dev/null || echo "Unknown error")
        rm -f "$temp_file"
    
        # Log the full error for debugging
        echo "🔍 DEBUG: gh pr checks failed with error: $error_output" >&2
    
        # Check for specific error conditions with more comprehensive patterns
        if echo "$error_output" | grep -q "pull request not found\|could not resolve to a PullRequest\|PR not found"; then
          echo "❌ Error: PR #$pr_num not found"
          return 2
        elif echo "$error_output" | grep -q "network\|timeout\|connection\|HTTP\|API rate limit"; then
          echo "❌ Error: Network or API issue accessing GitHub ($error_output)"
          return 3
        elif echo "$error_output" | grep -q "authentication\|token\|unauthorized\|forbidden"; then
          echo "❌ Error: Authentication failed - check GitHub token permissions"
          return 4
        elif echo "$error_output" | grep -q "repository not found\|not accessible"; then
          echo "❌ Error: Repository not accessible or not found"
          return 5
        else
          echo "❌ Error: Failed to get PR checks: $error_output"
          return 1
        fi
      fi
    
      rm -f "$temp_file"
      return 0
    }
    
    # Only perform PR review if GitHub CLI is available
    if [ "$GH_AVAILABLE" = "true" ]; then
      # Get CI status using robust JSON parsing
      CI_JSON=$(check_ci_status "$PR_NUM")
      CI_STATUS=$?
    
      # Validate CI_JSON is valid JSON before proceeding
      if [ $CI_STATUS -eq 0 ] && [ -n "$CI_JSON" ]; then
        # Basic JSON validation - check if it starts and ends with brackets
        if ! (echo "$CI_JSON" | grep -q '^\[' && echo "$CI_JSON" | grep -q '\]$'); then
          echo "⚠️ Invalid JSON format received from gh pr checks - falling back to text parsing"
          CI_STATUS=1
        fi
      fi
    
      case $CI_STATUS in
      1)
        echo "⚠️ GitHub CLI unavailable - cannot perform PR reviews"
        echo "📝 Tess QA completed but unable to post PR review due to GitHub CLI issues"
        echo "✅ QA workflow finished successfully despite GitHub CLI problems"
        echo "🔍 Recommendation: Install and authenticate GitHub CLI for full functionality"
        # Don't exit here - continue to sidecar shutdown
        ;;
      2)
        echo "⚠️ PR not found - posting REQUEST CHANGES review"
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ❌ **PR Not Found**: Pull request #$PR_NUM does not exist
    ❌ **Cannot verify**: Invalid PR reference
    
    ## Required Actions
    - [ ] Verify correct PR number
    - [ ] Check if PR was closed or merged
    - [ ] Update PR reference if needed
    
    **Note**: Cannot proceed with QA until valid PR is specified." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
        ;;
      3)
        echo "⚠️ Network error - posting REQUEST CHANGES review"
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ❌ **Network Error**: Unable to connect to GitHub API
    ❌ **Cannot verify**: CI status check failed due to connectivity issues
    
    ## Required Actions
    - [ ] Check network connectivity
    - [ ] Verify GitHub API access
    - [ ] Retry after network issues are resolved
    
    **Note**: Cannot proceed with QA until CI status can be verified." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
        ;;
      4)
        echo "⚠️ Authentication error - posting REQUEST CHANGES review"
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ❌ **Authentication Error**: GitHub token permissions insufficient
    ❌ **Cannot verify**: CI status check failed due to auth issues
    
    ## Required Actions
    - [ ] Verify GitHub token has correct permissions
    - [ ] Check repository access permissions
    - [ ] Ensure token hasn't expired
    - [ ] Contact administrator for token refresh
    
    **Note**: Cannot proceed with QA until authentication is resolved." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
        ;;
      5)
        echo "⚠️ Repository access error - posting REQUEST CHANGES review"
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ❌ **Repository Access Error**: Repository not found or not accessible
    ❌ **Cannot verify**: CI status check failed due to repo access issues
    
    ## Required Actions
    - [ ] Verify repository exists and is accessible
    - [ ] Check repository permissions for the token
    - [ ] Ensure repository URL is correct
    - [ ] Contact administrator for access issues
    
    **Note**: Cannot proceed with QA until repository access is resolved." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
        ;;
      esac
    
      # Parse CI status from JSON output
      if [ -z "$CI_JSON" ] || [ "$CI_JSON" = "[]" ]; then
        echo "⚠️ No CI checks found - posting REQUEST CHANGES review"
        # Post REQUEST CHANGES review for missing CI
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ❌ **Missing CI Setup**: No GitHub Actions workflows detected
    ❌ **Cannot verify**: Test execution and deployment status unknown
    
    ## Required Actions
    - [ ] Set up GitHub Actions CI pipeline
    - [ ] Add automated testing workflow
    - [ ] Configure deployment verification
    - [ ] Add branch protection rules
    
    **Note**: Cannot proceed with QA until CI is properly configured." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
    else
      # Function to parse JSON without jq dependency
      parse_ci_json() {
        local json="$1"
        local field="$2"
        local value="$3"
    
        # Count total checks
        if [ "$field" = "total" ]; then
          echo "$json" | grep -o '"name"' | wc -l
          return
        fi
    
        # Count by status and conclusion
        case "$field" in
          "completed")
            echo "$json" | grep -o '"status":"completed"' | wc -l
            ;;
          "success")
            # Count objects that have both completed status and success conclusion
            echo "$json" | sed 's/},{/\n/g' | grep '"status":"completed"' | grep '"conclusion":"success"' | wc -l
            ;;
          "failed")
            # Count objects that have completed status and failure/cancelled/timed_out conclusion
            echo "$json" | sed 's/},{/\n/g' | grep '"status":"completed"' | grep -E '"conclusion":"(failure|cancelled|timed_out)"' | wc -l
            ;;
          "pending")
            local total completed
            total=$(echo "$json" | grep -o '"name"' | wc -l)
            completed=$(echo "$json" | grep -o '"status":"completed"' | wc -l)
            echo $((total - completed))
            ;;
        esac
      }
    
      # Function to extract check details
      extract_check_details() {
        local json="$1"
        local type="$2"
    
        case "$type" in
          "failed")
            # Extract failed check names and conclusions
            echo "$json" | sed 's/},{/\n/g' | grep '"status":"completed"' | grep -E '"conclusion":"(failure|cancelled|timed_out)"' | sed -E 's/.*"name":"([^"]+)".*"conclusion":"([^"]+)".*/- \1 (\2)/'
            ;;
          "pending")
            # Extract pending check names and statuses
            echo "$json" | sed 's/},{/\n/g' | grep -v '"status":"completed"' | sed -E 's/.*"name":"([^"]+)".*"status":"([^"]+)".*/- \1 (\2)/'
            ;;
          "success")
            # Extract successful check names
            echo "$json" | sed 's/},{/\n/g' | grep '"status":"completed"' | grep '"conclusion":"success"' | sed -E 's/.*"name":"([^"]+)".*/- \1 ✅/'
            ;;
        esac
      }
    
      # Use jq if available, otherwise use fallback parsing
      if command -v jq >/dev/null 2>&1; then
        echo "📋 Using jq for JSON parsing"
        TOTAL_CHECKS=$(echo "$CI_JSON" | jq -r '. | length')
        COMPLETED_CHECKS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status == "completed")] | length')
        SUCCESS_CHECKS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status == "completed" and .conclusion == "success")] | length')
        FAILED_CHECKS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status == "completed" and (.conclusion == "failure" or .conclusion == "cancelled" or .conclusion == "timed_out"))] | length')
        PENDING_CHECKS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status != "completed")] | length')
      else
        echo "📋 Using fallback JSON parsing (jq not available)"
        TOTAL_CHECKS=$(parse_ci_json "$CI_JSON" "total")
        COMPLETED_CHECKS=$(parse_ci_json "$CI_JSON" "completed")
        SUCCESS_CHECKS=$(parse_ci_json "$CI_JSON" "success")
        FAILED_CHECKS=$(parse_ci_json "$CI_JSON" "failed")
        PENDING_CHECKS=$(parse_ci_json "$CI_JSON" "pending")
      fi
    
      echo "📊 CI Status Summary:"
      echo "  - Total checks: $TOTAL_CHECKS"
      echo "  - Completed: $COMPLETED_CHECKS"
      echo "  - Successful: $SUCCESS_CHECKS"
      echo "  - Failed: $FAILED_CHECKS"
      echo "  - Pending: $PENDING_CHECKS"
    
      if [ "$FAILED_CHECKS" -gt 0 ]; then
        echo "❌ CI failures detected - posting REQUEST CHANGES review"
        # Get details of failed checks
        if command -v jq >/dev/null 2>&1; then
          FAILED_DETAILS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status == "completed" and (.conclusion == "failure" or .conclusion == "cancelled" or .conclusion == "timed_out"))] | map("- " + .name + " (" + .conclusion + ")") | join("\n")')
        else
          FAILED_DETAILS=$(extract_check_details "$CI_JSON" "failed")
        fi
    
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ❌ **CI Failures Detected**: $FAILED_CHECKS out of $TOTAL_CHECKS check(s) failing
    ❌ **Cannot approve**: All CI checks must pass
    
    ## Failed Checks
    $FAILED_DETAILS
    
    ## Required Actions
    - [ ] Fix all failing CI checks
    - [ ] Address test failures
    - [ ] Resolve build errors
    - [ ] Verify all workflows pass
    
    **Note**: Will re-evaluate once CI issues are resolved." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
      elif [ "$PENDING_CHECKS" -gt 0 ]; then
        echo "⏳ CI checks still pending - posting REQUEST CHANGES review"
        # Get details of pending checks
        if command -v jq >/dev/null 2>&1; then
          PENDING_DETAILS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status != "completed")] | map("- " + .name + " (" + .status + ")") | join("\n")')
        else
          PENDING_DETAILS=$(extract_check_details "$CI_JSON" "pending")
        fi
    
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ⏳ **CI Checks Pending**: $PENDING_CHECKS out of $TOTAL_CHECKS check(s) still running
    ❌ **Cannot approve**: All CI checks must complete successfully
    
    ## Pending Checks
    $PENDING_DETAILS
    
    ## Required Actions
    - [ ] Wait for all CI checks to complete
    - [ ] Verify all checks pass successfully
    - [ ] Address any failures that may occur
    
    **Note**: Will re-evaluate once all CI checks are complete." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
      elif [ "$SUCCESS_CHECKS" -eq "$TOTAL_CHECKS" ] && [ "$TOTAL_CHECKS" -gt 0 ]; then
        echo "✅ All CI checks passing - posting APPROVE review"
        # Get details of successful checks
        if command -v jq >/dev/null 2>&1; then
          SUCCESS_DETAILS=$(echo "$CI_JSON" | jq -r '[.[] | select(.status == "completed" and .conclusion == "success")] | map("- " + .name + " ✅") | join("\n")')
        else
          SUCCESS_DETAILS=$(extract_check_details "$CI_JSON" "success")
        fi
    
        timeout 30 gh pr review "$PR_NUM" --approve --body "### ✅ QA Review for Task $TASK_ID - APPROVED
    
    ## Pre-Approval Verification
    ✅ **ALL CI checks verified**: $SUCCESS_CHECKS out of $TOTAL_CHECKS checks passing
    ✅ **No failures found**: Zero failing checks confirmed
    
    ## CI Status
    ✅ **GitHub Actions CI**: All checks passing
    $SUCCESS_DETAILS
    
    ## Task $TASK_ID Acceptance Criteria
    ✅ **All criteria met**: Implementation complete and verified
    ✅ **Code quality**: Passes all standards
    ✅ **Testing**: Comprehensive test coverage achieved
    
    ## Final Assessment
    - **Quality Score**: Excellent implementation
    - **Ready for merge**: All requirements satisfied
    - **No outstanding issues**: Clean, production-ready code
    
    **APPROVED** - Ready for merge to main branch." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
      else
        echo "⚠️ Unexpected CI state - posting REQUEST CHANGES review"
        timeout 30 gh pr review "$PR_NUM" --request-changes --body "### 🔍 QA Review for Task $TASK_ID - Changes Required
    
    ## CI Status
    ⚠️ **Unexpected CI State**: Unable to determine final CI status
    ❌ **Cannot approve**: CI status unclear
    
    ## Current Status
    - Total checks: $TOTAL_CHECKS
    - Completed: $COMPLETED_CHECKS
    - Successful: $SUCCESS_CHECKS
    - Failed: $FAILED_CHECKS
    - Pending: $PENDING_CHECKS
    
    ## Required Actions
    - [ ] Review CI check configuration
    - [ ] Ensure all checks are properly defined
    - [ ] Verify workflow completion
    - [ ] Contact administrator if issues persist
    
    **Note**: Will re-evaluate once CI status is clear." || echo "⚠️ PR review command timed out or failed (exit code: $?)"
      fi
    
    else
      # GitHub CLI not available - skip PR review
      echo "📝 Skipping PR review posting due to GitHub CLI unavailability"
      echo "✅ Tess QA workflow completed but could not post PR review"
    fi
    
    
    
    # =============================================================================
    # DEBUG LOGGING: FINAL STATUS
    # =============================================================================
    if [ $CLAUDE_EXIT_CODE -eq 0 ]; then
      echo "✅ Tess QA testing completed successfully"
      echo "📊 Final status: SUCCESS (exit code 0)"
    else
      echo "⚠️ Tess QA testing exited with code: $CLAUDE_EXIT_CODE"
      echo "📊 Final status: FAILURE (exit code $CLAUDE_EXIT_CODE)"
      echo "🔍 This usually indicates a cache_control or API error occurred"
    fi
    
    echo "🔍 Process information:"
    echo "  - PID: $CLAUDE_PID"
    echo "  - Exit code: $CLAUDE_EXIT_CODE"
    echo "  - Working directory: $(pwd)"
    echo "  - Repository: $REPO_NAME"
    echo "  - PR Review: Posted to #$PR_NUM"
    
    # Sidecar shutdown is handled by the EXIT trap defined earlier
    # The shutdown_sidecar function will be called automatically when the script exits
    
    # Perform final cleanup of our own processes
    echo "🔧 Performing final process cleanup..."
    
    # Clean up any child processes we may have spawned
    cleanup_child_processes() {
      if [ $$ -gt 1 ] && [ -d "/proc" ]; then
        # Get all child processes
        local child_pids=""
        child_pids=$(ps -o pid,ppid | awk -v ppid=$$ '$2 == ppid {print $1}' 2>/dev/null || echo "")
    
        if [ -n "$child_pids" ]; then
          echo "🔍 Found child processes to clean up: $child_pids"
          echo "$child_pids" | xargs kill -TERM 2>/dev/null || true
          sleep 2
          echo "$child_pids" | xargs kill -KILL 2>/dev/null || true
        fi
      fi
    }
    
    cleanup_child_processes
    
    # Write completion marker for workflow tracking
    echo "tess-qa-completed:$(date -u +%Y-%m-%dT%H:%M:%SZ)" > /workspace/.tess-complete
    
    # Final termination sequence
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 TESS CONTAINER TERMINATION                    ║'
    echo '════════════════════════════════════════════════════════════════'
    echo "Container PID: $$"
    echo "Final Process Check:"
    ps aux | head -5
    
    # Cleanup FIFO
    rm -f "$FIFO_PATH" 2>/dev/null || true
    
    # Force exit to terminate the pod
    echo "🔚 Force terminating container..."
    exit 0  code_container.sh.hbs: |
    #!/bin/sh
    
    # Ensure Rust environment is always properly set up
    echo "🔧 Setting up Rust environment..."
    
    # Source Rust environment if available (fixes cargo not found issues)
    if [ -f "$HOME/.cargo/env" ]; then
        . "$HOME/.cargo/env"
        echo "✓ Sourced Rust environment from $HOME/.cargo/env"
    fi
    
    # Also try root cargo env as fallback
    if [ -f "/root/.cargo/env" ]; then
        . "/root/.cargo/env"
        echo "✓ Sourced Rust environment from /root/.cargo/env"
    fi
    
    # Ensure rustup has a default toolchain set
    if command -v rustup >/dev/null 2>&1; then
        rustup default stable 2>/dev/null || true
        echo "✓ Ensured stable Rust toolchain is default"
    else
        echo "⚠️ rustup not found in PATH"
    fi
    
    # Verify Rust is available
    if command -v cargo >/dev/null 2>&1; then
        echo "✓ Cargo is available: $(cargo --version)"
    else
        echo "❌ Cargo not found in PATH"
        echo "Current PATH: $PATH"
        echo "Attempting to find cargo..."
        find /usr -name cargo 2>/dev/null | head -5 || echo "No cargo found in /usr"
        find /home -name cargo 2>/dev/null | head -5 || echo "No cargo found in /home"
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 IMPLEMENTATION TASK STARTING                 ║'
    echo '════════════════════════════════════════════════════════════════'
    
    # Disable interactive Git prompts globally
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # Repository URL
    REPO_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    
    # GitHub App authentication is configured via environment variables
    echo "Using GitHub App authentication"
    
    # Authenticate with GitHub App
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        echo "Authenticating with GitHub App..."
    
        # Create temporary private key file (support escaped newlines)
        TEMP_KEY_FILE="/tmp/github-app-key.pem"
        printf '%b' "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
        chmod 600 "$TEMP_KEY_FILE"
    
        # Generate JWT token for GitHub App (fixed JWT generation for Linux containers)
        # JWT header
        JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # JWT payload with current time and expiration (10 minutes)
        NOW=$(date +%s)
        EXP=$((NOW + 600))
        JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # Sign the JWT
        JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
        JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
    
        # Get installation ID for the repository (robust parsing of owner/repo)
        INPUT_REPO="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        REPO_OWNER=""
        REPO_NAME=""
    
        if echo "$INPUT_REPO" | grep -qE '^https://github.com/'; then
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
        elif echo "$INPUT_REPO" | grep -qE '^git@github.com:'; then
            # SSH format git@github.com:owner/repo(.git)
            REPO_OWNER=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$INPUT_REPO" | sed -E 's|git@github.com:[^/]+/([^/]+)(\.git)?|\1|')
        else
            # Fallback: assume slug owner/repo (possibly with .git)
            SLUG=$(echo "$INPUT_REPO" | sed -E 's|\.git$||')
            REPO_OWNER=$(echo "$SLUG" | cut -d'/' -f1)
            REPO_NAME=$(echo "$SLUG" | cut -d'/' -f2)
        fi
    
        echo "DEBUG: Parsed repository - Owner: '$REPO_OWNER', Name: '$REPO_NAME'"
    
        echo "Getting installation ID for $REPO_OWNER/$REPO_NAME..."
    
        # Get the installation ID (retry and follow redirects). Fallback to org installation.
        INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
            --connect-timeout 5 --max-time 12 \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
        INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "⚠️ Repo installation not found, trying org installation..."
            ORG_INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/orgs/$REPO_OWNER/installation")
            INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
        fi
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "❌ Failed to get installation ID for $REPO_OWNER/$REPO_NAME"
            echo "Response (repo): $INSTALLATION_RESPONSE"
            echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "Installation ID: $INSTALLATION_ID"
    
        # Get installation access token
        TOKEN_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
        GITHUB_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
    
        if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ Failed to get installation access token"
            echo "Response: $TOKEN_RESPONSE"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        # Clean up temporary key file
        rm -f "$TEMP_KEY_FILE"
    
        # Export the token for git to use
        export GITHUB_TOKEN
    
        # Configure git to use the token (use --replace-all to handle multiple existing helpers)
        git config --global --replace-all credential.helper store
        echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
    
        # Also authenticate gh CLI with the token
        echo "$GITHUB_TOKEN" | gh auth login --with-token
    
        echo "✓ GitHub App authenticated successfully"
    
    else
        echo "❌ GITHUB_APP_PRIVATE_KEY or GITHUB_APP_ID not found"
        exit 1
    fi
    
    # Git configuration with proper GitHub App attribution
    git config --global --add safe.directory /workspace
    
    # Set GitHub App attribution - use generic format for all agents
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    # Generic attribution that works for any agent
    GIT_AUTHOR_NAME="${GITHUB_APP} Agent (Claude Code)"
    GIT_AUTHOR_EMAIL="${GITHUB_APP}[bot]@users.noreply.github.com"
    
    # Configure git with proper GitHub App attribution
    git config --global user.name "$GIT_AUTHOR_NAME"
    git config --global user.email "$GIT_AUTHOR_EMAIL"
    
    # Set environment variables for Claude Code to use
    export GIT_AUTHOR_NAME="$GIT_AUTHOR_NAME"
    export GIT_AUTHOR_EMAIL="$GIT_AUTHOR_EMAIL"
    export GIT_COMMITTER_NAME="$GIT_AUTHOR_NAME"
    export GIT_COMMITTER_EMAIL="$GIT_AUTHOR_EMAIL"
    echo "✓ Git configured"
    
    # =============================================================================
    # AUTHENTICATION VERIFICATION
    # =============================================================================
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "🔐 AUTHENTICATION VERIFICATION"
    echo "═══════════════════════════════════════════════════════════════"
    echo ""
    
    # Repository URLs - Handle both full URLs and org/repo format
    # Check if repository_url already contains https://github.com/
    if echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        REPO_HTTP_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | grep -q "\.git$"; then
            REPO_HTTP_URL="${REPO_HTTP_URL}.git"
        fi
    else
        REPO_HTTP_URL="https://github.com/{{`{{`{{`}}`}}repository_url{{`}}`}}.git"
    fi
    
    # Same for docs repository
    if echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "^https://github.com/"; then
        DOCS_HTTP_URL="{{`{{`{{`}}`}}docs_repository_url{{`}}`}}"
        if ! echo "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" | grep -q "\.git$"; then
            DOCS_HTTP_URL="${DOCS_HTTP_URL}.git"
        fi
    else
        DOCS_HTTP_URL="https://github.com/{{`{{`{{`}}`}}docs_repository_url{{`}}`}}.git"
    fi
    
    # DEBUG: Show what URLs are being constructed
    echo "🔍 DEBUG: URL Construction & Parameters"
    echo "  Input repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  Input docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  Input docs_project_directory: '{{`{{`{{`}}`}}docs_project_directory{{`}}`}}'"
    echo "  Input working_directory: '{{`{{`{{`}}`}}working_directory{{`}}`}}'"
    echo "  Input docs_branch: '{{`{{`{{`}}`}}docs_branch{{`}}`}}'"
    echo "  Input github_app: '{{`{{`{{`}}`}}github_app{{`}}`}}'"
    echo "  Input task_id: '{{`{{`{{`}}`}}task_id{{`}}`}}'"
    echo "  Input service: '{{`{{`{{`}}`}}service{{`}}`}}'"
    echo "  Constructed REPO_HTTP_URL: '$REPO_HTTP_URL'"
    echo "  Constructed DOCS_HTTP_URL: '$DOCS_HTTP_URL'"
    echo "  Current working directory: $(pwd)"
    echo "  Available environment variables:"
    env | grep -E "(GITHUB|ANTHROPIC)" | sort
    
    # Test HTTPS access to repository
    echo "🔍 DEBUG: Testing HTTPS repository access..."
    echo "  Command: git ls-remote \"$REPO_HTTP_URL\" HEAD"
    if git ls-remote "$REPO_HTTP_URL" HEAD > /tmp/repo_test.out 2>&1; then
      echo "✓ HTTPS repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Output: $(cat /tmp/repo_test.out | head -1)"
    else
      echo "❌ HTTPS repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
      echo "  Error output: $(cat /tmp/repo_test.out)"
      echo "  Git credential helper status:"
      git config --list | grep credential || echo "  No credential helpers configured"
      echo ""
      echo "🚫 ABORTING: Cannot access repository via HTTPS"
      exit 1
    fi
    
    # Test docs repository access
    echo "🔍 DEBUG: Testing docs repository access..."
    echo "  Command: git ls-remote \"$DOCS_HTTP_URL\" HEAD"
    if git ls-remote "$DOCS_HTTP_URL" HEAD > /tmp/docs_test.out 2>&1; then
      echo "✓ Docs repository access successful"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Output: $(cat /tmp/docs_test.out | head -1)"
    else
      echo "❌ Docs repository access failed"
      echo "  Repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
      echo "  Error output: $(cat /tmp/docs_test.out)"
      echo ""
      echo "🚫 ABORTING: Cannot access docs repository via HTTPS"
      exit 1
    fi
    
    # Dual Repository Setup - Platform repo for docs, Target repo for implementation
    echo ""
    echo "═══════════════════════════════════════════════════════════════"
    echo "║                 DUAL REPOSITORY SETUP                        ║"
    echo "═══════════════════════════════════════════════════════════════"
    
    # Repository Information
    DOCS_BRANCH="{{`{{`{{`}}`}}docs_branch{{`}}`}}"
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Helper: derive safe workspace directory name from repo input (URL, SSH, or slug)
    sanitize_repo_dir() {
        input="$1"
        if echo "$input" | grep -qE '^https://github.com/'; then
            owner=$(echo "$input" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            name=$(echo "$input" | sed -E 's|https://github.com/[^/]+/([^/]+)(\\.git)?|\1|')
            printf '%s-%s' "$owner" "$name"
        elif echo "$input" | grep -qE '^git@github.com:'; then
            owner=$(echo "$input" | sed -E 's|git@github.com:([^/]+)/.*|\1|')
            name=$(echo "$input" | sed -E 's|git@github.com:[^/]+/([^/]+)(\\.git)?|\1|')
            printf '%s-%s' "$owner" "$name"
        else
            # Assume owner/repo (optionally with .git)
            slug=$(echo "$input" | sed -E 's|\\.git$||')
            echo "$slug" | tr '/' '-'
        fi
    }
    
    # Derive workspace directory names (owner-repo)
    DOCS_REPO_DIR=$(sanitize_repo_dir "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}")
    TARGET_REPO_DIR=$(sanitize_repo_dir "{{`{{`{{`}}`}}repository_url{{`}}`}}")
    
    echo "=== REPOSITORY SETUP ==="
    echo "Docs repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
    echo "Target repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
    echo "Docs branch: $DOCS_BRANCH"
    echo "GitHub App: $GITHUB_APP"
    
    # Determine workflow type
    echo "🔍 DEBUG: Workflow type detection"
    echo "  docs_repository_url: '{{`{{`{{`}}`}}docs_repository_url{{`}}`}}'"
    echo "  repository_url: '{{`{{`{{`}}`}}repository_url{{`}}`}}'"
    echo "  Comparison result: $( [ "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" = "{{`{{`{{`}}`}}repository_url{{`}}`}}" ] && echo 'EQUAL' || echo 'DIFFERENT' )"
    
    if [ "{{`{{`{{`}}`}}docs_repository_url{{`}}`}}" = "{{`{{`{{`}}`}}repository_url{{`}}`}}" ]; then
        echo "✓ Single-repo workflow detected (same repository for docs and implementation)"
        WORKFLOW_TYPE="single-repo"
        echo "  └─ TaskMaster files expected at repository root"
    else
        echo "✓ Multi-repo workflow detected (separate docs and target repositories)"
        WORKFLOW_TYPE="multi-repo"
        echo "  └─ TaskMaster files expected in docs repo at: {{`{{`{{`}}`}}docs_project_directory{{`}}`}}"
    fi
    echo "🔍 DEBUG: WORKFLOW_TYPE set to: $WORKFLOW_TYPE"
    
    # Repository Setup Based on Workflow Type
    if [ "$WORKFLOW_TYPE" = "single-repo" ]; then
        echo "=== SINGLE-REPO WORKFLOW ==="
        # Check if repository already exists (retry scenario)
        echo "🔍 DEBUG: Checking for existing repository directory: $TARGET_REPO_DIR"
        echo "  Workspace contents: $(ls -la /workspace/ | grep -v '^total')"
    
        if [ -d "$TARGET_REPO_DIR" ]; then
            echo "🔄 REPOSITORY: UPDATE - directory already exists"
            echo "📁 Found existing repository '$TARGET_REPO_DIR', updating..."
            echo "  Directory contents: $(ls -la $TARGET_REPO_DIR | head -5)"
            cd "$TARGET_REPO_DIR"
            echo "  Current branch: $(git branch --show-current 2>/dev/null || echo 'unknown')"
            echo "  Git status before update: $(git status --porcelain | wc -l) files changed"
            git fetch origin
            git checkout "$DOCS_BRANCH"
            git reset --hard "origin/$DOCS_BRANCH"
            cd /workspace
            echo "✓ Repository updated successfully to $DOCS_BRANCH"
        else
            echo "📥 REPOSITORY: CLONING - first time setup"
            echo "  Clone command: git clone \"$REPO_HTTP_URL\" \"$TARGET_REPO_DIR\""
            if ! git clone "$REPO_HTTP_URL" "$TARGET_REPO_DIR"; then
                echo "❌ Failed to clone repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
                echo "  Last git error: $(git config --get-regexp 'credential|remote')"
                exit 1
            fi
            echo "  Clone successful, changing to directory and checking out $DOCS_BRANCH"
            cd "$TARGET_REPO_DIR" && git checkout "$DOCS_BRANCH" && cd /workspace
            echo "✓ Repository cloned successfully"
            echo "  Final directory structure: $(ls -la $TARGET_REPO_DIR | head -5)"
        fi
    
        # Preserve Task Master files before branch switching (single-repo workflow)
        echo "🔄 Preserving Task Master files from docs branch before switching to feature branch..."
        TEMP_TASK_DIR="/tmp/taskmaster-preserve"
        rm -rf "$TEMP_TASK_DIR"
        mkdir -p "$TEMP_TASK_DIR"
    
        cd "/workspace/$TARGET_REPO_DIR"
        echo "🔍 DEBUG: TaskMaster file preservation"
        echo "  docs_project_directory: '{{`{{`{{`}}`}}docs_project_directory{{`}}`}}'"
        echo "  task_id: '{{`{{`{{`}}`}}task_id{{`}}`}}'"
    
        # Copy Task Master files from docs branch to temporary location
        {{`{{`{{`}}`}}#if docs_project_directory{{`}}`}}
        if [ "{{`{{`{{`}}`}}docs_project_directory{{`}}`}}" = "." ]; then
            PRESERVE_FROM="/workspace/$TARGET_REPO_DIR/.taskmaster/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
            echo "  └─ Using root taskmaster path (docs_project_directory='.')"
        else
            PRESERVE_FROM="/workspace/$TARGET_REPO_DIR/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
            echo "  └─ Using project subdirectory: {{`{{`{{`}}`}}docs_project_directory{{`}}`}}"
        fi
        {{`{{`{{`}}`}}else{{`}}`}}
        PRESERVE_FROM="/workspace/$TARGET_REPO_DIR/.taskmaster/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
        echo "  └─ Using default root taskmaster path (no docs_project_directory)"
        {{`{{`{{`}}`}}/if{{`}}`}}
    
        echo "  PRESERVE_FROM resolved to: $PRESERVE_FROM"
    
        echo "🔍 DEBUG: Attempting to preserve Task Master files from: $PRESERVE_FROM"
        echo "  Checking if directory exists..."
        if [ -d "$PRESERVE_FROM" ]; then
            echo "  ✓ TaskMaster directory found!"
            echo "  Directory contents: $(ls -la "$PRESERVE_FROM" | wc -l) items"
            ls -la "$PRESERVE_FROM"
            cp -r "$PRESERVE_FROM"/* "$TEMP_TASK_DIR/" 2>/dev/null && echo "✓ Task Master files preserved to temporary location" || echo "⚠️ Some files may not have been preserved"
    
            # Also preserve architecture.md from docs directory (one level up from task directory)
            {{`{{`{{`}}`}}#if docs_project_directory{{`}}`}}
            if [ "{{`{{`{{`}}`}}docs_project_directory{{`}}`}}" = "." ]; then
                ARCH_SOURCE="/workspace/$TARGET_REPO_DIR/.taskmaster/docs/architecture.md"
            else
                ARCH_SOURCE="/workspace/$TARGET_REPO_DIR/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster/docs/architecture.md"
            fi
            {{`{{`{{`}}`}}else{{`}}`}}
            ARCH_SOURCE="/workspace/$TARGET_REPO_DIR/.taskmaster/docs/architecture.md"
            {{`{{`{{`}}`}}/if{{`}}`}}
    
            if [ -f "$ARCH_SOURCE" ]; then
                cp "$ARCH_SOURCE" "$TEMP_TASK_DIR/" && echo "✓ architecture.md preserved from docs branch" || echo "⚠️ Failed to preserve architecture.md"
            else
                echo "⚠️ architecture.md not found at: $ARCH_SOURCE"
            fi
    
            echo "🔍 DEBUG: Preserved files:"
            ls -la "$TEMP_TASK_DIR/" || echo "No files in temp directory"
        else
            echo "❌ Task Master directory not found at: $PRESERVE_FROM"
            echo "❌ CRITICAL: TaskMaster files must exist at the specified location"
            echo "❌ Expected location: $PRESERVE_FROM"
            echo "❌ This job cannot continue without the specified TaskMaster files"
            echo "❌ Verify that:"
            echo "   1. The docs-project-directory parameter is correct"
            echo "   2. The task-id exists in the TaskMaster directory"
            echo "   3. The docs-branch contains the TaskMaster files"
            exit 1
        fi
        cd /workspace
    
        # Set working directory to the repository root
        REPO_NAME="$TARGET_REPO_DIR"
        echo "✓ Working directory: /workspace/$REPO_NAME"
        echo "✓ Task files preserved from docs branch"
    
    else
        echo "=== MULTI-REPO WORKFLOW ==="
    
        # Step 1: Clone or update docs repository temporarily
        if [ -d "/tmp/docs-repo" ]; then
            echo "🔄 DOCS REPOSITORY: UPDATE - temporary directory exists"
            cd /tmp/docs-repo
            git fetch origin
            git checkout "$DOCS_BRANCH"
            git reset --hard "origin/$DOCS_BRANCH"
            cd /workspace
            echo "✓ Docs repository updated"
        else
            echo "📥 DOCS REPOSITORY: CLONING - extracting task files"
            if ! git clone "$DOCS_HTTP_URL" /tmp/docs-repo; then
                echo "❌ Failed to clone docs repository: {{`{{`{{`}}`}}docs_repository_url{{`}}`}} ($DOCS_HTTP_URL)"
                exit 1
            fi
            cd /tmp/docs-repo && git checkout "$DOCS_BRANCH" && cd /workspace
            echo "✓ Docs repository cloned to temporary location"
        fi
    
        # Step 2: Clone or update target repository
        if [ -d "$TARGET_REPO_DIR" ]; then
            echo "🔄 TARGET REPOSITORY: UPDATE - directory already exists"
            echo "📁 Found existing target repository '$TARGET_REPO_DIR', updating..."
            cd "$TARGET_REPO_DIR"
            git fetch origin main
            git reset --hard origin/main
            cd /workspace
            echo "✓ Target repository updated successfully"
        else
            echo "📥 TARGET REPOSITORY: CLONING - first time setup"
            if ! git clone "$REPO_HTTP_URL" "$TARGET_REPO_DIR"; then
                echo "❌ Failed to clone target repository: {{`{{`{{`}}`}}repository_url{{`}}`}} ($REPO_HTTP_URL)"
                exit 1
            fi
            echo "✓ Target repository cloned successfully"
        fi
    
        # Step 3: Copy task files from docs repo to target repo
        echo "📋 TASK FILES: COPYING from docs to target repository"
        mkdir -p "/workspace/$TARGET_REPO_DIR/task"
    
        # Determine docs project directory path
        {{`{{`{{`}}`}}#if docs_project_directory{{`}}`}}
        if [ "{{`{{`{{`}}`}}docs_project_directory{{`}}`}}" = "." ]; then
            DOCS_PATH="/tmp/docs-repo/.taskmaster"
        else
            DOCS_PATH="/tmp/docs-repo/{{`{{`{{`}}`}}docs_project_directory{{`}}`}}/.taskmaster"
        fi
        {{`{{`{{`}}`}}else{{`}}`}}
        DOCS_PATH="/tmp/docs-repo/.taskmaster"
        {{`{{`{{`}}`}}/if{{`}}`}}
    
        # Copy specific task files
        TASK_DIR="$DOCS_PATH/docs/task-{{`{{`{{`}}`}}task_id{{`}}`}}"
        echo "🔍 DEBUG: Looking for task files at: $TASK_DIR"
        echo "🔍 DEBUG: Docs path is: $DOCS_PATH"
        echo "🔍 DEBUG: Contents of docs temp directory:"
        ls -la /tmp/docs-repo/.taskmaster/ || echo "No .taskmaster found"
        echo "🔍 DEBUG: Contents of docs directory:"
        ls -la /tmp/docs-repo/.taskmaster/docs/ || echo "No docs directory found"
    
        if [ -d "$TASK_DIR" ]; then
            echo "🔍 DEBUG: Task directory found, contents:"
            ls -la "$TASK_DIR"
    
            echo "✅ Copying task.md..."
            cp "$TASK_DIR/task.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ task.md copied" || echo "❌ task.md copy failed"
    
            echo "✅ Copying acceptance-criteria.md..."
            cp "$TASK_DIR/acceptance-criteria.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ acceptance-criteria.md copied" || echo "❌ acceptance-criteria.md copy failed"
    
            echo "✅ Copying prompt.md..."
            cp "$TASK_DIR/prompt.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ prompt.md copied" || echo "❌ prompt.md copy failed"
    
            echo "✅ Copying client-config.json..."
            if [ -f "$TASK_DIR/client-config.json" ]; then
                cp "$TASK_DIR/client-config.json" "$CLAUDE_WORK_DIR/client-config.json" && echo "✓ client-config.json copied to Claude working directory" || echo "❌ client-config.json copy failed"
            else
                echo "⚠️ client-config.json not found - MCP client may not be configured"
            fi
    
            echo "✅ Copying toolman-guide.md..."
            if [ -f "$TASK_DIR/toolman-guide.md" ]; then
                cp "$TASK_DIR/toolman-guide.md" "/workspace/$TARGET_REPO_DIR/task/" && echo "✓ toolman-guide.md copied" || echo "❌ toolman-guide.md copy failed"
            else
                echo "⚠️ toolman-guide.md not found - code agent won't have tool usage guidance"
            fi
    
            echo "✓ Task {{`{{`{{`}}`}}task_id{{`}}`}} files copied from $TASK_DIR"
        else
            echo "❌ CRITICAL: Task {{`{{`{{`}}`}}task_id{{`}}`}} directory not found at: $TASK_DIR"
            echo "🔍 DEBUG: Available directories in docs:"
            find /tmp/docs-repo -name "task-*" -type d || echo "No task directories found"
        fi
    
        # Copy architecture.md from docs root
        ARCH_FILE="$DOCS_PATH/docs/architecture.md"
        if [ -f "$ARCH_FILE" ]; then
            cp "$ARCH_FILE" "/workspace/$TARGET_REPO_DIR/task/"
            echo "✓ Architecture documentation copied"
        else
            echo "⚠️ architecture.md not found at: $ARCH_FILE"
        fi
    
        # Copy tasks.json if it exists
        if [ -f "$DOCS_PATH/tasks.json" ]; then
            cp "$DOCS_PATH/tasks.json" "/workspace/$TARGET_REPO_DIR/task/"
            echo "✓ tasks.json copied"
        fi
    
        echo "✓ Task files copied to target repository"
    
        # DEBUG: Verify files were copied successfully
        echo "🔍 DEBUG: Contents of target task directory after copy:"
        ls -la "/workspace/$TARGET_REPO_DIR/task/" || echo "Task directory not found"
        echo "🔍 DEBUG: Checking if prompt.md exists:"
        [ -f "/workspace/$TARGET_REPO_DIR/task/prompt.md" ] && echo "✅ prompt.md exists" || echo "❌ prompt.md missing"
    
        # Step 4: Clean up docs repository
        echo "🧹 CLEANUP: Removing temporary docs repository"
        rm -rf /tmp/docs-repo
        echo "✓ Docs repository cleaned up"
    
        # Set working directory to the target repository root
        REPO_NAME="$TARGET_REPO_DIR"
        echo "✓ Working directory: /workspace/$REPO_NAME"
    fi
    
    # Setup feature branch for implementation
    echo "=== BRANCH SETUP ==="
    cd "/workspace/$REPO_NAME"
    
    # Sync with latest main to prevent conflicts
    echo "🔄 Syncing with latest main to prevent conflicts..."
    git fetch origin main 2>/dev/null || git fetch origin master 2>/dev/null || echo "⚠️ Could not fetch main/master branch"
    
    # Create or checkout feature branch
    FEATURE_BRANCH="feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation"
    BRANCH_EXISTS="false"
    
        if git show-ref --verify --quiet refs/heads/$FEATURE_BRANCH; then
            BRANCH_EXISTS="true"
            echo "Feature branch '$FEATURE_BRANCH' exists, checking out..."
            git checkout $FEATURE_BRANCH
    
            echo "📥 Merging latest main into $FEATURE_BRANCH..."
            if git merge origin/main --no-edit; then
                echo "✓ Successfully merged latest main into feature branch"
            else
                echo "⚠️ MERGE CONFLICT: Cannot auto-merge main into $FEATURE_BRANCH"
                echo "❗ Manual conflict resolution required by Claude agent"
                echo ""
                echo "📋 Conflict files:"
                git status --porcelain | grep "^UU\|^AA\|^DD" || echo "   (Use 'git status' to see details)"
                echo ""
                echo "🔧 Claude will need to resolve conflicts manually before proceeding"
                # Don't exit - let Claude handle the conflicts
            fi
        else
            # Create new feature branch from latest main
            echo "Creating new feature branch '$FEATURE_BRANCH' from latest main..."
            git checkout -b $FEATURE_BRANCH origin/main
            echo "✓ Created feature branch: $FEATURE_BRANCH"
        fi
    
    # 5. Set Working Directory (Critical for Claude Execution)
    WORK_DIR="{{`{{`{{`}}`}}working_directory{{`}}`}}"
    if [ "$WORK_DIR" = "." ] || [ -z "$WORK_DIR" ]; then
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME"
    else
      CLAUDE_WORK_DIR="/workspace/$REPO_NAME/$WORK_DIR"
    fi
    mkdir -p "$CLAUDE_WORK_DIR" && cd "$CLAUDE_WORK_DIR"
    echo "✓ Set working directory: $CLAUDE_WORK_DIR"
    echo "🔑 CRITICAL: Claude will be launched from this directory"
    
    # Working directory setup completed above
    
    # Configure git user after successful clone
    echo "=== POST-CLONE GIT CONFIGURATION ==="
    # Fix dubious ownership issues
    git config --global --add safe.directory "/workspace/$REPO_NAME"
    echo "✓ Added repository to safe directories"
    
    # Set git config locally in the working repository (persistent on PVC)
    if [ -d "/workspace/$REPO_NAME/.git" ]; then
        cd "/workspace/$REPO_NAME"
        git config --local user.name "$GIT_AUTHOR_NAME"
        git config --local user.email "$GIT_AUTHOR_EMAIL"
        # Set up automatic upstream for new branches
        git config --local push.autoSetupRemote true
        echo "✓ Configured git user in target repository: $GIT_AUTHOR_NAME"
        echo "✓ Enabled automatic upstream setup for new branches"
    fi
    
    cd /workspace
    
    # Copy ConfigMap files to working directory (AFTER repository clone)
    echo "=== CONFIGMAP FILE SETUP ==="
    
    # Claude working directory already set above during repository setup
    
    echo "Setting up files in Claude working directory: $CLAUDE_WORK_DIR"
    cd "$CLAUDE_WORK_DIR"
    
    # Copy all files from ConfigMap to working directory
    if [ -d "/task-files" ]; then
      echo "Copying ConfigMap files to working directory..."
    
      # CLAUDE.md Memory Persistence Logic (controlled by overwriteMemory CRD field)
            OVERWRITE_MEMORY="{{`{{`{{`}}`}}overwrite_memory{{`}}`}}"
    
      # Handle CLAUDE.md based on overwriteMemory setting
            if [ "$OVERWRITE_MEMORY" = "true" ]; then
              # Overwrite mode: Always replace CLAUDE.md with fresh template
        cp "/task-files/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
        cp "/task-files/CLAUDE.md" "/workspace/CLAUDE.md"
              echo "✓ Overwrote CLAUDE.md memory file (fresh start requested)"
              echo "✓ Copied CLAUDE.md to workspace root for easy access"
            else
              # Preserve mode (default): Only copy if doesn't exist
              if [ ! -f "$CLAUDE_WORK_DIR/CLAUDE.md" ]; then
          # Initial creation - copy from ConfigMap
          cp "/task-files/CLAUDE.md" "$CLAUDE_WORK_DIR/CLAUDE.md"
          cp "/task-files/CLAUDE.md" "/workspace/CLAUDE.md"
                echo "✓ Created initial CLAUDE.md memory file"
                echo "✓ Copied CLAUDE.md to workspace root for easy access"
              else
                echo "✓ Preserved existing CLAUDE.md memory file (maintaining accumulated context)"
                # Still copy to workspace root for consistency
                cp "$CLAUDE_WORK_DIR/CLAUDE.md" "/workspace/CLAUDE.md"
                echo "✓ Synced CLAUDE.md to workspace root"
              fi
            fi
    
      # Copy all other markdown files (excluding CLAUDE.md)
      for md_file in /task-files/*.md; do
        if [ -f "$md_file" ]; then
          basename_file=$(basename "$md_file")
          # Skip CLAUDE.md since we handled it above
          if [ "$basename_file" != "CLAUDE.md" ]; then
            cp "$md_file" "$CLAUDE_WORK_DIR/"
            echo "✓ Updated $basename_file"
          fi
        fi
      done
    
      # Verify enterprise settings (mounted directly from ConfigMap)
      if [ -f "/etc/claude-code/managed-settings.json" ]; then
        echo "✓ Enterprise settings verified"
        if ! jq empty /etc/claude-code/managed-settings.json 2>/dev/null; then
          echo "❌ Invalid enterprise settings JSON"
          exit 1
        fi
      else
        echo "❌ Enterprise settings not found"
        exit 1
      fi
    
      # Copy guidelines files to working directory
      if [ -f "/task-files/coding-guidelines.md" ]; then
        cp /task-files/coding-guidelines.md "$CLAUDE_WORK_DIR/"
        echo "✓ Copied coding-guidelines.md to working directory"
      fi
    
      if [ -f "/task-files/github-guidelines.md" ]; then
        cp /task-files/github-guidelines.md "$CLAUDE_WORK_DIR/"
        echo "✓ Copied github-guidelines.md to working directory"
      fi
    
      # System prompt will be rendered inline (no file copying needed)
      echo "✓ System prompt template will be rendered inline"
    
      # Hook copying disabled
      echo "! Hook scripts disabled - no hooks will be copied"
    
      # Set up MCP configuration
      echo "Setting up MCP configuration..."
    
      # Copy MCP configuration from ConfigMap to project root (project scope)
      if [ -f "/task-files/mcp.json" ]; then
        cp /task-files/mcp.json "$CLAUDE_WORK_DIR/.mcp.json"
        echo "✓ Copied mcp.json to .mcp.json (project scope)"
      else
        echo "⚠️  mcp.json template not found"
      fi
    
      # Enterprise managed settings are mounted directly from ConfigMap
      echo "=== ENTERPRISE MANAGED SETTINGS ==="
      echo "✓ Settings mounted directly from ConfigMap at: /etc/claude-code/managed-settings.json"
      echo "✓ No copying needed - mount automatically reflects latest ConfigMap changes"
    
      echo "✓ ConfigMap files copied to $CLAUDE_WORK_DIR"
    else
      echo "⚠️  Warning: /task-files directory not found (ConfigMap not mounted?)"
    fi
    
    
    # Copy Current Task Documentation to Working Directory
    echo "=== TASK DOCUMENTATION SETUP ==="
    echo "🔍 DEBUG: WORKFLOW_TYPE is: $WORKFLOW_TYPE"
    echo "🔍 DEBUG: REPO_NAME is: $REPO_NAME"
    echo "🔍 DEBUG: CLAUDE_WORK_DIR is: $CLAUDE_WORK_DIR"
    echo "🔍 DEBUG: Task ID is: {{`{{`{{`}}`}}task_id{{`}}`}}"
    
    # Task directory should already exist from multi-repo workflow or be created as needed
    mkdir -p "$CLAUDE_WORK_DIR/task"
    echo "✓ Created task directory at: $CLAUDE_WORK_DIR/task"
    
    # Task documentation should already be available in the task/ directory
    if [ "$WORKFLOW_TYPE" = "single-repo" ]; then
        echo "✓ Restoring task documentation from preserved temporary location"
    
        # Use the preserved Task Master files from temporary location
        TEMP_TASK_DIR="/tmp/taskmaster-preserve"
        echo "🔍 DEBUG: Restoring task files from: $TEMP_TASK_DIR"
    
        if [ -d "$TEMP_TASK_DIR" ] && [ "$(ls -A $TEMP_TASK_DIR 2>/dev/null)" ]; then
            echo "✓ Preserved Task Master files found"
            echo "🔍 DEBUG: Preserved task files:"
            ls -la "$TEMP_TASK_DIR/"
    
            echo "✅ Copying all preserved files to task directory..."
    
            # Copy all files from preserved directory to task directory
            if cp -r "$TEMP_TASK_DIR"/* "$CLAUDE_WORK_DIR/task/" 2>/dev/null; then
                echo "✓ All task files copied from preserved temporary location"
            else
                echo "❌ Failed to copy task files from preserved location"
                exit 1
            fi
    
            # Copy task.txt as task.md if it exists (specific rename needed)
            if [ -f "$CLAUDE_WORK_DIR/task/task.txt" ]; then
                cp "$CLAUDE_WORK_DIR/task/task.txt" "$CLAUDE_WORK_DIR/task/task.md" && echo "✓ task.txt copied as task.md" || echo "❌ task.txt copy failed"
            fi
    
            # Move client-config.json to Claude working directory (not in task/ subdirectory)
            if [ -f "$CLAUDE_WORK_DIR/task/client-config.json" ]; then
                mv "$CLAUDE_WORK_DIR/task/client-config.json" "$CLAUDE_WORK_DIR/client-config.json" && echo "✓ client-config.json moved to Claude working directory" || echo "❌ client-config.json move failed"
            else
                echo "⚠️ client-config.json not found - MCP client may not be configured"
            fi
    
            echo "✓ Task {{`{{`{{`}}`}}task_id{{`}}`}} files copied from preserved temporary location"
    
            # Clean up temporary directory
            rm -rf "$TEMP_TASK_DIR"
            echo "✓ Cleaned up temporary preservation directory"
        else
            echo "❌ CRITICAL: No preserved Task Master files found at: $TEMP_TASK_DIR"
            echo "🔍 DEBUG: This indicates the Task Master preservation step failed earlier"
            echo "❌ Task {{`{{`{{`}}`}}task_id{{`}}`}} files are not available for this job"
            exit 1
        fi
    
        # DEBUG: Verify files were copied successfully
        echo "🔍 DEBUG: Contents of target task directory after copy:"
        ls -la "$CLAUDE_WORK_DIR/task/" || echo "Task directory not found"
        echo "🔍 DEBUG: Checking if prompt.md exists:"
        [ -f "$CLAUDE_WORK_DIR/task/prompt.md" ] && echo "✅ prompt.md exists" || echo "❌ prompt.md missing"
    
    else
        echo "✓ Task documentation copied from docs repository during multi-repo setup"
    fi
    
    # Verify client-config.json is available in Claude's working directory
    echo "=== TOOLMAN CONFIG SETUP ==="
    CLAUDE_CONFIG="$CLAUDE_WORK_DIR/client-config.json"
    
    if [ -f "$CLAUDE_CONFIG" ]; then
      echo "✓ client-config.json found in Claude working directory"
      # Set MCP_CLIENT_CONFIG environment variable for MCP server/bridge
      export MCP_CLIENT_CONFIG="$CLAUDE_CONFIG"
      echo "✓ MCP_CLIENT_CONFIG set to: $MCP_CLIENT_CONFIG"
    else
      echo "⚠️ client-config.json not found in Claude working directory - MCP client may not work correctly"
    fi
    
    echo '=== WORKSPACE VALIDATION ==='
    
    # Check for required files in Claude's working directory
    MISSING_FILES=""
    REQUIRED_FILES="CLAUDE.md"
    
    echo "Checking for required files..."
    for file in $REQUIRED_FILES; do
      if [ ! -f "$CLAUDE_WORK_DIR/$file" ]; then
        echo "ERROR: Missing required file: $CLAUDE_WORK_DIR/$file"
        MISSING_FILES="$MISSING_FILES $file"
      else
        echo "✓ Found: $CLAUDE_WORK_DIR/$file"
        # Show file size for verification
        size=$(wc -c < "$CLAUDE_WORK_DIR/$file" 2>/dev/null || echo "0")
        echo "  File size: $size bytes"
      fi
    done
    
    # Check git repository (REQUIRED for implementation tasks)
    if [ ! -d "/workspace/$REPO_NAME/.git" ]; then
      echo "✗ CRITICAL ERROR: No target git repository found!"
      MISSING_FILES="$MISSING_FILES git-repository"
    else
      echo "✓ Found: target git repository"
    fi
    
    # If any files are missing, abort
    if [ -n "$MISSING_FILES" ]; then
      echo ""
      echo "═══════════════════════════════════════════════════════════════"
      echo "║                 WORKSPACE VALIDATION FAILED                  ║"
      echo "═══════════════════════════════════════════════════════════════"
      echo ""
      echo "The following required files are missing:"
      for missing in $MISSING_FILES; do
        case "$missing" in
          "CLAUDE.md")
            echo "  ❌ $missing - Main task instructions for Claude"
            ;;
          "git-repository")
            echo "  ❌ $missing - Required for committing implementation changes"
            ;;
          *)
            echo "  ❌ $missing"
            ;;
        esac
      done
      echo ""
      echo "These files should have been created by the ConfigMap setup process."
      echo "Claude will NOT be started to avoid wasting API credits."
      echo ""
      exit 1
    fi
    
    echo "✓ All required files present. Workspace is valid."
    
    echo '=== IMPLEMENTATION TASK DIAGNOSTICS ==='
    echo "Project directory: $CLAUDE_WORK_DIR"
    echo "Project directory contents:"
    ls -la "$CLAUDE_WORK_DIR"
    echo ""
    
    # Show git status
    echo "Git status:"
    git status 2>/dev/null || echo "Git status unavailable"
    echo ""
    
    echo '=== CLAUDE EXECUTION ==='
    
    # Export necessary variables
    export SERVICE_NAME="{{`{{`{{`}}`}}service{{`}}`}}"
    export TASK_ID="{{`{{`{{`}}`}}task_id{{`}}`}}"
    export GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Change to project directory before running Claude
    cd "$CLAUDE_WORK_DIR"
    echo "Changed to directory: $(pwd)"
    
    # Verify we're in the correct directory and have required files
    echo "=== WORKING DIRECTORY VERIFICATION ==="
    echo "Current working directory: $(pwd)"
    echo "Expected directory: $CLAUDE_WORK_DIR"
    if [ "$(pwd)" != "$CLAUDE_WORK_DIR" ]; then
      echo "❌ ERROR: Failed to change to correct working directory!"
      echo "Attempting to change directory again..."
      cd "$CLAUDE_WORK_DIR" || exit 1
      echo "✓ Successfully changed to: $(pwd)"
    fi
    
    # Verify setup
    echo "✓ Code implementation environment ready"
    
    # Build Claude command
    CLAUDE_CMD="claude -p --output-format stream-json --input-format stream-json --verbose"
    
    # Look for agent-specific system prompt file from agents ConfigMap
    # The system prompt should be in the agents ConfigMap if configured
    if [ -f "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        echo "✓ Found system prompt file for {{`{{`{{`}}`}}github_app{{`}}`}}, adding to Claude command"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    elif [ -f "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        # Fallback to task-files if included inline
        echo "✓ Found system prompt in task ConfigMap for {{`{{`{{`}}`}}github_app{{`}}`}}"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    else
        echo "ℹ️ No system prompt file found for agent {{`{{`{{`}}`}}github_app{{`}}`}}, using defaults"
    fi
    
    # Model is set via settings.json template, not CLI flag
    
    # Add continue flag if this is a retry attempt or user requested continuation
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    CLAUDE_CMD="$CLAUDE_CMD --continue"
    echo 'Adding --continue flag (attempt {{`{{`{{`}}`}}attempts{{`}}`}}{{`{{`{{`}}`}}#if user_requested{{`}}`}} - user requested{{`{{`{{`}}`}}/if{{`}}`}})'
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    echo "════════════════════════════════════════════════════════════════"
    echo "║                    STARTING CLAUDE EXECUTION                  ║"
    echo "════════════════════════════════════════════════════════════════"
    echo "Command: $CLAUDE_CMD"
    echo "Note: Claude will automatically read CLAUDE.md from the working directory"
    
    # Inline system prompt (static content)
    SYSTEM_PROMPT='## 🚨 CRITICAL SYSTEM REQUIREMENTS 🚨
    
    **⛔ OVERCONFIDENCE MITIGATION - MANDATORY VERIFICATION ⛔**
    
    You have a DANGEROUS tendency to declare task completion before actually verifying everything works. This is ABSOLUTELY UNACCEPTABLE.
    
    **MANDATORY VERIFICATION REQUIREMENTS:**
    - ✅ **MUST** actually run and test your code - never assume it works
    - ✅ **MUST** verify ALL acceptance criteria through actual testing
    - ✅ **MUST** confirm your changes don'\''t break existing functionality
    - ✅ **MUST** test end-to-end workflows and edge cases
    - ✅ **MUST** run all linters and build checks successfully
    - ✅ **CANNOT** claim completion based on code appearance alone
    
    **YOU ARE PROHIBITED FROM CLAIMING SUCCESS UNTIL:**
    1. You have executed and verified every piece of functionality
    2. You have tested integration with existing systems
    3. You have confirmed all acceptance criteria pass through testing
    4. All automated tests pass (linting, builds, unit tests)
    5. You have verified the solution works end-to-end in practice
    
    **IF YOU DECLARE SUCCESS WITHOUT VERIFICATION, YOU HAVE FAILED.**
    
    ## 🔧 ORCHESTRATOR EXECUTION CONTEXT
    
    - **Service**: {{`{{`{{`}}`}}service{{`}}`}}
    - **Task ID**: {{`{{`{{`}}`}}task_id{{`}}`}}
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Docs Repository**: {{`{{`{{`}}`}}docs_repository_url{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    - **GitHub App**: {{`{{`{{`}}`}}github_app{{`}}`}}
    
    {{`{{`{{`}}`}}#if continue_session{{`}}`}}
    ## 🔄 CONTINUE SESSION - PR COMMENT RESOLUTION PRIORITY
    
    **⚠️ MANDATORY FIRST STEP: Before proceeding with any other work, you MUST:**
    
    1. **Check for unresolved PR comments**: Use `gh pr view --json reviews` or check the PR directly
    2. **Resolve ALL pending comments first**: Address reviewer feedback, fix issues, respond to questions
    3. **Push comment resolutions**: Commit and push any fixes for reviewer concerns
    4. **Only then proceed**: After ALL PR comments are resolved, continue with the main task
    
    **This ensures reviewer feedback takes priority and maintains collaborative workflow quality.**
    
    {{`{{`{{`}}`}}/if{{`}}`}}
    ## ⚠️ EXECUTION REQUIREMENTS
    
    - **Follow patterns**: Use @coding-guidelines.md and @github-guidelines.md
    - **Pre-PR quality gates (MANDATORY)**: Do NOT open a PR unless all of these pass locally:
      - `cargo fmt --all -- --check`
      - `cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic`
      - `cargo test --workspace --all-features` and high coverage (aim ≥95%, target ~100% on critical paths)
    - **GitHub workflow**: Read @github-guidelines.md for commit standards and **🚨 MANDATORY: CREATE A PULL REQUEST USING `gh pr create` - THE TASK IS NOT COMPLETE WITHOUT THIS STEP 🚨**
    - **Verify continuously**: Run tests and checks after each significant change
    - **Commit incrementally**: Don'\''t save all changes for the end
    - **Test thoroughly**: Validate against acceptance criteria before completion
    
    **Remember**: Focus on thorough implementation and verification.'
    
    echo "Starting Claude execution (stream-json via FIFO)..."
    echo "=========================="
    
    # Safe mode toggle for debugging (prevents token consumption)
    SAFE_MODE="false"  # Set to "false" for full task execution
    
    if [ "$SAFE_MODE" = "true" ]; then
        echo "🛡️ SAFE MODE ENABLED - Running simple test instead of full task"
        FIFO_PATH="/workspace/agent-input.jsonl"
        rm -f "$FIFO_PATH" 2>/dev/null || true
        mkfifo "$FIFO_PATH"
        chmod 666 "$FIFO_PATH" || true
        # Keep a persistent writer open and start Claude in background to avoid EOF race
        exec 9>"$FIFO_PATH"
        $CLAUDE_CMD < "$FIFO_PATH" &
        CLAUDE_PID=$!
        printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":"What time is it? Please answer this simple question and exit immediately."}]{{`}}`}}\n' >&9
        # Close writer so reader can exit cleanly
        exec 9>&-
        wait $CLAUDE_PID
    else
        # Debug: Show what's actually in the task directory before checking for prompt.md
        echo "🔍 DEBUG: About to check for prompt.md at: $CLAUDE_WORK_DIR/task/prompt.md"
        echo "🔍 DEBUG: Contents of task directory:"
        ls -la "$CLAUDE_WORK_DIR/task/" || echo "Task directory not found or empty"
        echo "🔍 DEBUG: Current working directory contents:"
        ls -la "$CLAUDE_WORK_DIR/" || echo "Working directory not accessible"
    
        # Check if prompt.md exists and use it as main prompt
        if [ -f "$CLAUDE_WORK_DIR/task/prompt.md" ]; then
            echo "✓ Using task-specific prompt from docs service: task/prompt.md"
    
            echo "startingTask:{{`{{`{{`}}`}}task_id{{`}}`}}"
            echo ""
    
            # DEBUG: Print MCP_CLIENT_CONFIG for troubleshooting client config issues
            echo "🔍 DEBUG: MCP_CLIENT_CONFIG is set to: '$MCP_CLIENT_CONFIG'"
            if [ -f "$MCP_CLIENT_CONFIG" ]; then
                echo "🔍 DEBUG: MCP_CLIENT_CONFIG file exists and is readable"
                echo "🔍 DEBUG: First few lines of client config:"
                head -10 "$MCP_CLIENT_CONFIG" 2>/dev/null || echo "Could not read client config file"
            else
                echo "🔍 DEBUG: MCP_CLIENT_CONFIG file does NOT exist or is not readable"
            fi
            echo ""
    
            # Prepare prompt prefix for toolman guidance
            PROMPT_PREFIX=""
            if [ -f "$CLAUDE_WORK_DIR/task/toolman-guide.md" ]; then
                PROMPT_PREFIX="🔧 **CRITICAL: Tool Usage Reference**
    
    Before starting implementation, you MUST read and follow the task-specific tool guidance in the file \`task/toolman-guide.md\`. This file contains:
    - Selected tools for this specific task
    - When and how to use each tool
    - Tool arguments, parameters, and configuration options
    - Implementation workflow and best practices
    - Tool relationships and sequencing
    
    **The toolman-guide.md is your authoritative reference for tool usage in this task.**
    
    ---
    
    "
                echo "✓ Including toolman guidance prefix"
            else
                echo "⚠️ No toolman-guide.md found - proceeding without tool guidance"
            fi
    
            # Seed initial user turn via a FIFO (system prompts are set via CLI flags, not streamed)
            FIFO_PATH="/workspace/agent-input.jsonl"
            rm -f "$FIFO_PATH" 2>/dev/null || true
            mkfifo "$FIFO_PATH"
            chmod 666 "$FIFO_PATH" || true
    
            # Start Claude (reader) first in background to avoid writer-open blocking
            $CLAUDE_CMD < "$FIFO_PATH" &
            CLAUDE_PID=$!
    
            # Compose initial user turn
            USER_COMBINED=$(printf "%s" "${PROMPT_PREFIX}$(cat "$CLAUDE_WORK_DIR/task/prompt.md")" | jq -Rs .)
    
            # Prefer sending via sidecar HTTP endpoint (opens-writes-closes per request)
            if printf '{"text":%s}\n' "$USER_COMBINED" | \
                 curl -fsS -X POST http://127.0.0.1:8080/input \
                   -H 'Content-Type: application/json' \
                   --data-binary @- >/dev/null 2>&1; then
              echo "✓ Initial prompt sent via sidecar /input"
            else
              echo "⚠️ Sidecar /input failed, falling back to direct FIFO write"
              # Fallback: open FIFO writer and keep it open until Claude exits
              exec 9>"$FIFO_PATH"
              printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":%s}]{{`}}`}}\n' "$USER_COMBINED" >&9
            fi
    
            # Optional debug: dump FIFO holders if requested
            if [ "${DEBUG_FIFO:-false}" = "true" ]; then
              echo "[DEBUG] Dumping FIFO holders for $FIFO_PATH"
              for p in /proc/[0-9]*; do
                pid=${p##*/}
                [ -d "$p/fd" ] || continue
                for fd in "$p"/fd/*; do
                  tgt=$(readlink "$fd" 2>/dev/null || true)
                  case "$tgt" in *agent-input.jsonl*)
                    fdnum=${fd##*/}
                    comm=$(cat "$p/comm" 2>/dev/null || echo "?")
                    echo "  PID=$pid COMM=$comm FD=$fdnum -> $tgt"
                  ;;
                  esac
                done
              done
            fi
    
            # Optional hang diagnostics without enforcing a timeout
            if [ -n "${HANG_DIAG_SECONDS:-}" ] && [ "$HANG_DIAG_SECONDS" -gt 0 ] 2>/dev/null; then
              (
                sleep "$HANG_DIAG_SECONDS"
                if kill -0 "$CLAUDE_PID" 2>/dev/null; then
                  echo "[DEBUG] Hang diag after ${HANG_DIAG_SECONDS}s: dumping FIFO holders and ps"
                  for p in /proc/[0-9]*; do
                    pid=${p##*/}; [ -d "$p/fd" ] || continue
                    for fd in "$p"/fd/*; do tgt=$(readlink "$fd" 2>/dev/null || true); case "$tgt" in *agent-input.jsonl*) fdnum=${fd##*/}; comm=$(cat "$p/comm" 2>/dev/null || echo "?"); echo "  PID=$pid COMM=$comm FD=$fdnum -> $tgt";; esac; done
                  done
                  ps -eo pid,ppid,comm,args | head -200 || true
                fi
              ) & HANG_DIAG_PID=$!
            fi
    
            # Wait for Claude process to complete, then stop diagnostics if running
            wait "$CLAUDE_PID"
            if [ -n "${HANG_DIAG_PID:-}" ]; then kill "$HANG_DIAG_PID" 2>/dev/null || true; fi
            # Close FIFO writer if it was opened (in fallback) now that Claude has exited
            exec 9>&- 2>/dev/null || true
    
            # Gracefully stop sidecar to allow Job to complete (all containers must exit)
            if curl -fsS -X POST http://127.0.0.1:8080/shutdown >/dev/null 2>&1; then
              echo "✓ Requested sidecar shutdown"
            else
              echo "⚠️ Failed to request sidecar shutdown (it may not be running)"
            fi
        else
            echo "❌ ERROR: No prompt.md found from docs service"
            echo "The docs service should always provide task/prompt.md"
            echo "Check docs repository and task configuration"
            exit 1
        fi
    fi
    
    echo '════════════════════════════════════════════════════════════════'
    echo '║                 IMPLEMENTATION TASK COMPLETE                 ║'
    echo '════════════════════════════════════════════════════════════════'
    
    # Claude execution completed - no hooks configured
    echo "Claude has completed successfully."
    
    # Write sentinel file to signal sidecar to stop (Kubernetes-native file watch)
    touch /workspace/.agent_done 2>/dev/null || true
    
    # Exit to terminate the pod
    exit 0  code_github-guidelines.md.hbs: |
    # GitHub Workflow Guidelines
    
    ## �� **MANDATORY BRANCH AND PR REQUIREMENTS** 🚨
    
    **YOU MUST COMMIT REGULARLY AND SUBMIT A PR WHEN IMPLEMENTATION IS COMPLETE**
    
    ### **Critical Requirements:**
    
    - ⭐ **COMMIT AND PUSH FREQUENTLY** - Ideally after every significant change or turn
    - ⭐ **SUBMIT A PULL REQUEST** when implementation meets all acceptance criteria
    - ⭐ **NEVER PUSH TO MAIN BRANCH** - Always work on your feature branch only
    - ⭐ **USE GITHUB APP AUTHENTICATION** - All git operations use GitHub App tokens (already configured)
    
    ## Git Workflow
    
    ### Your Current Context
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Feature Branch**: feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation
    - **Target Branch**: main (never push directly to this)
    - **Authentication**: GitHub App ({{`{{`{{`}}`}}github_app{{`}}`}} - pre-configured)
    
    ### **Required Git Pattern:**
    
    ```bash
    # After making changes, always commit and push to feature branch:
    git add .
    git commit -m "feat: implement [specific change made]"
    git push origin feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation
    ```
    
    ### **When to Commit & Push:**
    - ✅ After implementing a significant feature or fix
    - ✅ After completing a subtask or milestone
    - ✅ When you've made meaningful progress (ideally every turn)
    - ✅ Before running tests or verification steps
    - ✅ When switching between different areas of the codebase
    
    ### **Commit Message Format:**
    ```
    <type>: <brief description of what was implemented>
    
    Examples:
    feat: add user authentication endpoint
    fix: resolve database connection timeout
    refactor: extract validation logic to helpers
    test: add unit tests for payment processing
    ```
    
    ## 🔄 **Merge Conflict Prevention & Resolution**
    
    ### **Prevention (Automated in Container Script):**
    The container automatically syncs with main before you start work:
    ```bash
    # This happens automatically for you:
    git fetch origin main
    git merge origin/main --no-edit  # Auto-merge if possible
    ```
    
    ### **⚠️ Manual Resolution Required (If Auto-Merge Fails):**
    
    **If you see merge conflict warnings during startup or at any time:**
    
    1. **Check conflict status:**
       ```bash
       git status
       # Look for "Unmerged paths" or files marked with "UU", "AA", or "DD"
       ```
    
    2. **Identify conflicted files:**
       ```bash
       # Files with merge conflicts will show:
       # - <<<<<<< HEAD (your changes)
       # - ======= (separator)
       # - >>>>>>> origin/main (main branch changes)
       ```
    
    3. **Resolve conflicts manually:**
       - Edit each conflicted file
       - Remove conflict markers (`<<<<<<<`, `=======`, `>>>>>>>`)
       - Keep the correct combination of changes
       - Save the file
    
    4. **Complete the merge:**
       ```bash
       git add .                           # Stage resolved files
       git commit -m "Resolve merge conflicts with main"
       git push origin feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation          # Push resolution
       ```
    
    ### **Best Practices:**
    - ✅ **Always resolve conflicts immediately** - Don't ignore them
    - ✅ **Test after resolving** - Ensure your changes still work
    - ✅ **Ask for clarification** if unsure which changes to keep
    - ✅ **Sync frequently** - Smaller conflicts are easier to resolve
    
    ### **If Stuck on Conflicts:**
    Comment in your PR: "Need help resolving merge conflicts in [file names]" and describe what you're unsure about.
    
    ## **🚨 PULL REQUEST SUBMISSION - MANDATORY FOR TASK COMPLETION 🚨**
    
    **THE TASK IS NOT COMPLETE UNTIL YOU CREATE A PULL REQUEST. NO EXCEPTIONS.**
    
    When you have completed implementation and met all acceptance criteria, and ONLY after all pre-PR quality gates are green locally:
    
    ### ✅ Pre-PR Quality Gates (must pass locally)
    ```bash
    # Formatting
    cargo fmt --all -- --check
    
    # Clippy with pedantic and deny warnings
    cargo clippy --workspace --all-targets --all-features -- -D warnings -W clippy::pedantic
    
    # Tests and coverage (aim for ≥95%, target ~100% on critical paths)
    cargo test --workspace --all-features
    cargo llvm-cov --workspace --all-features --fail-under-lines 95 || \
      cargo tarpaulin --all --fail-under 95
    ```
    
    ### **✅ MANDATORY: Submit a Pull Request Using GitHub CLI:**
    ```bash
    # This command is REQUIRED - the task is not done without it
    gh pr create --title "feat: [brief summary of implementation]" \
                 --body "## Implementation Summary
    [Brief description of what was implemented]
    
    ## Changes Made
    - [List key changes]
    - [New features added]
    - [Bug fixes implemented]
    
    ## Testing Performed
    - [Tests written/updated]
    - [Manual testing completed]
    - [Verification steps]
    
    ## Notes
    - [Any important technical decisions]
    - [Performance/security considerations]"
    ```
    
    ### **✅ PR Requirements:**
    - Create PR from your feature branch (feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation) to main
    - Use descriptive title starting with feat:, fix:, etc.
    - Include comprehensive PR description with all sections above
    - **CRITICAL**: You MUST run the `gh pr create` command - just pushing is not enough
    
    ### **❌ NEVER Push to Main:**
    - ❌ **DO NOT** push directly to main branch
    - ❌ **DO NOT** merge your own PR
    - ✅ **ONLY** work on feature branch feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation
    
    ## Authentication
    
    ### GitHub App Configuration
    - GitHub App authentication is pre-configured in the container
    - All git operations use GitHub App tokens automatically
    - Repository access: `{{`{{`{{`}}`}}repository_url{{`}}`}}`
    - GitHub App: `{{`{{`{{`}}`}}github_app{{`}}`}}`
    
    ### Git Commands (GitHub App-based)
    ```bash
    # Check current status
    git status
    
    # Stage changes
    git add .
    
    # Commit with message
    git commit -m "feat: describe your change"
    
    # Push to feature branch (GitHub App authentication automatic)
    git push origin feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation
    
    # Create pull request (when implementation complete)
    gh pr create --title "feat: [summary]" --body "[detailed description]"
    
    # Check git log
    git log --oneline -10
    ```
    
    ### **Gitignore Requirements**
    - ⭐ **ALWAYS add hooks to .gitignore** - Never commit hook files
    - Add these patterns to your .gitignore:
      ```
      # Hook files - never commit
      hooks/
      .hooks/
      **/hooks/
      ```
    
    ## Progress Tracking Philosophy
    
    **The goal is continuous visibility and proper PR submission:**
    
    1. **Frequent commits** help track your thought process
    2. **Regular pushes** keep the team informed of progress
    3. **Clear commit messages** document your implementation decisions
    4. **PR submission** provides proper code review process
    
    ## **🚨 TASK COMPLETION CHECKLIST - ALL STEPS MANDATORY 🚨**
    
    **A task is ONLY complete when ALL these steps are done:**
    
    1. ✅ Implementation meets all acceptance criteria
    2. ✅ Final commit with all changes: `git add . && git commit -m "..."`
    3. ✅ Push to feature branch: `git push origin feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation`
    4. 🚨 **MANDATORY**: Create pull request: `gh pr create --title "..." --body "..."`
    5. ❌ **NEVER** push to main branch
    
    **WITHOUT STEP 4, THE TASK IS INCOMPLETE - NO EXCEPTIONS**
    
    ### **PR Description Template:**
    ```markdown
    ## Implementation Summary
    Brief description of what was implemented and why.
    
    ## Changes Made
    - List of significant changes
    - New features added
    - Bug fixes implemented
    - Refactoring completed
    
    ## Testing Performed
    - Unit tests written/updated
    - Integration testing completed
    - Manual testing performed
    - Edge cases verified
    
    ## Implementation Notes
    - Any important technical decisions
    - Performance considerations
    - Security implications
    - Breaking changes (if any)
    ```
    
    ---
    
    **Remember: Your feature branch (feature/task-{{`{{`{{`}}`}}task_id{{`}}`}}-implementation) is your workspace. Keep it updated with regular commits, then submit a comprehensive PR when implementation is complete!**
  code_mcp.json.hbs: |
    {
      "mcpServers": {
        "toolman": {
          "command": "toolman",
          "args": [
            "--working-dir",
            "/workspace"
          ],
          "env": {
            "TOOLMAN_SERVER_URL": "http://toolman.agent-platform.svc.cluster.local:3000/mcp"
          }
        }
      }
    }  code_settings.json.hbs: |
    {
      "enableAllProjectMcpServers": true,
      "permissions": {
        "allow": [
          {{`{{`{{`}}`}}#if agent_tools_override{{`}}`}}
          {{`{{`{{`}}`}}#each permissions.allow{{`}}`}}
          "{{`{{`{{`}}`}}this{{`}}`}}"{{`{{`{{`}}`}}#unless @last{{`}}`}},{{`{{`{{`}}`}}/unless{{`}}`}}
          {{`{{`{{`}}`}}/each{{`}}`}}
          {{`{{`{{`}}`}}else{{`}}`}}
          "Bash",
          "Edit",
          "Read",
          "Write",
          "MultiEdit",
          "Glob",
          "Grep",
          "LS",
          "Task",
          "ExitPlanMode",
          "NotebookRead",
          "NotebookEdit",
          "WebFetch",
          "WebSearch",
          "TodoRead",
          "TodoWrite"
          {{`{{`{{`}}`}}/if{{`}}`}}
        ],
        "deny": [
          {{`{{`{{`}}`}}#if agent_tools_override{{`}}`}}
          {{`{{`{{`}}`}}#each permissions.deny{{`}}`}}
          "{{`{{`{{`}}`}}this{{`}}`}}"{{`{{`{{`}}`}}#unless @last{{`}}`}},{{`{{`{{`}}`}}/unless{{`}}`}}
          {{`{{`{{`}}`}}/each{{`}}`}}
          {{`{{`{{`}}`}}else{{`}}`}}
          {{`{{`{{`}}`}}/if{{`}}`}}
        ],
        "defaultMode": "acceptEdits"
      },
      "env": {
        "NODE_ENV": "production",
        "DISABLE_AUTOUPDATER": "1",
        "DISABLE_COST_WARNINGS": "0",
        "DISABLE_NON_ESSENTIAL_MODEL_CALLS": "0",
        "CLAUDE_BASH_MAINTAIN_PROJECT_WORKING_DIR": "true",
        "CLAUDE_CODE_ENABLE_TELEMETRY": "{{`{{`{{`}}`}}#if telemetry.enabled{{`}}`}}1{{`{{`{{`}}`}}else{{`}}`}}0{{`{{`{{`}}`}}/if{{`}}`}}"{{`{{`{{`}}`}}#if telemetry.enabled{{`}}`}},
        "OTEL_METRICS_EXPORTER": "otlp",
        "OTEL_LOGS_EXPORTER": "otlp",
        "OTEL_EXPORTER_OTLP_METRICS_ENDPOINT": "otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317",
        "OTEL_EXPORTER_OTLP_METRICS_PROTOCOL": "grpc",
        "OTEL_EXPORTER_OTLP_LOGS_ENDPOINT": "otel-collector-opentelemetry-collector.telemetry.svc.cluster.local:4317",
        "OTEL_EXPORTER_OTLP_LOGS_PROTOCOL": "grpc"{{`{{`{{`}}`}}/if{{`}}`}}{{`{{`{{`}}`}}#if retry.is_retry{{`}}`}},
        "BASH_DEFAULT_TIMEOUT_MS": "30000",
        "BASH_MAX_TIMEOUT_MS": "300000"{{`{{`{{`}}`}}/if{{`}}`}}
      },
      "model": "{{`{{`{{`}}`}}model{{`}}`}}",
      "cleanupPeriodDays": 7,
      "includeCoAuthoredBy": false
    }  docs_claude.md.hbs: |
    # Claude Code Memory
    
    You are working on Task Master documentation generation.
    
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Source Branch**: {{`{{`{{`}}`}}source_branch{{`}}`}}
    - **GitHub App**: {{`{{`{{`}}`}}github_app{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    - **Documentation Target**: {{`{{`{{`}}`}}#if task_id{{`}}`}}task {{`{{`{{`}}`}}task_id{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}all tasks{{`{{`{{`}}`}}/if{{`}}`}}
    
    ## Task Master Documentation Generation
    
    Your role is to generate structured Task Master documentation by:
    
    1. **Reading individual task files** from `.taskmaster/docs/task-{id}/task.txt`
    2. **Checking for existing documentation** and skipping completed tasks
    3. **Creating exactly 3 files** for each incomplete task:
       - `task.md` - Comprehensive task overview and implementation guide
       - `prompt.md` - Autonomous prompt for AI agents
       - `acceptance-criteria.md` - Clear acceptance criteria and test cases
    
    ## Critical Instructions
    
    **SKIP TASKS WITH COMPLETE DOCUMENTATION:**
    Before processing any task, check if ALL required files already exist with substantial content:
    - `task.md`
    - `prompt.md`
    - `acceptance-criteria.md`
    
    If ALL three files exist and have substantial content, SKIP that task.
    
    **PROCESS ONLY INCOMPLETE TASKS:**
    Only generate documentation for tasks missing one or more of the required files.
    
    **FILE LOCATIONS:**
    All documentation goes in `.taskmaster/docs/task-{id}/` directories.
    
    ## Documentation Standards
    
    - **task.md**: Technical implementation guide with clear steps
    - **prompt.md**: Standalone prompt for autonomous AI agents
    - **acceptance-criteria.md**: Testable completion criteria
    - Use clear, professional language
    - Include code examples where helpful
    - Reference existing architecture patterns
    - Follow Task Master conventions
    
    ## Resources
    
    See .taskmaster/docs/architecture.md for system design details
    See .taskmaster/docs/prd.txt for product requirements
    Individual task files are available at .taskmaster/docs/task-{id}/task.txt
    
    ## Repository Context
    
    This documentation generation is working with:
    - **Repository**: {{`{{`{{`}}`}}repository_url{{`}}`}}
    - **Branch**: {{`{{`{{`}}`}}source_branch{{`}}`}}
    - **Working Directory**: {{`{{`{{`}}`}}working_directory{{`}}`}}
    
    Ensure all file paths and references are relative to the working directory.  docs_container.sh.hbs: |
    #!/bin/sh
    
    echo 'Starting documentation generation...'
    
    # Disable interactive Git prompts globally
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # Repository URL
    REPO_URL="{{`{{`{{`}}`}}repository_url{{`}}`}}"
    
    # GitHub App authentication is configured via environment variables
    echo "Using GitHub App authentication (SSH not required)"
    
    # Function to generate fresh GitHub App token (defined globally for reuse)
    generate_github_token() {
        echo "Generating fresh GitHub App token..."
    
        # Check if credentials are available
        if [ -z "$GITHUB_APP_PRIVATE_KEY" ] || [ -z "$GITHUB_APP_ID" ]; then
            echo "❌ GITHUB_APP_PRIVATE_KEY or GITHUB_APP_ID not found"
            return 1
        fi
    
        # Create temporary private key file from environment variable
        TEMP_KEY_FILE="/tmp/github-app-key.pem"
        echo "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
        chmod 600 "$TEMP_KEY_FILE"
    
        echo "Using private key from environment variable"
    
        # Generate JWT token for GitHub App (fixed JWT generation for Linux containers)
        # JWT header
        JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # JWT payload with current time and expiration (10 minutes)
        NOW=$(date +%s)
        EXP=$((NOW + 600))
        JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
    
        # Sign the JWT
        JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
        JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
    
        if [ -z "$JWT_TOKEN" ]; then
            echo "❌ Failed to generate JWT token"
            exit 1
        fi
    
        # Get installation ID for the repository
        REPO_OWNER=$(echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
        REPO_NAME=$(echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
    
        echo "Getting installation ID for $REPO_OWNER/$REPO_NAME..."
    
        # Try repository installation first (follow redirects)
        INSTALLATION_RESPONSE=$(curl -s -L -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
        INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
        # Fallback: try organization installation if repo lookup failed
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "⚠️ Repo installation not found, trying org installation..."
            ORG_INSTALLATION_RESPONSE=$(curl -s -L -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/orgs/$REPO_OWNER/installation")
            INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
        fi
    
        if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
            echo "❌ Failed to get installation ID for repository"
            echo "Response (repo): $INSTALLATION_RESPONSE"
            echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        echo "Installation ID: $INSTALLATION_ID"
    
        # Export for use by hooks
        export INSTALLATION_ID
    
        # Get installation access token
        TOKEN_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $JWT_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens")
    
        GITHUB_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.token')
    
        if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
            echo "❌ Failed to get installation access token"
            echo "Response: $TOKEN_RESPONSE"
            rm -f "$TEMP_KEY_FILE"
            exit 1
        fi
    
        # Clean up temporary key file
        rm -f "$TEMP_KEY_FILE"
    
        # Export the token for git to use
        export GITHUB_TOKEN
    
        # Store token generation time for refresh checks
        export TOKEN_GENERATED_AT=$(date +%s)
    
        # Configure git to use the token (use --replace-all to handle multiple existing helpers)
        git config --global --replace-all credential.helper store
        echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
    
        # Also authenticate gh CLI with the token
        echo "$GITHUB_TOKEN" | gh auth login --with-token
    
        echo "✓ GitHub App authenticated successfully"
    }
    
    # Function to check if token needs refresh (call before git operations)
    refresh_token_if_needed() {
        if [ -z "$TOKEN_GENERATED_AT" ]; then
            echo "⚠️ No token timestamp found, refreshing token..."
            generate_github_token
            return
        fi
    
        NOW=$(date +%s)
        TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
        # Refresh if token is older than 50 minutes (GitHub tokens last 1 hour, refresh at 50 min to be safe)
        if [ $TOKEN_AGE -gt 3000 ]; then
            echo "🔄 Token is $(($TOKEN_AGE / 60)) minutes old, refreshing..."
            generate_github_token
        fi
    }
    
    # Authenticate with GitHub App
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        # Initial authentication
        generate_github_token
    
        # Validate authentication by testing actual GitHub operations we'll need
        echo "🔍 Validating GitHub authentication with actual operations..."
        REPO_OWNER=$(echo "$REPO_URL" | sed 's|https://github.com/||' | sed 's|/.*||')
        REPO_NAME=$(echo "$REPO_URL" | sed 's|.*/||')
    
        # Test 1: Can we access the repository?
        if gh api "repos/$REPO_OWNER/$REPO_NAME" > /tmp/repo_test.json 2>&1; then
            echo "✅ Repository access confirmed"
        else
            echo "❌ Cannot access repository $REPO_OWNER/$REPO_NAME"
            echo "Error: $(cat /tmp/repo_test.json)"
            exit 1
        fi
    
        # Test 2: Can we list branches (needed for PR creation)?
        if gh api "repos/$REPO_OWNER/$REPO_NAME/branches" > /tmp/branches_test.json 2>&1; then
            echo "✅ Can list branches"
        else
            echo "❌ Cannot list branches"
            echo "Error: $(cat /tmp/branches_test.json)"
            exit 1
        fi
    
        # Test 3: Can we get app info (GitHub Apps can't access user endpoint)?
        if gh api app > /tmp/app_test.json 2>&1; then
            APP_NAME=$(jq -r '.name' /tmp/app_test.json 2>/dev/null || echo "unknown")
            echo "✅ GitHub App API access confirmed: $APP_NAME"
        else
            echo "✅ App endpoint not accessible (normal for GitHub Apps) - using repo access as confirmation"
        fi
    
        echo "✅ All GitHub authentication tests passed - proceeding with confidence"
    
    else
        echo "❌ GITHUB_APP_PRIVATE_KEY or GITHUB_APP_ID not found"
        exit 1
    fi
    
    
    # Git configuration with proper GitHub App attribution
    git config --global --add safe.directory /workspace
    
    # Set GitHub App attribution - use generic format for all agents
    GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    # Generic attribution that works for any agent
    GIT_AUTHOR_NAME="${GITHUB_APP} Agent (Claude Code)"
    GIT_AUTHOR_EMAIL="${GITHUB_APP}[bot]@users.noreply.github.com"
    
    # Configure git with proper GitHub App attribution
    git config --global user.name "$GIT_AUTHOR_NAME"
    git config --global user.email "$GIT_AUTHOR_EMAIL"
    
    # Set environment variables for Claude Code to use
    export GIT_AUTHOR_NAME="$GIT_AUTHOR_NAME"
    export GIT_AUTHOR_EMAIL="$GIT_AUTHOR_EMAIL"
    export GIT_COMMITTER_NAME="$GIT_AUTHOR_NAME"
    export GIT_COMMITTER_EMAIL="$GIT_AUTHOR_EMAIL"
    
    echo "✓ Git configured"
    
    # Repository setup
    REPO_BRANCH="{{`{{`{{`}}`}}source_branch{{`}}`}}"
    echo "Repository: $REPO_URL"
    echo "Branch: $REPO_BRANCH"
    
    if [ -d "/workspace/.git" ]; then
      echo "Repository exists, updating..."
      cd /workspace
      git remote set-url origin "$REPO_URL"
      git fetch origin
      git checkout "$REPO_BRANCH"
      git pull origin "$REPO_BRANCH"
    else
      echo "Setting up repository..."
      # Clone to temp directory first, then move contents
      TEMP_CLONE_DIR="/tmp/repo-clone"
      rm -rf "$TEMP_CLONE_DIR"
    
      if ! git clone --depth 1 --branch "$REPO_BRANCH" "$REPO_URL" "$TEMP_CLONE_DIR"; then
        echo "❌ Failed to clone repository"
        exit 1
      fi
    
      # Move repository contents to workspace
      mv "$TEMP_CLONE_DIR"/* /workspace/ 2>/dev/null || true
      mv "$TEMP_CLONE_DIR"/.[^.]* /workspace/ 2>/dev/null || true
      rm -rf "$TEMP_CLONE_DIR"
      cd /workspace
    fi
    
    echo "✓ Repository ready"
    
    # Working directory setup
    WORKING_DIR="{{`{{`{{`}}`}}working_directory{{`}}`}}"
    if [ -n "$WORKING_DIR" ] && [ "$WORKING_DIR" != "." ]; then
      CLAUDE_WORK_DIR="/workspace/$WORKING_DIR"
      cd "$CLAUDE_WORK_DIR" || exit 1
      echo "✓ Working directory: $CLAUDE_WORK_DIR"
    else
      CLAUDE_WORK_DIR="/workspace"
      echo "✓ Working directory: $CLAUDE_WORK_DIR"
    fi
    
    # Copy ConfigMap files
    echo "Setting up ConfigMap files..."
    if [ -d "/task-files" ]; then
      # Copy markdown files
      for md_file in /task-files/*.md; do
        if [ -f "$md_file" ]; then
          basename_file=$(basename "$md_file")
          if [ "$basename_file" = "claude.md" ]; then
            cp -f "$md_file" "$CLAUDE_WORK_DIR/CLAUDE.md"
          else
            cp -f "$md_file" "$CLAUDE_WORK_DIR/"
          fi
          echo "✓ Copied $basename_file"
        fi
      done
    
      # Verify enterprise settings
      if [ -f "/etc/claude-code/managed-settings.json" ]; then
        echo "✓ Enterprise settings verified"
        if ! jq empty /etc/claude-code/managed-settings.json 2>/dev/null; then
          echo "❌ Invalid enterprise settings JSON"
          exit 1
        fi
      else
        echo "❌ Enterprise settings not found"
        exit 1
      fi
    
      # Copy hook scripts (controller automatically includes any docs_hooks_* files)
      for hook_file in /task-files/hooks-*.sh; do
        if [ -f "$hook_file" ]; then
          hook_name=$(basename "$hook_file" | sed 's/^hooks-//')
          cp "$hook_file" "$CLAUDE_WORK_DIR/$hook_name"
          chmod +x "$CLAUDE_WORK_DIR/$hook_name"
          echo "✓ Copied hook: $hook_name"
        fi
      done
    
    else
      echo "❌ ConfigMap not mounted at /task-files"
      exit 1
    fi
    
    # Validate workspace
    echo "Validating workspace..."
    REQUIRED_FILES="CLAUDE.md"
    for file in $REQUIRED_FILES; do
      if [ ! -f "$CLAUDE_WORK_DIR/$file" ]; then
        echo "❌ Missing required file: $file"
        exit 1
      fi
    done
    
    # Check for .taskmaster directory
    if [ ! -d "$CLAUDE_WORK_DIR/.taskmaster" ]; then
      echo "❌ .taskmaster directory not found"
      exit 1
    fi
    
    # Ensure docs directory exists
    mkdir -p "$CLAUDE_WORK_DIR/.taskmaster/docs"
    
    ## Handle task files - support both JSON and individual file formats
    echo "Setting up task files..."
    if [ -f "$CLAUDE_WORK_DIR/.taskmaster/tasks/tasks.json" ]; then
      echo "📋 Found tasks.json, generating individual task files..."
    
      # Robust extraction: base64-encode each task to keep one line per task, then decode fields
      gen_count=0
      jq -c '.tasks[]? | select(.id != null) | @base64' "$CLAUDE_WORK_DIR/.taskmaster/tasks/tasks.json" \
        | while IFS= read -r row; do
          _decode() { printf '%s' "$row" | base64 -d | jq -r "$1"; }
          task_id=$(_decode '.id')
          [ -n "$task_id" ] && [ "$task_id" != "null" ] || continue
          title=$(_decode '.title // "No Title"')
          description=$(_decode '.description // ""')
          details=$(_decode '.details // ""')
          test_strategy=$(_decode '.testStrategy // ""')
    
          task_dir="$CLAUDE_WORK_DIR/.taskmaster/docs/task-$task_id"
          mkdir -p "$task_dir"
          cat > "$task_dir/task.txt" << EOF
    # Task $task_id: $title
    
    ## Description
    $description
    
    ## Implementation Details
    $details
    
    ## Test Strategy
    $test_strategy
    EOF
    
          # Generate XML format optimized for LLM consumption with enhanced structure
          # Extract additional fields for XML structure
          priority=$(_decode '.priority // "medium"')
          dependencies=$(_decode '.dependencies // []' | jq -r 'if type == "array" then . else [] end | join(", ")')
          status=$(_decode '.status // "pending"')
    
          # Determine technology stack from task content for role definition
          if echo "$details" | grep -qi "rust\|cargo\|tokio\|serde"; then
            tech_role="senior Rust developer specializing in Kubernetes controllers and cloud-native applications"
          elif echo "$details" | grep -qi "kubernetes\|k8s\|argo\|helm"; then
            tech_role="senior Kubernetes engineer specializing in GitOps workflows and Argo Events"
          elif echo "$details" | grep -qi "argo\|workflow\|events"; then
            tech_role="senior DevOps engineer specializing in Argo Workflows and event-driven automation"
          else
            tech_role="senior software engineer and coding agent specializing in the project's technology stack"
          fi
    
          # Extract technical specifications from task details
          specs=""
          if echo "$details" | grep -A 10 -i "technical\|requirements\|specifications" >/dev/null 2>&1; then
            specs_section=$(echo "$details" | sed -n '/technical\|requirements\|specifications/I,/^$/p' | head -10)
            while IFS= read -r line; do
              # Case-insensitive check to exclude section headers
              if [[ -n "$line" ]] && ! echo "$line" | grep -qi "^[[:space:]]*\(technical\|requirements\|specifications\)[[:space:]]*$"; then
                # XML escape the content
                escaped_line=$(echo "$line" | sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g; s/"/\&quot;/g; s/'\''/\&#39;/g')
                specs="${specs}<spec>$escaped_line</spec>
            "
              fi
            done <<< "$specs_section"
          fi
    
          # Fallback specs if none found
          if [ -z "$specs" ]; then
            specs="<spec>Follow the project&apos;s existing architecture and coding patterns</spec>
            <spec>Ensure compatibility with the current technology stack</spec>
            <spec>Implement proper error handling and logging</spec>
            <spec>Follow established security best practices</spec>"
          fi
    
          # Extract acceptance criteria from test strategy
          criteria=""
          if [ -n "$test_strategy" ]; then
            # Split test strategy into individual criteria on numbered items (1., 2., etc.)
            # Use word boundaries to avoid splitting on version numbers or decimals
            IFS=$'\n' read -rd '' -a test_parts <<< "$(echo "$test_strategy" | grep -E '^[[:space:]]*[0-9]+[[:space:]]*\.[[:space:]]*[A-Z]')"
            for part in "${test_parts[@]}"; do
              part=$(echo "$part" | sed 's/^[[:space:]]*[0-9]\+\.[[:space:]]*//;s/[[:space:]]*$//')
              if [ -n "$part" ] && [ ${#part} -gt 10 ]; then
                # XML escape the content
                escaped_part=$(echo "$part" | sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g; s/"/\&quot;/g; s/'\''/\&#39;/g')
                criteria="${criteria}<criterion>$escaped_part</criterion>
            "
              fi
            done
          fi
    
          # Fallback criteria if none extracted
          if [ -z "$criteria" ]; then
            criteria="<criterion>Implementation must be complete and functional</criterion>
            <criterion>Code must follow the project&apos;s style guidelines and conventions</criterion>
            <criterion>All edge cases should be properly handled</criterion>
            <criterion>Implementation should be well-documented with clear comments</criterion>"
          fi
    
          cat > "$task_dir/task.xml" << XML_EOF
    <prompt>
        <role>You are a $tech_role.</role>
        <task>
            <id>$task_id</id>
            <title>$title</title>
            <description>$description</description>
            <priority>$priority</priority>
            <status>$status</status>
            <dependencies>$dependencies</dependencies>
        </task>
        <technical_specifications>
            $specs
        </technical_specifications>
        <implementation_details>
            $details
        </implementation_details>
        <acceptance_criteria>
            $criteria
        </acceptance_criteria>
        <test_strategy>
            $test_strategy
        </test_strategy>
        <instructions>
            Think step-by-step about the implementation approach. Consider the existing codebase structure and patterns.
            Provide complete, production-ready code that follows best practices. Include necessary imports,
            error handling, and documentation. Test your solution thoroughly before finalizing.
            Ensure compatibility with the existing technology stack and architectural patterns.
        </instructions>
    </prompt>
    XML_EOF
    
          gen_count=$((gen_count+1))
          echo "✓ Generated docs/task-$task_id/task.txt"
          echo "✓ Generated docs/task-$task_id/task.xml (XML format for LLM consumption)"
        done
      echo "Generated $gen_count task directories with txt and xml files from tasks.json"
    elif [ -d "$CLAUDE_WORK_DIR/.taskmaster/tasks" ] && [ "$(ls -A "$CLAUDE_WORK_DIR/.taskmaster/tasks" 2>/dev/null)" ]; then
      echo "📋 Found individual task files, copying to docs directory..."
    
      # Copy individual task files from tasks/ to docs/ directory
      for task_dir in "$CLAUDE_WORK_DIR/.taskmaster/tasks"/task-*; do
        if [ -d "$task_dir" ]; then
          task_name=$(basename "$task_dir")
          target_dir="$CLAUDE_WORK_DIR/.taskmaster/docs/$task_name"
          mkdir -p "$target_dir"
          cp -r "$task_dir"/* "$target_dir/"
          echo "✓ Copied $task_name to docs directory"
        fi
      done
    else
      echo "❌ No task files found - expected either:"
      echo "  - tasks.json at .taskmaster/tasks/tasks.json"
      echo "  - Individual task directories at .taskmaster/tasks/task-*/"
      exit 1
    fi
    
    # Verify we have task files to work with
    if [ ! -d "$CLAUDE_WORK_DIR/.taskmaster/docs" ] || [ -z "$(ls -A "$CLAUDE_WORK_DIR/.taskmaster/docs" 2>/dev/null)" ]; then
      echo "❌ No task files available in .taskmaster/docs directory"
      exit 1
    fi
    
    echo "✓ Workspace validated"
    
    # Environment setup
    export SERVICE_NAME="{{`{{`{{`}}`}}service_name{{`}}`}}"
    export SOURCE_BRANCH="{{`{{`{{`}}`}}source_branch{{`}}`}}"
    export WORKING_DIR="{{`{{`{{`}}`}}working_directory{{`}}`}}"
    export GITHUB_USER="{{`{{`{{`}}`}}github_app{{`}}`}}"
    export GITHUB_APP="{{`{{`{{`}}`}}github_app{{`}}`}}"
    
    # Start background token refresh process (every 45 minutes to stay ahead of 1-hour expiry)
    (
        while true; do
            sleep 2700  # 45 minutes
            echo "[Background] Checking if token needs refresh..."
            if [ -n "$TOKEN_GENERATED_AT" ]; then
                NOW=$(date +%s)
                TOKEN_AGE=$((NOW - TOKEN_GENERATED_AT))
                echo "[Background] Token age: $(($TOKEN_AGE / 60)) minutes"
                if [ $TOKEN_AGE -gt 2700 ]; then
                    echo "[Background] Refreshing GitHub token proactively..."
                    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
                        generate_github_token
                    fi
                fi
            fi
        done
    ) &
    TOKEN_REFRESH_PID=$!
    echo "✓ Started background token refresh process (PID: $TOKEN_REFRESH_PID)"
    
    # Ensure we kill the background process on exit
    trap "kill $TOKEN_REFRESH_PID 2>/dev/null || true" EXIT
    
    # Claude execution
    echo "Starting Claude execution (stream-json via FIFO)..."
    
    # Check if system prompt file exists and add to command if available
    CLAUDE_CMD="claude -p --output-format stream-json --input-format stream-json --verbose"
    
    # Look for agent-specific system prompt file from agents ConfigMap
    # The system prompt should be in the agents ConfigMap if configured
    if [ -f "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        echo "✓ Found system prompt file for {{`{{`{{`}}`}}github_app{{`}}`}}, adding to Claude command"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/config/agents/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    elif [ -f "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" ]; then
        # Fallback to task-files if included inline
        echo "✓ Found system prompt in task ConfigMap for {{`{{`{{`}}`}}github_app{{`}}`}}"
        CLAUDE_CMD="$CLAUDE_CMD --system-prompt /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
        if [ "${DEBUG_PROMPT:-false}" = "true" ]; then
            echo "[DEBUG] System prompt path: /task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md"
            echo "[DEBUG] System prompt first 10 lines:"; head -n 10 "/task-files/{{`{{`{{`}}`}}github_app{{`}}`}}_system-prompt.md" | sed 's/^/[DEBUG] /'
            echo "[DEBUG] ----"
        fi
    else
        echo "ℹ️ No system prompt file found for agent {{`{{`{{`}}`}}github_app{{`}}`}}, using defaults"
    fi
    
    # Model is set via settings.json template, not CLI flag
    
    # Safe mode toggle for debugging (prevents token consumption)
    SAFE_MODE="false"  # Set to "false" for full docs generation
    
      if [ "$SAFE_MODE" = "true" ]; then
          echo "🛡️ SAFE MODE ENABLED - Running simple test instead of full docs generation"
          FIFO_PATH="/workspace/agent-input.jsonl"
          rm -f "$FIFO_PATH" 2>/dev/null || true
          mkfifo "$FIFO_PATH"
          chmod 666 "$FIFO_PATH" || true
          # Start Claude (reader) first to avoid blocking on writer open
          $CLAUDE_CMD < "$FIFO_PATH" &
          CLAUDE_PID=$!
          # Now open persistent writer and send one message
          exec 9>"$FIFO_PATH"
          printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":"What time is it? Please answer this simple question and exit immediately."}]{{`}}`}}\n' >&9
          # Close writer so reader gets EOF and exits
          exec 9>&-
          wait $CLAUDE_PID
          CLAUDE_EXIT_CODE=$?
        echo "Safe mode test completed with exit code: $CLAUDE_EXIT_CODE"
    
        # Exit successfully to prevent PR creation in safe mode
        echo "✅ Safe mode test complete, exiting without changes"
        exit 0
      else
          FIFO_PATH="/workspace/agent-input.jsonl"
          rm -f "$FIFO_PATH" 2>/dev/null || true
          mkfifo "$FIFO_PATH"
          chmod 666 "$FIFO_PATH" || true
          # Start Claude (reader) first to avoid blocking on writer open
          $CLAUDE_CMD < "$FIFO_PATH" &
          CLAUDE_PID=$!
          # Send initial prompt via sidecar HTTP when possible; fallback to FIFO
          if [ -f "prompt.md" ]; then
              INITIAL_TEXT=$(jq -Rs . < "prompt.md")
              if printf '{"text":%s}\n' "$INITIAL_TEXT" | \
                   curl -fsS -X POST http://127.0.0.1:8080/input \
                     -H 'Content-Type: application/json' \
                     --data-binary @- >/dev/null 2>&1; then
                echo "✓ Initial prompt sent via sidecar /input"
              else
                echo "⚠️ Sidecar /input failed, falling back to direct FIFO write"
                exec 9>"$FIFO_PATH"
                printf '{"type":"user","message":{"role":"user","content":[{"type":"text","text":%s}]{{`}}`}}\n' "$INITIAL_TEXT" >&9
              fi
    
              # Wait for Claude to complete, then close any fallback writer and request sidecar shutdown
              wait $CLAUDE_PID
              CLAUDE_EXIT_CODE=$?
              echo "Claude completed with exit code: $CLAUDE_EXIT_CODE"
              exec 9>&- 2>/dev/null || true
              if curl -fsS -X POST http://127.0.0.1:8080/shutdown >/dev/null 2>&1; then
                echo "✓ Requested sidecar shutdown"
              else
                echo "⚠️ Failed to request sidecar shutdown (it may not be running)"
              fi
          else
              echo "❌ No prompt.md found"
              exit 1
          fi
      fi
    
    # PR creation
    echo "Creating pull request..."
    
    # Ensure we're in the correct working directory for git operations
    cd /workspace/{{`{{`{{`}}`}}working_directory{{`}}`}}
    
    # Check for documentation changes (including untracked files)
    echo "Checking for documentation changes..."
    echo "Current directory: $(pwd)"
    
    # Check for any changes in .taskmaster directory
    MODIFIED_DOCS=$(git diff HEAD -- .taskmaster/ 2>/dev/null | wc -l)
    STAGED_DOCS=$(git diff --cached HEAD -- .taskmaster/ 2>/dev/null | wc -l)
    UNTRACKED_DOCS=$(git ls-files --others --exclude-standard .taskmaster/ 2>/dev/null | wc -l)
    
    echo "Modified files: $MODIFIED_DOCS lines of diff"
    echo "Staged files: $STAGED_DOCS lines of diff"
    echo "Untracked files: $UNTRACKED_DOCS files"
    
    if [ "$MODIFIED_DOCS" -eq 0 ] && [ "$STAGED_DOCS" -eq 0 ] && [ "$UNTRACKED_DOCS" -eq 0 ]; then
        echo "No documentation changes found in .taskmaster/"
        echo "Checking if .taskmaster exists:"
        ls -la .taskmaster/ 2>/dev/null || echo ".taskmaster directory not found"
        exit 0
    fi
    
    echo "✓ Documentation changes detected, proceeding with PR creation..."
    
    # Check if we're already on an auto-save branch from the hook
    CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
    if [[ "$CURRENT_BRANCH" == docs/auto-save-* ]]; then
        echo "✓ Already on auto-save branch from hook: $CURRENT_BRANCH"
        PR_BRANCH="$CURRENT_BRANCH"
        SOURCE_BRANCH="main"  # Assume we branched from main originally
    else
        # Create new PR branch if not already on one
        SOURCE_BRANCH=$(git rev-parse --abbrev-ref HEAD)
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        RANDOM_ID=$(date +%s | tail -c 6)
        PR_BRANCH="docs/{{`{{`{{`}}`}}#if task_id{{`}}`}}task-{{`{{`{{`}}`}}task_id{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}auto-gen{{`{{`{{`}}`}}/if{{`}}`}}-${TIMESTAMP}-${RANDOM_ID}"
    
        echo "Creating branch: $PR_BRANCH"
        if ! git checkout -b "$PR_BRANCH"; then
            echo "❌ Failed to create branch"
            exit 1
        fi
    fi
    
    echo "Staging all .taskmaster changes..."
    git add .taskmaster/
    
    echo "Checking for uncommitted changes..."
    STAGED_FILES=$(git status --porcelain | grep "^[AM]" | wc -l)
    
    if [ "$STAGED_FILES" -gt 0 ]; then
        echo "Showing what will be committed:"
        git status --porcelain
    
        echo "Committing changes..."
        if ! git commit -m "docs: generate Task Master documentation{{`{{`{{`}}`}}#if task_id{{`}}`}} (task {{`{{`{{`}}`}}task_id{{`}}`}}){{`{{`{{`}}`}}/if{{`}}`}}
    
    - Auto-generated comprehensive task documentation
    - Updated task breakdowns and implementation details
    - Added acceptance criteria and workflow prompts
    - Generated by orchestrator docs agent
    
    🤖 Auto-generated by Claude docs agent"; then
            echo "❌ Failed to commit changes"
            echo "Git status:"
            git status
            exit 1
        fi
    else
        echo "✓ All changes already committed by auto-save hook"
    fi
    
    # Check if we need to push (there might be unpushed commits from hook)
    if git rev-list --count origin/"$PR_BRANCH"..HEAD 2>/dev/null | grep -q '^0$'; then
        echo "✓ Branch already up to date with origin"
    else
        echo "Pushing branch..."
        if ! git push -u origin "$PR_BRANCH"; then
            echo "❌ Failed to push branch"
            echo "Retrying with verbose output..."
            GIT_CURL_VERBOSE=1 git push -u origin "$PR_BRANCH" 2>&1
            exit 1
        fi
    fi
    
    echo "✓ Branch pushed successfully"
    
    # Create PR
    if command -v gh >/dev/null 2>&1; then
        # GitHub CLI should already be authenticated from the beginning of the script
    
        PR_TITLE="docs: auto-generate Task Master documentation{{`{{`{{`}}`}}#if task_id{{`}}`}} for task {{`{{`{{`}}`}}task_id{{`}}`}}{{`{{`{{`}}`}}/if{{`}}`}}"
        PR_BODY="Auto-generated Task Master documentation by orchestrator container script.
    
    **Working Directory:** {{`{{`{{`}}`}}working_dir{{`}}`}}
    **Branch:** \`$PR_BRANCH\` → \`$SOURCE_BRANCH\`
    **Timestamp:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
    {{`{{`{{`}}`}}#if task_id{{`}}`}}**Target Task:** {{`{{`{{`}}`}}task_id{{`}}`}}{{`{{`{{`}}`}}/if{{`}}`}}
    
    🤖 Auto-generated by Container Script"
    
        # Refresh GitHub token if needed before PR creation
        refresh_token_if_needed
    
        # Retry PR creation up to 3 times for transient failures
        PR_CREATED=false
        for attempt in 1 2 3; do
            echo "Creating PR (attempt $attempt/3)..."
            if gh pr create --title "$PR_TITLE" --body "$PR_BODY" --base "$SOURCE_BRANCH" --head "$PR_BRANCH"; then
                echo "✓ Pull request created successfully"
                PR_CREATED=true
                break
            else
                echo "❌ PR creation attempt $attempt failed"
                if [ $attempt -lt 3 ]; then
                    echo "⏳ Waiting 5 seconds before retry..."
                    sleep 5
                fi
            fi
        done
    
        if [ "$PR_CREATED" = false ]; then
            echo "❌ Failed to create pull request after 3 attempts"
            echo "⚠️ Branch has been pushed, but PR creation failed"
            # Extract owner/repo from repository URL
            REPO_PATH=$(echo "{{`{{`{{`}}`}}repository_url{{`}}`}}" | sed -E 's|https://github.com/||' | sed 's|\.git$||')
            echo "💡 You can manually create a PR at: https://github.com/$REPO_PATH/pull/new/$PR_BRANCH"
            exit 1
        fi
    else
        echo "⚠️ GitHub CLI not available - create PR manually"
    fi
    
    echo "Documentation generation completed successfully!"  docs_prompt.md.hbs: |
    # CRITICAL: Complete Documentation Generation Task
    
    {{`{{`{{`}}`}}!-- Safety toggle: set to false to run safe test mode --{{`}}`}}
    {{`{{`{{`}}`}}#unless (eq "false" "true"){{`}}`}}
    
    **🚨 MANDATORY COMPLETION REQUIREMENT 🚨**
    You MUST complete ALL steps in this process. Partial completion is not acceptable. This is especially critical for large projects with many tasks.
    
    ## Task Overview
    Generate comprehensive documentation for {{`{{`{{`}}`}}#if task_id{{`}}`}}task {{`{{`{{`}}`}}task_id{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}**ALL Task Master tasks**{{`{{`{{`}}`}}/if{{`}}`}}.
    
    **If this is a large project with many tasks (10+ tasks), you MUST:**
    - Process ALL tasks without stopping
    - Show progress updates as you work through each task
    - Complete the ENTIRE git workflow including PR creation
    - Do NOT stop partway through - finish everything
    
    ## Required Process
    
    ### Step 1: Context Analysis (REQUIRED)
    1. Read CLAUDE.md for project context and standards
    2. **Use individual task files:**
       - Individual task files have been pre-copied to `.taskmaster/docs/task-{id}/task.txt`
       - Each `task.txt` contains complete task information including subtasks and implementation details
    3. Review architecture.md and prd.txt for context
    {{`{{`{{`}}`}}#if include_codebase{{`}}`}}
    4. **EXISTING PROJECT CONTEXT:**
       - **READ `.taskmaster/docs/codebase.md`** - This contains the complete existing codebase
       - Understand the current implementation state and architecture
       - Identify gaps between current code and task requirements
       - Focus on building upon existing patterns and code structure
       - Consider what's already implemented vs. what needs to be added
    5. **For large projects: Announce total task count and confirm you will process ALL of them**
    {{`{{`{{`}}`}}else{{`}}`}}
    4. **For large projects: Announce total task count and confirm you will process ALL of them**
    {{`{{`{{`}}`}}/if{{`}}`}}
    
    **🎯 IMPORTANT: Use individual `task.txt` files for each task**
    - Individual task files are available at: `.taskmaster/docs/task-{id}/task.txt`
    - Example: task 1 → `.taskmaster/docs/task-1/task.txt`, task 15 → `.taskmaster/docs/task-15/task.txt`
    - These files contain complete task information including subtasks and implementation details
    - This approach allows efficient processing of large projects with many tasks
    
    ### Step 2: Documentation Generation (MANDATORY FOR ALL TASKS)
    {{`{{`{{`}}`}}#if task_id{{`}}`}}
    Focus specifically on task {{`{{`{{`}}`}}task_id{{`}}`}} and create:
    {{`{{`{{`}}`}}else{{`}}`}}
    **IMPORTANT: SKIP TASKS THAT ALREADY HAVE COMPLETE DOCUMENTATION**
    
    Before processing any task, check if ALL required files already exist:
    - `task.md`
    - `prompt.md`
    - `acceptance-criteria.md`
    - `task.xml`
    
    If ALL four files exist and have substantial content (not just stubs), SKIP that task to save tokens and time.
    
    **YOU MUST CREATE DOCUMENTATION FOR EVERY TASK THAT NEEDS IT. DO NOT SKIP ANY INCOMPLETE TASKS.**
    
    For each task that needs documentation (process ALL incomplete tasks, no exceptions):
    {{`{{`{{`}}`}}/if{{`}}`}}
    - `task.md` - Comprehensive task overview and implementation guide
    - `prompt.md` - Autonomous prompt for AI agents
    - `acceptance-criteria.md` - Clear acceptance criteria and test cases
    - `task.xml` - XML-structured prompt optimized for LLM consumption
    
    **Progress Requirements:**
    - Announce each task as you start it: "📝 Processing Task [ID]: [Title]"
    - Confirm completion of each task: "✅ Completed Task [ID]"
    - **For large projects: Provide periodic updates (every 5 tasks): "Progress: [X] of [Y] tasks completed"**
    
    Place all documentation in `.taskmaster/docs/task-{id}/` directories.
    
    ### Step 2.3: XML Prompt Generation (MANDATORY)
    
    **🔧 CRITICAL: Generate XML-Structured Prompt for LLM Consumption**
    
    For each task, you MUST create a `task.xml` file that combines all task information into an XML structure optimized for LLM processing. This single file will contain all the technical specifications, acceptance criteria, and implementation guidance needed for coding agents.
    
    **REQUIRED XML STRUCTURE:**
    ```xml
    <prompt>
        <role>You are a senior coding agent specializing in [technology stack from task].</role>
        <task>
            <id>[Task ID]</id>
            <title>[Task Title]</title>
            <description>[Complete task description]</description>
            <priority>[high|medium|low]</priority>
            <status>[pending|in-progress|done]</status>
            <dependencies>[comma-separated dependency IDs]</dependencies>
        </task>
        <technical_specifications>
            <spec>[Technical requirement 1]</spec>
            <spec>[Technical requirement 2]</spec>
            <spec>[Technical requirement N]</spec>
        </technical_specifications>
        <implementation_details>
            [Detailed implementation guidance from task.txt]
        </implementation_details>
        <acceptance_criteria>
            <criterion>[Acceptance criterion 1]</criterion>
            <criterion>[Acceptance criterion 2]</criterion>
            <criterion>[Acceptance criterion N]</criterion>
        </acceptance_criteria>
        <test_strategy>
            [Testing approach and requirements]
        </test_strategy>
        <instructions>
            Think step-by-step about the implementation approach. Consider the existing codebase structure and patterns.
            Provide complete, production-ready code that follows best practices. Include necessary imports,
            error handling, and documentation. Test your solution thoroughly before finalizing.
        </instructions>
    </prompt>
    ```
    
    **XML Generation Requirements:**
    1. **Single Comprehensive File**: Combine task.md, prompt.md, and acceptance-criteria.md content into one XML structure
    2. **Structured Data**: Use appropriate XML tags to organize information hierarchically
    3. **LLM Optimization**: Follow the XML format proven to work best with Claude and other LLMs
    4. **Complete Information**: Include ALL technical specifications, dependencies, and implementation details
    5. **Machine Readable**: Ensure the XML is well-formed and parseable
    6. **Role Definition**: Set appropriate role based on task technology stack (e.g., "senior Rust developer", "Kubernetes expert")
    7. **Implementation Focus**: Emphasize production-ready code with proper error handling and testing
    
    **Content Mapping Guidelines:**
    - Extract role from task technology (Rust, Kubernetes, Go, etc.)
    - Pull task details from the individual task.txt file
    - Convert acceptance criteria into `<criterion>` elements
    - Include all technical specifications as `<spec>` elements
    - Add implementation details from task description
    - Include test strategy from task requirements
    
    ### Step 3: Complete Documentation Generation
    **⚠️ CRITICAL: You MUST generate ALL documentation files as specified above.**
    
    **Git Workflow:** The orchestrator post-completion hook will automatically handle:
    - Creating and checking out the feature branch: `docs-gen-{{`{{`{{`}}`}}source_branch{{`}}`}}`
    - Staging all documentation files
    - Committing with proper message
    - Pushing to origin
    - Creating pull request to target branch: `{{`{{`{{`}}`}}source_branch{{`}}`}}`
    
    **Your Job:** Focus ONLY on generating the documentation files. Do NOT run any git commands.
    
    ✅ **Final Confirmation Required:** "✅ DOCUMENTATION FILES GENERATED - Hook will handle git workflow and PR creation"
    
    ## Error Handling
    - If documentation generation fails, report the error and retry
    - If file creation fails, check permissions and retry
    - **DO NOT give up - complete the documentation generation**
    - **Note:** Git workflow and PR creation are handled by the hook, not the agent
    
    ## Quality Standards
    - Well-structured and comprehensive content
    - Actionable implementation guidance
    - Proper markdown formatting
    - Code examples where relevant
    - Clear cross-references between documents
    - Maintain consistency across ALL documents
    
    ## Final Confirmation Required
    **YOU MUST END WITH THIS EXACT MESSAGE:**
    ```
    🎉 DOCUMENTATION GENERATION COMPLETE 🎉
    ✅ Generated documentation for {{`{{`{{`}}`}}#if task_id{{`}}`}}task {{`{{`{{`}}`}}task_id{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}ALL tasks{{`{{`{{`}}`}}/if{{`}}`}}
    ✅ Created all required documentation files (task.md, prompt.md, acceptance-criteria.md, task.xml)
    📋 Total files created: [COUNT]
    🔧 Generated XML-structured prompts optimized for LLM consumption
    🔗 Git workflow and pull request will be handled automatically by orchestrator hook
    ```
    
    **If you cannot provide this final confirmation, the task is NOT complete and you must continue working until it is done.**
    
    {{`{{`{{`}}`}}else{{`}}`}}
    
    ## Safe Test Mode
    
    What time is it? Please answer this simple question and exit immediately.
    
    {{`{{`{{`}}`}}/unless{{`}}`}}  docs_settings.json.hbs: |
    {
      "permissions": {
        "allow": [
          {{`{{`{{`}}`}}#if agent_tools_override{{`}}`}}
          {{`{{`{{`}}`}}#each permissions.allow{{`}}`}}
          "{{`{{`{{`}}`}}this{{`}}`}}"{{`{{`{{`}}`}}#unless @last{{`}}`}},{{`{{`{{`}}`}}/unless{{`}}`}}
          {{`{{`{{`}}`}}/each{{`}}`}}
          {{`{{`{{`}}`}}else{{`}}`}}
          "Bash",
          "Edit",
          "Read",
          "Write",
          "MultiEdit",
          "Glob",
          "Grep",
          "LS",
          "WebSearch",
          "WebFetch",
          "Task",
          "ExitPlanMode",
          "TodoRead",
          "TodoWrite"
          {{`{{`{{`}}`}}/if{{`}}`}}
        ],
        "deny": [
          {{`{{`{{`}}`}}#if agent_tools_override{{`}}`}}
          {{`{{`{{`}}`}}#each permissions.deny{{`}}`}}
          "{{`{{`{{`}}`}}this{{`}}`}}"{{`{{`{{`}}`}}#unless @last{{`}}`}},{{`{{`{{`}}`}}/unless{{`}}`}}
          {{`{{`{{`}}`}}/each{{`}}`}}
          {{`{{`{{`}}`}}else{{`}}`}}
          {{`{{`{{`}}`}}/if{{`}}`}}
        ],
        "defaultMode": "acceptEdits"
      },
      "env": {
        "NODE_ENV": "production",
        "DISABLE_AUTOUPDATER": "1",
        "DISABLE_COST_WARNINGS": "1",
        "DISABLE_NON_ESSENTIAL_MODEL_CALLS": "1",
        "CLAUDE_BASH_MAINTAIN_PROJECT_WORKING_DIR": "true",
        "CLAUDE_CODE_ENABLE_TELEMETRY": "{{`{{`{{`}}`}}#if telemetry.enabled{{`}}`}}1{{`{{`{{`}}`}}else{{`}}`}}0{{`{{`{{`}}`}}/if{{`}}`}}"{{`{{`{{`}}`}}#if telemetry.enabled{{`}}`}},
        "OTEL_METRICS_EXPORTER": "otlp",
        "OTEL_LOGS_EXPORTER": "otlp",
        "OTEL_EXPORTER_OTLP_METRICS_ENDPOINT": "{{`{{`{{`}}`}}telemetry.otlpEndpoint{{`}}`}}",
        "OTEL_EXPORTER_OTLP_METRICS_PROTOCOL": "{{`{{`{{`}}`}}telemetry.otlpProtocol{{`}}`}}",
        "OTEL_EXPORTER_OTLP_LOGS_ENDPOINT": "{{`{{`{{`}}`}}telemetry.otlpEndpoint{{`}}`}}",
        "OTEL_EXPORTER_OTLP_LOGS_PROTOCOL": "{{`{{`{{`}}`}}telemetry.otlpProtocol{{`}}`}}"{{`{{`{{`}}`}}/if{{`}}`}}
      },
      "model": "{{`{{`{{`}}`}}model{{`}}`}}",
      "cleanupPeriodDays": 3,
      "includeCoAuthoredBy": false,
      "hooks": {
        "PostToolUse": [
          {
            "matcher": "Write",
            "hooks": [
              {
                "type": "command",
                "command": "/workspace/{{`{{`{{`}}`}}#if working_directory{{`}}`}}{{`{{`{{`}}`}}working_directory{{`}}`}}{{`{{`{{`}}`}}else{{`}}`}}.{{`{{`{{`}}`}}/if{{`}}`}}/after-file-saved.sh"
              }
            ]
          }
        ]
      }
    }
  docs_toolman-catalog.md.hbs: |
    {{`{{`{{`}}`}}!--
    Toolman Catalog Markdown Template for Docs Agent
    ================================================
    
    This template renders the toolman catalog data into markdown format for embedding
    in the docs agent's prompt. The agent uses this information to select appropriate
    tools when generating task-specific toolman-config.json files.
    
    Template Variables:
    - toolman_catalog: Complete tool catalog from toolman-tool-catalog ConfigMap
    - total_tool_count: Total number of available tools
    - generated_timestamp: Unix timestamp of generation
    --{{`}}`}}
    
    # Available Tools Catalog
    
    **Total Tools Available**: {{`{{`{{`}}`}}total_tool_count{{`}}`}}
    **Generated**: {{`{{`{{`}}`}}generated_timestamp{{`}}`}}
    
    Use this catalog to select appropriate tools for each task based on implementation requirements.
    
    ## Local Servers
    
    Local servers run within the agent's environment and provide file system and local operations.
    
    {{`{{`{{`}}`}}#each toolman_catalog.local{{`}}`}}
    ### {{`{{`{{`}}`}}@key{{`}}`}} Server
    
    **Description**: {{`{{`{{`}}`}}this.description{{`}}`}}
    **Command**: `{{`{{`{{`}}`}}this.command{{`}}`}}`
    **Arguments**: {{`{{`{{`}}`}}#each this.args{{`}}`}}`{{`{{`{{`}}`}}this{{`}}`}}`{{`{{`{{`}}`}}#unless @last{{`}}`}} {{`{{`{{`}}`}}/unless{{`}}`}}{{`{{`{{`}}`}}/each{{`}}`}}
    **Working Directory**: {{`{{`{{`}}`}}this.working_directory{{`}}`}}
    
    **Available Tools**:
    {{`{{`{{`}}`}}#each this.tools{{`}}`}}
    - **`{{`{{`{{`}}`}}this.name{{`}}`}}`** ({{`{{`{{`}}`}}this.category{{`}}`}})
      - **Description**: {{`{{`{{`}}`}}this.description{{`}}`}}
      - **Use Cases**: {{`{{`{{`}}`}}#each this.use_cases{{`}}`}}{{`{{`{{`}}`}}this{{`}}`}}{{`{{`{{`}}`}}#unless @last{{`}}`}}, {{`{{`{{`}}`}}/unless{{`}}`}}{{`{{`{{`}}`}}/each{{`}}`}}
    {{`{{`{{`}}`}}/each{{`}}`}}
    
    {{`{{`{{`}}`}}/each{{`}}`}}
    
    ## Remote Tools
    
    Remote tools are available via MCP servers running in the cluster.
    
    {{`{{`{{`}}`}}#each toolman_catalog.remote{{`}}`}}
    ### {{`{{`{{`}}`}}@key{{`}}`}} Server
    
    **Description**: {{`{{`{{`}}`}}this.description{{`}}`}}
    **Endpoint**: {{`{{`{{`}}`}}this.endpoint{{`}}`}}
    
    **Available Tools**:
    {{`{{`{{`}}`}}#each this.tools{{`}}`}}
    - **`{{`{{`{{`}}`}}this.name{{`}}`}}`** ({{`{{`{{`}}`}}this.category{{`}}`}})
      - **Description**: {{`{{`{{`}}`}}this.description{{`}}`}}
      - **Use Cases**: {{`{{`{{`}}`}}#each this.use_cases{{`}}`}}{{`{{`{{`}}`}}this{{`}}`}}{{`{{`{{`}}`}}#unless @last{{`}}`}}, {{`{{`{{`}}`}}/unless{{`}}`}}{{`{{`{{`}}`}}/each{{`}}`}}
    {{`{{`{{`}}`}}/each{{`}}`}}
    
    {{`{{`{{`}}`}}/each{{`}}`}}
    
    ## Tool Selection Guidelines
    
    ### How to Select Tools
    
    1. **Analyze Task Requirements**: Read the task description and implementation details carefully
    2. **Match Categories**: Look for tools whose categories align with your task needs:
       {{`{{`{{`}}`}}#each toolman_catalog.local{{`}}`}}
         {{`{{`{{`}}`}}#each this.tools{{`}}`}}
       - **{{`{{`{{`}}`}}this.category{{`}}`}}**: {{`{{`{{`}}`}}this.description{{`}}`}}
         {{`{{`{{`}}`}}/each{{`}}`}}
       {{`{{`{{`}}`}}/each{{`}}`}}
       {{`{{`{{`}}`}}#each toolman_catalog.remote{{`}}`}}
         {{`{{`{{`}}`}}#each this.tools{{`}}`}}
       - **{{`{{`{{`}}`}}this.category{{`}}`}}**: {{`{{`{{`}}`}}this.description{{`}}`}}
         {{`{{`{{`}}`}}/each{{`}}`}}
       {{`{{`{{`}}`}}/each{{`}}`}}
    3. **Check Use Cases**: Match tool use cases to your specific task requirements
    4. **Be Selective**: Only include tools relevant to the specific task
    
    ### Configuration Format
    
    **🚨 CRITICAL: client-config.json MUST use this EXACT format - nothing else!**
    
    ```json
    {
      "remoteTools": [
        "actual_tool_name_from_catalog",
        "another_tool_name_from_catalog"
      ],
      "localServers": {
        "filesystem": {
          "command": "npx",
          "args": ["-y", "@modelcontextprotocol/server-filesystem", "/workspace"],
          "tools": ["read_file", "write_file", "list_directory", "create_directory", "edit_file"],
          "workingDirectory": "project_root"
        }
      }
    }
    ```
    
    **❌ NEVER generate task specification documents with fields like:**
    - `task_id`, `task_name`, `task_type`, `priority`, `status`
    - `required_tools`, `recommended_tools`, `optional_tools`
    - `tool_configuration`, `technical_requirements`, `testing_requirements`
    - Complex nested objects or metadata
    
    **✅ ONLY generate simple MCP client configuration with:**
    - `remoteTools` array (tool names from this catalog)
    - `localServers` object (exact command/args shown above)
    
    ### Example Tool Selections
    
    **For file operations**: Include tools from local filesystem server like `read_file`, `write_file`, `list_directory`
    
    **For research/documentation**: Include remote tools like search and documentation tools
    
    **For infrastructure tasks**: Include Kubernetes and system management tools
    
    **For development tasks**: Include relevant language-specific documentation tools
    
    ### Validation Requirements
    
    - ✅ Use specific tool names from this catalog (never wildcards)
    - ✅ Include complete server configuration for local servers
    - ✅ Only select tools relevant to the specific task
    - ✅ Use `workingDirectory: "project_root"` for local filesystem servers
    - ✅ Verify all tool names exist in this catalog  intake_intake.sh: |
    #!/bin/bash
    set -e
    
    # Force output to be unbuffered
    exec 2>&1
    set -x  # Enable command tracing temporarily
    
    # Add error trap for debugging
    trap 'echo "❌ Error occurred at line $LINENO with exit code $?. Last command: $BASH_COMMAND"; exit 1' ERR
    
    echo "🚀 Starting Project Intake Process"
    echo "================================="
    
    # Debug: Show ALL environment variables related to our workflow
    echo "🔍 DEBUG: Environment Variables Received:"
    echo "  PRIMARY_MODEL: ${PRIMARY_MODEL:-[NOT SET]}"
    echo "  PRIMARY_PROVIDER: ${PRIMARY_PROVIDER:-[NOT SET]}"
    echo "  RESEARCH_MODEL: ${RESEARCH_MODEL:-[NOT SET]}"
    echo "  RESEARCH_PROVIDER: ${RESEARCH_PROVIDER:-[NOT SET]}"
    echo "  FALLBACK_MODEL: ${FALLBACK_MODEL:-[NOT SET]}"
    echo "  FALLBACK_PROVIDER: ${FALLBACK_PROVIDER:-[NOT SET]}"
    echo "  NUM_TASKS: ${NUM_TASKS:-[NOT SET]}"
    echo "  EXPAND_TASKS: ${EXPAND_TASKS:-[NOT SET]}"
    echo "  ANALYZE_COMPLEXITY: ${ANALYZE_COMPLEXITY:-[NOT SET]}"
    echo "  GITHUB_APP: ${GITHUB_APP:-[NOT SET]}"
    echo "================================="
    
    # Load configuration from mounted ConfigMap
    CONFIG_FILE="/intake-files/config.json"
    PRD_FILE="/intake-files/prd.txt"
    ARCH_FILE="/intake-files/architecture.md"
    
    if [ ! -f "$CONFIG_FILE" ]; then
        echo "❌ Configuration file not found at $CONFIG_FILE"
        exit 1
    fi
    
    # Debug: Show what's in the config file
    echo "📄 Config file contents (from ConfigMap):"
    cat "$CONFIG_FILE" || echo "Failed to cat config file"
    echo ""
    echo "📄 Parsed values from ConfigMap:"
    echo "  primary_model from JSON: $(jq -r '.primary_model // "[NOT IN JSON]"' "$CONFIG_FILE")"
    echo "  primary_provider from JSON: $(jq -r '.primary_provider // "[NOT IN JSON]"' "$CONFIG_FILE")"
    echo "  research_model from JSON: $(jq -r '.research_model // "[NOT IN JSON]"' "$CONFIG_FILE")"
    echo "  research_provider from JSON: $(jq -r '.research_provider // "[NOT IN JSON]"' "$CONFIG_FILE")"
    echo "  fallback_model from JSON: $(jq -r '.fallback_model // "[NOT IN JSON]"' "$CONFIG_FILE")"
    echo "  fallback_provider from JSON: $(jq -r '.fallback_provider // "[NOT IN JSON]"' "$CONFIG_FILE")"
    echo "---"
    
    # Preview PRD and Architecture to verify correctness
    echo "📄 PRD file preview (first 40 lines):"
    if [ -f "$PRD_FILE" ]; then
        head -40 "$PRD_FILE" || true
    else
        echo "PRD file not found at $PRD_FILE"
    fi
    echo ""
    if [ -f "$ARCH_FILE" ]; then
        echo "📐 Architecture file present: $ARCH_FILE"
    else
        echo "📐 No architecture.md provided (optional)"
    fi
    echo "---"
    
    # Parse configuration
    echo "📋 Loading configuration from ConfigMap..."
    
    # Parse each field with error handling
    PROJECT_NAME=$(jq -r '.project_name' "$CONFIG_FILE" 2>/dev/null || echo "")
    echo "  ✓ Project name: $PROJECT_NAME"
    
    REPOSITORY_URL=$(jq -r '.repository_url' "$CONFIG_FILE" 2>/dev/null || echo "")
    echo "  ✓ Repository URL: $REPOSITORY_URL"
    
    # GITHUB_APP is now required from environment variables (no ConfigMap fallback)
    
    # Parse granular model configuration (from Argo workflow parameters)
    # NO FALLBACKS - if parameters not received, fail loudly to expose configuration issues
    
    if [ -z "$PRIMARY_MODEL" ]; then
        echo "❌ PRIMARY_MODEL environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$RESEARCH_MODEL" ]; then
        echo "❌ RESEARCH_MODEL environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$FALLBACK_MODEL" ]; then
        echo "❌ FALLBACK_MODEL environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$PRIMARY_PROVIDER" ]; then
        echo "❌ PRIMARY_PROVIDER environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$RESEARCH_PROVIDER" ]; then
        echo "❌ RESEARCH_PROVIDER environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$FALLBACK_PROVIDER" ]; then
        echo "❌ FALLBACK_PROVIDER environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$NUM_TASKS" ]; then
        echo "❌ NUM_TASKS environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$EXPAND_TASKS" ]; then
        echo "❌ EXPAND_TASKS environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$ANALYZE_COMPLEXITY" ]; then
        echo "❌ ANALYZE_COMPLEXITY environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    if [ -z "$GITHUB_APP" ]; then
        echo "❌ GITHUB_APP environment variable not set - configuration transmission failed"
        exit 1
    fi
    
    echo "  ✓ GitHub App: $GITHUB_APP"
    echo "  ✓ Primary Model: $PRIMARY_MODEL ($PRIMARY_PROVIDER)"
    echo "  ✓ Research Model: $RESEARCH_MODEL ($RESEARCH_PROVIDER)"
    echo "  ✓ Fallback Model: $FALLBACK_MODEL ($FALLBACK_PROVIDER)"
    echo "  ✓ Num tasks: $NUM_TASKS"
    echo "  ✓ Expand tasks: $EXPAND_TASKS"
    echo "  ✓ Analyze complexity: $ANALYZE_COMPLEXITY"
    
    # Legacy MODEL variable for backward compatibility
    MODEL="$PRIMARY_MODEL"
    
    echo "🔍 Configuration summary:"
    echo "  - Project: ${PROJECT_NAME:-[empty]}"
    echo "  - Repository: ${REPOSITORY_URL:-[empty]}"
    echo "  - GitHub App: ${GITHUB_APP:-[empty]}"
    echo "  - Primary Model: ${PRIMARY_MODEL:-[empty]} (${PRIMARY_PROVIDER:-[empty]})"
    echo "  - Research Model: ${RESEARCH_MODEL:-[empty]} (${RESEARCH_PROVIDER:-[empty]})"
    echo "  - Fallback Model: ${FALLBACK_MODEL:-[empty]} (${FALLBACK_PROVIDER:-[empty]})"
    echo "  - Num Tasks: ${NUM_TASKS:-[empty]}"
    echo "  - Expand: ${EXPAND_TASKS:-[empty]}"
    echo "  - Analyze: ${ANALYZE_COMPLEXITY:-[empty]}"
    
    # Turn off command tracing after configuration parsing
    set +x
    
    # If project name is empty, try to extract from PRD
    if [ -z "$PROJECT_NAME" ] || [ "$PROJECT_NAME" = "null" ]; then
        echo "📝 Extracting project name from PRD..."
        
        # Try to extract from first heading
        PROJECT_NAME=$(head -10 "$PRD_FILE" | grep -E "^#\s+" | head -1 | sed 's/^#\s*//' | \
                       sed 's/[^a-zA-Z0-9 -]//g' | tr '[:upper:]' '[:lower:]' | \
                       sed 's/ /-/g' | sed 's/--*/-/g' | sed 's/^-*//;s/-*$//')
        
        # Fallback to timestamp-based name
        if [ -z "$PROJECT_NAME" ]; then
            PROJECT_NAME="project-$(date +%Y%m%d-%H%M%S)"
        fi
        
        echo "✅ Using project name: $PROJECT_NAME"
    fi
    
    # Check for required environment variables
    echo "🔍 Checking environment variables..."
    if [ -z "$ANTHROPIC_API_KEY" ]; then
        echo "⚠️ Warning: ANTHROPIC_API_KEY is not set"
    fi
    
    # Disable interactive Git prompts
    export GIT_TERMINAL_PROMPT=0
    export GIT_ASKPASS=/bin/true
    export SSH_ASKPASS=/bin/true
    
    # GitHub App authentication setup
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ] && [ -n "$GITHUB_APP_ID" ]; then
        echo "🔐 Setting up GitHub App authentication..."
        echo "  - GitHub App ID found: ${GITHUB_APP_ID:0:10}..."
        echo "  - GitHub App Private Key found: [REDACTED]"
        
        # Function to generate GitHub App token (reusing from container.sh logic)
        generate_github_token() {
            echo "Generating fresh GitHub App token..."
            
            # Create temporary private key file
            TEMP_KEY_FILE="/tmp/github-app-key.pem"
            echo "$GITHUB_APP_PRIVATE_KEY" > "$TEMP_KEY_FILE"
            chmod 600 "$TEMP_KEY_FILE"
            
            # Generate JWT token
            JWT_HEADER=$(printf '{"alg":"RS256","typ":"JWT"}' | base64 -w 0 | tr '+/' '-_' | tr -d '=')
            NOW=$(date +%s)
            EXP=$((NOW + 600))
            JWT_PAYLOAD=$(printf '{"iat":%d,"exp":%d,"iss":"%s"}' "$NOW" "$EXP" "$GITHUB_APP_ID" | base64 -w 0 | tr '+/' '-_' | tr -d '=')
            JWT_SIGNATURE=$(printf '%s.%s' "$JWT_HEADER" "$JWT_PAYLOAD" | openssl dgst -sha256 -sign "$TEMP_KEY_FILE" -binary | base64 -w 0 | tr '+/' '-_' | tr -d '=')
            JWT_TOKEN="$JWT_HEADER.$JWT_PAYLOAD.$JWT_SIGNATURE"
            
            # Get installation ID
            REPO_OWNER=$(echo "$REPOSITORY_URL" | sed -E 's|https://github.com/([^/]+)/.*|\1|')
            REPO_NAME=$(echo "$REPOSITORY_URL" | sed -E 's|https://github.com/[^/]+/([^/]+)(\.git)?|\1|')
            
            # Try repository installation first (follow redirects)
            INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/installation")
    
            INSTALLATION_ID=$(echo "$INSTALLATION_RESPONSE" | jq -r '.id')
    
            # Fallback: try organization installation if repo lookup failed
            if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
                echo "⚠️ Repo installation not found for $REPO_OWNER/$REPO_NAME, trying org installation..."
                ORG_INSTALLATION_RESPONSE=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                    --connect-timeout 5 --max-time 12 \
                    -H "Authorization: Bearer $JWT_TOKEN" \
                    -H "Accept: application/vnd.github+json" \
                    "https://api.github.com/orgs/$REPO_OWNER/installation")
                INSTALLATION_ID=$(echo "$ORG_INSTALLATION_RESPONSE" | jq -r '.id')
            fi
    
            if [ "$INSTALLATION_ID" = "null" ] || [ -z "$INSTALLATION_ID" ]; then
                echo "❌ Failed to get installation ID for $REPO_OWNER/$REPO_NAME"
                echo "Response (repo): $INSTALLATION_RESPONSE"
                echo "Response (org):  ${ORG_INSTALLATION_RESPONSE:-[none]}"
                return 1
            fi
            
            echo "Installation ID: $INSTALLATION_ID"
            
            # Generate installation access token
            GITHUB_TOKEN=$(curl -s -L --retry 5 --retry-delay 2 --retry-connrefused \
                --connect-timeout 5 --max-time 12 \
                -X POST \
                -H "Authorization: Bearer $JWT_TOKEN" \
                -H "Accept: application/vnd.github.v3+json" \
                "https://api.github.com/app/installations/$INSTALLATION_ID/access_tokens" | jq -r '.token')
            
            if [ "$GITHUB_TOKEN" = "null" ] || [ -z "$GITHUB_TOKEN" ]; then
                echo "❌ Failed to generate GitHub token"
                return 1
            fi
            
            export GITHUB_TOKEN
            export GH_TOKEN="$GITHUB_TOKEN"
            
            # Configure git
            git config --global --replace-all credential.helper store
            echo "https://x-access-token:${GITHUB_TOKEN}@github.com" > ~/.git-credentials
            
            # Configure GitHub CLI
            echo "🔧 Configuring GitHub CLI..."
            echo "$GITHUB_TOKEN" | timeout 10 gh auth login --with-token || {
                echo "⚠️ gh auth login returned non-zero or timed out, but continuing..."
            }
            
            # Check auth status (this may return non-zero even when auth is valid)
            echo "🔍 Checking GitHub CLI auth status..."
            timeout 10 gh auth status || {
                echo "⚠️ gh auth status returned non-zero or timed out, but token is likely still valid"
            }
            
            echo "✅ GitHub authentication configured"
            return 0
        }
        
        # Initial token generation
        generate_github_token || exit 1
    else
        echo "⚠️ GitHub App credentials not found, using default authentication"
    fi
    
    # Clone repository
    echo "📦 Cloning repository: $REPOSITORY_URL"
    
    # Validate repository URL
    if [ -z "$REPOSITORY_URL" ] || [ "$REPOSITORY_URL" = "null" ]; then
        echo "❌ Repository URL is empty or null"
        exit 1
    fi
    
    CLONE_DIR="/tmp/repo-$(date +%s)"
    echo "📂 Clone directory: $CLONE_DIR"
    echo "🔍 Attempting git clone..."
    git clone "$REPOSITORY_URL" "$CLONE_DIR" || {
        echo "❌ Git clone failed with exit code $?"
        echo "Repository URL: $REPOSITORY_URL"
        echo "Clone directory: $CLONE_DIR"
        exit 1
    }
    
    echo "✅ Repository cloned successfully"
    cd "$CLONE_DIR"
    echo "📂 Changed to clone directory: $(pwd)"
    
    # Normalize project name for filesystem (lowercase, safe characters)
    PROJECT_DIR_NAME=$(echo "$PROJECT_NAME" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]/-/g' | sed 's/--*/-/g' | sed 's/^-*//;s/-*$//')
    
    # Set PROJECT_DIR to a subdirectory within the cloned repository
    PROJECT_DIR="$CLONE_DIR/$PROJECT_DIR_NAME"
    
    # Create project directory if it doesn't exist
    if [ ! -d "$PROJECT_DIR" ]; then
        echo "📁 Creating project directory: $PROJECT_DIR_NAME"
        mkdir -p "$PROJECT_DIR"
    fi
    
    # Configure git identity
    git config user.name "Project Intake Bot"
    git config user.email "intake@5dlabs.com"
    
    # Set up nvm environment if available (Claude Code image uses nvm)
    if [ -s "/usr/local/nvm/nvm.sh" ]; then
        echo "🔧 Setting up nvm environment..."
        export NVM_DIR="/usr/local/nvm"
        [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
        [ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"
        echo "✅ nvm loaded, node version: $(node --version)"
    fi
    
    # Check if npm is available
    if ! command -v npm &> /dev/null; then
        echo "❌ npm is not installed or not in PATH"
        echo "🔍 PATH: $PATH"
        echo "🔍 Checking for node/npm in common locations..."
        
        # Check common locations
        for npm_path in /usr/local/nvm/versions/node/*/bin/npm /usr/bin/npm /usr/local/bin/npm; do
            if [ -f "$npm_path" ]; then
                echo "✅ Found npm at: $npm_path"
                # Add to PATH
                export PATH="$(dirname $npm_path):$PATH"
                break
            fi
        done
        
        # Final check
        if ! command -v npm &> /dev/null; then
            echo "❌ Cannot find npm after checking common locations"
            exit 1
        fi
    fi
    
    # TaskMaster is pre-installed in the agent image
    echo "📦 TaskMaster is pre-installed in the agent image"
    echo "📋 Node version: $(node --version)"
    echo "📋 NPM version: $(npm --version)"
    
    # Verify TaskMaster is available
    if ! command -v task-master &> /dev/null; then
        echo "❌ task-master command not found in agent image"
        echo "🔍 PATH: $PATH"
        echo "🔍 Looking for task-master in common locations:"
        for path in /usr/local/bin /usr/bin /home/node/.npm-global/bin; do
            if [ -f "$path/task-master" ]; then
                echo "✅ Found task-master at: $path/task-master"
                export PATH="$path:$PATH"
                break
            fi
        done
        
        if ! command -v task-master &> /dev/null; then
            echo "❌ task-master not found after checking common locations"
            exit 1
        fi
    fi
    
    # Get the actual path to task-master
    TASK_MASTER_PATH=$(which task-master)
    echo "✅ TaskMaster found at: $TASK_MASTER_PATH"
    echo "✅ TaskMaster version: $(task-master --version 2>/dev/null || echo 'version check failed')"
    
    # Change to project directory
    cd "$PROJECT_DIR"
    
    # Set environment variables for TaskMaster
    export TASKMASTER_LOG_LEVEL="debug"
    export CI="true"  # This might help TaskMaster run in non-interactive mode
    export TASKMASTER_AUTO_ACCEPT="true"
    
    # Initialize TaskMaster
    echo "🚀 Initializing TaskMaster project in $PROJECT_NAME..."
    echo "📂 Current directory: $(pwd)"
    echo "📂 Directory contents before init:"
    ls -la
    
    # Debug: Check if task-master command works
    echo "🔍 Testing task-master command..."
    task-master --version || echo "⚠️ task-master --version failed"
    task-master --help > /dev/null 2>&1 || echo "⚠️ task-master --help failed"
    
    # First attempt: Try clean init with Claude rules only
    echo "🔍 Attempting TaskMaster init..."
    # Use the full path to ensure we're calling the right binary
    # --rules "claude" creates only Claude-specific files (CLAUDE.md)
    "$TASK_MASTER_PATH" init --yes \
        --name "$PROJECT_NAME" \
        --description "Auto-generated project from intake pipeline" \
        --version "0.1.0" \
        --rules "claude" \
        --skip-install
    INIT_EXIT_CODE=$?
    
    echo "🔍 Init result: exit code $INIT_EXIT_CODE"
    
    # Check if initialization was successful
    if [ $INIT_EXIT_CODE -eq 0 ] && [ -d ".taskmaster" ]; then
        echo "✅ TaskMaster initialization successful!"
        echo "📂 Directory contents after init:"
        ls -la .taskmaster/
    else
        echo "⚠️ TaskMaster init failed or didn't create .taskmaster directory"
        echo "📂 Current directory contents:"
        ls -la
        
        # Try alternative approach: init with minimal flags
        echo "🔧 Trying init with minimal flags..."
        task-master init --name "$PROJECT_NAME" --yes
        INIT_EXIT_CODE=$?
        
        if [ $INIT_EXIT_CODE -eq 0 ] && [ -d ".taskmaster" ]; then
            echo "✅ Minimal init method worked!"
        else
            echo "🔧 Final attempt: Manual directory creation as fallback..."
            
            # Create the .taskmaster directory structure manually as last resort
            echo "📁 Creating .taskmaster directory structure manually..."
            mkdir -p .taskmaster/docs
            mkdir -p .taskmaster/tasks
            mkdir -p .taskmaster/reports
            mkdir -p .taskmaster/templates
            
            # Create config.json with granular model configuration
            cat > .taskmaster/config.json << EOF
    {
      "project": {
        "name": "$PROJECT_NAME",
        "description": "Auto-generated project from intake pipeline",
        "version": "0.1.0"
      },
      "models": {
        "main": {
          "provider": "$PRIMARY_PROVIDER",
          "modelId": "$PRIMARY_MODEL",
          "maxTokens": 64000,
          "temperature": 0.2
        },
        "research": {
          "provider": "$RESEARCH_PROVIDER",
          "modelId": "$RESEARCH_MODEL",
          "maxTokens": 32000,
          "temperature": 0.1
        },
        "fallback": {
          "provider": "$FALLBACK_PROVIDER",
          "modelId": "$FALLBACK_MODEL",
          "maxTokens": 8000,
          "temperature": 0.7
        }
      },
      "global": {
        "defaultTag": "master"
      }
    }
    EOF
            
            # Create empty tasks.json
            echo '{"tasks": []}' > .taskmaster/tasks/tasks.json
            
            echo "✅ Created .taskmaster directory structure manually"
        fi
    fi
    
    # Final check
    if [ ! -d ".taskmaster" ]; then
        echo "❌ Failed to create .taskmaster directory after all attempts"
        echo "📂 Final directory contents:"
        ls -la
        exit 1
    fi
    
    echo "✅ TaskMaster setup complete"
    echo "📂 Final .taskmaster contents:"
    ls -la .taskmaster/
    
    # Copy PRD and architecture files after initialization
    echo "📋 Copying PRD and architecture files..."
    # Ensure directories exist regardless of task-master version behavior
    mkdir -p .taskmaster/docs .taskmaster/tasks
    cp "$PRD_FILE" ".taskmaster/docs/prd.txt"
    if [ -f "$ARCH_FILE" ] && [ -s "$ARCH_FILE" ]; then
        cp "$ARCH_FILE" ".taskmaster/docs/architecture.md"
    fi
    
    # Configure models with Claude Code and GPT-5 fallback
    echo "🤖 Configuring AI models..."
    
    # Test if OpenAI API key is valid by making a simple API call
    OPENAI_VALID=false
    if [ -n "$OPENAI_API_KEY" ]; then
      echo "🔍 Testing OpenAI API key validity..."
      # Test the API key with a simple models call
      if curl -s -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "Content-Type: application/json" \
              "https://api.openai.com/v1/models" > /dev/null 2>&1; then
        echo "✅ OpenAI API key is valid"
        OPENAI_VALID=true
      else
        echo "⚠️ OpenAI API key is invalid or expired, falling back to Claude only"
        OPENAI_VALID=false
      fi
    fi
    
    # Check if ANTHROPIC_API_KEY is available for Claude Code
    if [ -z "$ANTHROPIC_API_KEY" ]; then
        echo "❌ ANTHROPIC_API_KEY is required for Claude Code but not set"
        exit 1
    fi
    
    # Configure Claude Code to use ANTHROPIC_API_KEY
    echo "🔧 Configuring Claude Code authentication..."
    # TaskMaster expects ANTHROPIC_API_KEY in environment, not config file
    # Export it to ensure it's available to child processes
    export ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY"
    
    # Also try to set up Claude Code config in case it's needed
    # Try to create config directory, fallback to /tmp if permission denied
    if mkdir -p ~/.config/claude-code 2>/dev/null; then
        CONFIG_DIR=~/.config/claude-code
        echo "✅ Using user config directory: $CONFIG_DIR"
    else
        CONFIG_DIR=/tmp/claude-code-config
        mkdir -p $CONFIG_DIR
        echo "⚠️ Permission denied for user config, using temp directory: $CONFIG_DIR"
        # Set environment variable so Claude Code knows where to find config
        export CLAUDE_CONFIG_DIR="$CONFIG_DIR"
    fi
    
    cat > $CONFIG_DIR/config.json << EOF
    {
      "apiKey": "$ANTHROPIC_API_KEY"
    }
    EOF
    
    # Debug: Verify API key is set
    echo "🔍 DEBUG: ANTHROPIC_API_KEY is ${ANTHROPIC_API_KEY:+[SET]}${ANTHROPIC_API_KEY:-[NOT SET]}"
    
    # Set up dynamic provider selection for different operations
    echo "✅ Configuring TaskMaster models: Primary=$PRIMARY_MODEL, Research=$RESEARCH_MODEL, Fallback=$FALLBACK_MODEL"
    
    # Enable codebase analysis for research operations
    export TASKMASTER_ENABLE_CODEBASE_ANALYSIS=true
    
    if [ "$OPENAI_VALID" = true ]; then
      cat > .taskmaster/config.json << EOF
    {
      "project": {
        "name": "$PROJECT_NAME",
        "description": "Auto-generated project from intake pipeline",
        "version": "0.1.0"
      },
      "models": {
        "main": {
          "provider": "$PRIMARY_PROVIDER",
          "modelId": "$PRIMARY_MODEL",
          "maxTokens": 64000,
          "temperature": 0.2
        },
        "research": {
          "provider": "$RESEARCH_PROVIDER",
          "modelId": "$RESEARCH_MODEL",
          "maxTokens": 32000,
          "temperature": 0.1
        },
        "fallback": {
          "provider": "$FALLBACK_PROVIDER",
          "modelId": "$FALLBACK_MODEL",
          "maxTokens": 8000,
          "temperature": 0.7
        }
      },
      "global": {
        "defaultTag": "master"
      }
    }
    EOF
    else
      # Use configured providers for main/research, but no fallback if OpenAI unavailable
      echo "⚠️ OpenAI API key invalid/missing, configuring without OpenAI fallback"
      cat > .taskmaster/config.json << EOF
    {
      "project": {
        "name": "$PROJECT_NAME",
        "description": "Auto-generated project from intake pipeline",
        "version": "0.1.0"
      },
      "models": {
        "main": {
          "provider": "$PRIMARY_PROVIDER",
          "modelId": "$PRIMARY_MODEL",
          "maxTokens": 64000,
          "temperature": 0.2
        },
        "research": {
          "provider": "$RESEARCH_PROVIDER",
          "modelId": "$RESEARCH_MODEL",
          "maxTokens": 32000,
          "temperature": 0.1
        },
        "fallback": {
          "provider": "$FALLBACK_PROVIDER",
          "modelId": "$FALLBACK_MODEL",
          "maxTokens": 8000,
          "temperature": 0.7
        }
      },
      "global": {
        "defaultTag": "master"
      }
    }
    EOF
    fi
    
    echo "✅ Claude Code configuration written"
    
    # Debug: Show what TaskMaster config was written
    echo "🔍 DEBUG: TaskMaster config contents:"
    cat .taskmaster/config.json | jq '.' || echo "Failed to display config"
    
    # Parse PRD with research model for better analysis
    echo "📄 Parsing PRD to generate tasks with Research model: $RESEARCH_MODEL ($RESEARCH_PROVIDER)..."
    # Debug: Check if claude command is available (for claude-code provider)
    if [ "$PRIMARY_PROVIDER" = "claude-code" ] || [ "$RESEARCH_PROVIDER" = "claude-code" ]; then
        echo "🔍 DEBUG: Checking claude-code availability..."
        which claude || echo "⚠️ claude command not found in PATH"
        echo "🔍 DEBUG: PATH=$PATH"
    fi
    # Use --research flag to use the configured research model
    task-master parse-prd \
        --input ".taskmaster/docs/prd.txt" \
        --force \
        --research || {
        echo "❌ Failed to parse PRD"
        exit 1
    }
    
    # Resolve tasks.json path (use default, fallback to discovery)
    TASKS_FILE=".taskmaster/tasks/tasks.json"
    if [ ! -f "$TASKS_FILE" ]; then
        ALT_TASKS_FILE=$(find .taskmaster -maxdepth 2 -name tasks.json | head -n 1 || true)
        if [ -n "$ALT_TASKS_FILE" ] && [ -f "$ALT_TASKS_FILE" ]; then
            TASKS_FILE="$ALT_TASKS_FILE"
        else
            echo "❌ tasks.json not found after parse"
            exit 1
        fi
    fi
    
    # Analyze complexity if requested
    if [ "$ANALYZE_COMPLEXITY" = "true" ]; then
        echo "🔍 Analyzing task complexity..."
        mkdir -p .taskmaster/reports
        task-master analyze-complexity --file "$TASKS_FILE" || {
            echo "❌ analyze-complexity failed"
            exit 1
        }
    fi
    
    # Expand tasks if requested (switch to regular Claude API for faster expansion)
    if [ "$EXPAND_TASKS" = "true" ]; then
        echo "🌳 Expanding tasks with subtasks using Claude API..."
    
        # Switch ONLY the main provider to regular Claude API for faster expansion
        # Keep research with Claude Code for any research operations
        if [ "$OPENAI_VALID" = true ]; then
            # Read current config and update only the main provider
            if [ -f ".taskmaster/config.json" ]; then
                # Use jq to update only the main provider in the existing config
                jq --arg provider "$PRIMARY_PROVIDER" --arg model "$PRIMARY_MODEL" '.models.main = {
                    "provider": $provider,
                    "modelId": $model,
                    "maxTokens": 64000,
                    "temperature": 0.2
                }' .taskmaster/config.json > .taskmaster/config_temp.json && mv .taskmaster/config_temp.json .taskmaster/config.json
                echo "✅ Updated main provider to $PRIMARY_PROVIDER ($PRIMARY_MODEL), kept research with $RESEARCH_PROVIDER"
            else
                echo "⚠️ Config file not found, using default Claude API config"
                cat > .taskmaster/config.json << EOF
    {
      "project": {
        "name": "$PROJECT_NAME",
        "description": "Auto-generated project from intake pipeline",
        "version": "0.1.0"
      },
      "models": {
        "main": {
          "provider": "$PRIMARY_PROVIDER",
          "modelId": "$PRIMARY_MODEL",
          "maxTokens": 64000,
          "temperature": 0.2
        },
        "research": {
          "provider": "$RESEARCH_PROVIDER",
          "modelId": "$RESEARCH_MODEL",
          "maxTokens": 32000,
          "temperature": 0.1
        },
        "fallback": {
          "provider": "$FALLBACK_PROVIDER",
          "modelId": "$FALLBACK_MODEL",
          "maxTokens": 8000,
          "temperature": 0.7
        }
      },
      "global": {
        "defaultTag": "master"
      }
    }
    EOF
            fi
        fi
    
        task-master expand --all --force --file "$TASKS_FILE" || {
            echo "❌ expand failed"
            exit 1
        }
    fi
    
    # Review and align tasks with architecture using Claude
    echo "🤖 Reviewing tasks against architecture with Claude..."
    if [ -f ".taskmaster/docs/architecture.md" ]; then
        # Check if claude command is available
        if command -v claude &> /dev/null; then
            echo "✅ Claude command found"
            
            # Create a prompt for Claude to review tasks
            cat > /tmp/review-prompt.md <<'EOF'
    Please review the tasks.json file against the architecture.md document and ensure they are properly aligned.
    
    Your task is to:
    1. Cross-reference all tasks in tasks.json with the architecture diagram
    2. Identify any missing tasks that are implied by the architecture
    3. Identify any tasks that don't align with the architecture
    4. Update, add, or remove tasks as needed to ensure full alignment
    
    Important:
    - Make direct edits to the tasks.json file
    - Ensure all architectural components have corresponding tasks
    - Ensure task dependencies match the architectural flow
    - Preserve the existing task structure and IDs where possible
    - Add clear details and implementation notes based on the architecture
    
    Files to review:
    - .taskmaster/tasks/tasks.json (the task list)
    - .taskmaster/docs/architecture.md (the architecture reference)
    
    Make the necessary modifications directly to ensure the tasks and architecture are fully aligned.
    EOF
    
            # Run Claude Code to review and update tasks
            echo "🔍 Running Claude Code review..."
            # Set Claude config directory
            export CLAUDE_CONFIG_DIR="$CONFIG_DIR"
            if [ -s "/tmp/review-prompt.md" ]; then
              echo "📝 Processing review prompt with Claude Code..."
              # Claude Code uses simpler command line arguments
              timeout 300 claude --model "$MODEL" < /tmp/review-prompt.md > /tmp/claude-output.json 2>/tmp/claude-error.log || {
                  echo "⚠️ Claude Code review failed (exit code: $?), but continuing..."
                  echo "Error log:" && cat /tmp/claude-error.log 2>/dev/null || echo "No error log available"
              }
              # Check if we got a valid response
              if [ -s "/tmp/claude-output.json" ]; then
                  echo "✅ Claude Code review completed successfully"
              else
                  echo "⚠️ Claude Code review produced no output"
              fi
            else
              echo "⚠️ Review prompt file missing or empty; skipping Claude Code review"
            fi
            
            echo "✅ Task review complete"
        else
            echo "⚠️ Claude command not found, skipping architecture alignment"
        fi
    else
        echo "⚠️ No architecture.md file found, skipping architecture alignment"
    fi
    
    # Generate task files
    echo "📝 Generating individual task files..."
    task-master generate
    
    # Create summary file
    echo "📊 Creating project summary..."
    cat > README.md <<EOF
    # $PROJECT_NAME
    
    Auto-generated project from intake pipeline.
    
    ## Project Structure
    
    - **.taskmaster/** - TaskMaster configuration and tasks
      - **docs/** - Source documents (PRD, architecture)
      - **tasks/** - Generated task definitions
    - **docs/** - Individual task documentation
    
    ## Getting Started
    
    1. Review the generated tasks in \`.taskmaster/tasks/tasks.json\`
    2. Use \`task-master list\` to view all tasks
    3. Use \`task-master next\` to get the next task to work on
    4. Implement tasks using the orchestrator workflow
    
    ## Generated Statistics
    
    - Total tasks: $(jq '.tasks | length' .taskmaster/tasks/tasks.json 2>/dev/null || echo "N/A")
    - Model used: $MODEL
    - Generated on: $(date)
    
    ## Source Documents
    
    - [Product Requirements](/.taskmaster/docs/prd.txt)
    $([ -f ".taskmaster/docs/architecture.md" ] && echo "- [Architecture](/.taskmaster/docs/architecture.md)")
    EOF
    
    # Commit changes
    echo "💾 Committing project structure..."
    cd "$CLONE_DIR"
    git add -A
    git commit -m "feat: initialize project $PROJECT_NAME
    
    - Automated project intake via orchestrator
    - Parsed PRD and architecture documents
    - Generated TaskMaster task breakdown
    - Created standardized project structure
    - Set up CI/CD workflows and templates
    
    🤖 Auto-generated by project intake workflow"
    - Model: $MODEL
    - Tasks: $NUM_TASKS targets
    $([ "$EXPAND_TASKS" = "true" ] && echo "- Expanded with subtasks")
    $([ "$ANALYZE_COMPLEXITY" = "true" ] && echo "- Complexity analysis performed")
    "
    
    # Create branch and push
    # Use a hyphenated prefix to avoid collisions when a flat ref named 'intake' exists remotely
    # Also prefer the sanitized, lowercase project directory name for the branch component
    BRANCH_NAME="intake-${PROJECT_DIR_NAME}-$(date +%Y%m%d-%H%M%S)"
    echo "🌿 Creating branch: $BRANCH_NAME"
    git checkout -b "$BRANCH_NAME"
    git push -u origin "$BRANCH_NAME"
    
    # Create pull request
    echo "🔀 Creating pull request..."
    PR_BODY="## 🎉 Project Intake: $PROJECT_NAME
    
    This PR contains the auto-generated project structure and tasks.
    
    ### 📋 What was processed:
    - ✅ PRD document parsed
    $([ -f "$PROJECT_DIR/.taskmaster/docs/architecture.md" ] && echo "- ✅ Architecture document included")
    - ✅ TaskMaster initialized
    - ✅ Tasks generated (target: $NUM_TASKS)
    $([ "$ANALYZE_COMPLEXITY" = "true" ] && echo "- ✅ Complexity analysis performed")
    $([ "$EXPAND_TASKS" = "true" ] && echo "- ✅ Tasks expanded with subtasks")
    - ✅ Project structure created
    
    ### 🏗️ Generated Structure:
    \`\`\`
    $PROJECT_DIR/
    ├── .taskmaster/
    │   ├── docs/
    │   │   ├── prd.txt
    │   │   └── architecture.md
    │   ├── tasks/
    │   │   └── tasks.json
    │   └── config.json
    ├── docs/
    │   ├── task-1/
    │   │   └── task.md
    │   └── ...
    └── README.md
    \`\`\`
    
    ### 🤖 Configuration:
    - **Model**: $MODEL
    - **Tasks Generated**: $(jq '.tasks | length' "$PROJECT_DIR/.taskmaster/tasks/tasks.json" 2>/dev/null || echo "N/A")
    - **Complexity Analysis**: $ANALYZE_COMPLEXITY
    - **Task Expansion**: $EXPAND_TASKS
    
    ### 🎯 Next Steps:
    1. Review the generated tasks
    2. Merge this PR to add the project
    3. Use orchestrator workflows to implement tasks
    "
    
    # Refresh GitHub token before PR creation
    if [ -n "$GITHUB_APP_PRIVATE_KEY" ]; then
        echo "🔄 Refreshing GitHub token for PR creation..."
        generate_github_token
    fi
    
    gh pr create \
        --title "🚀 Project Intake: $PROJECT_NAME" \
        --body "$PR_BODY" \
        --head "$BRANCH_NAME" \
        --base main || {
            echo "⚠️ Failed to create PR, but branch has been pushed"
            echo "Branch: $BRANCH_NAME"
            echo "You can create the PR manually"
        }
    
    echo "✅ Project intake complete!"
    echo "================================="
    echo "Project: $PROJECT_NAME"
    echo "Location: $PROJECT_DIR"
    echo "Branch: $BRANCH_NAME"
    echo "Repository: $REPOSITORY_URL"
